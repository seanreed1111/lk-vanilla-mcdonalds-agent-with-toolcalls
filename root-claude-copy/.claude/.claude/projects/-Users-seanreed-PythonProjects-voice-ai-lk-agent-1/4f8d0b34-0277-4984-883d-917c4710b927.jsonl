{"type":"file-history-snapshot","messageId":"ac1ff87f-25fa-45dc-8ad0-250568338495","snapshot":{"messageId":"ac1ff87f-25fa-45dc-8ad0-250568338495","trackedFileBackups":{},"timestamp":"2026-01-25T09:44:20.011Z"},"isSnapshotUpdate":false}
{"parentUuid":null,"isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","type":"user","message":{"role":"user","content":"please update plans and summary in plan/future-plans/ to specify that no user video or screenshare permissions should be requested. this is an audio-only app."},"uuid":"ac1ff87f-25fa-45dc-8ad0-250568338495","timestamp":"2026-01-25T09:44:20.006Z","thinkingMetadata":{"maxThinkingTokens":31999},"todos":[],"permissionMode":"default"}
{"parentUuid":"ac1ff87f-25fa-45dc-8ad0-250568338495","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_012tGjhtuuZdJz1uhjPj5rgj","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"The user is asking me to update plans and summary in the `plan/future-plans/` directory to specify that no user video or screenshare permissions should be requested since this is an audio-only app.\n\nThis is an action request - they want me to make changes to files. Let me:\n1. First, explore what's in the `plan/future-plans/` directory\n2. Read the relevant files\n3. Update them to specify that video/screenshare permissions should not be requested\n\nLet me start by seeing what files are in that directory.","signature":"Ep8FCkYICxgCKkAWJDavOZfRDu4d1zh/YeXHIp5ytw5N863ofdYet8emPKd3CKn2lb4f0csc9HmuoxK4vxIMBls0fuJI+q5xn/4/Egy/55xuscWSDZwOHpEaDPOt+NzSO/AWHcxzsyIwnAAVYNjvPEtiFmhPf8SYu03wYYoI9CyjUGy+mjLAf/whay+rWraZROzFOU0ig/b2KoYEOky1DqyMfM6xkf8hFa6h5zqxxtciI9gQcy1icw701X5e4UkUfBNIY8tTHp0F7iVorPUzsc37APQ6YfnS2PsWbFPOYoVnA1nMeD9dX51L9OwGhqDe9ZRVyDsP7Ztu++kKmzsw33OxbVUumo2nkQy/+A/rIkA+gQT3jX5OS3pv3Beu2Y7sfWPszkFzIOrRxE/yoo61qDuOFIVrfSCrWiLHJsmd4+sVXTFC8GkZHxs7aEvh51McZZGRybhLvET2lzCUQrPXSW4hKXdfHrniFPuWcm8dvt2bHxSFv95YcSicUhryhz6KJqfmAHQFEnEhSoB0A7v3SSKYciRcJjkt7SSELAd3UcvETFXpq0QaHm8LpSAkcK4CLLDyMJTwoyHP8/1DKMRWXNCnhF6zvD6yu2qF3q5Owo7B5ZMesEt37KAbtBOMMlFm4roXQYu4tUT6U95xTe7fvIUMsXo0O2XyDQzs2mF/ZqdAxIaleT19BPip1fsQpGzW7hekky3OBTIl7Ns482u6Oz5KS5UG7QjhgfIq2hvJ1M0szxAnOluhJ4DOnxDTsxo1V7jwSQOkN9lZDOICKKw/MyRGmvgh7UMAI95hQziAMLmzl6621GhbgXMi3yhC1owCrOZ4Hy0T6zLKA1bznubnrCeipQCrAyh7R7uyZw9hLlUhXz/NOogsSgE+/mxCECexqo0YAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":10,"cache_creation_input_tokens":27388,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":27388,"ephemeral_1h_input_tokens":0},"output_tokens":8,"service_tier":"standard"}},"requestId":"req_011CXTt2ZntdknrZ7QWYEkZ5","type":"assistant","uuid":"33b5be46-210e-4c22-9a69-b99bb662ead2","timestamp":"2026-01-25T09:44:24.513Z"}
{"parentUuid":"33b5be46-210e-4c22-9a69-b99bb662ead2","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_012tGjhtuuZdJz1uhjPj5rgj","type":"message","role":"assistant","content":[{"type":"text","text":"I'll update the plans and summary in the `plan/future-plans/` directory to specify that this is an audio-only app and no video/screenshare permissions should be requested.\n\nLet me first check what files are in that directory."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":10,"cache_creation_input_tokens":27388,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":27388,"ephemeral_1h_input_tokens":0},"output_tokens":8,"service_tier":"standard"}},"requestId":"req_011CXTt2ZntdknrZ7QWYEkZ5","type":"assistant","uuid":"e9dbbe00-6943-4459-a619-be33682285db","timestamp":"2026-01-25T09:44:25.536Z"}
{"parentUuid":"e9dbbe00-6943-4459-a619-be33682285db","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_012tGjhtuuZdJz1uhjPj5rgj","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01R8Gtd9B1hKKnybVnJ3D7f8","name":"Bash","input":{"command":"ls -la plan/future-plans/","description":"List files in plan/future-plans directory"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":10,"cache_creation_input_tokens":27388,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":27388,"ephemeral_1h_input_tokens":0},"output_tokens":8,"service_tier":"standard"}},"requestId":"req_011CXTt2ZntdknrZ7QWYEkZ5","type":"assistant","uuid":"5d143047-e54f-4094-836a-27badc332424","timestamp":"2026-01-25T09:44:26.151Z"}
{"parentUuid":"5d143047-e54f-4094-836a-27badc332424","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01R8Gtd9B1hKKnybVnJ3D7f8","type":"tool_result","content":"total 176\ndrwxr-xr-x@ 4 seanreed  staff    128 Jan 25 04:15 .\ndrwxr-xr-x@ 5 seanreed  staff    160 Jan 24 20:37 ..\n-rw-r--r--@ 1 seanreed  staff  64654 Jan 25 04:13 2026-01-25-web-frontend-deployment.md\n-rw-r--r--@ 1 seanreed  staff  22091 Jan 25 04:15 2026-01-25-web-frontend-options-summary.md","is_error":false}]},"uuid":"73d2ff5e-856b-43b7-89ab-805565af5134","timestamp":"2026-01-25T09:44:26.288Z","toolUseResult":{"stdout":"total 176\ndrwxr-xr-x@ 4 seanreed  staff    128 Jan 25 04:15 .\ndrwxr-xr-x@ 5 seanreed  staff    160 Jan 24 20:37 ..\n-rw-r--r--@ 1 seanreed  staff  64654 Jan 25 04:13 2026-01-25-web-frontend-deployment.md\n-rw-r--r--@ 1 seanreed  staff  22091 Jan 25 04:15 2026-01-25-web-frontend-options-summary.md","stderr":"","interrupted":false,"isImage":false},"sourceToolAssistantUUID":"5d143047-e54f-4094-836a-27badc332424"}
{"parentUuid":"73d2ff5e-856b-43b7-89ab-805565af5134","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01FtsoJLsaSvKcLaFC7NfWH1","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Good, there are two files in the directory. Let me read both of them to understand their content and identify where I need to add the audio-only specification.","signature":"EsgCCkYICxgCKkD4OH/5zCIc4xmtbBwiC1aEWT+5tk+nqms1rHn7+1TzP/5JA7tGZAMXSWukbjqQuGP4LqImb8rV2onhSkpYyIWjEgzctnFEdubs4fDetZQaDHuuI+205trhkPzrviIw+OqEolu8xDlfPwVk0v1cYjiU1z+rQdfzVXvOPgacvoGwo4ZbYEuu5K0ovHJscXMfKq8B7yUbKMw7ww2Xjb1TlbQVlnjS1GkGjJIUaMZAUwGlX0JaP0vcjluGsF2N63IRoDjtSMUYB6lyc8ehHdSPLi+9VSnBhBhdtDgn7NhUjL6lbU5l2vuIyA+MYD37weq9hfUzeJQHlMHew5EPZhLaZSW5p2rYuuX9gdJ6eQWYGtrX1ecPXJhSuWRLZPY3VT8XazpdxJwuSoaHkzbb81MfYqQF6K29hHnPD7BEwhZ0fjYyChgB"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":13,"cache_creation_input_tokens":438,"cache_read_input_tokens":27388,"cache_creation":{"ephemeral_5m_input_tokens":438,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXTt31tXg5d1p8s81RDv9","type":"assistant","uuid":"c0ee8c49-4b59-49e3-b98b-3acf68935468","timestamp":"2026-01-25T09:44:29.913Z"}
{"parentUuid":"c0ee8c49-4b59-49e3-b98b-3acf68935468","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01FtsoJLsaSvKcLaFC7NfWH1","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01G4xKdJhLaRV7watjRGnEsu","name":"Read","input":{"file_path":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/plan/future-plans/2026-01-25-web-frontend-options-summary.md"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":13,"cache_creation_input_tokens":438,"cache_read_input_tokens":27388,"cache_creation":{"ephemeral_5m_input_tokens":438,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXTt31tXg5d1p8s81RDv9","type":"assistant","uuid":"8b7e853d-81a3-4d42-b034-a796e165315d","timestamp":"2026-01-25T09:44:31.270Z"}
{"parentUuid":"8b7e853d-81a3-4d42-b034-a796e165315d","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01FtsoJLsaSvKcLaFC7NfWH1","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01XCbLktmrMFcR8xzFpg4reD","name":"Read","input":{"file_path":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/plan/future-plans/2026-01-25-web-frontend-deployment.md"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":13,"cache_creation_input_tokens":438,"cache_read_input_tokens":27388,"cache_creation":{"ephemeral_5m_input_tokens":438,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXTt31tXg5d1p8s81RDv9","type":"assistant","uuid":"7eda4b89-34c2-4b4b-8c0b-75a47fb1e181","timestamp":"2026-01-25T09:44:31.815Z"}
{"parentUuid":"8b7e853d-81a3-4d42-b034-a796e165315d","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","slug":"enumerated-shimmying-starlight","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01G4xKdJhLaRV7watjRGnEsu","type":"tool_result","content":"     1→# Web Frontend Options for LiveKit Voice AI Agent - Research Summary\n     2→\n     3→**Date:** 2026-01-25\n     4→**Purpose:** Document TypeScript/JavaScript options for enabling web-based client interaction with deployed LiveKit agent\n     5→\n     6→---\n     7→\n     8→## Executive Summary\n     9→\n    10→LiveKit provides multiple JavaScript/TypeScript solutions for building web frontends that connect users to voice AI agents. The recommended approach is **agent-starter-react**, a production-ready Next.js template that includes all necessary components:\n    11→\n    12→- JWT token generation (server-side for security)\n    13→- WebRTC connection management via `livekit-client` SDK\n    14→- Voice assistant UI components (`@livekit/components-react`)\n    15→- Audio visualization and agent state tracking\n    16→- Automatic agent dispatch when users connect\n    17→\n    18→**Timeline:** 6-8 hours for complete deployment (agent + frontend + customization)\n    19→**Cost:** $0.01 per agent session minute (LiveKit Cloud) + Free (Vercel frontend hosting)\n    20→\n    21→---\n    22→\n    23→## Option 1: agent-starter-react (Recommended)\n    24→\n    25→### Overview\n    26→Official Next.js/React template from LiveKit with production-ready voice AI interface.\n    27→\n    28→### Repository\n    29→**GitHub:** https://github.com/livekit-examples/agent-starter-react\n    30→\n    31→### Tech Stack\n    32→- Next.js 14+ (App Router)\n    33→- React 18+ with TypeScript\n    34→- Tailwind CSS + Shadcn/ui components\n    35→- `livekit-client` SDK (WebRTC)\n    36→- `@livekit/components-react` (UI components)\n    37→- `livekit-server-sdk` (token generation)\n    38→\n    39→### Key Features\n    40→✓ Token generation API route (`/api/token`)\n    41→✓ `useVoiceAssistant` React hook for agent state\n    42→✓ Audio visualizer (`BarVisualizer`)\n    43→✓ Camera video and screen sharing support\n    44→✓ Light/dark theme with system preference\n    45→✓ Customizable branding via `app-config.ts`\n    46→✓ Mobile-responsive design\n    47→✓ Production-ready architecture\n    48→\n    49→### Setup Process\n    50→```bash\n    51→# Install via LiveKit CLI\n    52→lk app create --template agent-starter-react\n    53→cd voice-ai-frontend\n    54→pnpm install\n    55→\n    56→# Configure environment\n    57→cp .env.example .env.local\n    58→# Add: LIVEKIT_API_KEY, LIVEKIT_API_SECRET, LIVEKIT_URL\n    59→\n    60→# Run development server\n    61→pnpm dev\n    62→# Visit http://localhost:3000\n    63→```\n    64→\n    65→### Customization\n    66→**Easy to customize:**\n    67→- Company name and branding (app-config.ts)\n    68→- Logo and colors\n    69→- Welcome message and instructions\n    70→- Feature toggles (video, screen share, chat)\n    71→- Theme colors (Tailwind CSS)\n    72→\n    73→### Deployment\n    74→- **Recommended:** Vercel (free tier)\n    75→- **Alternatives:** Netlify, AWS Amplify, Cloudflare Pages\n    76→- **Build time:** ~2-5 minutes\n    77→- **Automatic deployments:** Via Git integration\n    78→\n    79→### Best For\n    80→- Production websites with custom branding\n    81→- Full feature control\n    82→- Professional, polished user experience\n    83→- Organizations needing customization\n    84→\n    85→### Pros\n    86→✓ Official template, actively maintained\n    87→✓ Production-ready out of the box\n    88→✓ Excellent documentation\n    89→✓ Easy customization\n    90→✓ Vercel deployment = free hosting\n    91→✓ TypeScript for type safety\n    92→✓ Modern UI with Shadcn/ui\n    93→\n    94→### Cons\n    95→✗ Requires some React/Next.js knowledge for customization\n    96→✗ Larger initial download (Next.js framework)\n    97→✗ More complex than simple embed\n    98→\n    99→---\n   100→\n   101→## Option 2: agent-starter-embed (Embeddable Widget)\n   102→\n   103→### Overview\n   104→Embeddable widget for adding voice AI to existing websites without major changes.\n   105→\n   106→### Repository\n   107→**GitHub:** https://github.com/livekit-examples/agent-starter-embed\n   108→\n   109→### Tech Stack\n   110→- Next.js with TypeScript\n   111→- Bundled JavaScript widget\n   112→- Same core LiveKit SDKs as agent-starter-react\n   113→\n   114→### Key Features\n   115→✓ Embeddable via `<script>` tag\n   116→✓ Popup-style or inline widget\n   117→✓ Minimal integration effort\n   118→✓ Same features as agent-starter-react\n   119→✓ Customizable appearance\n   120→\n   121→### Setup Process\n   122→```bash\n   123→git clone https://github.com/livekit-examples/agent-starter-embed.git\n   124→cd agent-starter-embed\n   125→pnpm install\n   126→pnpm build-embed-popup-script\n   127→pnpm dev\n   128→```\n   129→\n   130→### Integration\n   131→```html\n   132→<!-- Add to any website -->\n   133→<div id=\"livekit-agent\"></div>\n   134→<script src=\"https://your-cdn.com/embed-popup.js\"></script>\n   135→<script>\n   136→  LiveKitAgent.init({\n   137→    container: '#livekit-agent',\n   138→    tokenUrl: 'https://your-backend.com/api/token',\n   139→    theme: 'dark',\n   140→    position: 'bottom-right'\n   141→  });\n   142→</script>\n   143→```\n   144→\n   145→### Best For\n   146→- Adding voice AI to existing websites\n   147→- Minimal code changes required\n   148→- Quick implementation\n   149→- Embedded customer support agents\n   150→\n   151→### Pros\n   152→✓ Easy integration (just add script tag)\n   153→✓ No major site changes needed\n   154→✓ Works with any website/CMS\n   155→✓ Can be positioned anywhere (floating, inline)\n   156→\n   157→### Cons\n   158→✗ Less customization than full React app\n   159→✗ Still requires backend for token generation\n   160→✗ Limited control over widget internals\n   161→\n   162→---\n   163→\n   164→## Option 3: Custom Build with LiveKit SDKs\n   165→\n   166→### Overview\n   167→Build from scratch using core LiveKit packages for maximum customization.\n   168→\n   169→### NPM Packages\n   170→\n   171→**Client SDK:**\n   172→```bash\n   173→npm install livekit-client\n   174→```\n   175→- **Package:** `livekit-client` (v2.17.0+)\n   176→- **Purpose:** WebRTC client for browser\n   177→- **Docs:** https://docs.livekit.io/reference/client-sdk-js/\n   178→\n   179→**React Components:**\n   180→```bash\n   181→npm install @livekit/components-react @livekit/components-styles\n   182→```\n   183→- **Package:** `@livekit/components-react`\n   184→- **Purpose:** Pre-built React UI components\n   185→- **Key Exports:** `useVoiceAssistant`, `BarVisualizer`, `VoiceAssistantControlBar`\n   186→- **Docs:** https://docs.livekit.io/reference/components/react/\n   187→\n   188→**Server SDK (Backend):**\n   189→```bash\n   190→npm install livekit-server-sdk\n   191→```\n   192→- **Package:** `livekit-server-sdk` (v2.15.0+)\n   193→- **Purpose:** Token generation (server-side only)\n   194→- **Docs:** https://docs.livekit.io/reference/server-sdk-js/\n   195→\n   196→### Minimal Example\n   197→\n   198→**Frontend (React):**\n   199→```typescript\n   200→import { useVoiceAssistant, BarVisualizer } from '@livekit/components-react';\n   201→import '@livekit/components-styles';\n   202→\n   203→function VoiceAgent() {\n   204→  const { state, audioTrack } = useVoiceAssistant();\n   205→  // state: 'initializing' | 'listening' | 'thinking' | 'speaking'\n   206→\n   207→  return (\n   208→    <div>\n   209→      <p>Agent is {state}</p>\n   210→      <BarVisualizer state={state} audioTrack={audioTrack} />\n   211→      <button onClick={connect}>Connect</button>\n   212→    </div>\n   213→  );\n   214→}\n   215→```\n   216→\n   217→**Backend (Next.js API Route):**\n   218→```typescript\n   219→import { AccessToken } from 'livekit-server-sdk';\n   220→\n   221→export async function POST(req: Request) {\n   222→  const { roomName, participantName } = await req.json();\n   223→\n   224→  const token = new AccessToken(\n   225→    process.env.LIVEKIT_API_KEY,\n   226→    process.env.LIVEKIT_API_SECRET,\n   227→    { identity: participantName, ttl: '2h' }\n   228→  );\n   229→\n   230→  token.addGrant({\n   231→    room: roomName,\n   232→    roomJoin: true,\n   233→    canPublish: true,\n   234→    canSubscribe: true,\n   235→  });\n   236→\n   237→  return Response.json({ token: await token.toJwt() });\n   238→}\n   239→```\n   240→\n   241→### Best For\n   242→- Integrating into existing React applications\n   243→- Maximum customization control\n   244→- Unique UI/UX requirements\n   245→- Developers comfortable with WebRTC\n   246→\n   247→### Pros\n   248→✓ Complete control over every aspect\n   249→✓ Smaller bundle size (only what you need)\n   250→✓ Deep integration with existing app\n   251→✓ No template overhead\n   252→\n   253→### Cons\n   254→✗ Requires understanding of LiveKit concepts\n   255→✗ More time to build from scratch\n   256→✗ Need to handle edge cases yourself\n   257→✗ More maintenance burden\n   258→\n   259→---\n   260→\n   261→## Option 4: LiveKit Agents Playground (Quick Testing)\n   262→\n   263→### Overview\n   264→Zero-code web interface for instantly testing deployed agents.\n   265→\n   266→### Access\n   267→**URL:** https://agents-playground.livekit.io/\n   268→\n   269→### Use Case\n   270→- Quick testing of deployed agents\n   271→- No frontend setup required\n   272→- Demo to stakeholders\n   273→- Debugging agent behavior\n   274→\n   275→### How to Use\n   276→1. Visit https://agents-playground.livekit.io/\n   277→2. Enter LiveKit credentials:\n   278→   - LiveKit URL: `wss://your-project.livekit.cloud`\n   279→   - API Key: Your `LIVEKIT_API_KEY`\n   280→   - API Secret: Your `LIVEKIT_API_SECRET`\n   281→3. Click \"Connect\"\n   282→4. Speak to your agent\n   283→\n   284→### Best For\n   285→- Testing before building frontend\n   286→- Internal demos\n   287→- Debugging agent issues\n   288→- Validating deployment\n   289→\n   290→### Pros\n   291→✓ Zero setup required\n   292→✓ Instant testing\n   293→✓ No code needed\n   294→✓ Audio visualization included\n   295→\n   296→### Cons\n   297→✗ Not for end users (exposes API secrets)\n   298→✗ No customization\n   299→✗ Not production-ready\n   300→✗ Requires credentials each time\n   301→\n   302→---\n   303→\n   304→## Connection Flow Architecture\n   305→\n   306→### Standard Flow\n   307→\n   308→```\n   309→┌─────────────────────────────────────────────────────────────┐\n   310→│                      WEBSITE (FRONTEND)                     │\n   311→│  ┌─────────────────┐         ┌─────────────────┐           │\n   312→│  │   React/Next    │────────▶│  Token Server   │           │\n   313→│  │   (Browser)     │  fetch  │  (Node.js API)  │           │\n   314→│  └────────┬────────┘  token  └────────┬────────┘           │\n   315→│           │                           │                     │\n   316→│           │ WebRTC                    │ livekit-server-sdk  │\n   317→│           │ (audio)                   │ (JWT generation)    │\n   318→└───────────┼───────────────────────────┼─────────────────────┘\n   319→            │                           │\n   320→            ▼                           ▼\n   321→┌─────────────────────────────────────────────────────────────┐\n   322→│                    LIVEKIT CLOUD                            │\n   323→│  ┌─────────────────┐         ┌─────────────────┐           │\n   324→│  │  LiveKit Room   │◀────────│  Your Agent     │           │\n   325→│  │  (WebRTC SFU)   │  audio  │  (Python)       │           │\n   326→│  └─────────────────┘         └─────────────────┘           │\n   327→│                                                             │\n   328→│  Auto-dispatch agent when user joins room                  │\n   329→└─────────────────────────────────────────────────────────────┘\n   330→```\n   331→\n   332→### Connection Sequence\n   333→\n   334→1. **User clicks \"Connect\"** on website\n   335→2. **Frontend requests token** from `/api/token` endpoint (500ms)\n   336→3. **Backend generates JWT** using `livekit-server-sdk` (50ms)\n   337→4. **Frontend connects to LiveKit room** with token (1000ms)\n   338→5. **Agent automatically dispatched** to room (1000ms)\n   339→6. **Agent connects** and publishes audio track (1500ms)\n   340→7. **WebRTC media flow established** between user and agent\n   341→\n   342→**Total Time:** ~4 seconds (standard) → ~1.5 seconds (optimized)\n   343→\n   344→### Optimization Techniques\n   345→\n   346→**1. Pre-generate Tokens (Warm Token):**\n   347→- Generate token on page load\n   348→- Store for immediate use when \"Connect\" clicked\n   349→- Saves ~500ms\n   350→\n   351→**2. Concurrent Dispatch:**\n   352→- Connect user and dispatch agent in parallel\n   353→- Saves ~1000ms\n   354→\n   355→**3. Pre-connect Buffer:**\n   356→- Enable in `app-config.ts`\n   357→- Reduces perceived latency\n   358→\n   359→---\n   360→\n   361→## Authentication Deep Dive\n   362→\n   363→### JWT Token Structure\n   364→\n   365→**Token Payload Example:**\n   366→```json\n   367→{\n   368→  \"exp\": 1234567890,           // Expiration timestamp\n   369→  \"iss\": \"APIxxxxxxxxxxxx\",    // API Key (issuer)\n   370→  \"sub\": \"user-identity\",       // Participant identity\n   371→  \"nbf\": 1234567890,           // Not before timestamp\n   372→  \"video\": {\n   373→    \"room\": \"room-name\",        // Room name\n   374→    \"roomJoin\": true,           // Can join room\n   375→    \"canPublish\": true,         // Can publish tracks\n   376→    \"canSubscribe\": true,       // Can subscribe to tracks\n   377→    \"canPublishData\": true      // Can send data messages\n   378→  },\n   379→  \"metadata\": \"\"                // Custom participant data\n   380→}\n   381→```\n   382→\n   383→### Token Generation Security\n   384→\n   385→**✓ CORRECT (Server-Side):**\n   386→```typescript\n   387→// Next.js API route (/api/token/route.ts)\n   388→import { AccessToken } from 'livekit-server-sdk';\n   389→\n   390→export async function POST(req: Request) {\n   391→  // Secret keys stay on server - NEVER exposed to browser\n   392→  const token = new AccessToken(\n   393→    process.env.LIVEKIT_API_KEY,\n   394→    process.env.LIVEKIT_API_SECRET,\n   395→    { identity: 'user' }\n   396→  );\n   397→\n   398→  token.addGrant({ room: 'room', roomJoin: true });\n   399→  return Response.json({ token: await token.toJwt() });\n   400→}\n   401→```\n   402→\n   403→**✗ WRONG (Client-Side):**\n   404→```typescript\n   405→// NEVER do this - exposes API secrets to browser!\n   406→const token = new AccessToken(\n   407→  \"APIxxxxxxxxxxxx\",  // ⚠️ Exposed in browser\n   408→  \"secret-key\",        // ⚠️ CRITICAL: Security breach!\n   409→  { identity: 'user' }\n   410→);\n   411→```\n   412→\n   413→### Environment Variables\n   414→\n   415→**Server-Side Only (Never Exposed):**\n   416→- `LIVEKIT_API_KEY` - Used for token signing\n   417→- `LIVEKIT_API_SECRET` - Used for token signing\n   418→\n   419→**Public (Exposed to Browser):**\n   420→- `NEXT_PUBLIC_LIVEKIT_URL` - WebRTC server URL\n   421→\n   422→**Configuration Example:**\n   423→```env\n   424→# .env.local (server-side)\n   425→LIVEKIT_API_KEY=APIxxxxxxxxxxxx\n   426→LIVEKIT_API_SECRET=your-secret-key-here\n   427→LIVEKIT_URL=wss://your-project.livekit.cloud\n   428→\n   429→# Exposed to browser (NEXT_PUBLIC_ prefix)\n   430→NEXT_PUBLIC_LIVEKIT_URL=wss://your-project.livekit.cloud\n   431→```\n   432→\n   433→### Token Permissions\n   434→\n   435→**Recommended Grants:**\n   436→```typescript\n   437→token.addGrant({\n   438→  room: roomName,              // Specific room\n   439→  roomJoin: true,              // Can join\n   440→  canPublish: true,            // Can publish audio/video\n   441→  canSubscribe: true,          // Can receive audio/video\n   442→  canPublishData: true,        // Can send data messages\n   443→  canPublishSources: [         // Optional: restrict sources\n   444→    'microphone',\n   445→    'camera',\n   446→    'screen_share'\n   447→  ],\n   448→});\n   449→```\n   450→\n   451→### Token Expiration\n   452→\n   453→- **Default TTL:** 2 hours\n   454→- **Auto-Refresh:** LiveKit client automatically refreshes for connected users\n   455→- **Disconnected Users:** Must request new token\n   456→- **Production Recommendation:** 2h with auto-refresh\n   457→\n   458→---\n   459→\n   460→## Deployment Options\n   461→\n   462→### Frontend Hosting\n   463→\n   464→| Provider | Cost | Build Time | Auto Deploy | SSL | CDN |\n   465→|----------|------|------------|-------------|-----|-----|\n   466→| **Vercel** (Recommended) | Free tier | 2-5 min | ✓ Git | ✓ | ✓ |\n   467→| Netlify | Free tier | 2-5 min | ✓ Git | ✓ | ✓ |\n   468→| AWS Amplify | Free tier | 3-7 min | ✓ Git | ✓ | ✓ |\n   469→| Cloudflare Pages | Free | 2-4 min | ✓ Git | ✓ | ✓ |\n   470→\n   471→**Recommendation:** Vercel for Next.js (seamless integration, best DX)\n   472→\n   473→### Agent Hosting\n   474→\n   475→**LiveKit Cloud (Recommended):**\n   476→- **Cost:** $0.01 per agent session minute\n   477→- **Deployment:** `lk agent create --secrets-file .env.local`\n   478→- **Scaling:** Automatic (0 to N replicas)\n   479→- **Regions:** Global (US, EU, APAC)\n   480→\n   481→**Alternative:** Self-hosted (requires own infrastructure)\n   482→\n   483→---\n   484→\n   485→## Cost Analysis\n   486→\n   487→### Estimated Monthly Costs\n   488→\n   489→**Scenario 1: Low Traffic (100 sessions/month, 5 min avg)**\n   490→- Sessions: 100\n   491→- Total minutes: 500\n   492→- LiveKit Cloud: 500 × $0.01 = **$5/month**\n   493→- Vercel: **Free tier**\n   494→- **Total: ~$5/month**\n   495→\n   496→**Scenario 2: Medium Traffic (1,000 sessions/month, 10 min avg)**\n   497→- Sessions: 1,000\n   498→- Total minutes: 10,000\n   499→- LiveKit Cloud: 10,000 × $0.01 = **$100/month**\n   500→- Vercel: **Free tier** (or $20/month Pro)\n   501→- **Total: ~$100-120/month**\n   502→\n   503→**Scenario 3: High Traffic (10,000 sessions/month, 8 min avg)**\n   504→- Sessions: 10,000\n   505→- Total minutes: 80,000\n   506→- LiveKit Cloud: 80,000 × $0.01 = **$800/month**\n   507→- Vercel: **$20/month Pro**\n   508→- **Total: ~$820/month**\n   509→\n   510→**Additional Costs:**\n   511→- OpenAI API (LLM): ~$0.03 per conversation\n   512→- AssemblyAI (STT): ~$0.01 per minute\n   513→- Cartesia (TTS): ~$0.05 per 1K characters\n   514→\n   515→---\n   516→\n   517→## Browser Compatibility\n   518→\n   519→### Supported Browsers\n   520→\n   521→| Browser | Desktop | Mobile | Notes |\n   522→|---------|---------|--------|-------|\n   523→| Chrome | ✓ v90+ | ✓ v90+ | Best support |\n   524→| Firefox | ✓ v88+ | ✓ v88+ | Full support |\n   525→| Safari | ✓ 14+ | ✓ 14+ | Requires user interaction for audio |\n   526→| Edge | ✓ v90+ | ✓ v90+ | Chromium-based, same as Chrome |\n   527→| Opera | ✓ v76+ | ✓ v64+ | Full support |\n   528→\n   529→### WebRTC Requirements\n   530→\n   531→**Required Browser Features:**\n   532→- WebRTC support (RTCPeerConnection)\n   533→- getUserMedia API (microphone access)\n   534→- Web Audio API (audio processing)\n   535→- WebSockets (signaling)\n   536→\n   537→**Not Supported:**\n   538→- Internet Explorer (any version)\n   539→- Legacy Edge (pre-Chromium)\n   540→- Very old mobile browsers (<2020)\n   541→\n   542→---\n   543→\n   544→## Performance Benchmarks\n   545→\n   546→### Connection Time\n   547→\n   548→| Metric | Standard | Optimized |\n   549→|--------|----------|-----------|\n   550→| Token fetch | 500ms | 0ms (pre-generated) |\n   551→| Room connect | 1000ms | 1000ms |\n   552→| Agent dispatch | 1000ms | 500ms (concurrent) |\n   553→| Media establish | 1500ms | 1000ms |\n   554→| **Total** | **4000ms** | **1500ms** |\n   555→\n   556→### Audio Latency\n   557→\n   558→| Component | Latency |\n   559→|-----------|---------|\n   560→| User speech → STT | 500-800ms |\n   561→| LLM processing | 1000-2000ms |\n   562→| TTS generation | 300-500ms |\n   563→| Audio playback | 100-200ms |\n   564→| **Total (first response)** | **2-3.5 seconds** |\n   565→| **Subsequent turns** | **1.5-2.5 seconds** (streaming) |\n   566→\n   567→### Page Load Performance\n   568→\n   569→**Lighthouse Scores (agent-starter-react):**\n   570→- Performance: 90-95\n   571→- Accessibility: 95-100\n   572→- Best Practices: 90-95\n   573→- SEO: 95-100\n   574→\n   575→**Bundle Sizes:**\n   576→- Initial load: ~150-200 KB (gzipped)\n   577→- Total JavaScript: ~400-500 KB\n   578→- First Contentful Paint: <1.5s\n   579→- Time to Interactive: <2.5s\n   580→\n   581→---\n   582→\n   583→## Mobile Considerations\n   584→\n   585→### iOS Safari Quirks\n   586→\n   587→**Audio Autoplay:**\n   588→- Requires user interaction before audio playback\n   589→- Solution: Play silent audio on first user click\n   590→\n   591→**Microphone Access:**\n   592→- Must request permissions on user gesture\n   593→- Browser prompts for microphone access\n   594→\n   595→**Web Audio Context:**\n   596→- May be suspended on page load\n   597→- Resume on user interaction\n   598→\n   599→### Android Chrome\n   600→\n   601→**Generally Better Support:**\n   602→- Fewer audio restrictions\n   603→- Better WebRTC implementation\n   604→- More permissive autoplay policies\n   605→\n   606→**PWA Support:**\n   607→- Can be installed as app\n   608→- Better offline handling\n   609→- Push notifications available\n   610→\n   611→### Responsive Design\n   612→\n   613→**agent-starter-react includes:**\n   614→- Mobile-first responsive layout\n   615→- Touch-optimized controls\n   616→- Adaptive font sizes\n   617→- Mobile-friendly visualizations\n   618→\n   619→---\n   620→\n   621→## Security Best Practices\n   622→\n   623→### Token Security\n   624→\n   625→✓ **DO:**\n   626→- Generate tokens server-side only\n   627→- Use environment variables for secrets\n   628→- Set appropriate token expiration (2h)\n   629→- Validate token claims on server\n   630→- Use HTTPS in production\n   631→\n   632→✗ **DON'T:**\n   633→- Expose API secrets to browser\n   634→- Generate tokens client-side\n   635→- Use long-lived tokens (>24h)\n   636→- Store secrets in code or Git\n   637→- Use HTTP (always HTTPS)\n   638→\n   639→### API Security\n   640→\n   641→**Rate Limiting:**\n   642→```typescript\n   643→// Add to token endpoint\n   644→import rateLimit from 'express-rate-limit';\n   645→\n   646→const limiter = rateLimit({\n   647→  windowMs: 15 * 60 * 1000, // 15 minutes\n   648→  max: 100 // limit each IP to 100 requests per windowMs\n   649→});\n   650→\n   651→app.use('/api/token', limiter);\n   652→```\n   653→\n   654→**CORS Configuration:**\n   655→```typescript\n   656→// Only allow your domain\n   657→const allowedOrigins = ['https://yourdomain.com'];\n   658→\n   659→res.setHeader('Access-Control-Allow-Origin', allowedOrigins);\n   660→```\n   661→\n   662→### Content Security Policy\n   663→\n   664→```typescript\n   665→// Add CSP headers\n   666→res.setHeader('Content-Security-Policy',\n   667→  \"default-src 'self'; \" +\n   668→  \"connect-src 'self' wss://your-project.livekit.cloud; \" +\n   669→  \"media-src 'self';\"\n   670→);\n   671→```\n   672→\n   673→---\n   674→\n   675→## Troubleshooting Guide\n   676→\n   677→### Common Issues\n   678→\n   679→**\"Failed to connect to room\"**\n   680→- **Cause:** Invalid token or LiveKit URL\n   681→- **Fix:** Check environment variables, verify token generation\n   682→\n   683→**\"Microphone access denied\"**\n   684→- **Cause:** User denied browser permission\n   685→- **Fix:** Prompt user to grant permission in browser settings\n   686→\n   687→**\"No audio from agent\"**\n   688→- **Cause:** Agent not joining room, TTS API issues\n   689→- **Fix:** Check agent logs (`lk agent logs`), verify Cartesia API key\n   690→\n   691→**\"Token expired\"**\n   692→- **Cause:** Token TTL exceeded, user inactive too long\n   693→- **Fix:** Increase TTL or implement token refresh\n   694→\n   695→**\"WebRTC connection failed\"**\n   696→- **Cause:** Firewall blocking WebRTC ports\n   697→- **Fix:** Check firewall rules, ensure UDP ports open\n   698→\n   699→### Debug Tools\n   700→\n   701→**Browser DevTools:**\n   702→- Console: Check for JavaScript errors\n   703→- Network: Inspect WebSocket connections\n   704→- Application: View local storage/cookies\n   705→\n   706→**LiveKit CLI:**\n   707→```bash\n   708→# Monitor agent logs\n   709→lk agent logs --follow\n   710→\n   711→# Check agent status\n   712→lk agent status\n   713→\n   714→# List active rooms\n   715→lk room list\n   716→\n   717→# View room participants\n   718→lk room participants <room-name>\n   719→```\n   720→\n   721→**Vercel Logs:**\n   722→- Dashboard → Deployments → Functions\n   723→- Real-time function logs\n   724→- Error tracking\n   725→\n   726→---\n   727→\n   728→## Next Steps\n   729→\n   730→### Immediate Actions\n   731→\n   732→1. **Review implementation plan:** See `2026-01-25-web-frontend-deployment.md`\n   733→2. **Deploy agent:** Follow Phase 1 of plan\n   734→3. **Set up frontend:** Follow Phases 2-3 of plan\n   735→4. **Test connection:** Follow Phase 4 of plan\n   736→5. **Customize:** Follow Phase 5 of plan\n   737→6. **Deploy to production:** Follow Phase 6 of plan\n   738→\n   739→### Learning Resources\n   740→\n   741→**Documentation:**\n   742→- LiveKit Docs: https://docs.livekit.io\n   743→- agent-starter-react README: https://github.com/livekit-examples/agent-starter-react\n   744→- Next.js Docs: https://nextjs.org/docs\n   745→- React Hooks: https://react.dev/reference/react\n   746→\n   747→**Video Tutorials:**\n   748→- LiveKit YouTube: https://www.youtube.com/@livekit\n   749→- Next.js Learn: https://nextjs.org/learn\n   750→\n   751→**Community:**\n   752→- LiveKit Discord: https://livekit.io/discord\n   753→- GitHub Discussions: https://github.com/livekit/agents/discussions\n   754→\n   755→---\n   756→\n   757→## Appendix: Quick Reference\n   758→\n   759→### Essential Commands\n   760→\n   761→```bash\n   762→# Agent deployment\n   763→lk cloud auth\n   764→lk agent create --secrets-file .env.local\n   765→lk agent status\n   766→lk agent logs --follow\n   767→\n   768→# Frontend setup\n   769→lk app create --template agent-starter-react\n   770→pnpm install\n   771→pnpm dev\n   772→pnpm build\n   773→\n   774→# Production deployment (Vercel)\n   775→vercel\n   776→vercel --prod\n   777→```\n   778→\n   779→### Environment Variables Checklist\n   780→\n   781→**Backend (Agent - `.env.local`):**\n   782→```env\n   783→OPENAI_API_KEY=sk-...\n   784→ASSEMBLYAI_API_KEY=...\n   785→CARTESIA_API_KEY=...\n   786→# Note: LIVEKIT_* vars auto-injected by LiveKit Cloud\n   787→```\n   788→\n   789→**Frontend (Next.js - `.env.local`):**\n   790→```env\n   791→LIVEKIT_API_KEY=APIxxxxxxxxxxxx\n   792→LIVEKIT_API_SECRET=your-secret-here\n   793→LIVEKIT_URL=wss://your-project.livekit.cloud\n   794→NEXT_PUBLIC_LIVEKIT_URL=wss://your-project.livekit.cloud\n   795→AGENT_NAME=\n   796→```\n   797→\n   798→### URL Reference\n   799→\n   800→- **Agent Playground:** https://agents-playground.livekit.io/\n   801→- **LiveKit Cloud:** https://cloud.livekit.io\n   802→- **Vercel Dashboard:** https://vercel.com/dashboard\n   803→- **Your Production Frontend:** https://your-app.vercel.app\n   804→\n   805→---\n   806→\n   807→**Document Version:** 1.0\n   808→**Last Updated:** 2026-01-25\n   809→**Related Plan:** `2026-01-25-web-frontend-deployment.md`\n   810→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"7dafcc68-7c7d-429a-be57-486e61960529","timestamp":"2026-01-25T09:44:31.848Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/plan/future-plans/2026-01-25-web-frontend-options-summary.md","content":"# Web Frontend Options for LiveKit Voice AI Agent - Research Summary\n\n**Date:** 2026-01-25\n**Purpose:** Document TypeScript/JavaScript options for enabling web-based client interaction with deployed LiveKit agent\n\n---\n\n## Executive Summary\n\nLiveKit provides multiple JavaScript/TypeScript solutions for building web frontends that connect users to voice AI agents. The recommended approach is **agent-starter-react**, a production-ready Next.js template that includes all necessary components:\n\n- JWT token generation (server-side for security)\n- WebRTC connection management via `livekit-client` SDK\n- Voice assistant UI components (`@livekit/components-react`)\n- Audio visualization and agent state tracking\n- Automatic agent dispatch when users connect\n\n**Timeline:** 6-8 hours for complete deployment (agent + frontend + customization)\n**Cost:** $0.01 per agent session minute (LiveKit Cloud) + Free (Vercel frontend hosting)\n\n---\n\n## Option 1: agent-starter-react (Recommended)\n\n### Overview\nOfficial Next.js/React template from LiveKit with production-ready voice AI interface.\n\n### Repository\n**GitHub:** https://github.com/livekit-examples/agent-starter-react\n\n### Tech Stack\n- Next.js 14+ (App Router)\n- React 18+ with TypeScript\n- Tailwind CSS + Shadcn/ui components\n- `livekit-client` SDK (WebRTC)\n- `@livekit/components-react` (UI components)\n- `livekit-server-sdk` (token generation)\n\n### Key Features\n✓ Token generation API route (`/api/token`)\n✓ `useVoiceAssistant` React hook for agent state\n✓ Audio visualizer (`BarVisualizer`)\n✓ Camera video and screen sharing support\n✓ Light/dark theme with system preference\n✓ Customizable branding via `app-config.ts`\n✓ Mobile-responsive design\n✓ Production-ready architecture\n\n### Setup Process\n```bash\n# Install via LiveKit CLI\nlk app create --template agent-starter-react\ncd voice-ai-frontend\npnpm install\n\n# Configure environment\ncp .env.example .env.local\n# Add: LIVEKIT_API_KEY, LIVEKIT_API_SECRET, LIVEKIT_URL\n\n# Run development server\npnpm dev\n# Visit http://localhost:3000\n```\n\n### Customization\n**Easy to customize:**\n- Company name and branding (app-config.ts)\n- Logo and colors\n- Welcome message and instructions\n- Feature toggles (video, screen share, chat)\n- Theme colors (Tailwind CSS)\n\n### Deployment\n- **Recommended:** Vercel (free tier)\n- **Alternatives:** Netlify, AWS Amplify, Cloudflare Pages\n- **Build time:** ~2-5 minutes\n- **Automatic deployments:** Via Git integration\n\n### Best For\n- Production websites with custom branding\n- Full feature control\n- Professional, polished user experience\n- Organizations needing customization\n\n### Pros\n✓ Official template, actively maintained\n✓ Production-ready out of the box\n✓ Excellent documentation\n✓ Easy customization\n✓ Vercel deployment = free hosting\n✓ TypeScript for type safety\n✓ Modern UI with Shadcn/ui\n\n### Cons\n✗ Requires some React/Next.js knowledge for customization\n✗ Larger initial download (Next.js framework)\n✗ More complex than simple embed\n\n---\n\n## Option 2: agent-starter-embed (Embeddable Widget)\n\n### Overview\nEmbeddable widget for adding voice AI to existing websites without major changes.\n\n### Repository\n**GitHub:** https://github.com/livekit-examples/agent-starter-embed\n\n### Tech Stack\n- Next.js with TypeScript\n- Bundled JavaScript widget\n- Same core LiveKit SDKs as agent-starter-react\n\n### Key Features\n✓ Embeddable via `<script>` tag\n✓ Popup-style or inline widget\n✓ Minimal integration effort\n✓ Same features as agent-starter-react\n✓ Customizable appearance\n\n### Setup Process\n```bash\ngit clone https://github.com/livekit-examples/agent-starter-embed.git\ncd agent-starter-embed\npnpm install\npnpm build-embed-popup-script\npnpm dev\n```\n\n### Integration\n```html\n<!-- Add to any website -->\n<div id=\"livekit-agent\"></div>\n<script src=\"https://your-cdn.com/embed-popup.js\"></script>\n<script>\n  LiveKitAgent.init({\n    container: '#livekit-agent',\n    tokenUrl: 'https://your-backend.com/api/token',\n    theme: 'dark',\n    position: 'bottom-right'\n  });\n</script>\n```\n\n### Best For\n- Adding voice AI to existing websites\n- Minimal code changes required\n- Quick implementation\n- Embedded customer support agents\n\n### Pros\n✓ Easy integration (just add script tag)\n✓ No major site changes needed\n✓ Works with any website/CMS\n✓ Can be positioned anywhere (floating, inline)\n\n### Cons\n✗ Less customization than full React app\n✗ Still requires backend for token generation\n✗ Limited control over widget internals\n\n---\n\n## Option 3: Custom Build with LiveKit SDKs\n\n### Overview\nBuild from scratch using core LiveKit packages for maximum customization.\n\n### NPM Packages\n\n**Client SDK:**\n```bash\nnpm install livekit-client\n```\n- **Package:** `livekit-client` (v2.17.0+)\n- **Purpose:** WebRTC client for browser\n- **Docs:** https://docs.livekit.io/reference/client-sdk-js/\n\n**React Components:**\n```bash\nnpm install @livekit/components-react @livekit/components-styles\n```\n- **Package:** `@livekit/components-react`\n- **Purpose:** Pre-built React UI components\n- **Key Exports:** `useVoiceAssistant`, `BarVisualizer`, `VoiceAssistantControlBar`\n- **Docs:** https://docs.livekit.io/reference/components/react/\n\n**Server SDK (Backend):**\n```bash\nnpm install livekit-server-sdk\n```\n- **Package:** `livekit-server-sdk` (v2.15.0+)\n- **Purpose:** Token generation (server-side only)\n- **Docs:** https://docs.livekit.io/reference/server-sdk-js/\n\n### Minimal Example\n\n**Frontend (React):**\n```typescript\nimport { useVoiceAssistant, BarVisualizer } from '@livekit/components-react';\nimport '@livekit/components-styles';\n\nfunction VoiceAgent() {\n  const { state, audioTrack } = useVoiceAssistant();\n  // state: 'initializing' | 'listening' | 'thinking' | 'speaking'\n\n  return (\n    <div>\n      <p>Agent is {state}</p>\n      <BarVisualizer state={state} audioTrack={audioTrack} />\n      <button onClick={connect}>Connect</button>\n    </div>\n  );\n}\n```\n\n**Backend (Next.js API Route):**\n```typescript\nimport { AccessToken } from 'livekit-server-sdk';\n\nexport async function POST(req: Request) {\n  const { roomName, participantName } = await req.json();\n\n  const token = new AccessToken(\n    process.env.LIVEKIT_API_KEY,\n    process.env.LIVEKIT_API_SECRET,\n    { identity: participantName, ttl: '2h' }\n  );\n\n  token.addGrant({\n    room: roomName,\n    roomJoin: true,\n    canPublish: true,\n    canSubscribe: true,\n  });\n\n  return Response.json({ token: await token.toJwt() });\n}\n```\n\n### Best For\n- Integrating into existing React applications\n- Maximum customization control\n- Unique UI/UX requirements\n- Developers comfortable with WebRTC\n\n### Pros\n✓ Complete control over every aspect\n✓ Smaller bundle size (only what you need)\n✓ Deep integration with existing app\n✓ No template overhead\n\n### Cons\n✗ Requires understanding of LiveKit concepts\n✗ More time to build from scratch\n✗ Need to handle edge cases yourself\n✗ More maintenance burden\n\n---\n\n## Option 4: LiveKit Agents Playground (Quick Testing)\n\n### Overview\nZero-code web interface for instantly testing deployed agents.\n\n### Access\n**URL:** https://agents-playground.livekit.io/\n\n### Use Case\n- Quick testing of deployed agents\n- No frontend setup required\n- Demo to stakeholders\n- Debugging agent behavior\n\n### How to Use\n1. Visit https://agents-playground.livekit.io/\n2. Enter LiveKit credentials:\n   - LiveKit URL: `wss://your-project.livekit.cloud`\n   - API Key: Your `LIVEKIT_API_KEY`\n   - API Secret: Your `LIVEKIT_API_SECRET`\n3. Click \"Connect\"\n4. Speak to your agent\n\n### Best For\n- Testing before building frontend\n- Internal demos\n- Debugging agent issues\n- Validating deployment\n\n### Pros\n✓ Zero setup required\n✓ Instant testing\n✓ No code needed\n✓ Audio visualization included\n\n### Cons\n✗ Not for end users (exposes API secrets)\n✗ No customization\n✗ Not production-ready\n✗ Requires credentials each time\n\n---\n\n## Connection Flow Architecture\n\n### Standard Flow\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                      WEBSITE (FRONTEND)                     │\n│  ┌─────────────────┐         ┌─────────────────┐           │\n│  │   React/Next    │────────▶│  Token Server   │           │\n│  │   (Browser)     │  fetch  │  (Node.js API)  │           │\n│  └────────┬────────┘  token  └────────┬────────┘           │\n│           │                           │                     │\n│           │ WebRTC                    │ livekit-server-sdk  │\n│           │ (audio)                   │ (JWT generation)    │\n└───────────┼───────────────────────────┼─────────────────────┘\n            │                           │\n            ▼                           ▼\n┌─────────────────────────────────────────────────────────────┐\n│                    LIVEKIT CLOUD                            │\n│  ┌─────────────────┐         ┌─────────────────┐           │\n│  │  LiveKit Room   │◀────────│  Your Agent     │           │\n│  │  (WebRTC SFU)   │  audio  │  (Python)       │           │\n│  └─────────────────┘         └─────────────────┘           │\n│                                                             │\n│  Auto-dispatch agent when user joins room                  │\n└─────────────────────────────────────────────────────────────┘\n```\n\n### Connection Sequence\n\n1. **User clicks \"Connect\"** on website\n2. **Frontend requests token** from `/api/token` endpoint (500ms)\n3. **Backend generates JWT** using `livekit-server-sdk` (50ms)\n4. **Frontend connects to LiveKit room** with token (1000ms)\n5. **Agent automatically dispatched** to room (1000ms)\n6. **Agent connects** and publishes audio track (1500ms)\n7. **WebRTC media flow established** between user and agent\n\n**Total Time:** ~4 seconds (standard) → ~1.5 seconds (optimized)\n\n### Optimization Techniques\n\n**1. Pre-generate Tokens (Warm Token):**\n- Generate token on page load\n- Store for immediate use when \"Connect\" clicked\n- Saves ~500ms\n\n**2. Concurrent Dispatch:**\n- Connect user and dispatch agent in parallel\n- Saves ~1000ms\n\n**3. Pre-connect Buffer:**\n- Enable in `app-config.ts`\n- Reduces perceived latency\n\n---\n\n## Authentication Deep Dive\n\n### JWT Token Structure\n\n**Token Payload Example:**\n```json\n{\n  \"exp\": 1234567890,           // Expiration timestamp\n  \"iss\": \"APIxxxxxxxxxxxx\",    // API Key (issuer)\n  \"sub\": \"user-identity\",       // Participant identity\n  \"nbf\": 1234567890,           // Not before timestamp\n  \"video\": {\n    \"room\": \"room-name\",        // Room name\n    \"roomJoin\": true,           // Can join room\n    \"canPublish\": true,         // Can publish tracks\n    \"canSubscribe\": true,       // Can subscribe to tracks\n    \"canPublishData\": true      // Can send data messages\n  },\n  \"metadata\": \"\"                // Custom participant data\n}\n```\n\n### Token Generation Security\n\n**✓ CORRECT (Server-Side):**\n```typescript\n// Next.js API route (/api/token/route.ts)\nimport { AccessToken } from 'livekit-server-sdk';\n\nexport async function POST(req: Request) {\n  // Secret keys stay on server - NEVER exposed to browser\n  const token = new AccessToken(\n    process.env.LIVEKIT_API_KEY,\n    process.env.LIVEKIT_API_SECRET,\n    { identity: 'user' }\n  );\n\n  token.addGrant({ room: 'room', roomJoin: true });\n  return Response.json({ token: await token.toJwt() });\n}\n```\n\n**✗ WRONG (Client-Side):**\n```typescript\n// NEVER do this - exposes API secrets to browser!\nconst token = new AccessToken(\n  \"APIxxxxxxxxxxxx\",  // ⚠️ Exposed in browser\n  \"secret-key\",        // ⚠️ CRITICAL: Security breach!\n  { identity: 'user' }\n);\n```\n\n### Environment Variables\n\n**Server-Side Only (Never Exposed):**\n- `LIVEKIT_API_KEY` - Used for token signing\n- `LIVEKIT_API_SECRET` - Used for token signing\n\n**Public (Exposed to Browser):**\n- `NEXT_PUBLIC_LIVEKIT_URL` - WebRTC server URL\n\n**Configuration Example:**\n```env\n# .env.local (server-side)\nLIVEKIT_API_KEY=APIxxxxxxxxxxxx\nLIVEKIT_API_SECRET=your-secret-key-here\nLIVEKIT_URL=wss://your-project.livekit.cloud\n\n# Exposed to browser (NEXT_PUBLIC_ prefix)\nNEXT_PUBLIC_LIVEKIT_URL=wss://your-project.livekit.cloud\n```\n\n### Token Permissions\n\n**Recommended Grants:**\n```typescript\ntoken.addGrant({\n  room: roomName,              // Specific room\n  roomJoin: true,              // Can join\n  canPublish: true,            // Can publish audio/video\n  canSubscribe: true,          // Can receive audio/video\n  canPublishData: true,        // Can send data messages\n  canPublishSources: [         // Optional: restrict sources\n    'microphone',\n    'camera',\n    'screen_share'\n  ],\n});\n```\n\n### Token Expiration\n\n- **Default TTL:** 2 hours\n- **Auto-Refresh:** LiveKit client automatically refreshes for connected users\n- **Disconnected Users:** Must request new token\n- **Production Recommendation:** 2h with auto-refresh\n\n---\n\n## Deployment Options\n\n### Frontend Hosting\n\n| Provider | Cost | Build Time | Auto Deploy | SSL | CDN |\n|----------|------|------------|-------------|-----|-----|\n| **Vercel** (Recommended) | Free tier | 2-5 min | ✓ Git | ✓ | ✓ |\n| Netlify | Free tier | 2-5 min | ✓ Git | ✓ | ✓ |\n| AWS Amplify | Free tier | 3-7 min | ✓ Git | ✓ | ✓ |\n| Cloudflare Pages | Free | 2-4 min | ✓ Git | ✓ | ✓ |\n\n**Recommendation:** Vercel for Next.js (seamless integration, best DX)\n\n### Agent Hosting\n\n**LiveKit Cloud (Recommended):**\n- **Cost:** $0.01 per agent session minute\n- **Deployment:** `lk agent create --secrets-file .env.local`\n- **Scaling:** Automatic (0 to N replicas)\n- **Regions:** Global (US, EU, APAC)\n\n**Alternative:** Self-hosted (requires own infrastructure)\n\n---\n\n## Cost Analysis\n\n### Estimated Monthly Costs\n\n**Scenario 1: Low Traffic (100 sessions/month, 5 min avg)**\n- Sessions: 100\n- Total minutes: 500\n- LiveKit Cloud: 500 × $0.01 = **$5/month**\n- Vercel: **Free tier**\n- **Total: ~$5/month**\n\n**Scenario 2: Medium Traffic (1,000 sessions/month, 10 min avg)**\n- Sessions: 1,000\n- Total minutes: 10,000\n- LiveKit Cloud: 10,000 × $0.01 = **$100/month**\n- Vercel: **Free tier** (or $20/month Pro)\n- **Total: ~$100-120/month**\n\n**Scenario 3: High Traffic (10,000 sessions/month, 8 min avg)**\n- Sessions: 10,000\n- Total minutes: 80,000\n- LiveKit Cloud: 80,000 × $0.01 = **$800/month**\n- Vercel: **$20/month Pro**\n- **Total: ~$820/month**\n\n**Additional Costs:**\n- OpenAI API (LLM): ~$0.03 per conversation\n- AssemblyAI (STT): ~$0.01 per minute\n- Cartesia (TTS): ~$0.05 per 1K characters\n\n---\n\n## Browser Compatibility\n\n### Supported Browsers\n\n| Browser | Desktop | Mobile | Notes |\n|---------|---------|--------|-------|\n| Chrome | ✓ v90+ | ✓ v90+ | Best support |\n| Firefox | ✓ v88+ | ✓ v88+ | Full support |\n| Safari | ✓ 14+ | ✓ 14+ | Requires user interaction for audio |\n| Edge | ✓ v90+ | ✓ v90+ | Chromium-based, same as Chrome |\n| Opera | ✓ v76+ | ✓ v64+ | Full support |\n\n### WebRTC Requirements\n\n**Required Browser Features:**\n- WebRTC support (RTCPeerConnection)\n- getUserMedia API (microphone access)\n- Web Audio API (audio processing)\n- WebSockets (signaling)\n\n**Not Supported:**\n- Internet Explorer (any version)\n- Legacy Edge (pre-Chromium)\n- Very old mobile browsers (<2020)\n\n---\n\n## Performance Benchmarks\n\n### Connection Time\n\n| Metric | Standard | Optimized |\n|--------|----------|-----------|\n| Token fetch | 500ms | 0ms (pre-generated) |\n| Room connect | 1000ms | 1000ms |\n| Agent dispatch | 1000ms | 500ms (concurrent) |\n| Media establish | 1500ms | 1000ms |\n| **Total** | **4000ms** | **1500ms** |\n\n### Audio Latency\n\n| Component | Latency |\n|-----------|---------|\n| User speech → STT | 500-800ms |\n| LLM processing | 1000-2000ms |\n| TTS generation | 300-500ms |\n| Audio playback | 100-200ms |\n| **Total (first response)** | **2-3.5 seconds** |\n| **Subsequent turns** | **1.5-2.5 seconds** (streaming) |\n\n### Page Load Performance\n\n**Lighthouse Scores (agent-starter-react):**\n- Performance: 90-95\n- Accessibility: 95-100\n- Best Practices: 90-95\n- SEO: 95-100\n\n**Bundle Sizes:**\n- Initial load: ~150-200 KB (gzipped)\n- Total JavaScript: ~400-500 KB\n- First Contentful Paint: <1.5s\n- Time to Interactive: <2.5s\n\n---\n\n## Mobile Considerations\n\n### iOS Safari Quirks\n\n**Audio Autoplay:**\n- Requires user interaction before audio playback\n- Solution: Play silent audio on first user click\n\n**Microphone Access:**\n- Must request permissions on user gesture\n- Browser prompts for microphone access\n\n**Web Audio Context:**\n- May be suspended on page load\n- Resume on user interaction\n\n### Android Chrome\n\n**Generally Better Support:**\n- Fewer audio restrictions\n- Better WebRTC implementation\n- More permissive autoplay policies\n\n**PWA Support:**\n- Can be installed as app\n- Better offline handling\n- Push notifications available\n\n### Responsive Design\n\n**agent-starter-react includes:**\n- Mobile-first responsive layout\n- Touch-optimized controls\n- Adaptive font sizes\n- Mobile-friendly visualizations\n\n---\n\n## Security Best Practices\n\n### Token Security\n\n✓ **DO:**\n- Generate tokens server-side only\n- Use environment variables for secrets\n- Set appropriate token expiration (2h)\n- Validate token claims on server\n- Use HTTPS in production\n\n✗ **DON'T:**\n- Expose API secrets to browser\n- Generate tokens client-side\n- Use long-lived tokens (>24h)\n- Store secrets in code or Git\n- Use HTTP (always HTTPS)\n\n### API Security\n\n**Rate Limiting:**\n```typescript\n// Add to token endpoint\nimport rateLimit from 'express-rate-limit';\n\nconst limiter = rateLimit({\n  windowMs: 15 * 60 * 1000, // 15 minutes\n  max: 100 // limit each IP to 100 requests per windowMs\n});\n\napp.use('/api/token', limiter);\n```\n\n**CORS Configuration:**\n```typescript\n// Only allow your domain\nconst allowedOrigins = ['https://yourdomain.com'];\n\nres.setHeader('Access-Control-Allow-Origin', allowedOrigins);\n```\n\n### Content Security Policy\n\n```typescript\n// Add CSP headers\nres.setHeader('Content-Security-Policy',\n  \"default-src 'self'; \" +\n  \"connect-src 'self' wss://your-project.livekit.cloud; \" +\n  \"media-src 'self';\"\n);\n```\n\n---\n\n## Troubleshooting Guide\n\n### Common Issues\n\n**\"Failed to connect to room\"**\n- **Cause:** Invalid token or LiveKit URL\n- **Fix:** Check environment variables, verify token generation\n\n**\"Microphone access denied\"**\n- **Cause:** User denied browser permission\n- **Fix:** Prompt user to grant permission in browser settings\n\n**\"No audio from agent\"**\n- **Cause:** Agent not joining room, TTS API issues\n- **Fix:** Check agent logs (`lk agent logs`), verify Cartesia API key\n\n**\"Token expired\"**\n- **Cause:** Token TTL exceeded, user inactive too long\n- **Fix:** Increase TTL or implement token refresh\n\n**\"WebRTC connection failed\"**\n- **Cause:** Firewall blocking WebRTC ports\n- **Fix:** Check firewall rules, ensure UDP ports open\n\n### Debug Tools\n\n**Browser DevTools:**\n- Console: Check for JavaScript errors\n- Network: Inspect WebSocket connections\n- Application: View local storage/cookies\n\n**LiveKit CLI:**\n```bash\n# Monitor agent logs\nlk agent logs --follow\n\n# Check agent status\nlk agent status\n\n# List active rooms\nlk room list\n\n# View room participants\nlk room participants <room-name>\n```\n\n**Vercel Logs:**\n- Dashboard → Deployments → Functions\n- Real-time function logs\n- Error tracking\n\n---\n\n## Next Steps\n\n### Immediate Actions\n\n1. **Review implementation plan:** See `2026-01-25-web-frontend-deployment.md`\n2. **Deploy agent:** Follow Phase 1 of plan\n3. **Set up frontend:** Follow Phases 2-3 of plan\n4. **Test connection:** Follow Phase 4 of plan\n5. **Customize:** Follow Phase 5 of plan\n6. **Deploy to production:** Follow Phase 6 of plan\n\n### Learning Resources\n\n**Documentation:**\n- LiveKit Docs: https://docs.livekit.io\n- agent-starter-react README: https://github.com/livekit-examples/agent-starter-react\n- Next.js Docs: https://nextjs.org/docs\n- React Hooks: https://react.dev/reference/react\n\n**Video Tutorials:**\n- LiveKit YouTube: https://www.youtube.com/@livekit\n- Next.js Learn: https://nextjs.org/learn\n\n**Community:**\n- LiveKit Discord: https://livekit.io/discord\n- GitHub Discussions: https://github.com/livekit/agents/discussions\n\n---\n\n## Appendix: Quick Reference\n\n### Essential Commands\n\n```bash\n# Agent deployment\nlk cloud auth\nlk agent create --secrets-file .env.local\nlk agent status\nlk agent logs --follow\n\n# Frontend setup\nlk app create --template agent-starter-react\npnpm install\npnpm dev\npnpm build\n\n# Production deployment (Vercel)\nvercel\nvercel --prod\n```\n\n### Environment Variables Checklist\n\n**Backend (Agent - `.env.local`):**\n```env\nOPENAI_API_KEY=sk-...\nASSEMBLYAI_API_KEY=...\nCARTESIA_API_KEY=...\n# Note: LIVEKIT_* vars auto-injected by LiveKit Cloud\n```\n\n**Frontend (Next.js - `.env.local`):**\n```env\nLIVEKIT_API_KEY=APIxxxxxxxxxxxx\nLIVEKIT_API_SECRET=your-secret-here\nLIVEKIT_URL=wss://your-project.livekit.cloud\nNEXT_PUBLIC_LIVEKIT_URL=wss://your-project.livekit.cloud\nAGENT_NAME=\n```\n\n### URL Reference\n\n- **Agent Playground:** https://agents-playground.livekit.io/\n- **LiveKit Cloud:** https://cloud.livekit.io\n- **Vercel Dashboard:** https://vercel.com/dashboard\n- **Your Production Frontend:** https://your-app.vercel.app\n\n---\n\n**Document Version:** 1.0\n**Last Updated:** 2026-01-25\n**Related Plan:** `2026-01-25-web-frontend-deployment.md`\n","numLines":810,"startLine":1,"totalLines":810}},"sourceToolAssistantUUID":"8b7e853d-81a3-4d42-b034-a796e165315d"}
{"parentUuid":"7dafcc68-7c7d-429a-be57-486e61960529","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","slug":"enumerated-shimmying-starlight","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01G4xKdJhLaRV7watjRGnEsu","toolUseID":"toolu_01G4xKdJhLaRV7watjRGnEsu","timestamp":"2026-01-25T09:44:31.854Z","uuid":"8be964e5-20d6-496b-b4b4-9ee936dd8471"}
{"parentUuid":"7eda4b89-34c2-4b4b-8c0b-75a47fb1e181","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","slug":"enumerated-shimmying-starlight","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01XCbLktmrMFcR8xzFpg4reD","type":"tool_result","content":"     1→# Web Frontend Deployment Implementation Plan\n     2→\n     3→> **Status:** DRAFT\n     4→\n     5→## Table of Contents\n     6→\n     7→- [Overview](#overview)\n     8→- [Current State Analysis](#current-state-analysis)\n     9→- [Desired End State](#desired-end-state)\n    10→- [What We're NOT Doing](#what-were-not-doing)\n    11→- [Implementation Approach](#implementation-approach)\n    12→- [Dependencies](#dependencies)\n    13→- [Phase 1: Agent Deployment to LiveKit Cloud](#phase-1-agent-deployment-to-livekit-cloud)\n    14→- [Phase 2: Frontend Setup (agent-starter-react)](#phase-2-frontend-setup-agent-starter-react)\n    15→- [Phase 3: Authentication and Token Generation](#phase-3-authentication-and-token-generation)\n    16→- [Phase 4: Connection Testing and Optimization](#phase-4-connection-testing-and-optimization)\n    17→- [Phase 5: Frontend Customization](#phase-5-frontend-customization)\n    18→- [Phase 6: Production Deployment](#phase-6-production-deployment)\n    19→- [Testing Strategy](#testing-strategy)\n    20→- [References](#references)\n    21→\n    22→## Overview\n    23→\n    24→This plan enables potential clients to interact with the LiveKit voice AI agent from this repository by clicking a link on a website. The implementation covers:\n    25→\n    26→1. Deploying the Python agent to LiveKit Cloud\n    27→2. Setting up a Next.js/React frontend using the agent-starter-react template\n    28→3. Implementing JWT token-based authentication\n    29→4. Testing the connection flow\n    30→5. Customizing the frontend with branding\n    31→6. Deploying the frontend to production (Vercel)\n    32→\n    33→The solution uses LiveKit's official starter templates and SDKs to create a production-ready web application with TypeScript/JavaScript.\n    34→\n    35→## Current State Analysis\n    36→\n    37→### What Exists Now\n    38→\n    39→**Agent Backend:**\n    40→- Python voice AI agent in `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1`\n    41→- Built with LiveKit Agents SDK\n    42→- Uses OpenAI (LLM), AssemblyAI (STT), Cartesia (TTS)\n    43→- Configured with `uv` package manager\n    44→- Has `Dockerfile` for containerized deployment\n    45→- Environment variables in `.env.local` (OpenAI, AssemblyAI, Cartesia API keys)\n    46→\n    47→**Missing:**\n    48→- Agent not yet deployed to LiveKit Cloud\n    49→- No web frontend for client interaction\n    50→- No token generation server for authentication\n    51→- No public-facing URL for clients to access\n    52→\n    53→### Key Discoveries\n    54→\n    55→From `docs/DEPLOYMENT.md`:\n    56→- LiveKit Cloud deployment uses `lk` CLI\n    57→- Agent deployment command: `lk agent create --secrets-file .env.local`\n    58→- Multiple frontend options available (React, Flutter, Swift, Embed)\n    59→- Connection requires JWT tokens generated server-side\n    60→- agent-starter-react provides production-ready Next.js template\n    61→- Token generation uses `livekit-server-sdk` npm package\n    62→\n    63→### Constraints\n    64→\n    65→1. **Security:** API secrets (LIVEKIT_API_SECRET) must never be exposed to frontend\n    66→2. **Architecture:** Token generation must happen server-side (Next.js API routes)\n    67→3. **Dependencies:** Agent must be deployed and running before frontend can connect\n    68→4. **Cost:** LiveKit Cloud charges $0.01 per agent session minute\n    69→\n    70→## Desired End State\n    71→\n    72→### Success Criteria\n    73→\n    74→- [ ] Agent deployed and running on LiveKit Cloud\n    75→- [ ] Next.js frontend application running locally\n    76→- [ ] JWT token generation working via backend API route\n    77→- [ ] Users can click a link and connect to voice AI agent\n    78→- [ ] Audio conversation works end-to-end (STT → LLM → TTS)\n    79→- [ ] Frontend deployed to production URL (Vercel)\n    80→- [ ] Customized branding (logo, colors, company name)\n    81→- [ ] Light/dark theme support\n    82→- [ ] Audio visualization working\n    83→- [ ] Mobile-responsive design\n    84→\n    85→### How to Verify\n    86→\n    87→**Agent Deployment:**\n    88→```bash\n    89→lk agent status\n    90→# Expected: Status: Running, Replicas: X/X ready\n    91→```\n    92→\n    93→**Frontend Connection:**\n    94→1. Visit frontend URL (local: http://localhost:3000, prod: https://your-app.vercel.app)\n    95→2. Click \"Connect\" or \"Start Session\"\n    96→3. Grant microphone permissions when prompted\n    97→4. Speak to the agent\n    98→5. Verify agent responds with natural voice\n    99→6. Check agent logs: `lk agent logs --follow`\n   100→\n   101→**End-to-End Test:**\n   102→```bash\n   103→# Terminal 1: Monitor agent logs\n   104→lk agent logs --follow\n   105→\n   106→# Terminal 2: Run frontend\n   107→cd /path/to/frontend\n   108→pnpm dev\n   109→\n   110→# Browser: Visit http://localhost:3000, connect, and speak\n   111→```\n   112→\n   113→## What We're NOT Doing\n   114→\n   115→**Out of Scope:**\n   116→- Multiple agent types or agent selection UI\n   117→- User authentication/login system (anonymous users only)\n   118→- Database integration or conversation history storage\n   119→- Multi-language support (English only initially)\n   120→- iOS/Android native apps (web only)\n   121→- Custom voice customization UI\n   122→- Payment integration or usage metering\n   123→- Advanced analytics dashboard\n   124→- Server-side rendering (SSR) for the voice interface\n   125→- Custom WebRTC infrastructure (using LiveKit Cloud)\n   126→\n   127→**Future Considerations:**\n   128→- User accounts and saved conversations\n   129→- Analytics and usage tracking\n   130→- Custom domain with branding\n   131→- A/B testing different agent configurations\n   132→- Rate limiting and abuse prevention\n   133→\n   134→## Implementation Approach\n   135→\n   136→### High-Level Strategy\n   137→\n   138→1. **Deploy Agent First:** Ensure the Python agent is running on LiveKit Cloud before building frontend\n   139→2. **Use Official Template:** Start with agent-starter-react to avoid reinventing the wheel\n   140→3. **Iterative Testing:** Test each phase independently before proceeding\n   141→4. **Security-First:** Never expose API secrets; use environment variables and server-side token generation\n   142→5. **Quick Validation:** Use LiveKit Agents Playground first to verify agent works before building frontend\n   143→\n   144→### Technology Stack\n   145→\n   146→**Backend (Agent):**\n   147→- Python 3.11+\n   148→- LiveKit Agents SDK\n   149→- OpenAI GPT-4 (LLM)\n   150→- AssemblyAI (STT)\n   151→- Cartesia (TTS)\n   152→- Deployed to: LiveKit Cloud\n   153→\n   154→**Frontend:**\n   155→- Next.js 14+ (App Router)\n   156→- React 18+\n   157→- TypeScript\n   158→- Tailwind CSS\n   159→- Shadcn/ui components\n   160→- `livekit-client` SDK\n   161→- `@livekit/components-react`\n   162→- Deployed to: Vercel\n   163→\n   164→**Authentication:**\n   165→- JWT tokens (livekit-server-sdk)\n   166→- Server-side generation (Next.js API routes)\n   167→- 2-hour token expiration\n   168→\n   169→## Dependencies\n   170→\n   171→**Execution Order:**\n   172→\n   173→1. Phase 1: Agent Deployment (no dependencies)\n   174→2. Phase 2: Frontend Setup (depends on Phase 1 for credentials)\n   175→3. Phase 3: Authentication (depends on Phase 2)\n   176→4. Phase 4: Connection Testing (depends on Phases 1-3)\n   177→5. Phase 5: Frontend Customization (depends on Phase 4)\n   178→6. Phase 6: Production Deployment (depends on Phase 5)\n   179→\n   180→**Dependency Graph:**\n   181→\n   182→```\n   183→Phase 1 (Agent Deployment)\n   184→  └─> Phase 2 (Frontend Setup)\n   185→        └─> Phase 3 (Authentication)\n   186→              └─> Phase 4 (Testing)\n   187→                    └─> Phase 5 (Customization)\n   188→                          └─> Phase 6 (Production)\n   189→```\n   190→\n   191→**Parallelization:**\n   192→- All phases are sequential due to dependencies\n   193→- Within each phase, independent tasks can run in parallel\n   194→\n   195→---\n   196→\n   197→## Phase 1: Agent Deployment to LiveKit Cloud\n   198→\n   199→### Overview\n   200→\n   201→Deploy the Python voice AI agent to LiveKit Cloud to make it accessible via WebRTC. This creates a running agent that can be dispatched to rooms when users connect.\n   202→\n   203→### Context\n   204→\n   205→Before starting, ensure you have:\n   206→- LiveKit CLI installed: `brew install livekit/livekit/livekit-cli`\n   207→- LiveKit Cloud account at https://cloud.livekit.io\n   208→- Agent code in `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1`\n   209→- API keys in `.env.local` (OpenAI, AssemblyAI, Cartesia)\n   210→\n   211→Files to review:\n   212→- `docs/DEPLOYMENT.md` - Complete deployment guide\n   213→- `.env.local` - API keys and secrets\n   214→- `Dockerfile` - Container build configuration\n   215→- `src/app.py` - Agent entry point\n   216→\n   217→### Dependencies\n   218→\n   219→**Depends on:** None (first phase)\n   220→\n   221→**Required by:** Phase 2 (Frontend needs LiveKit credentials), Phase 4 (Testing needs deployed agent)\n   222→\n   223→### Changes Required\n   224→\n   225→#### 1.1: Authenticate with LiveKit Cloud\n   226→\n   227→**What:** Link your CLI to your LiveKit Cloud account\n   228→\n   229→**Command:**\n   230→```bash\n   231→lk cloud auth\n   232→```\n   233→\n   234→**Expected Outcome:**\n   235→- Browser opens for authentication\n   236→- CLI displays: \"Successfully authenticated with LiveKit Cloud\"\n   237→- Credentials saved in `~/.livekit/credentials`\n   238→\n   239→**Rationale:** Required for all subsequent `lk` CLI commands\n   240→\n   241→---\n   242→\n   243→#### 1.2: Create or Select LiveKit Project\n   244→\n   245→**What:** Create a new project or select an existing one for the agent deployment\n   246→\n   247→**Commands:**\n   248→```bash\n   249→# List existing projects\n   250→lk project list\n   251→\n   252→# Option A: Use existing project\n   253→lk project set-default \"your-project-name\"\n   254→\n   255→# Option B: Create new project via dashboard\n   256→# Visit https://cloud.livekit.io and create a new project\n   257→# Then set as default: lk project set-default \"new-project-name\"\n   258→\n   259→# Verify current project\n   260→lk project current\n   261→```\n   262→\n   263→**Expected Outcome:**\n   264→```\n   265→NAME                 PROJECT_ID\n   266→your-project-name   prj_abc123\n   267→```\n   268→\n   269→**Rationale:** Agent deployments are scoped to projects; need a target project first\n   270→\n   271→---\n   272→\n   273→#### 1.3: Verify Secrets File\n   274→\n   275→**What:** Ensure `.env.local` contains all required API keys\n   276→\n   277→**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/.env.local`\n   278→\n   279→**Verify contents:**\n   280→```bash\n   281→cat .env.local\n   282→```\n   283→\n   284→**Required secrets:**\n   285→```env\n   286→OPENAI_API_KEY=sk-...\n   287→ASSEMBLYAI_API_KEY=...\n   288→CARTESIA_API_KEY=...\n   289→```\n   290→\n   291→**Important Notes:**\n   292→- Do NOT include `LIVEKIT_URL`, `LIVEKIT_API_KEY`, or `LIVEKIT_API_SECRET` in `.env.local`\n   293→- LiveKit Cloud auto-injects these during deployment\n   294→- Verify `.env.local` is in `.gitignore`\n   295→\n   296→**Rationale:** Agent needs these API keys to function; LiveKit Cloud encrypts and injects them as environment variables\n   297→\n   298→---\n   299→\n   300→#### 1.4: Download Model Files\n   301→\n   302→**What:** Download required models (Silero VAD, turn detector) before deployment\n   303→\n   304→**Command:**\n   305→```bash\n   306→cd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\n   307→uv run python src/app.py download-files\n   308→```\n   309→\n   310→**Expected Outcome:**\n   311→```\n   312→Downloading Silero VAD model...\n   313→Downloading multilingual turn detector model...\n   314→Download complete.\n   315→```\n   316→\n   317→**Rationale:** Models are required at runtime; downloading during build ensures faster agent startup\n   318→\n   319→---\n   320→\n   321→#### 1.5: Deploy Agent to LiveKit Cloud\n   322→\n   323→**What:** Create and deploy the agent container to LiveKit Cloud\n   324→\n   325→**Command:**\n   326→```bash\n   327→cd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\n   328→lk agent create --secrets-file .env.local\n   329→```\n   330→\n   331→**Expected Outcome:**\n   332→```\n   333→Registering agent...\n   334→Agent ID: agent_abc123\n   335→Building container image...\n   336→Uploading code...\n   337→Build in progress (this may take 2-5 minutes)...\n   338→Build complete.\n   339→Deploying agent...\n   340→Deployment successful.\n   341→Status: Running\n   342→Replicas: 2/2 ready\n   343→```\n   344→\n   345→**What Happens:**\n   346→1. CLI registers new agent with Cloud project\n   347→2. Assigns unique agent ID (e.g., `agent_abc123`)\n   348→3. Creates/updates `livekit.toml` configuration file\n   349→4. Uploads source code to LiveKit build service\n   350→5. Builds Docker container from `Dockerfile`\n   351→6. Deploys container to Cloud project\n   352→7. Encrypts and injects secrets as environment variables\n   353→8. Starts 2 replica instances\n   354→\n   355→**Duration:** 2-5 minutes for initial build\n   356→\n   357→**Rationale:** Makes agent accessible via LiveKit's global WebRTC infrastructure\n   358→\n   359→---\n   360→\n   361→#### 1.6: Verify Agent Status\n   362→\n   363→**What:** Confirm agent is running and ready to accept sessions\n   364→\n   365→**Commands:**\n   366→```bash\n   367→# Check agent status\n   368→lk agent status\n   369→\n   370→# View live logs\n   371→lk agent logs --tail 50\n   372→```\n   373→\n   374→**Expected Status Output:**\n   375→```\n   376→Agent ID:     agent_abc123\n   377→Status:       Running\n   378→Replicas:     2/2 ready\n   379→Version:      v1\n   380→Last Deploy:  2026-01-25 10:30:00 UTC\n   381→Region:       us-west-2\n   382→```\n   383→\n   384→**Expected Log Output:**\n   385→- No error messages\n   386→- Successful initialization messages\n   387→- \"Waiting for room assignment\" or similar\n   388→\n   389→**Troubleshooting:**\n   390→- If status is `CrashLoop`: Check logs for Python exceptions\n   391→- If status is `Build Failed`: Run `lk agent logs --build` to see build errors\n   392→- If secrets missing: Run `lk agent secrets` to verify\n   393→\n   394→**Rationale:** Ensures agent is healthy before proceeding to frontend setup\n   395→\n   396→---\n   397→\n   398→#### 1.7: Quick Test with Agents Playground\n   399→\n   400→**What:** Test agent using LiveKit Agents Playground (no code required)\n   401→\n   402→**Steps:**\n   403→1. Get project credentials:\n   404→   ```bash\n   405→   lk project current --json\n   406→   ```\n   407→\n   408→2. Visit https://agents-playground.livekit.io/\n   409→\n   410→3. Enter credentials:\n   411→   - **LiveKit URL:** `wss://your-project.livekit.cloud` (from JSON output)\n   412→   - **API Key:** Your `LIVEKIT_API_KEY` (from JSON output)\n   413→   - **API Secret:** Your `LIVEKIT_API_SECRET` (from JSON output)\n   414→\n   415→4. Click \"Connect\"\n   416→\n   417→5. Allow microphone access when prompted\n   418→\n   419→6. Speak to your agent\n   420→\n   421→7. Monitor agent logs in terminal:\n   422→   ```bash\n   423→   lk agent logs --follow\n   424→   ```\n   425→\n   426→**Expected Outcome:**\n   427→- Agent responds to your voice with natural TTS\n   428→- Logs show STT transcriptions, LLM responses, TTS generation\n   429→- No errors in logs\n   430→\n   431→**Rationale:** Validates agent works end-to-end before investing in frontend development\n   432→\n   433→---\n   434→\n   435→#### 1.8: Save LiveKit Credentials\n   436→\n   437→**What:** Export LiveKit project credentials for frontend configuration\n   438→\n   439→**Command:**\n   440→```bash\n   441→lk project current --json > livekit-credentials.json\n   442→```\n   443→\n   444→**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/livekit-credentials.json`\n   445→\n   446→**Expected Contents:**\n   447→```json\n   448→{\n   449→  \"name\": \"your-project-name\",\n   450→  \"url\": \"wss://your-project.livekit.cloud\",\n   451→  \"api_key\": \"APIxxxxxxxxxxxx\",\n   452→  \"api_secret\": \"your-secret-here\"\n   453→}\n   454→```\n   455→\n   456→**Security Note:**\n   457→- Add `livekit-credentials.json` to `.gitignore`\n   458→- NEVER commit this file to version control\n   459→- This file is for local reference only\n   460→\n   461→**Rationale:** Frontend needs these credentials to generate tokens and connect to LiveKit\n   462→\n   463→---\n   464→\n   465→### Success Criteria\n   466→\n   467→#### Automated Verification:\n   468→\n   469→- [ ] CLI authenticated: `lk cloud auth` successful\n   470→- [ ] Project selected: `lk project current` shows correct project\n   471→- [ ] Agent deployed: `lk agent status` shows `Status: Running`\n   472→- [ ] Replicas ready: `lk agent status` shows `X/X ready` (e.g., 2/2)\n   473→- [ ] No crash loops: `lk agent logs --tail 50` shows no errors\n   474→- [ ] Credentials saved: `livekit-credentials.json` exists and contains valid JSON\n   475→\n   476→#### Manual Verification:\n   477→\n   478→- [ ] Agents Playground connection successful\n   479→- [ ] Agent responds to voice input with TTS output\n   480→- [ ] Agent logs show successful STT → LLM → TTS pipeline\n   481→- [ ] No API key errors in logs\n   482→- [ ] Agent state transitions visible (initializing → listening → thinking → speaking)\n   483→\n   484→**Verify:** After completing automated verification, test agent with Agents Playground before proceeding to Phase 2.\n   485→\n   486→---\n   487→\n   488→## Phase 2: Frontend Setup (agent-starter-react)\n   489→\n   490→### Overview\n   491→\n   492→Clone and configure the agent-starter-react template to create a Next.js web application that connects users to your deployed agent.\n   493→\n   494→### Context\n   495→\n   496→Before starting, ensure:\n   497→- Phase 1 completed successfully\n   498→- Agent is running on LiveKit Cloud\n   499→- `livekit-credentials.json` file exists with credentials\n   500→\n   501→Prerequisites:\n   502→- Node.js 18+ installed\n   503→- pnpm installed: `npm install -g pnpm`\n   504→- `lk` CLI authenticated\n   505→\n   506→Files to review:\n   507→- `livekit-credentials.json` - LiveKit project credentials\n   508→- N/A (frontend doesn't exist yet)\n   509→\n   510→### Dependencies\n   511→\n   512→**Depends on:** Phase 1 (needs LiveKit credentials)\n   513→\n   514→**Required by:** Phase 3 (authentication setup), Phase 4 (connection testing)\n   515→\n   516→### Changes Required\n   517→\n   518→#### 2.1: Create Frontend Project Directory\n   519→\n   520→**What:** Create a directory to house the frontend application\n   521→\n   522→**Commands:**\n   523→```bash\n   524→cd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\n   525→mkdir -p frontend\n   526→cd frontend\n   527→```\n   528→\n   529→**Expected Outcome:**\n   530→```\n   531→Directory created: /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/\n   532→```\n   533→\n   534→**Rationale:** Separates frontend code from agent backend code\n   535→\n   536→---\n   537→\n   538→#### 2.2: Clone agent-starter-react Template\n   539→\n   540→**What:** Use LiveKit CLI to create a new project from the official template\n   541→\n   542→**Command:**\n   543→```bash\n   544→cd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend\n   545→lk app create --template agent-starter-react\n   546→```\n   547→\n   548→**Interactive Prompts:**\n   549→- **Project name:** (Press Enter for default or enter custom name like \"voice-ai-frontend\")\n   550→- **Install dependencies?** Yes\n   551→\n   552→**Alternative (Manual Clone):**\n   553→```bash\n   554→git clone https://github.com/livekit-examples/agent-starter-react.git voice-ai-frontend\n   555→cd voice-ai-frontend\n   556→pnpm install\n   557→```\n   558→\n   559→**Expected Outcome:**\n   560→```\n   561→✓ Created project: voice-ai-frontend\n   562→✓ Installed dependencies\n   563→✓ Ready to configure\n   564→```\n   565→\n   566→**Directory Structure:**\n   567→```\n   568→frontend/voice-ai-frontend/\n   569→├── app/\n   570→│   ├── api/token/route.ts     # Token generation endpoint\n   571→│   ├── page.tsx               # Main page\n   572→│   └── layout.tsx\n   573→├── components/\n   574→│   ├── agents-ui/             # Agents UI components\n   575→│   ├── app/                   # Business logic\n   576→│   └── ui/                    # Shadcn/ui primitives\n   577→├── hooks/\n   578→├── lib/\n   579→├── public/\n   580→├── package.json\n   581→├── .env.example\n   582→└── next.config.js\n   583→```\n   584→\n   585→**Rationale:** Official template provides production-ready structure with all necessary LiveKit integrations\n   586→\n   587→---\n   588→\n   589→#### 2.3: Configure Environment Variables\n   590→\n   591→**What:** Set up LiveKit credentials for the frontend\n   592→\n   593→**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend/.env.local`\n   594→\n   595→**Commands:**\n   596→```bash\n   597→cd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\n   598→cp .env.example .env.local\n   599→```\n   600→\n   601→**Edit `.env.local`:**\n   602→```env\n   603→# LiveKit project credentials (from livekit-credentials.json)\n   604→LIVEKIT_API_KEY=APIxxxxxxxxxxxx\n   605→LIVEKIT_API_SECRET=your-secret-here\n   606→LIVEKIT_URL=wss://your-project.livekit.cloud\n   607→\n   608→# Public URL (exposed to browser - same as LIVEKIT_URL)\n   609→NEXT_PUBLIC_LIVEKIT_URL=wss://your-project.livekit.cloud\n   610→\n   611→# Agent configuration\n   612→AGENT_NAME=\n   613→# Leave AGENT_NAME blank for automatic agent dispatch\n   614→# Or set to specific agent name if you have multiple agents\n   615→```\n   616→\n   617→**How to Get Values:**\n   618→```bash\n   619→# Copy from livekit-credentials.json\n   620→cat /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/livekit-credentials.json\n   621→```\n   622→\n   623→**Security Notes:**\n   624→- `LIVEKIT_API_SECRET` is server-side only (never exposed to browser)\n   625→- `NEXT_PUBLIC_*` variables are exposed to browser\n   626→- Only `NEXT_PUBLIC_LIVEKIT_URL` should be public\n   627→- Never expose `LIVEKIT_API_KEY` or `LIVEKIT_API_SECRET` to browser\n   628→\n   629→**Rationale:** Frontend needs credentials to generate tokens and connect to LiveKit rooms\n   630→\n   631→---\n   632→\n   633→#### 2.4: Verify Dependencies Installation\n   634→\n   635→**What:** Ensure all npm packages are installed correctly\n   636→\n   637→**Command:**\n   638→```bash\n   639→cd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\n   640→pnpm install\n   641→```\n   642→\n   643→**Expected Outcome:**\n   644→```\n   645→Packages: +XXX\n   646→Progress: resolved XXX, reused XXX, downloaded X, added XXX, done\n   647→```\n   648→\n   649→**Key Dependencies (verify in `package.json`):**\n   650→- `next` (v14+)\n   651→- `react` (v18+)\n   652→- `livekit-client`\n   653→- `@livekit/components-react`\n   654→- `livekit-server-sdk`\n   655→- `tailwindcss`\n   656→- `typescript`\n   657→\n   658→**Troubleshooting:**\n   659→- If pnpm not installed: `npm install -g pnpm`\n   660→- If peer dependency warnings: Generally safe to ignore\n   661→- If install fails: Delete `node_modules` and `pnpm-lock.yaml`, retry\n   662→\n   663→**Rationale:** Ensures all required packages are available for development\n   664→\n   665→---\n   666→\n   667→#### 2.5: Run Development Server\n   668→\n   669→**What:** Start the Next.js development server to verify basic setup\n   670→\n   671→**Command:**\n   672→```bash\n   673→cd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\n   674→pnpm dev\n   675→```\n   676→\n   677→**Expected Outcome:**\n   678→```\n   679→> next dev\n   680→\n   681→  ▲ Next.js 14.x.x\n   682→  - Local:        http://localhost:3000\n   683→  - Environments: .env.local\n   684→\n   685→ ✓ Ready in X.Xs\n   686→```\n   687→\n   688→**Verification:**\n   689→1. Open browser to http://localhost:3000\n   690→2. Should see agent interface with \"Connect\" button\n   691→3. No console errors in browser DevTools\n   692→4. Page loads without 500 errors\n   693→\n   694→**Expected UI:**\n   695→- Welcome/landing view\n   696→- \"Connect\" or \"Start Session\" button\n   697→- Logo and branding elements\n   698→- Theme toggle (light/dark)\n   699→\n   700→**Troubleshooting:**\n   701→- If port 3000 in use: `pnpm dev -- -p 3001`\n   702→- If env vars missing: Check `.env.local` exists and has correct values\n   703→- If build errors: Check `pnpm install` completed successfully\n   704→\n   705→**Rationale:** Validates Next.js setup before proceeding to authentication\n   706→\n   707→---\n   708→\n   709→#### 2.6: Inspect Token Generation API Route\n   710→\n   711→**What:** Review the built-in token generation endpoint to understand how authentication works\n   712→\n   713→**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend/app/api/token/route.ts`\n   714→\n   715→**Read the file:**\n   716→```typescript\n   717→// Expected structure (review actual implementation)\n   718→import { AccessToken } from 'livekit-server-sdk';\n   719→\n   720→export async function POST(request: Request) {\n   721→  const { roomName, participantName } = await request.json();\n   722→\n   723→  const token = new AccessToken(\n   724→    process.env.LIVEKIT_API_KEY,\n   725→    process.env.LIVEKIT_API_SECRET,\n   726→    {\n   727→      identity: participantName,\n   728→      ttl: '2h', // Token valid for 2 hours\n   729→    }\n   730→  );\n   731→\n   732→  token.addGrant({\n   733→    room: roomName,\n   734→    roomJoin: true,\n   735→    canPublish: true,\n   736→    canSubscribe: true,\n   737→  });\n   738→\n   739→  return Response.json({ token: await token.toJwt() });\n   740→}\n   741→```\n   742→\n   743→**Key Points:**\n   744→- Uses `livekit-server-sdk` to generate JWT tokens\n   745→- Reads `LIVEKIT_API_KEY` and `LIVEKIT_API_SECRET` from environment\n   746→- Grants room join, publish, and subscribe permissions\n   747→- Returns JWT token to frontend\n   748→- Token expires after 2 hours (LiveKit auto-refreshes for connected clients)\n   749→\n   750→**Security Review:**\n   751→- ✓ API key/secret are server-side only (not exposed to browser)\n   752→- ✓ Token generation happens on server\n   753→- ✓ Appropriate permissions granted\n   754→- ⚠ Consider adding rate limiting for production\n   755→\n   756→**Rationale:** Understanding token flow is critical for debugging connection issues\n   757→\n   758→---\n   759→\n   760→#### 2.7: Add Frontend to .gitignore (Backend Repo)\n   761→\n   762→**What:** Prevent frontend from being committed to agent backend repo\n   763→\n   764→**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/.gitignore`\n   765→\n   766→**Add to `.gitignore`:**\n   767→```bash\n   768→echo \"frontend/\" >> .gitignore\n   769→```\n   770→\n   771→**Verify:**\n   772→```bash\n   773→git status\n   774→# frontend/ should not appear in untracked files\n   775→```\n   776→\n   777→**Alternative Approach:**\n   778→If you want to commit the frontend to the same repo:\n   779→- Create a separate `.gitignore` in `frontend/voice-ai-frontend/`\n   780→- Add standard Next.js ignores (`.next/`, `node_modules/`, `.env.local`)\n   781→\n   782→**Rationale:** Keep frontend and backend as separate concerns, or manage carefully if in same repo\n   783→\n   784→---\n   785→\n   786→### Success Criteria\n   787→\n   788→#### Automated Verification:\n   789→\n   790→- [ ] Frontend directory created: `ls frontend/voice-ai-frontend`\n   791→- [ ] Dependencies installed: `pnpm list --depth=0` shows key packages\n   792→- [ ] Environment variables configured: `cat .env.local | grep LIVEKIT_API_KEY`\n   793→- [ ] Development server starts: `pnpm dev` runs without errors\n   794→- [ ] No TypeScript errors: `pnpm run build` completes successfully\n   795→\n   796→#### Manual Verification:\n   797→\n   798→- [ ] Visit http://localhost:3000 in browser\n   799→- [ ] Page loads without 500 errors\n   800→- [ ] UI displays welcome screen with \"Connect\" button\n   801→- [ ] No console errors in browser DevTools\n   802→- [ ] Theme toggle works (light/dark mode)\n   803→- [ ] Responsive design works on mobile viewport\n   804→\n   805→**Verify:** After completing automated verification, open the app in a browser and verify UI loads correctly before proceeding to Phase 3.\n   806→\n   807→---\n   808→\n   809→## Phase 3: Authentication and Token Generation\n   810→\n   811→### Overview\n   812→\n   813→Configure and test the JWT token generation flow to ensure frontend can authenticate users with LiveKit and connect them to agent sessions.\n   814→\n   815→### Context\n   816→\n   817→Before starting, ensure:\n   818→- Phase 2 completed successfully\n   819→- Development server running at http://localhost:3000\n   820→- Environment variables configured in `.env.local`\n   821→\n   822→Files to review:\n   823→- `frontend/voice-ai-frontend/app/api/token/route.ts` - Token generation endpoint\n   824→- `frontend/voice-ai-frontend/.env.local` - Environment configuration\n   825→- `frontend/voice-ai-frontend/components/app/` - Client-side connection logic\n   826→\n   827→### Dependencies\n   828→\n   829→**Depends on:** Phase 2 (frontend setup)\n   830→\n   831→**Required by:** Phase 4 (connection testing)\n   832→\n   833→### Changes Required\n   834→\n   835→#### 3.1: Test Token Generation Endpoint\n   836→\n   837→**What:** Verify the token API endpoint works correctly\n   838→\n   839→**Command:**\n   840→```bash\n   841→# Start dev server (if not running)\n   842→cd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\n   843→pnpm dev\n   844→\n   845→# In another terminal, test the endpoint\n   846→curl -X POST http://localhost:3000/api/token \\\n   847→  -H \"Content-Type: application/json\" \\\n   848→  -d '{\"roomName\": \"test-room\", \"participantName\": \"test-user\"}'\n   849→```\n   850→\n   851→**Expected Response:**\n   852→```json\n   853→{\n   854→  \"token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\"\n   855→}\n   856→```\n   857→\n   858→**Validate Token:**\n   859→```bash\n   860→# Decode the JWT to inspect claims (copy token from response)\n   861→echo \"eyJhbGciOiJ...\" | cut -d'.' -f2 | base64 -d | jq\n   862→```\n   863→\n   864→**Expected Token Payload:**\n   865→```json\n   866→{\n   867→  \"exp\": 1234567890,\n   868→  \"iss\": \"APIxxxxxxxxxxxx\",\n   869→  \"sub\": \"test-user\",\n   870→  \"nbf\": 1234567890,\n   871→  \"video\": {\n   872→    \"room\": \"test-room\",\n   873→    \"roomJoin\": true,\n   874→    \"canPublish\": true,\n   875→    \"canSubscribe\": true,\n   876→    \"canPublishData\": true\n   877→  }\n   878→}\n   879→```\n   880→\n   881→**Troubleshooting:**\n   882→- If 500 error: Check environment variables in `.env.local`\n   883→- If \"api_key undefined\": Verify `LIVEKIT_API_KEY` is set\n   884→- If \"invalid signature\": Check `LIVEKIT_API_SECRET` is correct\n   885→- If no response: Verify dev server is running on port 3000\n   886→\n   887→**Rationale:** Token generation must work before attempting to connect to LiveKit\n   888→\n   889→---\n   890→\n   891→#### 3.2: Review Client-Side Connection Logic\n   892→\n   893→**What:** Understand how the frontend connects to LiveKit rooms\n   894→\n   895→**Files to Review:**\n   896→```bash\n   897→# Main session component\n   898→cat frontend/voice-ai-frontend/components/app/session-view.tsx\n   899→\n   900→# View controller\n   901→cat frontend/voice-ai-frontend/components/app/view-controller.tsx\n   902→\n   903→# Connection utilities\n   904→cat frontend/voice-ai-frontend/lib/connection.ts\n   905→```\n   906→\n   907→**Key Flow:**\n   908→1. User clicks \"Connect\" button\n   909→2. Frontend generates room name (random or predefined)\n   910→3. Frontend fetches token from `/api/token` endpoint\n   911→4. Frontend connects to LiveKit room using `livekit-client`\n   912→5. Agent is automatically dispatched to room\n   913→6. User and agent establish WebRTC connection\n   914→7. Audio tracks are exchanged\n   915→\n   916→**Important Variables:**\n   917→- `NEXT_PUBLIC_LIVEKIT_URL` - LiveKit server URL (browser-accessible)\n   918→- Room name generation logic\n   919→- Participant name/identity\n   920→- Agent dispatch configuration\n   921→\n   922→**Rationale:** Understanding client-side logic helps debug connection issues\n   923→\n   924→---\n   925→\n   926→#### 3.3: Configure Agent Dispatch\n   927→\n   928→**What:** Ensure frontend triggers automatic agent dispatch when users connect\n   929→\n   930→**File:** Review `frontend/voice-ai-frontend/app/api/connection-details/route.ts` (if exists) or equivalent\n   931→\n   932→**Verify Agent Name Configuration:**\n   933→\n   934→**Option A: Automatic Dispatch (Recommended):**\n   935→```env\n   936→# In .env.local\n   937→AGENT_NAME=\n   938→# Blank means \"dispatch any available agent\"\n   939→```\n   940→\n   941→**Option B: Specific Agent:**\n   942→```env\n   943→# In .env.local\n   944→AGENT_NAME=agent_abc123\n   945→# Uses specific agent by ID or name\n   946→```\n   947→\n   948→**Check Token Grant Configuration:**\n   949→```typescript\n   950→// In app/api/token/route.ts or connection-details/route.ts\n   951→token.addGrant({\n   952→  room: roomName,\n   953→  roomJoin: true,\n   954→  canPublish: true,\n   955→  canSubscribe: true,\n   956→  // Optional: Agent dispatch configuration\n   957→});\n   958→```\n   959→\n   960→**For agent-starter-react:**\n   961→The template typically handles agent dispatch automatically when a participant joins a room. Verify this by checking the token generation code and connection details endpoint.\n   962→\n   963→**Rationale:** Agent won't join room unless dispatch is configured correctly\n   964→\n   965→---\n   966→\n   967→#### 3.4: Test Token Expiration and Refresh\n   968→\n   969→**What:** Verify token expiration is set correctly and LiveKit handles refresh\n   970→\n   971→**Check Current TTL:**\n   972→```typescript\n   973→// In app/api/token/route.ts\n   974→const token = new AccessToken(\n   975→  process.env.LIVEKIT_API_KEY,\n   976→  process.env.LIVEKIT_API_SECRET,\n   977→  {\n   978→    identity: participantName,\n   979→    ttl: '2h', // Current setting\n   980→  }\n   981→);\n   982→```\n   983→\n   984→**Recommended TTL:**\n   985→- Development: `2h` (2 hours)\n   986→- Production: `2h` (LiveKit auto-refreshes for connected clients)\n   987→- Pre-generated tokens: `1h` (if caching tokens)\n   988→\n   989→**Token Refresh Behavior:**\n   990→- LiveKit client SDK automatically refreshes tokens before expiration\n   991→- Refresh happens for connected clients only\n   992→- Disconnected users must request new tokens\n   993→\n   994→**No changes needed if TTL is already `2h`.**\n   995→\n   996→**Rationale:** Prevents users from being disconnected due to token expiration\n   997→\n   998→---\n   999→\n  1000→#### 3.5: Add Security Headers (Optional but Recommended)\n  1001→\n  1002→**What:** Add security headers to token API route\n  1003→\n  1004→**File:** `frontend/voice-ai-frontend/middleware.ts` (create if doesn't exist)\n  1005→\n  1006→**Content:**\n  1007→```typescript\n  1008→import { NextResponse } from 'next/server';\n  1009→import type { NextRequest } from 'next/server';\n  1010→\n  1011→export function middleware(request: NextRequest) {\n  1012→  const response = NextResponse.next();\n  1013→\n  1014→  // Security headers\n  1015→  response.headers.set('X-Content-Type-Options', 'nosniff');\n  1016→  response.headers.set('X-Frame-Options', 'DENY');\n  1017→  response.headers.set('X-XSS-Protection', '1; mode=block');\n  1018→\n  1019→  return response;\n  1020→}\n  1021→\n  1022→export const config = {\n  1023→  matcher: '/api/:path*',\n  1024→};\n  1025→```\n  1026→\n  1027→**Optional Rate Limiting:**\n  1028→Consider adding rate limiting to `/api/token` endpoint to prevent abuse.\n  1029→\n  1030→**Rationale:** Basic security hardening for production deployments\n  1031→\n  1032→---\n  1033→\n  1034→### Success Criteria\n  1035→\n  1036→#### Automated Verification:\n  1037→\n  1038→- [ ] Token endpoint returns valid JWT: `curl -X POST http://localhost:3000/api/token -H \"Content-Type: application/json\" -d '{\"roomName\":\"test\",\"participantName\":\"user\"}' | jq .token`\n  1039→- [ ] Token payload contains correct claims: Decode JWT and verify `video.roomJoin: true`\n  1040→- [ ] Environment variables loaded: `console.log(process.env.LIVEKIT_API_KEY)` in token route shows value (not undefined)\n  1041→- [ ] Token has correct expiration: Decoded JWT shows `exp` timestamp 2 hours in future\n  1042→\n  1043→#### Manual Verification:\n  1044→\n  1045→- [ ] Token endpoint accessible via browser: Visit http://localhost:3000/api/token (should return 405 Method Not Allowed for GET)\n  1046→- [ ] No errors in Next.js server logs when generating tokens\n  1047→- [ ] Token decodes successfully at https://jwt.io\n  1048→- [ ] Token issuer (`iss`) matches your LiveKit API key\n  1049→- [ ] Token subject (`sub`) matches requested participant name\n  1050→\n  1051→**Verify:** After completing automated verification, test token generation with curl and decode the JWT to inspect claims before proceeding to Phase 4.\n  1052→\n  1053→---\n  1054→\n  1055→## Phase 4: Connection Testing and Optimization\n  1056→\n  1057→### Overview\n  1058→\n  1059→Test the end-to-end connection flow from frontend to agent, verify audio works correctly, and optimize the connection speed.\n  1060→\n  1061→### Context\n  1062→\n  1063→Before starting, ensure:\n  1064→- Phase 3 completed successfully\n  1065→- Agent running on LiveKit Cloud (`lk agent status` shows Running)\n  1066→- Frontend running at http://localhost:3000\n  1067→- Token generation working\n  1068→\n  1069→Files to review:\n  1070→- `frontend/voice-ai-frontend/components/app/session-view.tsx` - Session management\n  1071→- `frontend/voice-ai-frontend/components/agents-ui/` - UI components\n  1072→\n  1073→Tools needed:\n  1074→- Browser with microphone access\n  1075→- Terminal for monitoring agent logs\n  1076→\n  1077→### Dependencies\n  1078→\n  1079→**Depends on:** Phases 1-3 (agent deployed, frontend configured, authentication working)\n  1080→\n  1081→**Required by:** Phase 5 (customization), Phase 6 (production deployment)\n  1082→\n  1083→### Changes Required\n  1084→\n  1085→#### 4.1: Monitor Agent Logs\n  1086→\n  1087→**What:** Start monitoring agent logs before testing connection\n  1088→\n  1089→**Command:**\n  1090→```bash\n  1091→# Open a dedicated terminal window for agent logs\n  1092→lk agent logs --follow\n  1093→```\n  1094→\n  1095→**Keep this terminal open during all testing.**\n  1096→\n  1097→**What to Look For:**\n  1098→- Agent initialization messages\n  1099→- Room join events\n  1100→- STT transcriptions\n  1101→- LLM requests/responses\n  1102→- TTS generation\n  1103→- WebRTC connection events\n  1104→- Any error messages\n  1105→\n  1106→**Rationale:** Real-time logs are essential for debugging connection issues\n  1107→\n  1108→---\n  1109→\n  1110→#### 4.2: Test Basic Connection Flow\n  1111→\n  1112→**What:** Connect to the agent via frontend and verify basic functionality\n  1113→\n  1114→**Steps:**\n  1115→\n  1116→1. Open browser to http://localhost:3000\n  1117→2. Open browser DevTools Console (F12 → Console tab)\n  1118→3. Click \"Connect\" or \"Start Session\" button\n  1119→4. Grant microphone permissions when prompted\n  1120→5. Observe connection states in UI:\n  1121→   - \"Initializing...\"\n  1122→   - \"Listening\" (agent ready for input)\n  1123→   - \"Thinking\" (processing speech)\n  1124→   - \"Speaking\" (agent responding)\n  1125→\n  1126→**Expected Behavior:**\n  1127→- Connection establishes within 3-5 seconds\n  1128→- Agent state transitions to \"Listening\"\n  1129→- No errors in browser console\n  1130→- Agent logs show room join event\n  1131→\n  1132→**Troubleshooting:**\n  1133→- **Connection hangs:** Check token endpoint, verify LIVEKIT_URL is correct\n  1134→- **\"Failed to connect\":** Check agent status (`lk agent status`), verify agent is Running\n  1135→- **Microphone permission denied:** Grant permission in browser settings\n  1136→- **No audio:** Check browser audio output, verify speakers are enabled\n  1137→- **WebRTC errors:** Check firewall, ensure WebRTC ports not blocked\n  1138→\n  1139→**Rationale:** Validates basic connection before testing voice interaction\n  1140→\n  1141→---\n  1142→\n  1143→#### 4.3: Test Voice Interaction\n  1144→\n  1145→**What:** Verify end-to-end voice pipeline (STT → LLM → TTS)\n  1146→\n  1147→**Steps:**\n  1148→\n  1149→1. With frontend connected and agent in \"Listening\" state\n  1150→2. Speak clearly into your microphone: \"Hello, can you hear me?\"\n  1151→3. Observe agent state transition:\n  1152→   - \"Listening\" → \"Thinking\" → \"Speaking\"\n  1153→4. Listen for agent's voice response\n  1154→5. Check agent logs for:\n  1155→   - STT transcription of your speech\n  1156→   - LLM request and response\n  1157→   - TTS generation\n  1158→\n  1159→**Expected Outcome:**\n  1160→- Agent responds with natural voice within 2-4 seconds\n  1161→- Transcription appears in logs (if logging enabled)\n  1162→- No audio dropouts or distortion\n  1163→- Agent response is contextually appropriate\n  1164→\n  1165→**Additional Test Cases:**\n  1166→- **Interruption:** Speak while agent is speaking (should handle gracefully)\n  1167→- **Silence:** Wait 10 seconds without speaking (agent should remain connected)\n  1168→- **Background Noise:** Test with ambient noise (should filter with VAD)\n  1169→- **Multiple Turns:** Have a multi-turn conversation\n  1170→\n  1171→**Troubleshooting:**\n  1172→- **No transcription:** Check AssemblyAI API key in agent secrets\n  1173→- **No LLM response:** Check OpenAI API key, verify LLM model is available\n  1174→- **No TTS audio:** Check Cartesia API key, verify TTS voice model\n  1175→- **Garbled audio:** Check network connection, reduce network congestion\n  1176→- **High latency:** Check agent logs for slow API calls, consider region optimization\n  1177→\n  1178→**Rationale:** Validates the complete voice AI pipeline works end-to-end\n  1179→\n  1180→---\n  1181→\n  1182→#### 4.4: Verify Audio Visualization\n  1183→\n  1184→**What:** Test the audio visualizer component works correctly\n  1185→\n  1186→**Steps:**\n  1187→\n  1188→1. With frontend connected\n  1189→2. Speak into microphone\n  1190→3. Observe audio visualization:\n  1191→   - Bars should animate when you speak\n  1192→   - Bars should pulse when agent speaks\n  1193→   - Different colors/states for listening vs speaking\n  1194→\n  1195→**Expected Behavior:**\n  1196→- `BarVisualizer` component shows real-time audio levels\n  1197→- Smooth animations\n  1198→- Clear visual feedback of agent state\n  1199→- No lag between audio and visualization\n  1200→\n  1201→**Check Component:**\n  1202→```bash\n  1203→# Review visualizer component\n  1204→cat frontend/voice-ai-frontend/components/agents-ui/bar-visualizer.tsx\n  1205→```\n  1206→\n  1207→**Troubleshooting:**\n  1208→- **No visualization:** Check if audio track is being passed to component\n  1209→- **Choppy animation:** Check browser performance, reduce animation complexity\n  1210→- **Wrong colors:** Review CSS/Tailwind classes\n  1211→\n  1212→**Rationale:** Visual feedback improves user experience and debugging\n  1213→\n  1214→---\n  1215→\n  1216→#### 4.5: Test Disconnection and Reconnection\n  1217→\n  1218→**What:** Verify graceful disconnect and ability to reconnect\n  1219→\n  1220→**Steps:**\n  1221→\n  1222→**Test Disconnect:**\n  1223→1. With frontend connected\n  1224→2. Click \"Disconnect\" or \"End Session\" button\n  1225→3. Observe clean disconnect:\n  1226→   - Agent logs show participant left\n  1227→   - No error messages\n  1228→   - UI returns to welcome screen\n  1229→\n  1230→**Test Reconnect:**\n  1231→1. Click \"Connect\" again\n  1232→2. Verify new session starts successfully\n  1233→3. Test voice interaction again\n  1234→\n  1235→**Test Network Interruption (Optional):**\n  1236→1. While connected, disable network (Wi-Fi off)\n  1237→2. Observe reconnection behavior\n  1238→3. Re-enable network\n  1239→4. Verify auto-reconnect or error message\n  1240→\n  1241→**Expected Behavior:**\n  1242→- Clean disconnect without errors\n  1243→- Ability to reconnect immediately\n  1244→- Each session gets unique room/token\n  1245→- No lingering WebRTC connections\n  1246→\n  1247→**Rationale:** Ensures robust connection lifecycle management\n  1248→\n  1249→---\n  1250→\n  1251→#### 4.6: Optimize Connection Speed\n  1252→\n  1253→**What:** Reduce connection time from 3-5 seconds to <1 second using optimization techniques\n  1254→\n  1255→**Current Flow (Sequential):**\n  1256→```\n  1257→1. Click Connect (0ms)\n  1258→2. Fetch token from /api/token (500ms)\n  1259→3. Connect to LiveKit room (1000ms)\n  1260→4. Agent dispatched (1000ms)\n  1261→5. Agent connects and publishes (1500ms)\n  1262→Total: ~4000ms (4 seconds)\n  1263→```\n  1264→\n  1265→**Optimization 1: Pre-generate Tokens**\n  1266→\n  1267→Create a \"warm token\" approach for faster connection:\n  1268→\n  1269→**File:** Create `frontend/voice-ai-frontend/hooks/use-warm-token.ts`\n  1270→\n  1271→```typescript\n  1272→'use client';\n  1273→\n  1274→import { useState, useEffect } from 'react';\n  1275→\n  1276→export function useWarmToken() {\n  1277→  const [token, setToken] = useState<string | null>(null);\n  1278→\n  1279→  useEffect(() => {\n  1280→    // Pre-generate token on page load\n  1281→    async function generateToken() {\n  1282→      const response = await fetch('/api/token', {\n  1283→        method: 'POST',\n  1284→        headers: { 'Content-Type': 'application/json' },\n  1285→        body: JSON.stringify({\n  1286→          roomName: `room-${Date.now()}`,\n  1287→          participantName: `user-${Math.random().toString(36).substring(7)}`,\n  1288→        }),\n  1289→      });\n  1290→      const data = await response.json();\n  1291→      setToken(data.token);\n  1292→    }\n  1293→\n  1294→    generateToken();\n  1295→  }, []);\n  1296→\n  1297→  return token;\n  1298→}\n  1299→```\n  1300→\n  1301→**Usage in Session Component:**\n  1302→```typescript\n  1303→// In session-view.tsx or similar\n  1304→const warmToken = useWarmToken();\n  1305→\n  1306→// Use warmToken when connecting instead of fetching on-demand\n  1307→```\n  1308→\n  1309→**Optimization 2: Concurrent Dispatch**\n  1310→\n  1311→Modify connection logic to dispatch agent and connect user simultaneously:\n  1312→\n  1313→```typescript\n  1314→// Parallel connection\n  1315→const [roomConnection, agentDispatch] = await Promise.all([\n  1316→  connectToRoom(token),\n  1317→  dispatchAgent(roomName) // If manual dispatch required\n  1318→]);\n  1319→```\n  1320→\n  1321→**Expected Improvement:**\n  1322→- Pre-generated token: -500ms (eliminates token fetch delay)\n  1323→- Concurrent dispatch: -1000ms (parallel instead of sequential)\n  1324→- **New total:** ~2500ms → ~1500ms (1.5 seconds)\n  1325→\n  1326→**Trade-offs:**\n  1327→- Pre-generated tokens have expiration (ensure 2h TTL)\n  1328→- Unused tokens waste resources (minimal cost)\n  1329→- Complexity slightly increases\n  1330→\n  1331→**Rationale:** Faster connections improve user experience and perceived performance\n  1332→\n  1333→---\n  1334→\n  1335→#### 4.7: Test on Multiple Browsers\n  1336→\n  1337→**What:** Verify cross-browser compatibility\n  1338→\n  1339→**Browsers to Test:**\n  1340→- Chrome/Chromium\n  1341→- Firefox\n  1342→- Safari (macOS/iOS)\n  1343→- Edge\n  1344→\n  1345→**Test Matrix:**\n  1346→\n  1347→| Browser | Connection | Audio Input | Audio Output | Visualization |\n  1348→|---------|-----------|-------------|--------------|---------------|\n  1349→| Chrome  | ✓         | ✓           | ✓            | ✓             |\n  1350→| Firefox | ?         | ?           | ?            | ?             |\n  1351→| Safari  | ?         | ?           | ?            | ?             |\n  1352→| Edge    | ?         | ?           | ?            | ?             |\n  1353→\n  1354→**Common Issues:**\n  1355→- **Safari:** May require user interaction before audio playback\n  1356→- **Firefox:** Different WebRTC implementation, may have quirks\n  1357→- **Mobile Safari:** Requires specific audio context handling\n  1358→- **Edge:** Generally compatible with Chrome\n  1359→\n  1360→**Rationale:** Ensures wide browser support for production deployment\n  1361→\n  1362→---\n  1363→\n  1364→### Success Criteria\n  1365→\n  1366→#### Automated Verification:\n  1367→\n  1368→- [ ] Connection establishes successfully: Monitor for \"Room connected\" event in logs\n  1369→- [ ] Agent joins room: `lk agent logs` shows room join event\n  1370→- [ ] WebRTC connection: Browser DevTools Network tab shows WebRTC connections\n  1371→- [ ] No console errors: Browser DevTools Console shows no red errors\n  1372→- [ ] Audio tracks published: Check LiveKit Cloud dashboard for active tracks\n  1373→\n  1374→#### Manual Verification:\n  1375→\n  1376→- [ ] Voice input recognized: Speak and verify agent responds\n  1377→- [ ] Voice output works: Hear agent's TTS response clearly\n  1378→- [ ] Audio visualization animates correctly\n  1379→- [ ] Agent state transitions work (initializing → listening → thinking → speaking)\n  1380→- [ ] Interruption handling works (speak during agent response)\n  1381→- [ ] Disconnect and reconnect works cleanly\n  1382→- [ ] Connection time <3 seconds (before optimization) or <1.5s (after optimization)\n  1383→- [ ] Works in Chrome, Firefox, and Safari\n  1384→\n  1385→**Verify:** After completing automated verification, have a multi-turn conversation with the agent and test all edge cases before proceeding to Phase 5.\n  1386→\n  1387→---\n  1388→\n  1389→## Phase 5: Frontend Customization\n  1390→\n  1391→### Overview\n  1392→\n  1393→Customize the frontend with your branding, colors, logo, and company information to make it production-ready.\n  1394→\n  1395→### Context\n  1396→\n  1397→Before starting, ensure:\n  1398→- Phase 4 completed successfully\n  1399→- Voice interaction working end-to-end\n  1400→- Frontend running at http://localhost:3000\n  1401→\n  1402→Files to customize:\n  1403→- `frontend/voice-ai-frontend/app-config.ts` - Main configuration\n  1404→- `frontend/voice-ai-frontend/public/` - Static assets (logo, favicon)\n  1405→- `frontend/voice-ai-frontend/app/layout.tsx` - Page metadata\n  1406→- `frontend/voice-ai-frontend/tailwind.config.ts` - Theme colors\n  1407→\n  1408→### Dependencies\n  1409→\n  1410→**Depends on:** Phase 4 (connection testing completed)\n  1411→\n  1412→**Required by:** Phase 6 (production deployment)\n  1413→\n  1414→### Changes Required\n  1415→\n  1416→#### 5.1: Update App Configuration\n  1417→\n  1418→**What:** Customize company name, page title, and feature flags\n  1419→\n  1420→**File:** `frontend/voice-ai-frontend/app-config.ts`\n  1421→\n  1422→**Edit:**\n  1423→```typescript\n  1424→export const APP_CONFIG_DEFAULTS = {\n  1425→  // Branding\n  1426→  companyName: \"Your Company Name\", // Change this\n  1427→  pageTitle: \"AI Voice Assistant | Your Company\", // Change this\n  1428→\n  1429→  // Logo URLs\n  1430→  logoUrl: \"/logo.svg\", // Update after adding logo in 5.2\n  1431→  logoUrlDark: \"/logo-dark.svg\", // Optional: separate dark mode logo\n  1432→\n  1433→  // Accent color\n  1434→  accentColor: \"#4F46E5\", // Change to your brand color (hex)\n  1435→\n  1436→  // Feature toggles\n  1437→  supportsChatInput: true, // Allow text chat alongside voice\n  1438→  supportsVideoInput: true, // Enable camera video\n  1439→  supportsScreenShare: true, // Enable screen sharing\n  1440→  isPreConnectBufferEnabled: true, // Pre-load for faster connection\n  1441→\n  1442→  // Optional: Agent configuration\n  1443→  defaultAgentName: \"\", // Leave blank for auto-dispatch\n  1444→};\n  1445→```\n  1446→\n  1447→**Example Customization:**\n  1448→```typescript\n  1449→export const APP_CONFIG_DEFAULTS = {\n  1450→  companyName: \"Acme Voice AI\",\n  1451→  pageTitle: \"Voice AI Assistant | Acme Corp\",\n  1452→  logoUrl: \"/acme-logo.svg\",\n  1453→  accentColor: \"#FF6B35\", // Orange\n  1454→  supportsChatInput: true,\n  1455→  supportsVideoInput: false, // Disable video for voice-only\n  1456→  supportsScreenShare: false,\n  1457→  isPreConnectBufferEnabled: true,\n  1458→};\n  1459→```\n  1460→\n  1461→**Rationale:** Centralizes configuration for easy customization without code changes\n  1462→\n  1463→---\n  1464→\n  1465→#### 5.2: Add Custom Logo\n  1466→\n  1467→**What:** Replace default logo with your company logo\n  1468→\n  1469→**Steps:**\n  1470→\n  1471→1. Prepare logo files:\n  1472→   - **Format:** SVG (preferred) or PNG\n  1473→   - **Size:**\n  1474→     - SVG: Any size (scalable)\n  1475→     - PNG: 200x200px minimum, transparent background\n  1476→   - **Naming:**\n  1477→     - Light mode: `logo.svg` or `logo.png`\n  1478→     - Dark mode (optional): `logo-dark.svg` or `logo-dark.png`\n  1479→\n  1480→2. Copy to public directory:\n  1481→   ```bash\n  1482→   cp /path/to/your/logo.svg frontend/voice-ai-frontend/public/logo.svg\n  1483→   # Optional: dark mode logo\n  1484→   cp /path/to/your/logo-dark.svg frontend/voice-ai-frontend/public/logo-dark.svg\n  1485→   ```\n  1486→\n  1487→3. Update `app-config.ts`:\n  1488→   ```typescript\n  1489→   logoUrl: \"/logo.svg\",\n  1490→   logoUrlDark: \"/logo-dark.svg\", // If you have separate dark logo\n  1491→   ```\n  1492→\n  1493→4. Verify logo appears:\n  1494→   - Restart dev server: `pnpm dev`\n  1495→   - Visit http://localhost:3000\n  1496→   - Check logo displays correctly\n  1497→   - Toggle light/dark mode to test both logos\n  1498→\n  1499→**Fallback:**\n  1500→If you don't have a logo ready, the template includes a default placeholder logo.\n  1501→\n  1502→**Rationale:** Custom logo reinforces brand identity\n  1503→\n  1504→---\n  1505→\n  1506→#### 5.3: Customize Theme Colors\n  1507→\n  1508→**What:** Update color scheme to match your brand\n  1509→\n  1510→**File:** `frontend/voice-ai-frontend/tailwind.config.ts`\n  1511→\n  1512→**Edit:**\n  1513→```typescript\n  1514→export default {\n  1515→  theme: {\n  1516→    extend: {\n  1517→      colors: {\n  1518→        // Primary brand color\n  1519→        primary: {\n  1520→          50: '#f0f9ff',\n  1521→          100: '#e0f2fe',\n  1522→          // ... continue through 950\n  1523→          500: '#4F46E5', // Main brand color (change this)\n  1524→          600: '#4338ca',\n  1525→          // ...\n  1526→        },\n  1527→        // Accent color\n  1528→        accent: {\n  1529→          DEFAULT: '#FF6B35', // Change to your accent color\n  1530→          light: '#FF8A5B',\n  1531→          dark: '#E5501F',\n  1532→        },\n  1533→      },\n  1534→    },\n  1535→  },\n  1536→};\n  1537→```\n  1538→\n  1539→**Quick Method (Use Accent Color from app-config.ts):**\n  1540→\n  1541→The template may automatically use `accentColor` from `app-config.ts`. If so, just update that value:\n  1542→\n  1543→```typescript\n  1544→// In app-config.ts\n  1545→accentColor: \"#FF6B35\", // Your brand color\n  1546→```\n  1547→\n  1548→**Generate Full Color Palette:**\n  1549→Use tools like https://uicolors.app/create to generate a full Tailwind color palette from your brand color.\n  1550→\n  1551→**Test Theme:**\n  1552→- Restart dev server\n  1553→- Visit http://localhost:3000\n  1554→- Check buttons, links, highlights use new colors\n  1555→- Toggle light/dark mode to verify both themes\n  1556→\n  1557→**Rationale:** Consistent color scheme creates professional, branded experience\n  1558→\n  1559→---\n  1560→\n  1561→#### 5.4: Update Page Metadata\n  1562→\n  1563→**What:** Set page title, description, and favicon for SEO and browser display\n  1564→\n  1565→**File:** `frontend/voice-ai-frontend/app/layout.tsx`\n  1566→\n  1567→**Edit:**\n  1568→```typescript\n  1569→export const metadata: Metadata = {\n  1570→  title: \"AI Voice Assistant | Your Company\", // Change this\n  1571→  description: \"Connect with our AI voice assistant for instant help and support.\", // Change this\n  1572→  icons: {\n  1573→    icon: '/favicon.ico', // Update after adding favicon\n  1574→  },\n  1575→  openGraph: {\n  1576→    title: \"AI Voice Assistant | Your Company\",\n  1577→    description: \"Connect with our AI voice assistant for instant help and support.\",\n  1578→    images: ['/og-image.png'], // Optional: social share image\n  1579→  },\n  1580→};\n  1581→```\n  1582→\n  1583→**Add Custom Favicon:**\n  1584→\n  1585→1. Generate favicon files (use https://realfavicongenerator.net/):\n  1586→   - `favicon.ico` (16x16, 32x32, 48x48)\n  1587→   - `apple-touch-icon.png` (180x180)\n  1588→   - `favicon-16x16.png`\n  1589→   - `favicon-32x32.png`\n  1590→\n  1591→2. Copy to `public/`:\n  1592→   ```bash\n  1593→   cp /path/to/favicon.ico frontend/voice-ai-frontend/public/\n  1594→   cp /path/to/apple-touch-icon.png frontend/voice-ai-frontend/public/\n  1595→   ```\n  1596→\n  1597→3. Verify in browser:\n  1598→   - Clear browser cache\n  1599→   - Visit http://localhost:3000\n  1600→   - Check browser tab shows your favicon\n  1601→\n  1602→**Optional: Open Graph Image (Social Sharing):**\n  1603→Create `og-image.png` (1200x630px) for social media previews.\n  1604→\n  1605→**Rationale:** Professional metadata improves SEO and user experience\n  1606→\n  1607→---\n  1608→\n  1609→#### 5.5: Customize Welcome Message\n  1610→\n  1611→**What:** Update the welcome screen text and instructions\n  1612→\n  1613→**File:** `frontend/voice-ai-frontend/components/app/welcome-view.tsx` or similar\n  1614→\n  1615→**Find and Edit:**\n  1616→```typescript\n  1617→<h1>Welcome to [Your Company] Voice AI</h1>\n  1618→<p>\n  1619→  Click the button below to start a voice conversation with our AI assistant.\n  1620→  We can help you with questions, information, and more.\n  1621→</p>\n  1622→```\n  1623→\n  1624→**Example Customization:**\n  1625→```typescript\n  1626→<h1>Welcome to Acme Voice Assistant</h1>\n  1627→<p>\n  1628→  Our AI assistant is ready to help you 24/7. Click \"Connect\" to start a\n  1629→  natural voice conversation. Just speak naturally - no keywords or commands needed.\n  1630→</p>\n  1631→<ul>\n  1632→  <li>Get instant answers to your questions</li>\n  1633→  <li>Learn about our products and services</li>\n  1634→  <li>Get personalized recommendations</li>\n  1635→</ul>\n  1636→```\n  1637→\n  1638→**Rationale:** Clear messaging helps users understand what to expect\n  1639→\n  1640→---\n  1641→\n  1642→#### 5.6: Optional - Disable Features Not Needed\n  1643→\n  1644→**What:** Hide video/screen share features if you only need voice\n  1645→\n  1646→**File:** `frontend/voice-ai-frontend/app-config.ts`\n  1647→\n  1648→**For Voice-Only App:**\n  1649→```typescript\n  1650→export const APP_CONFIG_DEFAULTS = {\n  1651→  // ... other settings\n  1652→  supportsChatInput: false, // Disable text chat\n  1653→  supportsVideoInput: false, // Disable camera\n  1654→  supportsScreenShare: false, // Disable screen sharing\n  1655→  isPreConnectBufferEnabled: true, // Keep for faster connection\n  1656→};\n  1657→```\n  1658→\n  1659→**Effect:**\n  1660→- Video camera icon hidden\n  1661→- Screen share button removed\n  1662→- UI simplified to voice-only interface\n  1663→- Reduced complexity for users\n  1664→\n  1665→**Rationale:** Simplify UI by removing unused features\n  1666→\n  1667→---\n  1668→\n  1669→#### 5.7: Test Customizations\n  1670→\n  1671→**What:** Verify all customizations display correctly\n  1672→\n  1673→**Checklist:**\n  1674→- [ ] Company name displays on welcome screen\n  1675→- [ ] Custom logo appears (both light and dark modes)\n  1676→- [ ] Page title shows in browser tab\n  1677→- [ ] Custom favicon appears in browser tab\n  1678→- [ ] Brand colors visible on buttons and accents\n  1679→- [ ] Welcome message updated with custom text\n  1680→- [ ] Disabled features are hidden (if applicable)\n  1681→- [ ] No broken images or 404s\n  1682→- [ ] Responsive design maintained on mobile\n  1683→\n  1684→**Testing Steps:**\n  1685→1. Restart dev server: `pnpm dev`\n  1686→2. Clear browser cache (Cmd+Shift+R on Mac, Ctrl+Shift+R on Windows)\n  1687→3. Visit http://localhost:3000\n  1688→4. Toggle light/dark theme\n  1689→5. Resize browser to mobile size (375px width)\n  1690→6. Check all visual elements\n  1691→\n  1692→**Rationale:** Ensures professional, branded appearance before production deployment\n  1693→\n  1694→---\n  1695→\n  1696→### Success Criteria\n  1697→\n  1698→#### Automated Verification:\n  1699→\n  1700→- [ ] Build succeeds: `pnpm run build` completes without errors\n  1701→- [ ] No TypeScript errors: `pnpm run type-check` (if available)\n  1702→- [ ] Static assets exist: `ls public/logo.svg public/favicon.ico`\n  1703→- [ ] Config updated: `cat app-config.ts | grep companyName` shows your company\n  1704→\n  1705→#### Manual Verification:\n  1706→\n  1707→- [ ] Custom company name displays on welcome screen\n  1708→- [ ] Custom logo visible (light and dark modes)\n  1709→- [ ] Page title correct in browser tab\n  1710→- [ ] Favicon visible in browser tab\n  1711→- [ ] Brand colors applied throughout UI\n  1712→- [ ] Welcome message updated\n  1713→- [ ] Unused features hidden (if disabled)\n  1714→- [ ] Mobile responsive (test at 375px width)\n  1715→- [ ] No console errors or warnings\n  1716→- [ ] All images load correctly (no broken images)\n  1717→\n  1718→**Verify:** After completing automated verification, thoroughly test the UI on desktop and mobile, in light and dark modes, before proceeding to Phase 6.\n  1719→\n  1720→---\n  1721→\n  1722→## Phase 6: Production Deployment\n  1723→\n  1724→### Overview\n  1725→\n  1726→Deploy the customized frontend to Vercel (or another hosting provider) to make it publicly accessible via a URL that clients can visit.\n  1727→\n  1728→### Context\n  1729→\n  1730→Before starting, ensure:\n  1731→- Phase 5 completed successfully\n  1732→- All customizations tested locally\n  1733→- Frontend builds successfully (`pnpm run build`)\n  1734→- Agent deployed and running on LiveKit Cloud\n  1735→\n  1736→Files to review:\n  1737→- `frontend/voice-ai-frontend/.env.local` - Environment variables (will configure in Vercel)\n  1738→- `frontend/voice-ai-frontend/next.config.js` - Next.js configuration\n  1739→- `frontend/voice-ai-frontend/package.json` - Dependencies and scripts\n  1740→\n  1741→Accounts needed:\n  1742→- Vercel account (free tier sufficient): https://vercel.com\n  1743→- GitHub account (for connecting repo)\n  1744→\n  1745→### Dependencies\n  1746→\n  1747→**Depends on:** Phases 1-5 (agent deployed, frontend customized and tested)\n  1748→\n  1749→**Required by:** None (final phase)\n  1750→\n  1751→### Changes Required\n  1752→\n  1753→#### 6.1: Create Production Build\n  1754→\n  1755→**What:** Verify the production build works correctly before deploying\n  1756→\n  1757→**Commands:**\n  1758→```bash\n  1759→cd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\n  1760→\n  1761→# Create production build\n  1762→pnpm run build\n  1763→\n  1764→# Test production build locally\n  1765→pnpm start\n  1766→```\n  1767→\n  1768→**Expected Output:**\n  1769→```\n  1770→> next build\n  1771→\n  1772→✓ Compiled successfully\n  1773→✓ Linting and checking validity of types\n  1774→✓ Collecting page data\n  1775→✓ Generating static pages (X/X)\n  1776→✓ Finalizing page optimization\n  1777→\n  1778→Route (app)                              Size     First Load JS\n  1779→┌ ○ /                                    XXX kB        XXX kB\n  1780→└ ○ /api/token                          XXX B          XXX kB\n  1781→```\n  1782→\n  1783→**Test Production Build:**\n  1784→1. Visit http://localhost:3000 (pnpm start)\n  1785→2. Connect to agent\n  1786→3. Verify voice interaction works\n  1787→4. Check for any errors in console\n  1788→\n  1789→**Troubleshooting:**\n  1790→- If build fails: Check TypeScript errors, fix before proceeding\n  1791→- If errors about environment variables: Ensure `.env.local` exists\n  1792→- If runtime errors: Check browser console for specific issues\n  1793→\n  1794→**Rationale:** Catches production-specific issues before deployment\n  1795→\n  1796→---\n  1797→\n  1798→#### 6.2: Push Frontend to GitHub (Optional but Recommended)\n  1799→\n  1800→**What:** Create a Git repository for the frontend to enable easy Vercel deployment\n  1801→\n  1802→**Option A: Separate Repository (Recommended):**\n  1803→\n  1804→```bash\n  1805→cd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\n  1806→\n  1807→# Initialize git repository\n  1808→git init\n  1809→\n  1810→# Add .gitignore for Next.js\n  1811→cat > .gitignore << 'EOF'\n  1812→# Next.js\n  1813→.next/\n  1814→out/\n  1815→build/\n  1816→dist/\n  1817→\n  1818→# Dependencies\n  1819→node_modules/\n  1820→\n  1821→# Environment variables\n  1822→.env\n  1823→.env.local\n  1824→.env.production.local\n  1825→.env.development.local\n  1826→.env.test.local\n  1827→\n  1828→# Logs\n  1829→npm-debug.log*\n  1830→yarn-debug.log*\n  1831→yarn-error.log*\n  1832→pnpm-debug.log*\n  1833→\n  1834→# OS\n  1835→.DS_Store\n  1836→*.swp\n  1837→*.swo\n  1838→\n  1839→# IDE\n  1840→.vscode/\n  1841→.idea/\n  1842→\n  1843→# Vercel\n  1844→.vercel\n  1845→EOF\n  1846→\n  1847→# Add files\n  1848→git add .\n  1849→git commit -m \"Initial commit: Voice AI frontend\"\n  1850→\n  1851→# Create GitHub repository (via GitHub UI or CLI)\n  1852→gh repo create voice-ai-frontend --public --source=. --remote=origin --push\n  1853→```\n  1854→\n  1855→**Option B: Same Repository as Agent:**\n  1856→\n  1857→If you want frontend and agent in the same repo:\n  1858→```bash\n  1859→cd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\n  1860→\n  1861→# Remove frontend/ from .gitignore\n  1862→sed -i '' '/^frontend\\//d' .gitignore\n  1863→\n  1864→# Add and commit\n  1865→git add frontend/\n  1866→git commit -m \"Add voice AI frontend\"\n  1867→git push\n  1868→```\n  1869→\n  1870→**Rationale:** Git repository enables continuous deployment and version control\n  1871→\n  1872→---\n  1873→\n  1874→#### 6.3: Sign Up for Vercel\n  1875→\n  1876→**What:** Create a Vercel account for hosting the frontend\n  1877→\n  1878→**Steps:**\n  1879→\n  1880→1. Visit https://vercel.com\n  1881→2. Click \"Sign Up\"\n  1882→3. Choose \"Continue with GitHub\" (recommended)\n  1883→4. Authorize Vercel to access your GitHub repositories\n  1884→\n  1885→**Pricing:**\n  1886→- **Free Tier:** Sufficient for testing and low traffic\n  1887→  - Unlimited deployments\n  1888→  - 100 GB bandwidth/month\n  1889→  - Serverless functions included\n  1890→- **Pro Tier:** $20/month (for production with higher traffic)\n  1891→\n  1892→**Rationale:** Vercel provides seamless Next.js hosting with automatic deployments\n  1893→\n  1894→---\n  1895→\n  1896→#### 6.4: Deploy Frontend to Vercel\n  1897→\n  1898→**What:** Deploy the frontend application to Vercel\n  1899→\n  1900→**Steps:**\n  1901→\n  1902→1. **From Vercel Dashboard:**\n  1903→   - Click \"Add New...\" → \"Project\"\n  1904→   - Select \"Import Git Repository\"\n  1905→   - Choose your frontend repository\n  1906→   - Configure project:\n  1907→     - **Framework Preset:** Next.js (auto-detected)\n  1908→     - **Root Directory:** `./` (or `frontend/voice-ai-frontend` if in monorepo)\n  1909→     - **Build Command:** `pnpm run build` (auto-detected)\n  1910→     - **Output Directory:** `.next` (auto-detected)\n  1911→     - **Install Command:** `pnpm install` (auto-detected)\n  1912→\n  1913→2. **Configure Environment Variables:**\n  1914→   Click \"Environment Variables\" and add:\n  1915→\n  1916→   ```\n  1917→   LIVEKIT_API_KEY=APIxxxxxxxxxxxx\n  1918→   LIVEKIT_API_SECRET=your-secret-here\n  1919→   LIVEKIT_URL=wss://your-project.livekit.cloud\n  1920→   NEXT_PUBLIC_LIVEKIT_URL=wss://your-project.livekit.cloud\n  1921→   AGENT_NAME=\n  1922→   ```\n  1923→\n  1924→   **Important:**\n  1925→   - Copy values from your local `.env.local`\n  1926→   - Apply to \"Production\", \"Preview\", and \"Development\" environments\n  1927→\n  1928→3. **Deploy:**\n  1929→   - Click \"Deploy\"\n  1930→   - Wait for build to complete (2-5 minutes)\n  1931→\n  1932→**Expected Outcome:**\n  1933→```\n  1934→✓ Build successful\n  1935→✓ Deployment successful\n  1936→Your project is now live at: https://your-app.vercel.app\n  1937→```\n  1938→\n  1939→**Rationale:** Makes frontend publicly accessible via HTTPS URL\n  1940→\n  1941→---\n  1942→\n  1943→#### 6.5: Test Production Deployment\n  1944→\n  1945→**What:** Verify the deployed frontend works correctly\n  1946→\n  1947→**Steps:**\n  1948→\n  1949→1. Visit your Vercel URL: `https://your-app.vercel.app`\n  1950→\n  1951→2. **Test Checklist:**\n  1952→   - [ ] Page loads without errors\n  1953→   - [ ] Custom branding displays correctly\n  1954→   - [ ] Click \"Connect\" button\n  1955→   - [ ] Grant microphone permissions\n  1956→   - [ ] Speak to agent\n  1957→   - [ ] Verify agent responds with voice\n  1958→   - [ ] Test on mobile device\n  1959→   - [ ] Test in different browsers\n  1960→\n  1961→3. **Monitor Logs:**\n  1962→   ```bash\n  1963→   # Monitor agent logs during production test\n  1964→   lk agent logs --follow\n  1965→   ```\n  1966→\n  1967→4. **Check Vercel Deployment Logs:**\n  1968→   - Go to Vercel dashboard → Your project → Deployments\n  1969→   - Click on latest deployment → \"Functions\" tab\n  1970→   - Check for any errors in `/api/token` function\n  1971→\n  1972→**Troubleshooting:**\n  1973→- **\"Failed to connect\":** Check environment variables in Vercel\n  1974→- **Token errors:** Verify `LIVEKIT_API_KEY` and `LIVEKIT_API_SECRET` are correct\n  1975→- **CORS errors:** Ensure `NEXT_PUBLIC_LIVEKIT_URL` is set correctly\n  1976→- **Agent not joining:** Check agent status, verify agent is Running\n  1977→\n  1978→**Rationale:** Ensures production environment works correctly\n  1979→\n  1980→---\n  1981→\n  1982→#### 6.6: Configure Custom Domain (Optional)\n  1983→\n  1984→**What:** Use a custom domain instead of `your-app.vercel.app`\n  1985→\n  1986→**Prerequisites:**\n  1987→- Own a domain name (e.g., `voiceai.yourcompany.com`)\n  1988→- Access to domain DNS settings\n  1989→\n  1990→**Steps:**\n  1991→\n  1992→1. **In Vercel Dashboard:**\n  1993→   - Go to your project → Settings → Domains\n  1994→   - Click \"Add Domain\"\n  1995→   - Enter your domain: `voiceai.yourcompany.com`\n  1996→\n  1997→2. **Configure DNS:**\n  1998→   Vercel will provide DNS configuration instructions:\n  1999→\n  2000→   **Option A: CNAME (Subdomain):**\n  2001→   ```\n  2002→   Type: CNAME\n  2003→   Name: voiceai\n  2004→   Value: cname.vercel-dns.com\n  2005→   ```\n  2006→\n  2007→   **Option B: A Record (Root Domain):**\n  2008→   ```\n  2009→   Type: A\n  2010→   Name: @\n  2011→   Value: 76.76.21.21\n  2012→   ```\n  2013→\n  2014→3. **Wait for DNS Propagation:**\n  2015→   - Usually takes 5-60 minutes\n  2016→   - Vercel will auto-configure SSL certificate (Let's Encrypt)\n  2017→\n  2018→4. **Verify:**\n  2019→   - Visit `https://voiceai.yourcompany.com`\n  2020→   - Should show your frontend with SSL (green lock icon)\n  2021→\n  2022→**Rationale:** Custom domain provides professional appearance and brand consistency\n  2023→\n  2024→---\n  2025→\n  2026→#### 6.7: Enable Automatic Deployments\n  2027→\n  2028→**What:** Configure automatic deployments when you push to GitHub\n  2029→\n  2030→**Vercel Auto-Deploys By Default:**\n  2031→- **Production:** Deploys on push to `main` branch\n  2032→- **Preview:** Deploys on push to any other branch or PR\n  2033→\n  2034→**Customize (Optional):**\n  2035→1. Go to Vercel dashboard → Your project → Settings → Git\n  2036→2. Configure:\n  2037→   - **Production Branch:** `main` (or `master`)\n  2038→   - **Ignored Build Step:** (leave blank to build on every commit)\n  2039→\n  2040→**Test Automatic Deployment:**\n  2041→```bash\n  2042→cd frontend/voice-ai-frontend\n  2043→\n  2044→# Make a small change\n  2045→echo \"# Updated\" >> README.md\n  2046→\n  2047→# Commit and push\n  2048→git add README.md\n  2049→git commit -m \"Test automatic deployment\"\n  2050→git push origin main\n  2051→```\n  2052→\n  2053→**Verify:**\n  2054→- Visit Vercel dashboard\n  2055→- Should see new deployment triggered automatically\n  2056→- Wait for build to complete\n  2057→- Visit production URL to see changes\n  2058→\n  2059→**Rationale:** Enables continuous deployment for easy updates\n  2060→\n  2061→---\n  2062→\n  2063→#### 6.8: Set Up Production Monitoring (Recommended)\n  2064→\n  2065→**What:** Monitor production errors and usage\n  2066→\n  2067→**Vercel Analytics (Built-in):**\n  2068→1. Go to Vercel dashboard → Your project → Analytics\n  2069→2. View:\n  2070→   - Page views\n  2071→   - Geographic distribution\n  2072→   - Performance metrics (Web Vitals)\n  2073→\n  2074→**Error Tracking (Optional):**\n  2075→Consider integrating Sentry or similar:\n  2076→```bash\n  2077→pnpm add @sentry/nextjs\n  2078→npx @sentry/wizard@latest -i nextjs\n  2079→```\n  2080→\n  2081→**LiveKit Cloud Monitoring:**\n  2082→- Visit LiveKit Cloud dashboard\n  2083→- Monitor:\n  2084→  - Active sessions\n  2085→  - Agent usage\n  2086→  - Costs (session minutes)\n  2087→\n  2088→**Rationale:** Production monitoring helps identify and resolve issues quickly\n  2089→\n  2090→---\n  2091→\n  2092→#### 6.9: Create Shareable Link\n  2093→\n  2094→**What:** Generate a clean, shareable URL for potential clients\n  2095→\n  2096→**Your Production URL:**\n  2097→```\n  2098→https://your-app.vercel.app\n  2099→```\n  2100→\n  2101→**Or with Custom Domain:**\n  2102→```\n  2103→https://voiceai.yourcompany.com\n  2104→```\n  2105→\n  2106→**Create Marketing Materials:**\n  2107→- Add link to your website\n  2108→- Share via email campaigns\n  2109→- Include in social media bios\n  2110→- Create QR code for physical materials\n  2111→\n  2112→**Example QR Code Generation:**\n  2113→```bash\n  2114→# Generate QR code (using qrencode)\n  2115→brew install qrencode\n  2116→qrencode -o voiceai-qr.png \"https://voiceai.yourcompany.com\"\n  2117→```\n  2118→\n  2119→**Rationale:** Easy sharing enables potential clients to access your voice AI\n  2120→\n  2121→---\n  2122→\n  2123→#### 6.10: Document Production URLs and Credentials\n  2124→\n  2125→**What:** Save all production information for future reference\n  2126→\n  2127→**Create:** `frontend/voice-ai-frontend/PRODUCTION.md`\n  2128→\n  2129→**Content:**\n  2130→```markdown\n  2131→# Production Deployment Information\n  2132→\n  2133→## URLs\n  2134→- **Production Frontend:** https://your-app.vercel.app\n  2135→- **Custom Domain:** https://voiceai.yourcompany.com (if configured)\n  2136→- **LiveKit Cloud Dashboard:** https://cloud.livekit.io\n  2137→\n  2138→## Vercel\n  2139→- **Project:** voice-ai-frontend\n  2140→- **Account:** your-email@example.com\n  2141→- **Git Repository:** https://github.com/yourusername/voice-ai-frontend\n  2142→\n  2143→## LiveKit Cloud\n  2144→- **Project:** your-project-name\n  2145→- **Region:** us-west-2\n  2146→- **Agent ID:** agent_abc123\n  2147→\n  2148→## Deployment Commands\n  2149→```bash\n  2150→# Deploy agent updates\n  2151→cd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\n  2152→lk agent deploy\n  2153→\n  2154→# Deploy frontend updates (automatic via Git)\n  2155→cd frontend/voice-ai-frontend\n  2156→git add .\n  2157→git commit -m \"Update frontend\"\n  2158→git push origin main\n  2159→```\n  2160→\n  2161→## Monitoring\n  2162→- **Agent Logs:** `lk agent logs --follow`\n  2163→- **Vercel Logs:** https://vercel.com/your-project/deployments\n  2164→- **LiveKit Dashboard:** https://cloud.livekit.io/projects/your-project\n  2165→\n  2166→## Environment Variables (Vercel)\n  2167→- LIVEKIT_API_KEY=APIxxxxxxxxxxxx\n  2168→- LIVEKIT_API_SECRET=*** (not shown)\n  2169→- LIVEKIT_URL=wss://your-project.livekit.cloud\n  2170→- NEXT_PUBLIC_LIVEKIT_URL=wss://your-project.livekit.cloud\n  2171→\n  2172→## Costs\n  2173→- **LiveKit Cloud:** $0.01 per agent session minute\n  2174→- **Vercel:** Free tier (or $20/month Pro)\n  2175→\n  2176→## Support\n  2177→- **LiveKit:** https://livekit.io/discord\n  2178→- **Vercel:** https://vercel.com/support\n  2179→```\n  2180→\n  2181→**Rationale:** Documentation ensures you can manage production deployment long-term\n  2182→\n  2183→---\n  2184→\n  2185→### Success Criteria\n  2186→\n  2187→#### Automated Verification:\n  2188→\n  2189→- [ ] Production build succeeds: `pnpm run build` completes without errors\n  2190→- [ ] Vercel deployment successful: Deployment status shows \"Ready\"\n  2191→- [ ] HTTPS enabled: Visit production URL with green lock icon\n  2192→- [ ] Environment variables configured: Check Vercel dashboard\n  2193→- [ ] Custom domain configured (if applicable): DNS records set\n  2194→\n  2195→#### Manual Verification:\n  2196→\n  2197→- [ ] Visit production URL in browser\n  2198→- [ ] Page loads without errors\n  2199→- [ ] Custom branding displays correctly\n  2200→- [ ] Click \"Connect\" and grant microphone access\n  2201→- [ ] Speak to agent and verify voice response\n  2202→- [ ] Test on mobile device (iOS Safari, Android Chrome)\n  2203→- [ ] Test in incognito/private mode\n  2204→- [ ] Share URL with colleague and get confirmation it works\n  2205→- [ ] Agent logs show production sessions: `lk agent logs --follow`\n  2206→- [ ] No errors in Vercel function logs\n  2207→\n  2208→**Verify:** After completing automated verification, test the production URL on multiple devices and browsers, then share with a colleague to confirm public accessibility.\n  2209→\n  2210→---\n  2211→\n  2212→## Testing Strategy\n  2213→\n  2214→### Unit Tests\n  2215→\n  2216→**Not required for this plan.** The agent-starter-react template is a pre-built, production-ready template that doesn't require custom unit tests unless you add significant custom logic.\n  2217→\n  2218→**Optional:** Add tests if you customize components heavily:\n  2219→```bash\n  2220→pnpm add -D @testing-library/react @testing-library/jest-dom jest\n  2221→```\n  2222→\n  2223→### Integration Tests\n  2224→\n  2225→**End-to-End Testing:**\n  2226→\n  2227→Manually test the complete flow:\n  2228→1. User visits URL\n  2229→2. Clicks \"Connect\"\n  2230→3. Grants microphone access\n  2231→4. Speaks to agent\n  2232→5. Receives voice response\n  2233→6. Disconnects cleanly\n  2234→\n  2235→**Test Matrix:**\n  2236→\n  2237→| Scenario | Steps | Expected Outcome |\n  2238→|----------|-------|------------------|\n  2239→| First Connection | Visit URL → Click Connect → Speak | Agent responds with voice |\n  2240→| Interruption | Speak while agent is speaking | Agent handles gracefully |\n  2241→| Disconnect/Reconnect | End session → Start new session | New session works |\n  2242→| Multiple Turns | Have 3-5 turn conversation | All responses relevant |\n  2243→| Mobile Safari | Test on iPhone/iPad | Full functionality |\n  2244→| Network Interruption | Disable Wi-Fi during session | Reconnection or error message |\n  2245→\n  2246→### Manual Testing Steps\n  2247→\n  2248→**Pre-Deployment Checklist:**\n  2249→1. [ ] Agent deployed and running: `lk agent status`\n  2250→2. [ ] Local frontend works: `pnpm dev` at http://localhost:3000\n  2251→3. [ ] Voice interaction successful\n  2252→4. [ ] Audio visualization working\n  2253→5. [ ] Custom branding applied\n  2254→6. [ ] Production build succeeds: `pnpm run build`\n  2255→\n  2256→**Post-Deployment Checklist:**\n  2257→1. [ ] Production URL accessible\n  2258→2. [ ] HTTPS enabled (green lock)\n  2259→3. [ ] Voice interaction works on production\n  2260→4. [ ] Mobile responsive\n  2261→5. [ ] Cross-browser compatible\n  2262→6. [ ] Shareable link works for external users\n  2263→\n  2264→### Performance Considerations\n  2265→\n  2266→**Metrics to Monitor:**\n  2267→- **Connection Time:** Should be <3 seconds (or <1.5s with optimization)\n  2268→- **Response Latency:** STT → LLM → TTS should be 2-4 seconds\n  2269→- **Page Load Time:** Initial load <2 seconds (Lighthouse score >90)\n  2270→- **Audio Quality:** No dropouts or distortion\n  2271→\n  2272→**Optimization:**\n  2273→- Enable pre-connect buffering in `app-config.ts`\n  2274→- Use warm token approach (Phase 4.6)\n  2275→- Minimize bundle size (Next.js handles automatically)\n  2276→- Use CDN for static assets (Vercel provides automatically)\n  2277→\n  2278→## References\n  2279→\n  2280→### Original Ticket/Request\n  2281→- User request: \"I want potential clients to be able to interact with the livekit agent from this repo by clicking a link on a website.\"\n  2282→\n  2283→### Documentation\n  2284→- `docs/DEPLOYMENT.md` - Complete deployment guide for agent and frontend options\n  2285→- `README.md` - Project overview and setup instructions\n  2286→- `AGENTS.md` - Project guidelines and standards\n  2287→\n  2288→### LiveKit Resources\n  2289→- **Frontend Deployment Guide:** https://docs.livekit.io/agents/start/frontend/\n  2290→- **agent-starter-react Repository:** https://github.com/livekit-examples/agent-starter-react\n  2291→- **Token Authentication:** https://docs.livekit.io/home/get-started/authentication/\n  2292→- **Agents Playground:** https://agents-playground.livekit.io/\n  2293→- **LiveKit Cloud Dashboard:** https://cloud.livekit.io\n  2294→- **React Components Docs:** https://docs.livekit.io/reference/components/react/\n  2295→\n  2296→### NPM Packages\n  2297→- **livekit-client:** Client SDK for browser WebRTC\n  2298→- **@livekit/components-react:** React UI components\n  2299→- **livekit-server-sdk:** Server-side token generation\n  2300→\n  2301→### Vercel Resources\n  2302→- **Vercel Platform:** https://vercel.com\n  2303→- **Next.js Documentation:** https://nextjs.org/docs\n  2304→- **Deployment Docs:** https://vercel.com/docs\n  2305→\n  2306→### Related Plans\n  2307→- None (initial implementation)\n  2308→\n  2309→---\n  2310→\n  2311→**End of Implementation Plan**\n  2312→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"f15f1953-769e-4148-874a-fb1a1afad061","timestamp":"2026-01-25T09:44:31.973Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/plan/future-plans/2026-01-25-web-frontend-deployment.md","content":"# Web Frontend Deployment Implementation Plan\n\n> **Status:** DRAFT\n\n## Table of Contents\n\n- [Overview](#overview)\n- [Current State Analysis](#current-state-analysis)\n- [Desired End State](#desired-end-state)\n- [What We're NOT Doing](#what-were-not-doing)\n- [Implementation Approach](#implementation-approach)\n- [Dependencies](#dependencies)\n- [Phase 1: Agent Deployment to LiveKit Cloud](#phase-1-agent-deployment-to-livekit-cloud)\n- [Phase 2: Frontend Setup (agent-starter-react)](#phase-2-frontend-setup-agent-starter-react)\n- [Phase 3: Authentication and Token Generation](#phase-3-authentication-and-token-generation)\n- [Phase 4: Connection Testing and Optimization](#phase-4-connection-testing-and-optimization)\n- [Phase 5: Frontend Customization](#phase-5-frontend-customization)\n- [Phase 6: Production Deployment](#phase-6-production-deployment)\n- [Testing Strategy](#testing-strategy)\n- [References](#references)\n\n## Overview\n\nThis plan enables potential clients to interact with the LiveKit voice AI agent from this repository by clicking a link on a website. The implementation covers:\n\n1. Deploying the Python agent to LiveKit Cloud\n2. Setting up a Next.js/React frontend using the agent-starter-react template\n3. Implementing JWT token-based authentication\n4. Testing the connection flow\n5. Customizing the frontend with branding\n6. Deploying the frontend to production (Vercel)\n\nThe solution uses LiveKit's official starter templates and SDKs to create a production-ready web application with TypeScript/JavaScript.\n\n## Current State Analysis\n\n### What Exists Now\n\n**Agent Backend:**\n- Python voice AI agent in `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1`\n- Built with LiveKit Agents SDK\n- Uses OpenAI (LLM), AssemblyAI (STT), Cartesia (TTS)\n- Configured with `uv` package manager\n- Has `Dockerfile` for containerized deployment\n- Environment variables in `.env.local` (OpenAI, AssemblyAI, Cartesia API keys)\n\n**Missing:**\n- Agent not yet deployed to LiveKit Cloud\n- No web frontend for client interaction\n- No token generation server for authentication\n- No public-facing URL for clients to access\n\n### Key Discoveries\n\nFrom `docs/DEPLOYMENT.md`:\n- LiveKit Cloud deployment uses `lk` CLI\n- Agent deployment command: `lk agent create --secrets-file .env.local`\n- Multiple frontend options available (React, Flutter, Swift, Embed)\n- Connection requires JWT tokens generated server-side\n- agent-starter-react provides production-ready Next.js template\n- Token generation uses `livekit-server-sdk` npm package\n\n### Constraints\n\n1. **Security:** API secrets (LIVEKIT_API_SECRET) must never be exposed to frontend\n2. **Architecture:** Token generation must happen server-side (Next.js API routes)\n3. **Dependencies:** Agent must be deployed and running before frontend can connect\n4. **Cost:** LiveKit Cloud charges $0.01 per agent session minute\n\n## Desired End State\n\n### Success Criteria\n\n- [ ] Agent deployed and running on LiveKit Cloud\n- [ ] Next.js frontend application running locally\n- [ ] JWT token generation working via backend API route\n- [ ] Users can click a link and connect to voice AI agent\n- [ ] Audio conversation works end-to-end (STT → LLM → TTS)\n- [ ] Frontend deployed to production URL (Vercel)\n- [ ] Customized branding (logo, colors, company name)\n- [ ] Light/dark theme support\n- [ ] Audio visualization working\n- [ ] Mobile-responsive design\n\n### How to Verify\n\n**Agent Deployment:**\n```bash\nlk agent status\n# Expected: Status: Running, Replicas: X/X ready\n```\n\n**Frontend Connection:**\n1. Visit frontend URL (local: http://localhost:3000, prod: https://your-app.vercel.app)\n2. Click \"Connect\" or \"Start Session\"\n3. Grant microphone permissions when prompted\n4. Speak to the agent\n5. Verify agent responds with natural voice\n6. Check agent logs: `lk agent logs --follow`\n\n**End-to-End Test:**\n```bash\n# Terminal 1: Monitor agent logs\nlk agent logs --follow\n\n# Terminal 2: Run frontend\ncd /path/to/frontend\npnpm dev\n\n# Browser: Visit http://localhost:3000, connect, and speak\n```\n\n## What We're NOT Doing\n\n**Out of Scope:**\n- Multiple agent types or agent selection UI\n- User authentication/login system (anonymous users only)\n- Database integration or conversation history storage\n- Multi-language support (English only initially)\n- iOS/Android native apps (web only)\n- Custom voice customization UI\n- Payment integration or usage metering\n- Advanced analytics dashboard\n- Server-side rendering (SSR) for the voice interface\n- Custom WebRTC infrastructure (using LiveKit Cloud)\n\n**Future Considerations:**\n- User accounts and saved conversations\n- Analytics and usage tracking\n- Custom domain with branding\n- A/B testing different agent configurations\n- Rate limiting and abuse prevention\n\n## Implementation Approach\n\n### High-Level Strategy\n\n1. **Deploy Agent First:** Ensure the Python agent is running on LiveKit Cloud before building frontend\n2. **Use Official Template:** Start with agent-starter-react to avoid reinventing the wheel\n3. **Iterative Testing:** Test each phase independently before proceeding\n4. **Security-First:** Never expose API secrets; use environment variables and server-side token generation\n5. **Quick Validation:** Use LiveKit Agents Playground first to verify agent works before building frontend\n\n### Technology Stack\n\n**Backend (Agent):**\n- Python 3.11+\n- LiveKit Agents SDK\n- OpenAI GPT-4 (LLM)\n- AssemblyAI (STT)\n- Cartesia (TTS)\n- Deployed to: LiveKit Cloud\n\n**Frontend:**\n- Next.js 14+ (App Router)\n- React 18+\n- TypeScript\n- Tailwind CSS\n- Shadcn/ui components\n- `livekit-client` SDK\n- `@livekit/components-react`\n- Deployed to: Vercel\n\n**Authentication:**\n- JWT tokens (livekit-server-sdk)\n- Server-side generation (Next.js API routes)\n- 2-hour token expiration\n\n## Dependencies\n\n**Execution Order:**\n\n1. Phase 1: Agent Deployment (no dependencies)\n2. Phase 2: Frontend Setup (depends on Phase 1 for credentials)\n3. Phase 3: Authentication (depends on Phase 2)\n4. Phase 4: Connection Testing (depends on Phases 1-3)\n5. Phase 5: Frontend Customization (depends on Phase 4)\n6. Phase 6: Production Deployment (depends on Phase 5)\n\n**Dependency Graph:**\n\n```\nPhase 1 (Agent Deployment)\n  └─> Phase 2 (Frontend Setup)\n        └─> Phase 3 (Authentication)\n              └─> Phase 4 (Testing)\n                    └─> Phase 5 (Customization)\n                          └─> Phase 6 (Production)\n```\n\n**Parallelization:**\n- All phases are sequential due to dependencies\n- Within each phase, independent tasks can run in parallel\n\n---\n\n## Phase 1: Agent Deployment to LiveKit Cloud\n\n### Overview\n\nDeploy the Python voice AI agent to LiveKit Cloud to make it accessible via WebRTC. This creates a running agent that can be dispatched to rooms when users connect.\n\n### Context\n\nBefore starting, ensure you have:\n- LiveKit CLI installed: `brew install livekit/livekit/livekit-cli`\n- LiveKit Cloud account at https://cloud.livekit.io\n- Agent code in `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1`\n- API keys in `.env.local` (OpenAI, AssemblyAI, Cartesia)\n\nFiles to review:\n- `docs/DEPLOYMENT.md` - Complete deployment guide\n- `.env.local` - API keys and secrets\n- `Dockerfile` - Container build configuration\n- `src/app.py` - Agent entry point\n\n### Dependencies\n\n**Depends on:** None (first phase)\n\n**Required by:** Phase 2 (Frontend needs LiveKit credentials), Phase 4 (Testing needs deployed agent)\n\n### Changes Required\n\n#### 1.1: Authenticate with LiveKit Cloud\n\n**What:** Link your CLI to your LiveKit Cloud account\n\n**Command:**\n```bash\nlk cloud auth\n```\n\n**Expected Outcome:**\n- Browser opens for authentication\n- CLI displays: \"Successfully authenticated with LiveKit Cloud\"\n- Credentials saved in `~/.livekit/credentials`\n\n**Rationale:** Required for all subsequent `lk` CLI commands\n\n---\n\n#### 1.2: Create or Select LiveKit Project\n\n**What:** Create a new project or select an existing one for the agent deployment\n\n**Commands:**\n```bash\n# List existing projects\nlk project list\n\n# Option A: Use existing project\nlk project set-default \"your-project-name\"\n\n# Option B: Create new project via dashboard\n# Visit https://cloud.livekit.io and create a new project\n# Then set as default: lk project set-default \"new-project-name\"\n\n# Verify current project\nlk project current\n```\n\n**Expected Outcome:**\n```\nNAME                 PROJECT_ID\nyour-project-name   prj_abc123\n```\n\n**Rationale:** Agent deployments are scoped to projects; need a target project first\n\n---\n\n#### 1.3: Verify Secrets File\n\n**What:** Ensure `.env.local` contains all required API keys\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/.env.local`\n\n**Verify contents:**\n```bash\ncat .env.local\n```\n\n**Required secrets:**\n```env\nOPENAI_API_KEY=sk-...\nASSEMBLYAI_API_KEY=...\nCARTESIA_API_KEY=...\n```\n\n**Important Notes:**\n- Do NOT include `LIVEKIT_URL`, `LIVEKIT_API_KEY`, or `LIVEKIT_API_SECRET` in `.env.local`\n- LiveKit Cloud auto-injects these during deployment\n- Verify `.env.local` is in `.gitignore`\n\n**Rationale:** Agent needs these API keys to function; LiveKit Cloud encrypts and injects them as environment variables\n\n---\n\n#### 1.4: Download Model Files\n\n**What:** Download required models (Silero VAD, turn detector) before deployment\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\nuv run python src/app.py download-files\n```\n\n**Expected Outcome:**\n```\nDownloading Silero VAD model...\nDownloading multilingual turn detector model...\nDownload complete.\n```\n\n**Rationale:** Models are required at runtime; downloading during build ensures faster agent startup\n\n---\n\n#### 1.5: Deploy Agent to LiveKit Cloud\n\n**What:** Create and deploy the agent container to LiveKit Cloud\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\nlk agent create --secrets-file .env.local\n```\n\n**Expected Outcome:**\n```\nRegistering agent...\nAgent ID: agent_abc123\nBuilding container image...\nUploading code...\nBuild in progress (this may take 2-5 minutes)...\nBuild complete.\nDeploying agent...\nDeployment successful.\nStatus: Running\nReplicas: 2/2 ready\n```\n\n**What Happens:**\n1. CLI registers new agent with Cloud project\n2. Assigns unique agent ID (e.g., `agent_abc123`)\n3. Creates/updates `livekit.toml` configuration file\n4. Uploads source code to LiveKit build service\n5. Builds Docker container from `Dockerfile`\n6. Deploys container to Cloud project\n7. Encrypts and injects secrets as environment variables\n8. Starts 2 replica instances\n\n**Duration:** 2-5 minutes for initial build\n\n**Rationale:** Makes agent accessible via LiveKit's global WebRTC infrastructure\n\n---\n\n#### 1.6: Verify Agent Status\n\n**What:** Confirm agent is running and ready to accept sessions\n\n**Commands:**\n```bash\n# Check agent status\nlk agent status\n\n# View live logs\nlk agent logs --tail 50\n```\n\n**Expected Status Output:**\n```\nAgent ID:     agent_abc123\nStatus:       Running\nReplicas:     2/2 ready\nVersion:      v1\nLast Deploy:  2026-01-25 10:30:00 UTC\nRegion:       us-west-2\n```\n\n**Expected Log Output:**\n- No error messages\n- Successful initialization messages\n- \"Waiting for room assignment\" or similar\n\n**Troubleshooting:**\n- If status is `CrashLoop`: Check logs for Python exceptions\n- If status is `Build Failed`: Run `lk agent logs --build` to see build errors\n- If secrets missing: Run `lk agent secrets` to verify\n\n**Rationale:** Ensures agent is healthy before proceeding to frontend setup\n\n---\n\n#### 1.7: Quick Test with Agents Playground\n\n**What:** Test agent using LiveKit Agents Playground (no code required)\n\n**Steps:**\n1. Get project credentials:\n   ```bash\n   lk project current --json\n   ```\n\n2. Visit https://agents-playground.livekit.io/\n\n3. Enter credentials:\n   - **LiveKit URL:** `wss://your-project.livekit.cloud` (from JSON output)\n   - **API Key:** Your `LIVEKIT_API_KEY` (from JSON output)\n   - **API Secret:** Your `LIVEKIT_API_SECRET` (from JSON output)\n\n4. Click \"Connect\"\n\n5. Allow microphone access when prompted\n\n6. Speak to your agent\n\n7. Monitor agent logs in terminal:\n   ```bash\n   lk agent logs --follow\n   ```\n\n**Expected Outcome:**\n- Agent responds to your voice with natural TTS\n- Logs show STT transcriptions, LLM responses, TTS generation\n- No errors in logs\n\n**Rationale:** Validates agent works end-to-end before investing in frontend development\n\n---\n\n#### 1.8: Save LiveKit Credentials\n\n**What:** Export LiveKit project credentials for frontend configuration\n\n**Command:**\n```bash\nlk project current --json > livekit-credentials.json\n```\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/livekit-credentials.json`\n\n**Expected Contents:**\n```json\n{\n  \"name\": \"your-project-name\",\n  \"url\": \"wss://your-project.livekit.cloud\",\n  \"api_key\": \"APIxxxxxxxxxxxx\",\n  \"api_secret\": \"your-secret-here\"\n}\n```\n\n**Security Note:**\n- Add `livekit-credentials.json` to `.gitignore`\n- NEVER commit this file to version control\n- This file is for local reference only\n\n**Rationale:** Frontend needs these credentials to generate tokens and connect to LiveKit\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] CLI authenticated: `lk cloud auth` successful\n- [ ] Project selected: `lk project current` shows correct project\n- [ ] Agent deployed: `lk agent status` shows `Status: Running`\n- [ ] Replicas ready: `lk agent status` shows `X/X ready` (e.g., 2/2)\n- [ ] No crash loops: `lk agent logs --tail 50` shows no errors\n- [ ] Credentials saved: `livekit-credentials.json` exists and contains valid JSON\n\n#### Manual Verification:\n\n- [ ] Agents Playground connection successful\n- [ ] Agent responds to voice input with TTS output\n- [ ] Agent logs show successful STT → LLM → TTS pipeline\n- [ ] No API key errors in logs\n- [ ] Agent state transitions visible (initializing → listening → thinking → speaking)\n\n**Verify:** After completing automated verification, test agent with Agents Playground before proceeding to Phase 2.\n\n---\n\n## Phase 2: Frontend Setup (agent-starter-react)\n\n### Overview\n\nClone and configure the agent-starter-react template to create a Next.js web application that connects users to your deployed agent.\n\n### Context\n\nBefore starting, ensure:\n- Phase 1 completed successfully\n- Agent is running on LiveKit Cloud\n- `livekit-credentials.json` file exists with credentials\n\nPrerequisites:\n- Node.js 18+ installed\n- pnpm installed: `npm install -g pnpm`\n- `lk` CLI authenticated\n\nFiles to review:\n- `livekit-credentials.json` - LiveKit project credentials\n- N/A (frontend doesn't exist yet)\n\n### Dependencies\n\n**Depends on:** Phase 1 (needs LiveKit credentials)\n\n**Required by:** Phase 3 (authentication setup), Phase 4 (connection testing)\n\n### Changes Required\n\n#### 2.1: Create Frontend Project Directory\n\n**What:** Create a directory to house the frontend application\n\n**Commands:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\nmkdir -p frontend\ncd frontend\n```\n\n**Expected Outcome:**\n```\nDirectory created: /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/\n```\n\n**Rationale:** Separates frontend code from agent backend code\n\n---\n\n#### 2.2: Clone agent-starter-react Template\n\n**What:** Use LiveKit CLI to create a new project from the official template\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend\nlk app create --template agent-starter-react\n```\n\n**Interactive Prompts:**\n- **Project name:** (Press Enter for default or enter custom name like \"voice-ai-frontend\")\n- **Install dependencies?** Yes\n\n**Alternative (Manual Clone):**\n```bash\ngit clone https://github.com/livekit-examples/agent-starter-react.git voice-ai-frontend\ncd voice-ai-frontend\npnpm install\n```\n\n**Expected Outcome:**\n```\n✓ Created project: voice-ai-frontend\n✓ Installed dependencies\n✓ Ready to configure\n```\n\n**Directory Structure:**\n```\nfrontend/voice-ai-frontend/\n├── app/\n│   ├── api/token/route.ts     # Token generation endpoint\n│   ├── page.tsx               # Main page\n│   └── layout.tsx\n├── components/\n│   ├── agents-ui/             # Agents UI components\n│   ├── app/                   # Business logic\n│   └── ui/                    # Shadcn/ui primitives\n├── hooks/\n├── lib/\n├── public/\n├── package.json\n├── .env.example\n└── next.config.js\n```\n\n**Rationale:** Official template provides production-ready structure with all necessary LiveKit integrations\n\n---\n\n#### 2.3: Configure Environment Variables\n\n**What:** Set up LiveKit credentials for the frontend\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend/.env.local`\n\n**Commands:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\ncp .env.example .env.local\n```\n\n**Edit `.env.local`:**\n```env\n# LiveKit project credentials (from livekit-credentials.json)\nLIVEKIT_API_KEY=APIxxxxxxxxxxxx\nLIVEKIT_API_SECRET=your-secret-here\nLIVEKIT_URL=wss://your-project.livekit.cloud\n\n# Public URL (exposed to browser - same as LIVEKIT_URL)\nNEXT_PUBLIC_LIVEKIT_URL=wss://your-project.livekit.cloud\n\n# Agent configuration\nAGENT_NAME=\n# Leave AGENT_NAME blank for automatic agent dispatch\n# Or set to specific agent name if you have multiple agents\n```\n\n**How to Get Values:**\n```bash\n# Copy from livekit-credentials.json\ncat /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/livekit-credentials.json\n```\n\n**Security Notes:**\n- `LIVEKIT_API_SECRET` is server-side only (never exposed to browser)\n- `NEXT_PUBLIC_*` variables are exposed to browser\n- Only `NEXT_PUBLIC_LIVEKIT_URL` should be public\n- Never expose `LIVEKIT_API_KEY` or `LIVEKIT_API_SECRET` to browser\n\n**Rationale:** Frontend needs credentials to generate tokens and connect to LiveKit rooms\n\n---\n\n#### 2.4: Verify Dependencies Installation\n\n**What:** Ensure all npm packages are installed correctly\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\npnpm install\n```\n\n**Expected Outcome:**\n```\nPackages: +XXX\nProgress: resolved XXX, reused XXX, downloaded X, added XXX, done\n```\n\n**Key Dependencies (verify in `package.json`):**\n- `next` (v14+)\n- `react` (v18+)\n- `livekit-client`\n- `@livekit/components-react`\n- `livekit-server-sdk`\n- `tailwindcss`\n- `typescript`\n\n**Troubleshooting:**\n- If pnpm not installed: `npm install -g pnpm`\n- If peer dependency warnings: Generally safe to ignore\n- If install fails: Delete `node_modules` and `pnpm-lock.yaml`, retry\n\n**Rationale:** Ensures all required packages are available for development\n\n---\n\n#### 2.5: Run Development Server\n\n**What:** Start the Next.js development server to verify basic setup\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\npnpm dev\n```\n\n**Expected Outcome:**\n```\n> next dev\n\n  ▲ Next.js 14.x.x\n  - Local:        http://localhost:3000\n  - Environments: .env.local\n\n ✓ Ready in X.Xs\n```\n\n**Verification:**\n1. Open browser to http://localhost:3000\n2. Should see agent interface with \"Connect\" button\n3. No console errors in browser DevTools\n4. Page loads without 500 errors\n\n**Expected UI:**\n- Welcome/landing view\n- \"Connect\" or \"Start Session\" button\n- Logo and branding elements\n- Theme toggle (light/dark)\n\n**Troubleshooting:**\n- If port 3000 in use: `pnpm dev -- -p 3001`\n- If env vars missing: Check `.env.local` exists and has correct values\n- If build errors: Check `pnpm install` completed successfully\n\n**Rationale:** Validates Next.js setup before proceeding to authentication\n\n---\n\n#### 2.6: Inspect Token Generation API Route\n\n**What:** Review the built-in token generation endpoint to understand how authentication works\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend/app/api/token/route.ts`\n\n**Read the file:**\n```typescript\n// Expected structure (review actual implementation)\nimport { AccessToken } from 'livekit-server-sdk';\n\nexport async function POST(request: Request) {\n  const { roomName, participantName } = await request.json();\n\n  const token = new AccessToken(\n    process.env.LIVEKIT_API_KEY,\n    process.env.LIVEKIT_API_SECRET,\n    {\n      identity: participantName,\n      ttl: '2h', // Token valid for 2 hours\n    }\n  );\n\n  token.addGrant({\n    room: roomName,\n    roomJoin: true,\n    canPublish: true,\n    canSubscribe: true,\n  });\n\n  return Response.json({ token: await token.toJwt() });\n}\n```\n\n**Key Points:**\n- Uses `livekit-server-sdk` to generate JWT tokens\n- Reads `LIVEKIT_API_KEY` and `LIVEKIT_API_SECRET` from environment\n- Grants room join, publish, and subscribe permissions\n- Returns JWT token to frontend\n- Token expires after 2 hours (LiveKit auto-refreshes for connected clients)\n\n**Security Review:**\n- ✓ API key/secret are server-side only (not exposed to browser)\n- ✓ Token generation happens on server\n- ✓ Appropriate permissions granted\n- ⚠ Consider adding rate limiting for production\n\n**Rationale:** Understanding token flow is critical for debugging connection issues\n\n---\n\n#### 2.7: Add Frontend to .gitignore (Backend Repo)\n\n**What:** Prevent frontend from being committed to agent backend repo\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/.gitignore`\n\n**Add to `.gitignore`:**\n```bash\necho \"frontend/\" >> .gitignore\n```\n\n**Verify:**\n```bash\ngit status\n# frontend/ should not appear in untracked files\n```\n\n**Alternative Approach:**\nIf you want to commit the frontend to the same repo:\n- Create a separate `.gitignore` in `frontend/voice-ai-frontend/`\n- Add standard Next.js ignores (`.next/`, `node_modules/`, `.env.local`)\n\n**Rationale:** Keep frontend and backend as separate concerns, or manage carefully if in same repo\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Frontend directory created: `ls frontend/voice-ai-frontend`\n- [ ] Dependencies installed: `pnpm list --depth=0` shows key packages\n- [ ] Environment variables configured: `cat .env.local | grep LIVEKIT_API_KEY`\n- [ ] Development server starts: `pnpm dev` runs without errors\n- [ ] No TypeScript errors: `pnpm run build` completes successfully\n\n#### Manual Verification:\n\n- [ ] Visit http://localhost:3000 in browser\n- [ ] Page loads without 500 errors\n- [ ] UI displays welcome screen with \"Connect\" button\n- [ ] No console errors in browser DevTools\n- [ ] Theme toggle works (light/dark mode)\n- [ ] Responsive design works on mobile viewport\n\n**Verify:** After completing automated verification, open the app in a browser and verify UI loads correctly before proceeding to Phase 3.\n\n---\n\n## Phase 3: Authentication and Token Generation\n\n### Overview\n\nConfigure and test the JWT token generation flow to ensure frontend can authenticate users with LiveKit and connect them to agent sessions.\n\n### Context\n\nBefore starting, ensure:\n- Phase 2 completed successfully\n- Development server running at http://localhost:3000\n- Environment variables configured in `.env.local`\n\nFiles to review:\n- `frontend/voice-ai-frontend/app/api/token/route.ts` - Token generation endpoint\n- `frontend/voice-ai-frontend/.env.local` - Environment configuration\n- `frontend/voice-ai-frontend/components/app/` - Client-side connection logic\n\n### Dependencies\n\n**Depends on:** Phase 2 (frontend setup)\n\n**Required by:** Phase 4 (connection testing)\n\n### Changes Required\n\n#### 3.1: Test Token Generation Endpoint\n\n**What:** Verify the token API endpoint works correctly\n\n**Command:**\n```bash\n# Start dev server (if not running)\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\npnpm dev\n\n# In another terminal, test the endpoint\ncurl -X POST http://localhost:3000/api/token \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"roomName\": \"test-room\", \"participantName\": \"test-user\"}'\n```\n\n**Expected Response:**\n```json\n{\n  \"token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\"\n}\n```\n\n**Validate Token:**\n```bash\n# Decode the JWT to inspect claims (copy token from response)\necho \"eyJhbGciOiJ...\" | cut -d'.' -f2 | base64 -d | jq\n```\n\n**Expected Token Payload:**\n```json\n{\n  \"exp\": 1234567890,\n  \"iss\": \"APIxxxxxxxxxxxx\",\n  \"sub\": \"test-user\",\n  \"nbf\": 1234567890,\n  \"video\": {\n    \"room\": \"test-room\",\n    \"roomJoin\": true,\n    \"canPublish\": true,\n    \"canSubscribe\": true,\n    \"canPublishData\": true\n  }\n}\n```\n\n**Troubleshooting:**\n- If 500 error: Check environment variables in `.env.local`\n- If \"api_key undefined\": Verify `LIVEKIT_API_KEY` is set\n- If \"invalid signature\": Check `LIVEKIT_API_SECRET` is correct\n- If no response: Verify dev server is running on port 3000\n\n**Rationale:** Token generation must work before attempting to connect to LiveKit\n\n---\n\n#### 3.2: Review Client-Side Connection Logic\n\n**What:** Understand how the frontend connects to LiveKit rooms\n\n**Files to Review:**\n```bash\n# Main session component\ncat frontend/voice-ai-frontend/components/app/session-view.tsx\n\n# View controller\ncat frontend/voice-ai-frontend/components/app/view-controller.tsx\n\n# Connection utilities\ncat frontend/voice-ai-frontend/lib/connection.ts\n```\n\n**Key Flow:**\n1. User clicks \"Connect\" button\n2. Frontend generates room name (random or predefined)\n3. Frontend fetches token from `/api/token` endpoint\n4. Frontend connects to LiveKit room using `livekit-client`\n5. Agent is automatically dispatched to room\n6. User and agent establish WebRTC connection\n7. Audio tracks are exchanged\n\n**Important Variables:**\n- `NEXT_PUBLIC_LIVEKIT_URL` - LiveKit server URL (browser-accessible)\n- Room name generation logic\n- Participant name/identity\n- Agent dispatch configuration\n\n**Rationale:** Understanding client-side logic helps debug connection issues\n\n---\n\n#### 3.3: Configure Agent Dispatch\n\n**What:** Ensure frontend triggers automatic agent dispatch when users connect\n\n**File:** Review `frontend/voice-ai-frontend/app/api/connection-details/route.ts` (if exists) or equivalent\n\n**Verify Agent Name Configuration:**\n\n**Option A: Automatic Dispatch (Recommended):**\n```env\n# In .env.local\nAGENT_NAME=\n# Blank means \"dispatch any available agent\"\n```\n\n**Option B: Specific Agent:**\n```env\n# In .env.local\nAGENT_NAME=agent_abc123\n# Uses specific agent by ID or name\n```\n\n**Check Token Grant Configuration:**\n```typescript\n// In app/api/token/route.ts or connection-details/route.ts\ntoken.addGrant({\n  room: roomName,\n  roomJoin: true,\n  canPublish: true,\n  canSubscribe: true,\n  // Optional: Agent dispatch configuration\n});\n```\n\n**For agent-starter-react:**\nThe template typically handles agent dispatch automatically when a participant joins a room. Verify this by checking the token generation code and connection details endpoint.\n\n**Rationale:** Agent won't join room unless dispatch is configured correctly\n\n---\n\n#### 3.4: Test Token Expiration and Refresh\n\n**What:** Verify token expiration is set correctly and LiveKit handles refresh\n\n**Check Current TTL:**\n```typescript\n// In app/api/token/route.ts\nconst token = new AccessToken(\n  process.env.LIVEKIT_API_KEY,\n  process.env.LIVEKIT_API_SECRET,\n  {\n    identity: participantName,\n    ttl: '2h', // Current setting\n  }\n);\n```\n\n**Recommended TTL:**\n- Development: `2h` (2 hours)\n- Production: `2h` (LiveKit auto-refreshes for connected clients)\n- Pre-generated tokens: `1h` (if caching tokens)\n\n**Token Refresh Behavior:**\n- LiveKit client SDK automatically refreshes tokens before expiration\n- Refresh happens for connected clients only\n- Disconnected users must request new tokens\n\n**No changes needed if TTL is already `2h`.**\n\n**Rationale:** Prevents users from being disconnected due to token expiration\n\n---\n\n#### 3.5: Add Security Headers (Optional but Recommended)\n\n**What:** Add security headers to token API route\n\n**File:** `frontend/voice-ai-frontend/middleware.ts` (create if doesn't exist)\n\n**Content:**\n```typescript\nimport { NextResponse } from 'next/server';\nimport type { NextRequest } from 'next/server';\n\nexport function middleware(request: NextRequest) {\n  const response = NextResponse.next();\n\n  // Security headers\n  response.headers.set('X-Content-Type-Options', 'nosniff');\n  response.headers.set('X-Frame-Options', 'DENY');\n  response.headers.set('X-XSS-Protection', '1; mode=block');\n\n  return response;\n}\n\nexport const config = {\n  matcher: '/api/:path*',\n};\n```\n\n**Optional Rate Limiting:**\nConsider adding rate limiting to `/api/token` endpoint to prevent abuse.\n\n**Rationale:** Basic security hardening for production deployments\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Token endpoint returns valid JWT: `curl -X POST http://localhost:3000/api/token -H \"Content-Type: application/json\" -d '{\"roomName\":\"test\",\"participantName\":\"user\"}' | jq .token`\n- [ ] Token payload contains correct claims: Decode JWT and verify `video.roomJoin: true`\n- [ ] Environment variables loaded: `console.log(process.env.LIVEKIT_API_KEY)` in token route shows value (not undefined)\n- [ ] Token has correct expiration: Decoded JWT shows `exp` timestamp 2 hours in future\n\n#### Manual Verification:\n\n- [ ] Token endpoint accessible via browser: Visit http://localhost:3000/api/token (should return 405 Method Not Allowed for GET)\n- [ ] No errors in Next.js server logs when generating tokens\n- [ ] Token decodes successfully at https://jwt.io\n- [ ] Token issuer (`iss`) matches your LiveKit API key\n- [ ] Token subject (`sub`) matches requested participant name\n\n**Verify:** After completing automated verification, test token generation with curl and decode the JWT to inspect claims before proceeding to Phase 4.\n\n---\n\n## Phase 4: Connection Testing and Optimization\n\n### Overview\n\nTest the end-to-end connection flow from frontend to agent, verify audio works correctly, and optimize the connection speed.\n\n### Context\n\nBefore starting, ensure:\n- Phase 3 completed successfully\n- Agent running on LiveKit Cloud (`lk agent status` shows Running)\n- Frontend running at http://localhost:3000\n- Token generation working\n\nFiles to review:\n- `frontend/voice-ai-frontend/components/app/session-view.tsx` - Session management\n- `frontend/voice-ai-frontend/components/agents-ui/` - UI components\n\nTools needed:\n- Browser with microphone access\n- Terminal for monitoring agent logs\n\n### Dependencies\n\n**Depends on:** Phases 1-3 (agent deployed, frontend configured, authentication working)\n\n**Required by:** Phase 5 (customization), Phase 6 (production deployment)\n\n### Changes Required\n\n#### 4.1: Monitor Agent Logs\n\n**What:** Start monitoring agent logs before testing connection\n\n**Command:**\n```bash\n# Open a dedicated terminal window for agent logs\nlk agent logs --follow\n```\n\n**Keep this terminal open during all testing.**\n\n**What to Look For:**\n- Agent initialization messages\n- Room join events\n- STT transcriptions\n- LLM requests/responses\n- TTS generation\n- WebRTC connection events\n- Any error messages\n\n**Rationale:** Real-time logs are essential for debugging connection issues\n\n---\n\n#### 4.2: Test Basic Connection Flow\n\n**What:** Connect to the agent via frontend and verify basic functionality\n\n**Steps:**\n\n1. Open browser to http://localhost:3000\n2. Open browser DevTools Console (F12 → Console tab)\n3. Click \"Connect\" or \"Start Session\" button\n4. Grant microphone permissions when prompted\n5. Observe connection states in UI:\n   - \"Initializing...\"\n   - \"Listening\" (agent ready for input)\n   - \"Thinking\" (processing speech)\n   - \"Speaking\" (agent responding)\n\n**Expected Behavior:**\n- Connection establishes within 3-5 seconds\n- Agent state transitions to \"Listening\"\n- No errors in browser console\n- Agent logs show room join event\n\n**Troubleshooting:**\n- **Connection hangs:** Check token endpoint, verify LIVEKIT_URL is correct\n- **\"Failed to connect\":** Check agent status (`lk agent status`), verify agent is Running\n- **Microphone permission denied:** Grant permission in browser settings\n- **No audio:** Check browser audio output, verify speakers are enabled\n- **WebRTC errors:** Check firewall, ensure WebRTC ports not blocked\n\n**Rationale:** Validates basic connection before testing voice interaction\n\n---\n\n#### 4.3: Test Voice Interaction\n\n**What:** Verify end-to-end voice pipeline (STT → LLM → TTS)\n\n**Steps:**\n\n1. With frontend connected and agent in \"Listening\" state\n2. Speak clearly into your microphone: \"Hello, can you hear me?\"\n3. Observe agent state transition:\n   - \"Listening\" → \"Thinking\" → \"Speaking\"\n4. Listen for agent's voice response\n5. Check agent logs for:\n   - STT transcription of your speech\n   - LLM request and response\n   - TTS generation\n\n**Expected Outcome:**\n- Agent responds with natural voice within 2-4 seconds\n- Transcription appears in logs (if logging enabled)\n- No audio dropouts or distortion\n- Agent response is contextually appropriate\n\n**Additional Test Cases:**\n- **Interruption:** Speak while agent is speaking (should handle gracefully)\n- **Silence:** Wait 10 seconds without speaking (agent should remain connected)\n- **Background Noise:** Test with ambient noise (should filter with VAD)\n- **Multiple Turns:** Have a multi-turn conversation\n\n**Troubleshooting:**\n- **No transcription:** Check AssemblyAI API key in agent secrets\n- **No LLM response:** Check OpenAI API key, verify LLM model is available\n- **No TTS audio:** Check Cartesia API key, verify TTS voice model\n- **Garbled audio:** Check network connection, reduce network congestion\n- **High latency:** Check agent logs for slow API calls, consider region optimization\n\n**Rationale:** Validates the complete voice AI pipeline works end-to-end\n\n---\n\n#### 4.4: Verify Audio Visualization\n\n**What:** Test the audio visualizer component works correctly\n\n**Steps:**\n\n1. With frontend connected\n2. Speak into microphone\n3. Observe audio visualization:\n   - Bars should animate when you speak\n   - Bars should pulse when agent speaks\n   - Different colors/states for listening vs speaking\n\n**Expected Behavior:**\n- `BarVisualizer` component shows real-time audio levels\n- Smooth animations\n- Clear visual feedback of agent state\n- No lag between audio and visualization\n\n**Check Component:**\n```bash\n# Review visualizer component\ncat frontend/voice-ai-frontend/components/agents-ui/bar-visualizer.tsx\n```\n\n**Troubleshooting:**\n- **No visualization:** Check if audio track is being passed to component\n- **Choppy animation:** Check browser performance, reduce animation complexity\n- **Wrong colors:** Review CSS/Tailwind classes\n\n**Rationale:** Visual feedback improves user experience and debugging\n\n---\n\n#### 4.5: Test Disconnection and Reconnection\n\n**What:** Verify graceful disconnect and ability to reconnect\n\n**Steps:**\n\n**Test Disconnect:**\n1. With frontend connected\n2. Click \"Disconnect\" or \"End Session\" button\n3. Observe clean disconnect:\n   - Agent logs show participant left\n   - No error messages\n   - UI returns to welcome screen\n\n**Test Reconnect:**\n1. Click \"Connect\" again\n2. Verify new session starts successfully\n3. Test voice interaction again\n\n**Test Network Interruption (Optional):**\n1. While connected, disable network (Wi-Fi off)\n2. Observe reconnection behavior\n3. Re-enable network\n4. Verify auto-reconnect or error message\n\n**Expected Behavior:**\n- Clean disconnect without errors\n- Ability to reconnect immediately\n- Each session gets unique room/token\n- No lingering WebRTC connections\n\n**Rationale:** Ensures robust connection lifecycle management\n\n---\n\n#### 4.6: Optimize Connection Speed\n\n**What:** Reduce connection time from 3-5 seconds to <1 second using optimization techniques\n\n**Current Flow (Sequential):**\n```\n1. Click Connect (0ms)\n2. Fetch token from /api/token (500ms)\n3. Connect to LiveKit room (1000ms)\n4. Agent dispatched (1000ms)\n5. Agent connects and publishes (1500ms)\nTotal: ~4000ms (4 seconds)\n```\n\n**Optimization 1: Pre-generate Tokens**\n\nCreate a \"warm token\" approach for faster connection:\n\n**File:** Create `frontend/voice-ai-frontend/hooks/use-warm-token.ts`\n\n```typescript\n'use client';\n\nimport { useState, useEffect } from 'react';\n\nexport function useWarmToken() {\n  const [token, setToken] = useState<string | null>(null);\n\n  useEffect(() => {\n    // Pre-generate token on page load\n    async function generateToken() {\n      const response = await fetch('/api/token', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          roomName: `room-${Date.now()}`,\n          participantName: `user-${Math.random().toString(36).substring(7)}`,\n        }),\n      });\n      const data = await response.json();\n      setToken(data.token);\n    }\n\n    generateToken();\n  }, []);\n\n  return token;\n}\n```\n\n**Usage in Session Component:**\n```typescript\n// In session-view.tsx or similar\nconst warmToken = useWarmToken();\n\n// Use warmToken when connecting instead of fetching on-demand\n```\n\n**Optimization 2: Concurrent Dispatch**\n\nModify connection logic to dispatch agent and connect user simultaneously:\n\n```typescript\n// Parallel connection\nconst [roomConnection, agentDispatch] = await Promise.all([\n  connectToRoom(token),\n  dispatchAgent(roomName) // If manual dispatch required\n]);\n```\n\n**Expected Improvement:**\n- Pre-generated token: -500ms (eliminates token fetch delay)\n- Concurrent dispatch: -1000ms (parallel instead of sequential)\n- **New total:** ~2500ms → ~1500ms (1.5 seconds)\n\n**Trade-offs:**\n- Pre-generated tokens have expiration (ensure 2h TTL)\n- Unused tokens waste resources (minimal cost)\n- Complexity slightly increases\n\n**Rationale:** Faster connections improve user experience and perceived performance\n\n---\n\n#### 4.7: Test on Multiple Browsers\n\n**What:** Verify cross-browser compatibility\n\n**Browsers to Test:**\n- Chrome/Chromium\n- Firefox\n- Safari (macOS/iOS)\n- Edge\n\n**Test Matrix:**\n\n| Browser | Connection | Audio Input | Audio Output | Visualization |\n|---------|-----------|-------------|--------------|---------------|\n| Chrome  | ✓         | ✓           | ✓            | ✓             |\n| Firefox | ?         | ?           | ?            | ?             |\n| Safari  | ?         | ?           | ?            | ?             |\n| Edge    | ?         | ?           | ?            | ?             |\n\n**Common Issues:**\n- **Safari:** May require user interaction before audio playback\n- **Firefox:** Different WebRTC implementation, may have quirks\n- **Mobile Safari:** Requires specific audio context handling\n- **Edge:** Generally compatible with Chrome\n\n**Rationale:** Ensures wide browser support for production deployment\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Connection establishes successfully: Monitor for \"Room connected\" event in logs\n- [ ] Agent joins room: `lk agent logs` shows room join event\n- [ ] WebRTC connection: Browser DevTools Network tab shows WebRTC connections\n- [ ] No console errors: Browser DevTools Console shows no red errors\n- [ ] Audio tracks published: Check LiveKit Cloud dashboard for active tracks\n\n#### Manual Verification:\n\n- [ ] Voice input recognized: Speak and verify agent responds\n- [ ] Voice output works: Hear agent's TTS response clearly\n- [ ] Audio visualization animates correctly\n- [ ] Agent state transitions work (initializing → listening → thinking → speaking)\n- [ ] Interruption handling works (speak during agent response)\n- [ ] Disconnect and reconnect works cleanly\n- [ ] Connection time <3 seconds (before optimization) or <1.5s (after optimization)\n- [ ] Works in Chrome, Firefox, and Safari\n\n**Verify:** After completing automated verification, have a multi-turn conversation with the agent and test all edge cases before proceeding to Phase 5.\n\n---\n\n## Phase 5: Frontend Customization\n\n### Overview\n\nCustomize the frontend with your branding, colors, logo, and company information to make it production-ready.\n\n### Context\n\nBefore starting, ensure:\n- Phase 4 completed successfully\n- Voice interaction working end-to-end\n- Frontend running at http://localhost:3000\n\nFiles to customize:\n- `frontend/voice-ai-frontend/app-config.ts` - Main configuration\n- `frontend/voice-ai-frontend/public/` - Static assets (logo, favicon)\n- `frontend/voice-ai-frontend/app/layout.tsx` - Page metadata\n- `frontend/voice-ai-frontend/tailwind.config.ts` - Theme colors\n\n### Dependencies\n\n**Depends on:** Phase 4 (connection testing completed)\n\n**Required by:** Phase 6 (production deployment)\n\n### Changes Required\n\n#### 5.1: Update App Configuration\n\n**What:** Customize company name, page title, and feature flags\n\n**File:** `frontend/voice-ai-frontend/app-config.ts`\n\n**Edit:**\n```typescript\nexport const APP_CONFIG_DEFAULTS = {\n  // Branding\n  companyName: \"Your Company Name\", // Change this\n  pageTitle: \"AI Voice Assistant | Your Company\", // Change this\n\n  // Logo URLs\n  logoUrl: \"/logo.svg\", // Update after adding logo in 5.2\n  logoUrlDark: \"/logo-dark.svg\", // Optional: separate dark mode logo\n\n  // Accent color\n  accentColor: \"#4F46E5\", // Change to your brand color (hex)\n\n  // Feature toggles\n  supportsChatInput: true, // Allow text chat alongside voice\n  supportsVideoInput: true, // Enable camera video\n  supportsScreenShare: true, // Enable screen sharing\n  isPreConnectBufferEnabled: true, // Pre-load for faster connection\n\n  // Optional: Agent configuration\n  defaultAgentName: \"\", // Leave blank for auto-dispatch\n};\n```\n\n**Example Customization:**\n```typescript\nexport const APP_CONFIG_DEFAULTS = {\n  companyName: \"Acme Voice AI\",\n  pageTitle: \"Voice AI Assistant | Acme Corp\",\n  logoUrl: \"/acme-logo.svg\",\n  accentColor: \"#FF6B35\", // Orange\n  supportsChatInput: true,\n  supportsVideoInput: false, // Disable video for voice-only\n  supportsScreenShare: false,\n  isPreConnectBufferEnabled: true,\n};\n```\n\n**Rationale:** Centralizes configuration for easy customization without code changes\n\n---\n\n#### 5.2: Add Custom Logo\n\n**What:** Replace default logo with your company logo\n\n**Steps:**\n\n1. Prepare logo files:\n   - **Format:** SVG (preferred) or PNG\n   - **Size:**\n     - SVG: Any size (scalable)\n     - PNG: 200x200px minimum, transparent background\n   - **Naming:**\n     - Light mode: `logo.svg` or `logo.png`\n     - Dark mode (optional): `logo-dark.svg` or `logo-dark.png`\n\n2. Copy to public directory:\n   ```bash\n   cp /path/to/your/logo.svg frontend/voice-ai-frontend/public/logo.svg\n   # Optional: dark mode logo\n   cp /path/to/your/logo-dark.svg frontend/voice-ai-frontend/public/logo-dark.svg\n   ```\n\n3. Update `app-config.ts`:\n   ```typescript\n   logoUrl: \"/logo.svg\",\n   logoUrlDark: \"/logo-dark.svg\", // If you have separate dark logo\n   ```\n\n4. Verify logo appears:\n   - Restart dev server: `pnpm dev`\n   - Visit http://localhost:3000\n   - Check logo displays correctly\n   - Toggle light/dark mode to test both logos\n\n**Fallback:**\nIf you don't have a logo ready, the template includes a default placeholder logo.\n\n**Rationale:** Custom logo reinforces brand identity\n\n---\n\n#### 5.3: Customize Theme Colors\n\n**What:** Update color scheme to match your brand\n\n**File:** `frontend/voice-ai-frontend/tailwind.config.ts`\n\n**Edit:**\n```typescript\nexport default {\n  theme: {\n    extend: {\n      colors: {\n        // Primary brand color\n        primary: {\n          50: '#f0f9ff',\n          100: '#e0f2fe',\n          // ... continue through 950\n          500: '#4F46E5', // Main brand color (change this)\n          600: '#4338ca',\n          // ...\n        },\n        // Accent color\n        accent: {\n          DEFAULT: '#FF6B35', // Change to your accent color\n          light: '#FF8A5B',\n          dark: '#E5501F',\n        },\n      },\n    },\n  },\n};\n```\n\n**Quick Method (Use Accent Color from app-config.ts):**\n\nThe template may automatically use `accentColor` from `app-config.ts`. If so, just update that value:\n\n```typescript\n// In app-config.ts\naccentColor: \"#FF6B35\", // Your brand color\n```\n\n**Generate Full Color Palette:**\nUse tools like https://uicolors.app/create to generate a full Tailwind color palette from your brand color.\n\n**Test Theme:**\n- Restart dev server\n- Visit http://localhost:3000\n- Check buttons, links, highlights use new colors\n- Toggle light/dark mode to verify both themes\n\n**Rationale:** Consistent color scheme creates professional, branded experience\n\n---\n\n#### 5.4: Update Page Metadata\n\n**What:** Set page title, description, and favicon for SEO and browser display\n\n**File:** `frontend/voice-ai-frontend/app/layout.tsx`\n\n**Edit:**\n```typescript\nexport const metadata: Metadata = {\n  title: \"AI Voice Assistant | Your Company\", // Change this\n  description: \"Connect with our AI voice assistant for instant help and support.\", // Change this\n  icons: {\n    icon: '/favicon.ico', // Update after adding favicon\n  },\n  openGraph: {\n    title: \"AI Voice Assistant | Your Company\",\n    description: \"Connect with our AI voice assistant for instant help and support.\",\n    images: ['/og-image.png'], // Optional: social share image\n  },\n};\n```\n\n**Add Custom Favicon:**\n\n1. Generate favicon files (use https://realfavicongenerator.net/):\n   - `favicon.ico` (16x16, 32x32, 48x48)\n   - `apple-touch-icon.png` (180x180)\n   - `favicon-16x16.png`\n   - `favicon-32x32.png`\n\n2. Copy to `public/`:\n   ```bash\n   cp /path/to/favicon.ico frontend/voice-ai-frontend/public/\n   cp /path/to/apple-touch-icon.png frontend/voice-ai-frontend/public/\n   ```\n\n3. Verify in browser:\n   - Clear browser cache\n   - Visit http://localhost:3000\n   - Check browser tab shows your favicon\n\n**Optional: Open Graph Image (Social Sharing):**\nCreate `og-image.png` (1200x630px) for social media previews.\n\n**Rationale:** Professional metadata improves SEO and user experience\n\n---\n\n#### 5.5: Customize Welcome Message\n\n**What:** Update the welcome screen text and instructions\n\n**File:** `frontend/voice-ai-frontend/components/app/welcome-view.tsx` or similar\n\n**Find and Edit:**\n```typescript\n<h1>Welcome to [Your Company] Voice AI</h1>\n<p>\n  Click the button below to start a voice conversation with our AI assistant.\n  We can help you with questions, information, and more.\n</p>\n```\n\n**Example Customization:**\n```typescript\n<h1>Welcome to Acme Voice Assistant</h1>\n<p>\n  Our AI assistant is ready to help you 24/7. Click \"Connect\" to start a\n  natural voice conversation. Just speak naturally - no keywords or commands needed.\n</p>\n<ul>\n  <li>Get instant answers to your questions</li>\n  <li>Learn about our products and services</li>\n  <li>Get personalized recommendations</li>\n</ul>\n```\n\n**Rationale:** Clear messaging helps users understand what to expect\n\n---\n\n#### 5.6: Optional - Disable Features Not Needed\n\n**What:** Hide video/screen share features if you only need voice\n\n**File:** `frontend/voice-ai-frontend/app-config.ts`\n\n**For Voice-Only App:**\n```typescript\nexport const APP_CONFIG_DEFAULTS = {\n  // ... other settings\n  supportsChatInput: false, // Disable text chat\n  supportsVideoInput: false, // Disable camera\n  supportsScreenShare: false, // Disable screen sharing\n  isPreConnectBufferEnabled: true, // Keep for faster connection\n};\n```\n\n**Effect:**\n- Video camera icon hidden\n- Screen share button removed\n- UI simplified to voice-only interface\n- Reduced complexity for users\n\n**Rationale:** Simplify UI by removing unused features\n\n---\n\n#### 5.7: Test Customizations\n\n**What:** Verify all customizations display correctly\n\n**Checklist:**\n- [ ] Company name displays on welcome screen\n- [ ] Custom logo appears (both light and dark modes)\n- [ ] Page title shows in browser tab\n- [ ] Custom favicon appears in browser tab\n- [ ] Brand colors visible on buttons and accents\n- [ ] Welcome message updated with custom text\n- [ ] Disabled features are hidden (if applicable)\n- [ ] No broken images or 404s\n- [ ] Responsive design maintained on mobile\n\n**Testing Steps:**\n1. Restart dev server: `pnpm dev`\n2. Clear browser cache (Cmd+Shift+R on Mac, Ctrl+Shift+R on Windows)\n3. Visit http://localhost:3000\n4. Toggle light/dark theme\n5. Resize browser to mobile size (375px width)\n6. Check all visual elements\n\n**Rationale:** Ensures professional, branded appearance before production deployment\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Build succeeds: `pnpm run build` completes without errors\n- [ ] No TypeScript errors: `pnpm run type-check` (if available)\n- [ ] Static assets exist: `ls public/logo.svg public/favicon.ico`\n- [ ] Config updated: `cat app-config.ts | grep companyName` shows your company\n\n#### Manual Verification:\n\n- [ ] Custom company name displays on welcome screen\n- [ ] Custom logo visible (light and dark modes)\n- [ ] Page title correct in browser tab\n- [ ] Favicon visible in browser tab\n- [ ] Brand colors applied throughout UI\n- [ ] Welcome message updated\n- [ ] Unused features hidden (if disabled)\n- [ ] Mobile responsive (test at 375px width)\n- [ ] No console errors or warnings\n- [ ] All images load correctly (no broken images)\n\n**Verify:** After completing automated verification, thoroughly test the UI on desktop and mobile, in light and dark modes, before proceeding to Phase 6.\n\n---\n\n## Phase 6: Production Deployment\n\n### Overview\n\nDeploy the customized frontend to Vercel (or another hosting provider) to make it publicly accessible via a URL that clients can visit.\n\n### Context\n\nBefore starting, ensure:\n- Phase 5 completed successfully\n- All customizations tested locally\n- Frontend builds successfully (`pnpm run build`)\n- Agent deployed and running on LiveKit Cloud\n\nFiles to review:\n- `frontend/voice-ai-frontend/.env.local` - Environment variables (will configure in Vercel)\n- `frontend/voice-ai-frontend/next.config.js` - Next.js configuration\n- `frontend/voice-ai-frontend/package.json` - Dependencies and scripts\n\nAccounts needed:\n- Vercel account (free tier sufficient): https://vercel.com\n- GitHub account (for connecting repo)\n\n### Dependencies\n\n**Depends on:** Phases 1-5 (agent deployed, frontend customized and tested)\n\n**Required by:** None (final phase)\n\n### Changes Required\n\n#### 6.1: Create Production Build\n\n**What:** Verify the production build works correctly before deploying\n\n**Commands:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\n\n# Create production build\npnpm run build\n\n# Test production build locally\npnpm start\n```\n\n**Expected Output:**\n```\n> next build\n\n✓ Compiled successfully\n✓ Linting and checking validity of types\n✓ Collecting page data\n✓ Generating static pages (X/X)\n✓ Finalizing page optimization\n\nRoute (app)                              Size     First Load JS\n┌ ○ /                                    XXX kB        XXX kB\n└ ○ /api/token                          XXX B          XXX kB\n```\n\n**Test Production Build:**\n1. Visit http://localhost:3000 (pnpm start)\n2. Connect to agent\n3. Verify voice interaction works\n4. Check for any errors in console\n\n**Troubleshooting:**\n- If build fails: Check TypeScript errors, fix before proceeding\n- If errors about environment variables: Ensure `.env.local` exists\n- If runtime errors: Check browser console for specific issues\n\n**Rationale:** Catches production-specific issues before deployment\n\n---\n\n#### 6.2: Push Frontend to GitHub (Optional but Recommended)\n\n**What:** Create a Git repository for the frontend to enable easy Vercel deployment\n\n**Option A: Separate Repository (Recommended):**\n\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\n\n# Initialize git repository\ngit init\n\n# Add .gitignore for Next.js\ncat > .gitignore << 'EOF'\n# Next.js\n.next/\nout/\nbuild/\ndist/\n\n# Dependencies\nnode_modules/\n\n# Environment variables\n.env\n.env.local\n.env.production.local\n.env.development.local\n.env.test.local\n\n# Logs\nnpm-debug.log*\nyarn-debug.log*\nyarn-error.log*\npnpm-debug.log*\n\n# OS\n.DS_Store\n*.swp\n*.swo\n\n# IDE\n.vscode/\n.idea/\n\n# Vercel\n.vercel\nEOF\n\n# Add files\ngit add .\ngit commit -m \"Initial commit: Voice AI frontend\"\n\n# Create GitHub repository (via GitHub UI or CLI)\ngh repo create voice-ai-frontend --public --source=. --remote=origin --push\n```\n\n**Option B: Same Repository as Agent:**\n\nIf you want frontend and agent in the same repo:\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\n\n# Remove frontend/ from .gitignore\nsed -i '' '/^frontend\\//d' .gitignore\n\n# Add and commit\ngit add frontend/\ngit commit -m \"Add voice AI frontend\"\ngit push\n```\n\n**Rationale:** Git repository enables continuous deployment and version control\n\n---\n\n#### 6.3: Sign Up for Vercel\n\n**What:** Create a Vercel account for hosting the frontend\n\n**Steps:**\n\n1. Visit https://vercel.com\n2. Click \"Sign Up\"\n3. Choose \"Continue with GitHub\" (recommended)\n4. Authorize Vercel to access your GitHub repositories\n\n**Pricing:**\n- **Free Tier:** Sufficient for testing and low traffic\n  - Unlimited deployments\n  - 100 GB bandwidth/month\n  - Serverless functions included\n- **Pro Tier:** $20/month (for production with higher traffic)\n\n**Rationale:** Vercel provides seamless Next.js hosting with automatic deployments\n\n---\n\n#### 6.4: Deploy Frontend to Vercel\n\n**What:** Deploy the frontend application to Vercel\n\n**Steps:**\n\n1. **From Vercel Dashboard:**\n   - Click \"Add New...\" → \"Project\"\n   - Select \"Import Git Repository\"\n   - Choose your frontend repository\n   - Configure project:\n     - **Framework Preset:** Next.js (auto-detected)\n     - **Root Directory:** `./` (or `frontend/voice-ai-frontend` if in monorepo)\n     - **Build Command:** `pnpm run build` (auto-detected)\n     - **Output Directory:** `.next` (auto-detected)\n     - **Install Command:** `pnpm install` (auto-detected)\n\n2. **Configure Environment Variables:**\n   Click \"Environment Variables\" and add:\n\n   ```\n   LIVEKIT_API_KEY=APIxxxxxxxxxxxx\n   LIVEKIT_API_SECRET=your-secret-here\n   LIVEKIT_URL=wss://your-project.livekit.cloud\n   NEXT_PUBLIC_LIVEKIT_URL=wss://your-project.livekit.cloud\n   AGENT_NAME=\n   ```\n\n   **Important:**\n   - Copy values from your local `.env.local`\n   - Apply to \"Production\", \"Preview\", and \"Development\" environments\n\n3. **Deploy:**\n   - Click \"Deploy\"\n   - Wait for build to complete (2-5 minutes)\n\n**Expected Outcome:**\n```\n✓ Build successful\n✓ Deployment successful\nYour project is now live at: https://your-app.vercel.app\n```\n\n**Rationale:** Makes frontend publicly accessible via HTTPS URL\n\n---\n\n#### 6.5: Test Production Deployment\n\n**What:** Verify the deployed frontend works correctly\n\n**Steps:**\n\n1. Visit your Vercel URL: `https://your-app.vercel.app`\n\n2. **Test Checklist:**\n   - [ ] Page loads without errors\n   - [ ] Custom branding displays correctly\n   - [ ] Click \"Connect\" button\n   - [ ] Grant microphone permissions\n   - [ ] Speak to agent\n   - [ ] Verify agent responds with voice\n   - [ ] Test on mobile device\n   - [ ] Test in different browsers\n\n3. **Monitor Logs:**\n   ```bash\n   # Monitor agent logs during production test\n   lk agent logs --follow\n   ```\n\n4. **Check Vercel Deployment Logs:**\n   - Go to Vercel dashboard → Your project → Deployments\n   - Click on latest deployment → \"Functions\" tab\n   - Check for any errors in `/api/token` function\n\n**Troubleshooting:**\n- **\"Failed to connect\":** Check environment variables in Vercel\n- **Token errors:** Verify `LIVEKIT_API_KEY` and `LIVEKIT_API_SECRET` are correct\n- **CORS errors:** Ensure `NEXT_PUBLIC_LIVEKIT_URL` is set correctly\n- **Agent not joining:** Check agent status, verify agent is Running\n\n**Rationale:** Ensures production environment works correctly\n\n---\n\n#### 6.6: Configure Custom Domain (Optional)\n\n**What:** Use a custom domain instead of `your-app.vercel.app`\n\n**Prerequisites:**\n- Own a domain name (e.g., `voiceai.yourcompany.com`)\n- Access to domain DNS settings\n\n**Steps:**\n\n1. **In Vercel Dashboard:**\n   - Go to your project → Settings → Domains\n   - Click \"Add Domain\"\n   - Enter your domain: `voiceai.yourcompany.com`\n\n2. **Configure DNS:**\n   Vercel will provide DNS configuration instructions:\n\n   **Option A: CNAME (Subdomain):**\n   ```\n   Type: CNAME\n   Name: voiceai\n   Value: cname.vercel-dns.com\n   ```\n\n   **Option B: A Record (Root Domain):**\n   ```\n   Type: A\n   Name: @\n   Value: 76.76.21.21\n   ```\n\n3. **Wait for DNS Propagation:**\n   - Usually takes 5-60 minutes\n   - Vercel will auto-configure SSL certificate (Let's Encrypt)\n\n4. **Verify:**\n   - Visit `https://voiceai.yourcompany.com`\n   - Should show your frontend with SSL (green lock icon)\n\n**Rationale:** Custom domain provides professional appearance and brand consistency\n\n---\n\n#### 6.7: Enable Automatic Deployments\n\n**What:** Configure automatic deployments when you push to GitHub\n\n**Vercel Auto-Deploys By Default:**\n- **Production:** Deploys on push to `main` branch\n- **Preview:** Deploys on push to any other branch or PR\n\n**Customize (Optional):**\n1. Go to Vercel dashboard → Your project → Settings → Git\n2. Configure:\n   - **Production Branch:** `main` (or `master`)\n   - **Ignored Build Step:** (leave blank to build on every commit)\n\n**Test Automatic Deployment:**\n```bash\ncd frontend/voice-ai-frontend\n\n# Make a small change\necho \"# Updated\" >> README.md\n\n# Commit and push\ngit add README.md\ngit commit -m \"Test automatic deployment\"\ngit push origin main\n```\n\n**Verify:**\n- Visit Vercel dashboard\n- Should see new deployment triggered automatically\n- Wait for build to complete\n- Visit production URL to see changes\n\n**Rationale:** Enables continuous deployment for easy updates\n\n---\n\n#### 6.8: Set Up Production Monitoring (Recommended)\n\n**What:** Monitor production errors and usage\n\n**Vercel Analytics (Built-in):**\n1. Go to Vercel dashboard → Your project → Analytics\n2. View:\n   - Page views\n   - Geographic distribution\n   - Performance metrics (Web Vitals)\n\n**Error Tracking (Optional):**\nConsider integrating Sentry or similar:\n```bash\npnpm add @sentry/nextjs\nnpx @sentry/wizard@latest -i nextjs\n```\n\n**LiveKit Cloud Monitoring:**\n- Visit LiveKit Cloud dashboard\n- Monitor:\n  - Active sessions\n  - Agent usage\n  - Costs (session minutes)\n\n**Rationale:** Production monitoring helps identify and resolve issues quickly\n\n---\n\n#### 6.9: Create Shareable Link\n\n**What:** Generate a clean, shareable URL for potential clients\n\n**Your Production URL:**\n```\nhttps://your-app.vercel.app\n```\n\n**Or with Custom Domain:**\n```\nhttps://voiceai.yourcompany.com\n```\n\n**Create Marketing Materials:**\n- Add link to your website\n- Share via email campaigns\n- Include in social media bios\n- Create QR code for physical materials\n\n**Example QR Code Generation:**\n```bash\n# Generate QR code (using qrencode)\nbrew install qrencode\nqrencode -o voiceai-qr.png \"https://voiceai.yourcompany.com\"\n```\n\n**Rationale:** Easy sharing enables potential clients to access your voice AI\n\n---\n\n#### 6.10: Document Production URLs and Credentials\n\n**What:** Save all production information for future reference\n\n**Create:** `frontend/voice-ai-frontend/PRODUCTION.md`\n\n**Content:**\n```markdown\n# Production Deployment Information\n\n## URLs\n- **Production Frontend:** https://your-app.vercel.app\n- **Custom Domain:** https://voiceai.yourcompany.com (if configured)\n- **LiveKit Cloud Dashboard:** https://cloud.livekit.io\n\n## Vercel\n- **Project:** voice-ai-frontend\n- **Account:** your-email@example.com\n- **Git Repository:** https://github.com/yourusername/voice-ai-frontend\n\n## LiveKit Cloud\n- **Project:** your-project-name\n- **Region:** us-west-2\n- **Agent ID:** agent_abc123\n\n## Deployment Commands\n```bash\n# Deploy agent updates\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\nlk agent deploy\n\n# Deploy frontend updates (automatic via Git)\ncd frontend/voice-ai-frontend\ngit add .\ngit commit -m \"Update frontend\"\ngit push origin main\n```\n\n## Monitoring\n- **Agent Logs:** `lk agent logs --follow`\n- **Vercel Logs:** https://vercel.com/your-project/deployments\n- **LiveKit Dashboard:** https://cloud.livekit.io/projects/your-project\n\n## Environment Variables (Vercel)\n- LIVEKIT_API_KEY=APIxxxxxxxxxxxx\n- LIVEKIT_API_SECRET=*** (not shown)\n- LIVEKIT_URL=wss://your-project.livekit.cloud\n- NEXT_PUBLIC_LIVEKIT_URL=wss://your-project.livekit.cloud\n\n## Costs\n- **LiveKit Cloud:** $0.01 per agent session minute\n- **Vercel:** Free tier (or $20/month Pro)\n\n## Support\n- **LiveKit:** https://livekit.io/discord\n- **Vercel:** https://vercel.com/support\n```\n\n**Rationale:** Documentation ensures you can manage production deployment long-term\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Production build succeeds: `pnpm run build` completes without errors\n- [ ] Vercel deployment successful: Deployment status shows \"Ready\"\n- [ ] HTTPS enabled: Visit production URL with green lock icon\n- [ ] Environment variables configured: Check Vercel dashboard\n- [ ] Custom domain configured (if applicable): DNS records set\n\n#### Manual Verification:\n\n- [ ] Visit production URL in browser\n- [ ] Page loads without errors\n- [ ] Custom branding displays correctly\n- [ ] Click \"Connect\" and grant microphone access\n- [ ] Speak to agent and verify voice response\n- [ ] Test on mobile device (iOS Safari, Android Chrome)\n- [ ] Test in incognito/private mode\n- [ ] Share URL with colleague and get confirmation it works\n- [ ] Agent logs show production sessions: `lk agent logs --follow`\n- [ ] No errors in Vercel function logs\n\n**Verify:** After completing automated verification, test the production URL on multiple devices and browsers, then share with a colleague to confirm public accessibility.\n\n---\n\n## Testing Strategy\n\n### Unit Tests\n\n**Not required for this plan.** The agent-starter-react template is a pre-built, production-ready template that doesn't require custom unit tests unless you add significant custom logic.\n\n**Optional:** Add tests if you customize components heavily:\n```bash\npnpm add -D @testing-library/react @testing-library/jest-dom jest\n```\n\n### Integration Tests\n\n**End-to-End Testing:**\n\nManually test the complete flow:\n1. User visits URL\n2. Clicks \"Connect\"\n3. Grants microphone access\n4. Speaks to agent\n5. Receives voice response\n6. Disconnects cleanly\n\n**Test Matrix:**\n\n| Scenario | Steps | Expected Outcome |\n|----------|-------|------------------|\n| First Connection | Visit URL → Click Connect → Speak | Agent responds with voice |\n| Interruption | Speak while agent is speaking | Agent handles gracefully |\n| Disconnect/Reconnect | End session → Start new session | New session works |\n| Multiple Turns | Have 3-5 turn conversation | All responses relevant |\n| Mobile Safari | Test on iPhone/iPad | Full functionality |\n| Network Interruption | Disable Wi-Fi during session | Reconnection or error message |\n\n### Manual Testing Steps\n\n**Pre-Deployment Checklist:**\n1. [ ] Agent deployed and running: `lk agent status`\n2. [ ] Local frontend works: `pnpm dev` at http://localhost:3000\n3. [ ] Voice interaction successful\n4. [ ] Audio visualization working\n5. [ ] Custom branding applied\n6. [ ] Production build succeeds: `pnpm run build`\n\n**Post-Deployment Checklist:**\n1. [ ] Production URL accessible\n2. [ ] HTTPS enabled (green lock)\n3. [ ] Voice interaction works on production\n4. [ ] Mobile responsive\n5. [ ] Cross-browser compatible\n6. [ ] Shareable link works for external users\n\n### Performance Considerations\n\n**Metrics to Monitor:**\n- **Connection Time:** Should be <3 seconds (or <1.5s with optimization)\n- **Response Latency:** STT → LLM → TTS should be 2-4 seconds\n- **Page Load Time:** Initial load <2 seconds (Lighthouse score >90)\n- **Audio Quality:** No dropouts or distortion\n\n**Optimization:**\n- Enable pre-connect buffering in `app-config.ts`\n- Use warm token approach (Phase 4.6)\n- Minimize bundle size (Next.js handles automatically)\n- Use CDN for static assets (Vercel provides automatically)\n\n## References\n\n### Original Ticket/Request\n- User request: \"I want potential clients to be able to interact with the livekit agent from this repo by clicking a link on a website.\"\n\n### Documentation\n- `docs/DEPLOYMENT.md` - Complete deployment guide for agent and frontend options\n- `README.md` - Project overview and setup instructions\n- `AGENTS.md` - Project guidelines and standards\n\n### LiveKit Resources\n- **Frontend Deployment Guide:** https://docs.livekit.io/agents/start/frontend/\n- **agent-starter-react Repository:** https://github.com/livekit-examples/agent-starter-react\n- **Token Authentication:** https://docs.livekit.io/home/get-started/authentication/\n- **Agents Playground:** https://agents-playground.livekit.io/\n- **LiveKit Cloud Dashboard:** https://cloud.livekit.io\n- **React Components Docs:** https://docs.livekit.io/reference/components/react/\n\n### NPM Packages\n- **livekit-client:** Client SDK for browser WebRTC\n- **@livekit/components-react:** React UI components\n- **livekit-server-sdk:** Server-side token generation\n\n### Vercel Resources\n- **Vercel Platform:** https://vercel.com\n- **Next.js Documentation:** https://nextjs.org/docs\n- **Deployment Docs:** https://vercel.com/docs\n\n### Related Plans\n- None (initial implementation)\n\n---\n\n**End of Implementation Plan**\n","numLines":2312,"startLine":1,"totalLines":2312}},"sourceToolAssistantUUID":"7eda4b89-34c2-4b4b-8c0b-75a47fb1e181"}
{"parentUuid":"f15f1953-769e-4148-874a-fb1a1afad061","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","slug":"enumerated-shimmying-starlight","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01XCbLktmrMFcR8xzFpg4reD","toolUseID":"toolu_01XCbLktmrMFcR8xzFpg4reD","timestamp":"2026-01-25T09:44:31.977Z","uuid":"c0d5d28c-9939-4d3d-89f7-b9a155db242e"}
{"parentUuid":"c0d5d28c-9939-4d3d-89f7-b9a155db242e","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","slug":"enumerated-shimmying-starlight","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_016NWSgPxg64XSb9hsQpB1Br","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I've read both files. I need to update them to specify that no user video or screenshare permissions should be requested since this is an audio-only app. Let me identify the sections that mention video or screen sharing permissions:\n\nIn the options summary file:\n- Line 43: \"✓ Camera video and screen sharing support\"\n- Line 437-447: Token permission grants mentioning video sources\n- Lines around 1438-1439, 1454-1456, and 1651-1655 discuss video/screenshare features\n\nIn the deployment plan file:\n- Lines around 5.6 (Optional - Disable Features Not Needed) already mention disabling video features\n- Token grant configuration sections mention video permissions\n\nI need to:\n1. Update the options summary to specify this is audio-only\n2. Update token permission examples to show audio-only configuration\n3. Emphasize in the deployment plan that video/screenshare should be disabled\n\nLet me make these edits.","signature":"ErEICkYICxgCKkAuz1Wu311jG2jpZjzqDDhfEzHricxjgP+GDwTZ55u2M4YVgLHztnhtj+eyVsw7fSJmG5Ze13LAB3MoBUOYkasDEgwF0rwWyUccNvcrs2gaDN/QJuWW2ihP9wvuUyIwqpHb8/IigKBGx81UKi1sDEEdDXX49UwtP8YukP8P/GItxw7fDDCE5bkJGhKTyikJKpgHuO8+P57mS8p60d/tjF1n5NKqcfLyrlLYJgYbnukB+HxULvNrhxU4loOXcySZlOx1wg5NqBqGYCO/eKl3WJuKtzOCgHGCgNYBuhMuSOMj+NYM2avc5lHutpFf2czYWlqiPcocxumkWY0MeWSJo3WBledSvhwwmCiHbIGpE3PVebhffrNRZNfQ+E9Ysg6rqMuq+Hm6EEbLPhWsqjC4EJvi/JJRMLCF57umd+80Cc9gs2x/EJANWJMGnJpsaPs7C5IY0wlVRVxdrOXDFo8AbF7PEEAgOo5z3pV+crVXK7WV/s+AR4NtEFCds2h3Wox/9IeCMKpZByzSpU4Xz1AjR4yWF/OGAmaIatlfRvYZDoB9NaZzSYj+uajry3HrW+VKCQhyh6dtCOMWDGJhvY83RS5/KQ3hCd1WLqPR0xdPB8u0OjRDau8WBSZjxLhjOXB30ipQMua/x6P18eNOqW76naz2oL6UkiavIQiQ9ip6LCZsF9dckHGIhW9hk+eFL92hUe1wvVfl+htq9y0InbTaErFcrl+VyA7YqGnXEnVlTwdjNJXZEeh8MfkKgEfaCJUq4I/vgpnm7uQvKCn4QJPJfK66Y+VQXmF9Lp8bailpLLJFIpgvebZWM23rjPailAkPxbrsGRnffY5UOTbTIuUuZeWBhO9dFPVejz2cQ3VeM3s0UQ2b7xiTKSQiLug9zEKWeKl2Y/Vaw1cyjnVODuGE7NlWBl1XJAbxz+zbKSnDiK5blpm5uHP7Ybp+5pGT21547oa9Z8sQ5AJKQ27fEGFXNr3fhdCcLxnWxqXSj/eSIZK5oONYS8y8P4iXbYw2OwDvjEJk17Y39xRKWPqEInHJqC3Zi0W6tumrCNUcCi4GCPV0RBHAxbpS/d9qcl2AD8QCA5BuIXL0N4HCVOu/2U9nV0oL9H92rGJV96pUeyynZ5cbp3LxNS8RqywERPE59NKIahR3JxPnVIATuDXPfvNRquRCJ8VJstecMwekGEWr4Pao3P3uO94YOAYSJF6IMUArp0gXZTCM/fETm3XKEAWYFHjGfKVOR6E+vnGwpHm2OTu4q8LAvZ4IV1E+PaqmNYDMxEjl6IsCHxfPQPHPCQUDmXw0exvKrGilQ8mLt45cHkx3iUCmRwh9Frq6KU+1aR5DwSFu+24rKjJQt6Zf2QrRHhlu52/QyZJ7VdX7VvWM24mIweC8Tua+gVV6YlPVmTsRVKNjVZ4HDggyE0gYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":14,"cache_creation_input_tokens":36645,"cache_read_input_tokens":27826,"cache_creation":{"ephemeral_5m_input_tokens":36645,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXTt3SDWVHNCguY6xxYte","type":"assistant","uuid":"ca5f1c8d-2999-4566-ba2b-e9eb23dfc88e","timestamp":"2026-01-25T09:44:41.301Z"}
{"parentUuid":"ca5f1c8d-2999-4566-ba2b-e9eb23dfc88e","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","slug":"enumerated-shimmying-starlight","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_016NWSgPxg64XSb9hsQpB1Br","type":"message","role":"assistant","content":[{"type":"text","text":"I'll update both files to specify that this is an audio-only app and no video/screenshare permissions should be requested."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":14,"cache_creation_input_tokens":36645,"cache_read_input_tokens":27826,"cache_creation":{"ephemeral_5m_input_tokens":36645,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXTt3SDWVHNCguY6xxYte","type":"assistant","uuid":"f9854be0-39ae-4447-9a18-48c74db4f1c0","timestamp":"2026-01-25T09:44:41.869Z"}
{"parentUuid":"f9854be0-39ae-4447-9a18-48c74db4f1c0","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","slug":"enumerated-shimmying-starlight","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_016NWSgPxg64XSb9hsQpB1Br","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01L1hxwM7TsKrtJ9cghuQxHX","name":"Edit","input":{"replace_all":false,"file_path":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/plan/future-plans/2026-01-25-web-frontend-options-summary.md","old_string":"### Key Features\n✓ Token generation API route (`/api/token`)\n✓ `useVoiceAssistant` React hook for agent state\n✓ Audio visualizer (`BarVisualizer`)\n✓ Camera video and screen sharing support\n✓ Light/dark theme with system preference\n✓ Customizable branding via `app-config.ts`\n✓ Mobile-responsive design\n✓ Production-ready architecture","new_string":"### Key Features\n✓ Token generation API route (`/api/token`)\n✓ `useVoiceAssistant` React hook for agent state\n✓ Audio visualizer (`BarVisualizer`)\n✓ Audio-only interface (video and screen sharing disabled)\n✓ Light/dark theme with system preference\n✓ Customizable branding via `app-config.ts`\n✓ Mobile-responsive design\n✓ Production-ready architecture\n\n**IMPORTANT: This is an audio-only application. Video camera and screen sharing features should be disabled in configuration.**"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":14,"cache_creation_input_tokens":36645,"cache_read_input_tokens":27826,"cache_creation":{"ephemeral_5m_input_tokens":36645,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXTt3SDWVHNCguY6xxYte","type":"assistant","uuid":"8275c832-5b69-43d9-89f5-13071a104afc","timestamp":"2026-01-25T09:44:48.073Z"}
{"type":"file-history-snapshot","messageId":"8275c832-5b69-43d9-89f5-13071a104afc","snapshot":{"messageId":"ac1ff87f-25fa-45dc-8ad0-250568338495","trackedFileBackups":{"plan/future-plans/2026-01-25-web-frontend-options-summary.md":{"backupFileName":"3498d1d231e1cf55@v1","version":1,"backupTime":"2026-01-25T09:44:58.644Z"}},"timestamp":"2026-01-25T09:44:20.011Z"},"isSnapshotUpdate":true}
{"parentUuid":"8275c832-5b69-43d9-89f5-13071a104afc","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","slug":"enumerated-shimmying-starlight","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01L1hxwM7TsKrtJ9cghuQxHX","type":"tool_result","content":"The file /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/plan/future-plans/2026-01-25-web-frontend-options-summary.md has been updated successfully."}]},"uuid":"ca3a2411-3813-4a75-8b14-47be49c4bd33","timestamp":"2026-01-25T09:44:58.643Z","toolUseResult":{"filePath":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/plan/future-plans/2026-01-25-web-frontend-options-summary.md","oldString":"### Key Features\n✓ Token generation API route (`/api/token`)\n✓ `useVoiceAssistant` React hook for agent state\n✓ Audio visualizer (`BarVisualizer`)\n✓ Camera video and screen sharing support\n✓ Light/dark theme with system preference\n✓ Customizable branding via `app-config.ts`\n✓ Mobile-responsive design\n✓ Production-ready architecture","newString":"### Key Features\n✓ Token generation API route (`/api/token`)\n✓ `useVoiceAssistant` React hook for agent state\n✓ Audio visualizer (`BarVisualizer`)\n✓ Audio-only interface (video and screen sharing disabled)\n✓ Light/dark theme with system preference\n✓ Customizable branding via `app-config.ts`\n✓ Mobile-responsive design\n✓ Production-ready architecture\n\n**IMPORTANT: This is an audio-only application. Video camera and screen sharing features should be disabled in configuration.**","originalFile":"# Web Frontend Options for LiveKit Voice AI Agent - Research Summary\n\n**Date:** 2026-01-25\n**Purpose:** Document TypeScript/JavaScript options for enabling web-based client interaction with deployed LiveKit agent\n\n---\n\n## Executive Summary\n\nLiveKit provides multiple JavaScript/TypeScript solutions for building web frontends that connect users to voice AI agents. The recommended approach is **agent-starter-react**, a production-ready Next.js template that includes all necessary components:\n\n- JWT token generation (server-side for security)\n- WebRTC connection management via `livekit-client` SDK\n- Voice assistant UI components (`@livekit/components-react`)\n- Audio visualization and agent state tracking\n- Automatic agent dispatch when users connect\n\n**Timeline:** 6-8 hours for complete deployment (agent + frontend + customization)\n**Cost:** $0.01 per agent session minute (LiveKit Cloud) + Free (Vercel frontend hosting)\n\n---\n\n## Option 1: agent-starter-react (Recommended)\n\n### Overview\nOfficial Next.js/React template from LiveKit with production-ready voice AI interface.\n\n### Repository\n**GitHub:** https://github.com/livekit-examples/agent-starter-react\n\n### Tech Stack\n- Next.js 14+ (App Router)\n- React 18+ with TypeScript\n- Tailwind CSS + Shadcn/ui components\n- `livekit-client` SDK (WebRTC)\n- `@livekit/components-react` (UI components)\n- `livekit-server-sdk` (token generation)\n\n### Key Features\n✓ Token generation API route (`/api/token`)\n✓ `useVoiceAssistant` React hook for agent state\n✓ Audio visualizer (`BarVisualizer`)\n✓ Camera video and screen sharing support\n✓ Light/dark theme with system preference\n✓ Customizable branding via `app-config.ts`\n✓ Mobile-responsive design\n✓ Production-ready architecture\n\n### Setup Process\n```bash\n# Install via LiveKit CLI\nlk app create --template agent-starter-react\ncd voice-ai-frontend\npnpm install\n\n# Configure environment\ncp .env.example .env.local\n# Add: LIVEKIT_API_KEY, LIVEKIT_API_SECRET, LIVEKIT_URL\n\n# Run development server\npnpm dev\n# Visit http://localhost:3000\n```\n\n### Customization\n**Easy to customize:**\n- Company name and branding (app-config.ts)\n- Logo and colors\n- Welcome message and instructions\n- Feature toggles (video, screen share, chat)\n- Theme colors (Tailwind CSS)\n\n### Deployment\n- **Recommended:** Vercel (free tier)\n- **Alternatives:** Netlify, AWS Amplify, Cloudflare Pages\n- **Build time:** ~2-5 minutes\n- **Automatic deployments:** Via Git integration\n\n### Best For\n- Production websites with custom branding\n- Full feature control\n- Professional, polished user experience\n- Organizations needing customization\n\n### Pros\n✓ Official template, actively maintained\n✓ Production-ready out of the box\n✓ Excellent documentation\n✓ Easy customization\n✓ Vercel deployment = free hosting\n✓ TypeScript for type safety\n✓ Modern UI with Shadcn/ui\n\n### Cons\n✗ Requires some React/Next.js knowledge for customization\n✗ Larger initial download (Next.js framework)\n✗ More complex than simple embed\n\n---\n\n## Option 2: agent-starter-embed (Embeddable Widget)\n\n### Overview\nEmbeddable widget for adding voice AI to existing websites without major changes.\n\n### Repository\n**GitHub:** https://github.com/livekit-examples/agent-starter-embed\n\n### Tech Stack\n- Next.js with TypeScript\n- Bundled JavaScript widget\n- Same core LiveKit SDKs as agent-starter-react\n\n### Key Features\n✓ Embeddable via `<script>` tag\n✓ Popup-style or inline widget\n✓ Minimal integration effort\n✓ Same features as agent-starter-react\n✓ Customizable appearance\n\n### Setup Process\n```bash\ngit clone https://github.com/livekit-examples/agent-starter-embed.git\ncd agent-starter-embed\npnpm install\npnpm build-embed-popup-script\npnpm dev\n```\n\n### Integration\n```html\n<!-- Add to any website -->\n<div id=\"livekit-agent\"></div>\n<script src=\"https://your-cdn.com/embed-popup.js\"></script>\n<script>\n  LiveKitAgent.init({\n    container: '#livekit-agent',\n    tokenUrl: 'https://your-backend.com/api/token',\n    theme: 'dark',\n    position: 'bottom-right'\n  });\n</script>\n```\n\n### Best For\n- Adding voice AI to existing websites\n- Minimal code changes required\n- Quick implementation\n- Embedded customer support agents\n\n### Pros\n✓ Easy integration (just add script tag)\n✓ No major site changes needed\n✓ Works with any website/CMS\n✓ Can be positioned anywhere (floating, inline)\n\n### Cons\n✗ Less customization than full React app\n✗ Still requires backend for token generation\n✗ Limited control over widget internals\n\n---\n\n## Option 3: Custom Build with LiveKit SDKs\n\n### Overview\nBuild from scratch using core LiveKit packages for maximum customization.\n\n### NPM Packages\n\n**Client SDK:**\n```bash\nnpm install livekit-client\n```\n- **Package:** `livekit-client` (v2.17.0+)\n- **Purpose:** WebRTC client for browser\n- **Docs:** https://docs.livekit.io/reference/client-sdk-js/\n\n**React Components:**\n```bash\nnpm install @livekit/components-react @livekit/components-styles\n```\n- **Package:** `@livekit/components-react`\n- **Purpose:** Pre-built React UI components\n- **Key Exports:** `useVoiceAssistant`, `BarVisualizer`, `VoiceAssistantControlBar`\n- **Docs:** https://docs.livekit.io/reference/components/react/\n\n**Server SDK (Backend):**\n```bash\nnpm install livekit-server-sdk\n```\n- **Package:** `livekit-server-sdk` (v2.15.0+)\n- **Purpose:** Token generation (server-side only)\n- **Docs:** https://docs.livekit.io/reference/server-sdk-js/\n\n### Minimal Example\n\n**Frontend (React):**\n```typescript\nimport { useVoiceAssistant, BarVisualizer } from '@livekit/components-react';\nimport '@livekit/components-styles';\n\nfunction VoiceAgent() {\n  const { state, audioTrack } = useVoiceAssistant();\n  // state: 'initializing' | 'listening' | 'thinking' | 'speaking'\n\n  return (\n    <div>\n      <p>Agent is {state}</p>\n      <BarVisualizer state={state} audioTrack={audioTrack} />\n      <button onClick={connect}>Connect</button>\n    </div>\n  );\n}\n```\n\n**Backend (Next.js API Route):**\n```typescript\nimport { AccessToken } from 'livekit-server-sdk';\n\nexport async function POST(req: Request) {\n  const { roomName, participantName } = await req.json();\n\n  const token = new AccessToken(\n    process.env.LIVEKIT_API_KEY,\n    process.env.LIVEKIT_API_SECRET,\n    { identity: participantName, ttl: '2h' }\n  );\n\n  token.addGrant({\n    room: roomName,\n    roomJoin: true,\n    canPublish: true,\n    canSubscribe: true,\n  });\n\n  return Response.json({ token: await token.toJwt() });\n}\n```\n\n### Best For\n- Integrating into existing React applications\n- Maximum customization control\n- Unique UI/UX requirements\n- Developers comfortable with WebRTC\n\n### Pros\n✓ Complete control over every aspect\n✓ Smaller bundle size (only what you need)\n✓ Deep integration with existing app\n✓ No template overhead\n\n### Cons\n✗ Requires understanding of LiveKit concepts\n✗ More time to build from scratch\n✗ Need to handle edge cases yourself\n✗ More maintenance burden\n\n---\n\n## Option 4: LiveKit Agents Playground (Quick Testing)\n\n### Overview\nZero-code web interface for instantly testing deployed agents.\n\n### Access\n**URL:** https://agents-playground.livekit.io/\n\n### Use Case\n- Quick testing of deployed agents\n- No frontend setup required\n- Demo to stakeholders\n- Debugging agent behavior\n\n### How to Use\n1. Visit https://agents-playground.livekit.io/\n2. Enter LiveKit credentials:\n   - LiveKit URL: `wss://your-project.livekit.cloud`\n   - API Key: Your `LIVEKIT_API_KEY`\n   - API Secret: Your `LIVEKIT_API_SECRET`\n3. Click \"Connect\"\n4. Speak to your agent\n\n### Best For\n- Testing before building frontend\n- Internal demos\n- Debugging agent issues\n- Validating deployment\n\n### Pros\n✓ Zero setup required\n✓ Instant testing\n✓ No code needed\n✓ Audio visualization included\n\n### Cons\n✗ Not for end users (exposes API secrets)\n✗ No customization\n✗ Not production-ready\n✗ Requires credentials each time\n\n---\n\n## Connection Flow Architecture\n\n### Standard Flow\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                      WEBSITE (FRONTEND)                     │\n│  ┌─────────────────┐         ┌─────────────────┐           │\n│  │   React/Next    │────────▶│  Token Server   │           │\n│  │   (Browser)     │  fetch  │  (Node.js API)  │           │\n│  └────────┬────────┘  token  └────────┬────────┘           │\n│           │                           │                     │\n│           │ WebRTC                    │ livekit-server-sdk  │\n│           │ (audio)                   │ (JWT generation)    │\n└───────────┼───────────────────────────┼─────────────────────┘\n            │                           │\n            ▼                           ▼\n┌─────────────────────────────────────────────────────────────┐\n│                    LIVEKIT CLOUD                            │\n│  ┌─────────────────┐         ┌─────────────────┐           │\n│  │  LiveKit Room   │◀────────│  Your Agent     │           │\n│  │  (WebRTC SFU)   │  audio  │  (Python)       │           │\n│  └─────────────────┘         └─────────────────┘           │\n│                                                             │\n│  Auto-dispatch agent when user joins room                  │\n└─────────────────────────────────────────────────────────────┘\n```\n\n### Connection Sequence\n\n1. **User clicks \"Connect\"** on website\n2. **Frontend requests token** from `/api/token` endpoint (500ms)\n3. **Backend generates JWT** using `livekit-server-sdk` (50ms)\n4. **Frontend connects to LiveKit room** with token (1000ms)\n5. **Agent automatically dispatched** to room (1000ms)\n6. **Agent connects** and publishes audio track (1500ms)\n7. **WebRTC media flow established** between user and agent\n\n**Total Time:** ~4 seconds (standard) → ~1.5 seconds (optimized)\n\n### Optimization Techniques\n\n**1. Pre-generate Tokens (Warm Token):**\n- Generate token on page load\n- Store for immediate use when \"Connect\" clicked\n- Saves ~500ms\n\n**2. Concurrent Dispatch:**\n- Connect user and dispatch agent in parallel\n- Saves ~1000ms\n\n**3. Pre-connect Buffer:**\n- Enable in `app-config.ts`\n- Reduces perceived latency\n\n---\n\n## Authentication Deep Dive\n\n### JWT Token Structure\n\n**Token Payload Example:**\n```json\n{\n  \"exp\": 1234567890,           // Expiration timestamp\n  \"iss\": \"APIxxxxxxxxxxxx\",    // API Key (issuer)\n  \"sub\": \"user-identity\",       // Participant identity\n  \"nbf\": 1234567890,           // Not before timestamp\n  \"video\": {\n    \"room\": \"room-name\",        // Room name\n    \"roomJoin\": true,           // Can join room\n    \"canPublish\": true,         // Can publish tracks\n    \"canSubscribe\": true,       // Can subscribe to tracks\n    \"canPublishData\": true      // Can send data messages\n  },\n  \"metadata\": \"\"                // Custom participant data\n}\n```\n\n### Token Generation Security\n\n**✓ CORRECT (Server-Side):**\n```typescript\n// Next.js API route (/api/token/route.ts)\nimport { AccessToken } from 'livekit-server-sdk';\n\nexport async function POST(req: Request) {\n  // Secret keys stay on server - NEVER exposed to browser\n  const token = new AccessToken(\n    process.env.LIVEKIT_API_KEY,\n    process.env.LIVEKIT_API_SECRET,\n    { identity: 'user' }\n  );\n\n  token.addGrant({ room: 'room', roomJoin: true });\n  return Response.json({ token: await token.toJwt() });\n}\n```\n\n**✗ WRONG (Client-Side):**\n```typescript\n// NEVER do this - exposes API secrets to browser!\nconst token = new AccessToken(\n  \"APIxxxxxxxxxxxx\",  // ⚠️ Exposed in browser\n  \"secret-key\",        // ⚠️ CRITICAL: Security breach!\n  { identity: 'user' }\n);\n```\n\n### Environment Variables\n\n**Server-Side Only (Never Exposed):**\n- `LIVEKIT_API_KEY` - Used for token signing\n- `LIVEKIT_API_SECRET` - Used for token signing\n\n**Public (Exposed to Browser):**\n- `NEXT_PUBLIC_LIVEKIT_URL` - WebRTC server URL\n\n**Configuration Example:**\n```env\n# .env.local (server-side)\nLIVEKIT_API_KEY=APIxxxxxxxxxxxx\nLIVEKIT_API_SECRET=your-secret-key-here\nLIVEKIT_URL=wss://your-project.livekit.cloud\n\n# Exposed to browser (NEXT_PUBLIC_ prefix)\nNEXT_PUBLIC_LIVEKIT_URL=wss://your-project.livekit.cloud\n```\n\n### Token Permissions\n\n**Recommended Grants:**\n```typescript\ntoken.addGrant({\n  room: roomName,              // Specific room\n  roomJoin: true,              // Can join\n  canPublish: true,            // Can publish audio/video\n  canSubscribe: true,          // Can receive audio/video\n  canPublishData: true,        // Can send data messages\n  canPublishSources: [         // Optional: restrict sources\n    'microphone',\n    'camera',\n    'screen_share'\n  ],\n});\n```\n\n### Token Expiration\n\n- **Default TTL:** 2 hours\n- **Auto-Refresh:** LiveKit client automatically refreshes for connected users\n- **Disconnected Users:** Must request new token\n- **Production Recommendation:** 2h with auto-refresh\n\n---\n\n## Deployment Options\n\n### Frontend Hosting\n\n| Provider | Cost | Build Time | Auto Deploy | SSL | CDN |\n|----------|------|------------|-------------|-----|-----|\n| **Vercel** (Recommended) | Free tier | 2-5 min | ✓ Git | ✓ | ✓ |\n| Netlify | Free tier | 2-5 min | ✓ Git | ✓ | ✓ |\n| AWS Amplify | Free tier | 3-7 min | ✓ Git | ✓ | ✓ |\n| Cloudflare Pages | Free | 2-4 min | ✓ Git | ✓ | ✓ |\n\n**Recommendation:** Vercel for Next.js (seamless integration, best DX)\n\n### Agent Hosting\n\n**LiveKit Cloud (Recommended):**\n- **Cost:** $0.01 per agent session minute\n- **Deployment:** `lk agent create --secrets-file .env.local`\n- **Scaling:** Automatic (0 to N replicas)\n- **Regions:** Global (US, EU, APAC)\n\n**Alternative:** Self-hosted (requires own infrastructure)\n\n---\n\n## Cost Analysis\n\n### Estimated Monthly Costs\n\n**Scenario 1: Low Traffic (100 sessions/month, 5 min avg)**\n- Sessions: 100\n- Total minutes: 500\n- LiveKit Cloud: 500 × $0.01 = **$5/month**\n- Vercel: **Free tier**\n- **Total: ~$5/month**\n\n**Scenario 2: Medium Traffic (1,000 sessions/month, 10 min avg)**\n- Sessions: 1,000\n- Total minutes: 10,000\n- LiveKit Cloud: 10,000 × $0.01 = **$100/month**\n- Vercel: **Free tier** (or $20/month Pro)\n- **Total: ~$100-120/month**\n\n**Scenario 3: High Traffic (10,000 sessions/month, 8 min avg)**\n- Sessions: 10,000\n- Total minutes: 80,000\n- LiveKit Cloud: 80,000 × $0.01 = **$800/month**\n- Vercel: **$20/month Pro**\n- **Total: ~$820/month**\n\n**Additional Costs:**\n- OpenAI API (LLM): ~$0.03 per conversation\n- AssemblyAI (STT): ~$0.01 per minute\n- Cartesia (TTS): ~$0.05 per 1K characters\n\n---\n\n## Browser Compatibility\n\n### Supported Browsers\n\n| Browser | Desktop | Mobile | Notes |\n|---------|---------|--------|-------|\n| Chrome | ✓ v90+ | ✓ v90+ | Best support |\n| Firefox | ✓ v88+ | ✓ v88+ | Full support |\n| Safari | ✓ 14+ | ✓ 14+ | Requires user interaction for audio |\n| Edge | ✓ v90+ | ✓ v90+ | Chromium-based, same as Chrome |\n| Opera | ✓ v76+ | ✓ v64+ | Full support |\n\n### WebRTC Requirements\n\n**Required Browser Features:**\n- WebRTC support (RTCPeerConnection)\n- getUserMedia API (microphone access)\n- Web Audio API (audio processing)\n- WebSockets (signaling)\n\n**Not Supported:**\n- Internet Explorer (any version)\n- Legacy Edge (pre-Chromium)\n- Very old mobile browsers (<2020)\n\n---\n\n## Performance Benchmarks\n\n### Connection Time\n\n| Metric | Standard | Optimized |\n|--------|----------|-----------|\n| Token fetch | 500ms | 0ms (pre-generated) |\n| Room connect | 1000ms | 1000ms |\n| Agent dispatch | 1000ms | 500ms (concurrent) |\n| Media establish | 1500ms | 1000ms |\n| **Total** | **4000ms** | **1500ms** |\n\n### Audio Latency\n\n| Component | Latency |\n|-----------|---------|\n| User speech → STT | 500-800ms |\n| LLM processing | 1000-2000ms |\n| TTS generation | 300-500ms |\n| Audio playback | 100-200ms |\n| **Total (first response)** | **2-3.5 seconds** |\n| **Subsequent turns** | **1.5-2.5 seconds** (streaming) |\n\n### Page Load Performance\n\n**Lighthouse Scores (agent-starter-react):**\n- Performance: 90-95\n- Accessibility: 95-100\n- Best Practices: 90-95\n- SEO: 95-100\n\n**Bundle Sizes:**\n- Initial load: ~150-200 KB (gzipped)\n- Total JavaScript: ~400-500 KB\n- First Contentful Paint: <1.5s\n- Time to Interactive: <2.5s\n\n---\n\n## Mobile Considerations\n\n### iOS Safari Quirks\n\n**Audio Autoplay:**\n- Requires user interaction before audio playback\n- Solution: Play silent audio on first user click\n\n**Microphone Access:**\n- Must request permissions on user gesture\n- Browser prompts for microphone access\n\n**Web Audio Context:**\n- May be suspended on page load\n- Resume on user interaction\n\n### Android Chrome\n\n**Generally Better Support:**\n- Fewer audio restrictions\n- Better WebRTC implementation\n- More permissive autoplay policies\n\n**PWA Support:**\n- Can be installed as app\n- Better offline handling\n- Push notifications available\n\n### Responsive Design\n\n**agent-starter-react includes:**\n- Mobile-first responsive layout\n- Touch-optimized controls\n- Adaptive font sizes\n- Mobile-friendly visualizations\n\n---\n\n## Security Best Practices\n\n### Token Security\n\n✓ **DO:**\n- Generate tokens server-side only\n- Use environment variables for secrets\n- Set appropriate token expiration (2h)\n- Validate token claims on server\n- Use HTTPS in production\n\n✗ **DON'T:**\n- Expose API secrets to browser\n- Generate tokens client-side\n- Use long-lived tokens (>24h)\n- Store secrets in code or Git\n- Use HTTP (always HTTPS)\n\n### API Security\n\n**Rate Limiting:**\n```typescript\n// Add to token endpoint\nimport rateLimit from 'express-rate-limit';\n\nconst limiter = rateLimit({\n  windowMs: 15 * 60 * 1000, // 15 minutes\n  max: 100 // limit each IP to 100 requests per windowMs\n});\n\napp.use('/api/token', limiter);\n```\n\n**CORS Configuration:**\n```typescript\n// Only allow your domain\nconst allowedOrigins = ['https://yourdomain.com'];\n\nres.setHeader('Access-Control-Allow-Origin', allowedOrigins);\n```\n\n### Content Security Policy\n\n```typescript\n// Add CSP headers\nres.setHeader('Content-Security-Policy',\n  \"default-src 'self'; \" +\n  \"connect-src 'self' wss://your-project.livekit.cloud; \" +\n  \"media-src 'self';\"\n);\n```\n\n---\n\n## Troubleshooting Guide\n\n### Common Issues\n\n**\"Failed to connect to room\"**\n- **Cause:** Invalid token or LiveKit URL\n- **Fix:** Check environment variables, verify token generation\n\n**\"Microphone access denied\"**\n- **Cause:** User denied browser permission\n- **Fix:** Prompt user to grant permission in browser settings\n\n**\"No audio from agent\"**\n- **Cause:** Agent not joining room, TTS API issues\n- **Fix:** Check agent logs (`lk agent logs`), verify Cartesia API key\n\n**\"Token expired\"**\n- **Cause:** Token TTL exceeded, user inactive too long\n- **Fix:** Increase TTL or implement token refresh\n\n**\"WebRTC connection failed\"**\n- **Cause:** Firewall blocking WebRTC ports\n- **Fix:** Check firewall rules, ensure UDP ports open\n\n### Debug Tools\n\n**Browser DevTools:**\n- Console: Check for JavaScript errors\n- Network: Inspect WebSocket connections\n- Application: View local storage/cookies\n\n**LiveKit CLI:**\n```bash\n# Monitor agent logs\nlk agent logs --follow\n\n# Check agent status\nlk agent status\n\n# List active rooms\nlk room list\n\n# View room participants\nlk room participants <room-name>\n```\n\n**Vercel Logs:**\n- Dashboard → Deployments → Functions\n- Real-time function logs\n- Error tracking\n\n---\n\n## Next Steps\n\n### Immediate Actions\n\n1. **Review implementation plan:** See `2026-01-25-web-frontend-deployment.md`\n2. **Deploy agent:** Follow Phase 1 of plan\n3. **Set up frontend:** Follow Phases 2-3 of plan\n4. **Test connection:** Follow Phase 4 of plan\n5. **Customize:** Follow Phase 5 of plan\n6. **Deploy to production:** Follow Phase 6 of plan\n\n### Learning Resources\n\n**Documentation:**\n- LiveKit Docs: https://docs.livekit.io\n- agent-starter-react README: https://github.com/livekit-examples/agent-starter-react\n- Next.js Docs: https://nextjs.org/docs\n- React Hooks: https://react.dev/reference/react\n\n**Video Tutorials:**\n- LiveKit YouTube: https://www.youtube.com/@livekit\n- Next.js Learn: https://nextjs.org/learn\n\n**Community:**\n- LiveKit Discord: https://livekit.io/discord\n- GitHub Discussions: https://github.com/livekit/agents/discussions\n\n---\n\n## Appendix: Quick Reference\n\n### Essential Commands\n\n```bash\n# Agent deployment\nlk cloud auth\nlk agent create --secrets-file .env.local\nlk agent status\nlk agent logs --follow\n\n# Frontend setup\nlk app create --template agent-starter-react\npnpm install\npnpm dev\npnpm build\n\n# Production deployment (Vercel)\nvercel\nvercel --prod\n```\n\n### Environment Variables Checklist\n\n**Backend (Agent - `.env.local`):**\n```env\nOPENAI_API_KEY=sk-...\nASSEMBLYAI_API_KEY=...\nCARTESIA_API_KEY=...\n# Note: LIVEKIT_* vars auto-injected by LiveKit Cloud\n```\n\n**Frontend (Next.js - `.env.local`):**\n```env\nLIVEKIT_API_KEY=APIxxxxxxxxxxxx\nLIVEKIT_API_SECRET=your-secret-here\nLIVEKIT_URL=wss://your-project.livekit.cloud\nNEXT_PUBLIC_LIVEKIT_URL=wss://your-project.livekit.cloud\nAGENT_NAME=\n```\n\n### URL Reference\n\n- **Agent Playground:** https://agents-playground.livekit.io/\n- **LiveKit Cloud:** https://cloud.livekit.io\n- **Vercel Dashboard:** https://vercel.com/dashboard\n- **Your Production Frontend:** https://your-app.vercel.app\n\n---\n\n**Document Version:** 1.0\n**Last Updated:** 2026-01-25\n**Related Plan:** `2026-01-25-web-frontend-deployment.md`\n","structuredPatch":[{"oldStart":40,"oldLines":12,"newStart":40,"newLines":14,"lines":[" ✓ Token generation API route (`/api/token`)"," ✓ `useVoiceAssistant` React hook for agent state"," ✓ Audio visualizer (`BarVisualizer`)","-✓ Camera video and screen sharing support","+✓ Audio-only interface (video and screen sharing disabled)"," ✓ Light/dark theme with system preference"," ✓ Customizable branding via `app-config.ts`"," ✓ Mobile-responsive design"," ✓ Production-ready architecture"," ","+**IMPORTANT: This is an audio-only application. Video camera and screen sharing features should be disabled in configuration.**","+"," ### Setup Process"," ```bash"," # Install via LiveKit CLI"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"8275c832-5b69-43d9-89f5-13071a104afc"}
{"parentUuid":"ca3a2411-3813-4a75-8b14-47be49c4bd33","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","slug":"enumerated-shimmying-starlight","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01GADxHpUJ9HdCFKeS5oCzW5","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Good. Now let me update the token permissions section to reflect audio-only usage.","signature":"EvoBCkYICxgCKkC56CU6Z2QYAOZ3pXoJMF6MVEOv0Gs9526pTJaM9fu4NA9Y2PBfaxh7vAexqRkZMhRgdYjnXq+lyFH9fnAxodHmEgzM1kNGgnip8BdKs8gaDEIWxGFAwiYJTdIwVCIwMEXVlIiSRx9TCDaa8kHsbUbHsIWd9Apdf41Y7HPYI64/pTKsRK0VtHPAAQ8zMJXNKmL/4EiRAzOOTHBkqd9JozOzJNOYsqPM7PWRTWvqZ2ylxCCZtyxdWX7iM6IlHqUzNOrLXHlMRxYc/rEP84DE83ftcdsoZWe9MgNAkyQy5q3OzV0+Be9JKG0vNaSNI9Ov9aFhsBgB"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":12,"cache_creation_input_tokens":716,"cache_read_input_tokens":64471,"cache_creation":{"ephemeral_5m_input_tokens":716,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXTt5QPBg8tKwVozDSr8h","type":"assistant","uuid":"5a405949-547e-4f6a-9703-81caff511dfb","timestamp":"2026-01-25T09:45:02.243Z"}
{"parentUuid":"5a405949-547e-4f6a-9703-81caff511dfb","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","slug":"enumerated-shimmying-starlight","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01GADxHpUJ9HdCFKeS5oCzW5","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_017tiN88BBbU9sgTB96Ys2Zr","name":"Edit","input":{"replace_all":false,"file_path":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/plan/future-plans/2026-01-25-web-frontend-options-summary.md","old_string":"### Token Permissions\n\n**Recommended Grants:**\n```typescript\ntoken.addGrant({\n  room: roomName,              // Specific room\n  roomJoin: true,              // Can join\n  canPublish: true,            // Can publish audio/video\n  canSubscribe: true,          // Can receive audio/video\n  canPublishData: true,        // Can send data messages\n  canPublishSources: [         // Optional: restrict sources\n    'microphone',\n    'camera',\n    'screen_share'\n  ],\n});\n```","new_string":"### Token Permissions\n\n**Recommended Grants (Audio-Only):**\n```typescript\ntoken.addGrant({\n  room: roomName,              // Specific room\n  roomJoin: true,              // Can join\n  canPublish: true,            // Can publish audio\n  canSubscribe: true,          // Can receive audio\n  canPublishData: true,        // Can send data messages\n  canPublishSources: [         // Audio-only: restrict to microphone only\n    'microphone'\n    // NOTE: 'camera' and 'screen_share' are NOT included\n    // This is an audio-only application\n  ],\n});\n```"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":12,"cache_creation_input_tokens":716,"cache_read_input_tokens":64471,"cache_creation":{"ephemeral_5m_input_tokens":716,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXTt5QPBg8tKwVozDSr8h","type":"assistant","uuid":"1d94aaf1-de38-4dc6-9e75-6b145de7e3d5","timestamp":"2026-01-25T09:45:07.525Z"}
{"parentUuid":"1d94aaf1-de38-4dc6-9e75-6b145de7e3d5","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","slug":"enumerated-shimmying-starlight","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_017tiN88BBbU9sgTB96Ys2Zr","type":"tool_result","content":"The file /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/plan/future-plans/2026-01-25-web-frontend-options-summary.md has been updated successfully."}]},"uuid":"06f3d94a-ae7b-42fb-836a-bada80eb54aa","timestamp":"2026-01-25T09:45:07.565Z","toolUseResult":{"filePath":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/plan/future-plans/2026-01-25-web-frontend-options-summary.md","oldString":"### Token Permissions\n\n**Recommended Grants:**\n```typescript\ntoken.addGrant({\n  room: roomName,              // Specific room\n  roomJoin: true,              // Can join\n  canPublish: true,            // Can publish audio/video\n  canSubscribe: true,          // Can receive audio/video\n  canPublishData: true,        // Can send data messages\n  canPublishSources: [         // Optional: restrict sources\n    'microphone',\n    'camera',\n    'screen_share'\n  ],\n});\n```","newString":"### Token Permissions\n\n**Recommended Grants (Audio-Only):**\n```typescript\ntoken.addGrant({\n  room: roomName,              // Specific room\n  roomJoin: true,              // Can join\n  canPublish: true,            // Can publish audio\n  canSubscribe: true,          // Can receive audio\n  canPublishData: true,        // Can send data messages\n  canPublishSources: [         // Audio-only: restrict to microphone only\n    'microphone'\n    // NOTE: 'camera' and 'screen_share' are NOT included\n    // This is an audio-only application\n  ],\n});\n```","originalFile":"# Web Frontend Options for LiveKit Voice AI Agent - Research Summary\n\n**Date:** 2026-01-25\n**Purpose:** Document TypeScript/JavaScript options for enabling web-based client interaction with deployed LiveKit agent\n\n---\n\n## Executive Summary\n\nLiveKit provides multiple JavaScript/TypeScript solutions for building web frontends that connect users to voice AI agents. The recommended approach is **agent-starter-react**, a production-ready Next.js template that includes all necessary components:\n\n- JWT token generation (server-side for security)\n- WebRTC connection management via `livekit-client` SDK\n- Voice assistant UI components (`@livekit/components-react`)\n- Audio visualization and agent state tracking\n- Automatic agent dispatch when users connect\n\n**Timeline:** 6-8 hours for complete deployment (agent + frontend + customization)\n**Cost:** $0.01 per agent session minute (LiveKit Cloud) + Free (Vercel frontend hosting)\n\n---\n\n## Option 1: agent-starter-react (Recommended)\n\n### Overview\nOfficial Next.js/React template from LiveKit with production-ready voice AI interface.\n\n### Repository\n**GitHub:** https://github.com/livekit-examples/agent-starter-react\n\n### Tech Stack\n- Next.js 14+ (App Router)\n- React 18+ with TypeScript\n- Tailwind CSS + Shadcn/ui components\n- `livekit-client` SDK (WebRTC)\n- `@livekit/components-react` (UI components)\n- `livekit-server-sdk` (token generation)\n\n### Key Features\n✓ Token generation API route (`/api/token`)\n✓ `useVoiceAssistant` React hook for agent state\n✓ Audio visualizer (`BarVisualizer`)\n✓ Audio-only interface (video and screen sharing disabled)\n✓ Light/dark theme with system preference\n✓ Customizable branding via `app-config.ts`\n✓ Mobile-responsive design\n✓ Production-ready architecture\n\n**IMPORTANT: This is an audio-only application. Video camera and screen sharing features should be disabled in configuration.**\n\n### Setup Process\n```bash\n# Install via LiveKit CLI\nlk app create --template agent-starter-react\ncd voice-ai-frontend\npnpm install\n\n# Configure environment\ncp .env.example .env.local\n# Add: LIVEKIT_API_KEY, LIVEKIT_API_SECRET, LIVEKIT_URL\n\n# Run development server\npnpm dev\n# Visit http://localhost:3000\n```\n\n### Customization\n**Easy to customize:**\n- Company name and branding (app-config.ts)\n- Logo and colors\n- Welcome message and instructions\n- Feature toggles (video, screen share, chat)\n- Theme colors (Tailwind CSS)\n\n### Deployment\n- **Recommended:** Vercel (free tier)\n- **Alternatives:** Netlify, AWS Amplify, Cloudflare Pages\n- **Build time:** ~2-5 minutes\n- **Automatic deployments:** Via Git integration\n\n### Best For\n- Production websites with custom branding\n- Full feature control\n- Professional, polished user experience\n- Organizations needing customization\n\n### Pros\n✓ Official template, actively maintained\n✓ Production-ready out of the box\n✓ Excellent documentation\n✓ Easy customization\n✓ Vercel deployment = free hosting\n✓ TypeScript for type safety\n✓ Modern UI with Shadcn/ui\n\n### Cons\n✗ Requires some React/Next.js knowledge for customization\n✗ Larger initial download (Next.js framework)\n✗ More complex than simple embed\n\n---\n\n## Option 2: agent-starter-embed (Embeddable Widget)\n\n### Overview\nEmbeddable widget for adding voice AI to existing websites without major changes.\n\n### Repository\n**GitHub:** https://github.com/livekit-examples/agent-starter-embed\n\n### Tech Stack\n- Next.js with TypeScript\n- Bundled JavaScript widget\n- Same core LiveKit SDKs as agent-starter-react\n\n### Key Features\n✓ Embeddable via `<script>` tag\n✓ Popup-style or inline widget\n✓ Minimal integration effort\n✓ Same features as agent-starter-react\n✓ Customizable appearance\n\n### Setup Process\n```bash\ngit clone https://github.com/livekit-examples/agent-starter-embed.git\ncd agent-starter-embed\npnpm install\npnpm build-embed-popup-script\npnpm dev\n```\n\n### Integration\n```html\n<!-- Add to any website -->\n<div id=\"livekit-agent\"></div>\n<script src=\"https://your-cdn.com/embed-popup.js\"></script>\n<script>\n  LiveKitAgent.init({\n    container: '#livekit-agent',\n    tokenUrl: 'https://your-backend.com/api/token',\n    theme: 'dark',\n    position: 'bottom-right'\n  });\n</script>\n```\n\n### Best For\n- Adding voice AI to existing websites\n- Minimal code changes required\n- Quick implementation\n- Embedded customer support agents\n\n### Pros\n✓ Easy integration (just add script tag)\n✓ No major site changes needed\n✓ Works with any website/CMS\n✓ Can be positioned anywhere (floating, inline)\n\n### Cons\n✗ Less customization than full React app\n✗ Still requires backend for token generation\n✗ Limited control over widget internals\n\n---\n\n## Option 3: Custom Build with LiveKit SDKs\n\n### Overview\nBuild from scratch using core LiveKit packages for maximum customization.\n\n### NPM Packages\n\n**Client SDK:**\n```bash\nnpm install livekit-client\n```\n- **Package:** `livekit-client` (v2.17.0+)\n- **Purpose:** WebRTC client for browser\n- **Docs:** https://docs.livekit.io/reference/client-sdk-js/\n\n**React Components:**\n```bash\nnpm install @livekit/components-react @livekit/components-styles\n```\n- **Package:** `@livekit/components-react`\n- **Purpose:** Pre-built React UI components\n- **Key Exports:** `useVoiceAssistant`, `BarVisualizer`, `VoiceAssistantControlBar`\n- **Docs:** https://docs.livekit.io/reference/components/react/\n\n**Server SDK (Backend):**\n```bash\nnpm install livekit-server-sdk\n```\n- **Package:** `livekit-server-sdk` (v2.15.0+)\n- **Purpose:** Token generation (server-side only)\n- **Docs:** https://docs.livekit.io/reference/server-sdk-js/\n\n### Minimal Example\n\n**Frontend (React):**\n```typescript\nimport { useVoiceAssistant, BarVisualizer } from '@livekit/components-react';\nimport '@livekit/components-styles';\n\nfunction VoiceAgent() {\n  const { state, audioTrack } = useVoiceAssistant();\n  // state: 'initializing' | 'listening' | 'thinking' | 'speaking'\n\n  return (\n    <div>\n      <p>Agent is {state}</p>\n      <BarVisualizer state={state} audioTrack={audioTrack} />\n      <button onClick={connect}>Connect</button>\n    </div>\n  );\n}\n```\n\n**Backend (Next.js API Route):**\n```typescript\nimport { AccessToken } from 'livekit-server-sdk';\n\nexport async function POST(req: Request) {\n  const { roomName, participantName } = await req.json();\n\n  const token = new AccessToken(\n    process.env.LIVEKIT_API_KEY,\n    process.env.LIVEKIT_API_SECRET,\n    { identity: participantName, ttl: '2h' }\n  );\n\n  token.addGrant({\n    room: roomName,\n    roomJoin: true,\n    canPublish: true,\n    canSubscribe: true,\n  });\n\n  return Response.json({ token: await token.toJwt() });\n}\n```\n\n### Best For\n- Integrating into existing React applications\n- Maximum customization control\n- Unique UI/UX requirements\n- Developers comfortable with WebRTC\n\n### Pros\n✓ Complete control over every aspect\n✓ Smaller bundle size (only what you need)\n✓ Deep integration with existing app\n✓ No template overhead\n\n### Cons\n✗ Requires understanding of LiveKit concepts\n✗ More time to build from scratch\n✗ Need to handle edge cases yourself\n✗ More maintenance burden\n\n---\n\n## Option 4: LiveKit Agents Playground (Quick Testing)\n\n### Overview\nZero-code web interface for instantly testing deployed agents.\n\n### Access\n**URL:** https://agents-playground.livekit.io/\n\n### Use Case\n- Quick testing of deployed agents\n- No frontend setup required\n- Demo to stakeholders\n- Debugging agent behavior\n\n### How to Use\n1. Visit https://agents-playground.livekit.io/\n2. Enter LiveKit credentials:\n   - LiveKit URL: `wss://your-project.livekit.cloud`\n   - API Key: Your `LIVEKIT_API_KEY`\n   - API Secret: Your `LIVEKIT_API_SECRET`\n3. Click \"Connect\"\n4. Speak to your agent\n\n### Best For\n- Testing before building frontend\n- Internal demos\n- Debugging agent issues\n- Validating deployment\n\n### Pros\n✓ Zero setup required\n✓ Instant testing\n✓ No code needed\n✓ Audio visualization included\n\n### Cons\n✗ Not for end users (exposes API secrets)\n✗ No customization\n✗ Not production-ready\n✗ Requires credentials each time\n\n---\n\n## Connection Flow Architecture\n\n### Standard Flow\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                      WEBSITE (FRONTEND)                     │\n│  ┌─────────────────┐         ┌─────────────────┐           │\n│  │   React/Next    │────────▶│  Token Server   │           │\n│  │   (Browser)     │  fetch  │  (Node.js API)  │           │\n│  └────────┬────────┘  token  └────────┬────────┘           │\n│           │                           │                     │\n│           │ WebRTC                    │ livekit-server-sdk  │\n│           │ (audio)                   │ (JWT generation)    │\n└───────────┼───────────────────────────┼─────────────────────┘\n            │                           │\n            ▼                           ▼\n┌─────────────────────────────────────────────────────────────┐\n│                    LIVEKIT CLOUD                            │\n│  ┌─────────────────┐         ┌─────────────────┐           │\n│  │  LiveKit Room   │◀────────│  Your Agent     │           │\n│  │  (WebRTC SFU)   │  audio  │  (Python)       │           │\n│  └─────────────────┘         └─────────────────┘           │\n│                                                             │\n│  Auto-dispatch agent when user joins room                  │\n└─────────────────────────────────────────────────────────────┘\n```\n\n### Connection Sequence\n\n1. **User clicks \"Connect\"** on website\n2. **Frontend requests token** from `/api/token` endpoint (500ms)\n3. **Backend generates JWT** using `livekit-server-sdk` (50ms)\n4. **Frontend connects to LiveKit room** with token (1000ms)\n5. **Agent automatically dispatched** to room (1000ms)\n6. **Agent connects** and publishes audio track (1500ms)\n7. **WebRTC media flow established** between user and agent\n\n**Total Time:** ~4 seconds (standard) → ~1.5 seconds (optimized)\n\n### Optimization Techniques\n\n**1. Pre-generate Tokens (Warm Token):**\n- Generate token on page load\n- Store for immediate use when \"Connect\" clicked\n- Saves ~500ms\n\n**2. Concurrent Dispatch:**\n- Connect user and dispatch agent in parallel\n- Saves ~1000ms\n\n**3. Pre-connect Buffer:**\n- Enable in `app-config.ts`\n- Reduces perceived latency\n\n---\n\n## Authentication Deep Dive\n\n### JWT Token Structure\n\n**Token Payload Example:**\n```json\n{\n  \"exp\": 1234567890,           // Expiration timestamp\n  \"iss\": \"APIxxxxxxxxxxxx\",    // API Key (issuer)\n  \"sub\": \"user-identity\",       // Participant identity\n  \"nbf\": 1234567890,           // Not before timestamp\n  \"video\": {\n    \"room\": \"room-name\",        // Room name\n    \"roomJoin\": true,           // Can join room\n    \"canPublish\": true,         // Can publish tracks\n    \"canSubscribe\": true,       // Can subscribe to tracks\n    \"canPublishData\": true      // Can send data messages\n  },\n  \"metadata\": \"\"                // Custom participant data\n}\n```\n\n### Token Generation Security\n\n**✓ CORRECT (Server-Side):**\n```typescript\n// Next.js API route (/api/token/route.ts)\nimport { AccessToken } from 'livekit-server-sdk';\n\nexport async function POST(req: Request) {\n  // Secret keys stay on server - NEVER exposed to browser\n  const token = new AccessToken(\n    process.env.LIVEKIT_API_KEY,\n    process.env.LIVEKIT_API_SECRET,\n    { identity: 'user' }\n  );\n\n  token.addGrant({ room: 'room', roomJoin: true });\n  return Response.json({ token: await token.toJwt() });\n}\n```\n\n**✗ WRONG (Client-Side):**\n```typescript\n// NEVER do this - exposes API secrets to browser!\nconst token = new AccessToken(\n  \"APIxxxxxxxxxxxx\",  // ⚠️ Exposed in browser\n  \"secret-key\",        // ⚠️ CRITICAL: Security breach!\n  { identity: 'user' }\n);\n```\n\n### Environment Variables\n\n**Server-Side Only (Never Exposed):**\n- `LIVEKIT_API_KEY` - Used for token signing\n- `LIVEKIT_API_SECRET` - Used for token signing\n\n**Public (Exposed to Browser):**\n- `NEXT_PUBLIC_LIVEKIT_URL` - WebRTC server URL\n\n**Configuration Example:**\n```env\n# .env.local (server-side)\nLIVEKIT_API_KEY=APIxxxxxxxxxxxx\nLIVEKIT_API_SECRET=your-secret-key-here\nLIVEKIT_URL=wss://your-project.livekit.cloud\n\n# Exposed to browser (NEXT_PUBLIC_ prefix)\nNEXT_PUBLIC_LIVEKIT_URL=wss://your-project.livekit.cloud\n```\n\n### Token Permissions\n\n**Recommended Grants:**\n```typescript\ntoken.addGrant({\n  room: roomName,              // Specific room\n  roomJoin: true,              // Can join\n  canPublish: true,            // Can publish audio/video\n  canSubscribe: true,          // Can receive audio/video\n  canPublishData: true,        // Can send data messages\n  canPublishSources: [         // Optional: restrict sources\n    'microphone',\n    'camera',\n    'screen_share'\n  ],\n});\n```\n\n### Token Expiration\n\n- **Default TTL:** 2 hours\n- **Auto-Refresh:** LiveKit client automatically refreshes for connected users\n- **Disconnected Users:** Must request new token\n- **Production Recommendation:** 2h with auto-refresh\n\n---\n\n## Deployment Options\n\n### Frontend Hosting\n\n| Provider | Cost | Build Time | Auto Deploy | SSL | CDN |\n|----------|------|------------|-------------|-----|-----|\n| **Vercel** (Recommended) | Free tier | 2-5 min | ✓ Git | ✓ | ✓ |\n| Netlify | Free tier | 2-5 min | ✓ Git | ✓ | ✓ |\n| AWS Amplify | Free tier | 3-7 min | ✓ Git | ✓ | ✓ |\n| Cloudflare Pages | Free | 2-4 min | ✓ Git | ✓ | ✓ |\n\n**Recommendation:** Vercel for Next.js (seamless integration, best DX)\n\n### Agent Hosting\n\n**LiveKit Cloud (Recommended):**\n- **Cost:** $0.01 per agent session minute\n- **Deployment:** `lk agent create --secrets-file .env.local`\n- **Scaling:** Automatic (0 to N replicas)\n- **Regions:** Global (US, EU, APAC)\n\n**Alternative:** Self-hosted (requires own infrastructure)\n\n---\n\n## Cost Analysis\n\n### Estimated Monthly Costs\n\n**Scenario 1: Low Traffic (100 sessions/month, 5 min avg)**\n- Sessions: 100\n- Total minutes: 500\n- LiveKit Cloud: 500 × $0.01 = **$5/month**\n- Vercel: **Free tier**\n- **Total: ~$5/month**\n\n**Scenario 2: Medium Traffic (1,000 sessions/month, 10 min avg)**\n- Sessions: 1,000\n- Total minutes: 10,000\n- LiveKit Cloud: 10,000 × $0.01 = **$100/month**\n- Vercel: **Free tier** (or $20/month Pro)\n- **Total: ~$100-120/month**\n\n**Scenario 3: High Traffic (10,000 sessions/month, 8 min avg)**\n- Sessions: 10,000\n- Total minutes: 80,000\n- LiveKit Cloud: 80,000 × $0.01 = **$800/month**\n- Vercel: **$20/month Pro**\n- **Total: ~$820/month**\n\n**Additional Costs:**\n- OpenAI API (LLM): ~$0.03 per conversation\n- AssemblyAI (STT): ~$0.01 per minute\n- Cartesia (TTS): ~$0.05 per 1K characters\n\n---\n\n## Browser Compatibility\n\n### Supported Browsers\n\n| Browser | Desktop | Mobile | Notes |\n|---------|---------|--------|-------|\n| Chrome | ✓ v90+ | ✓ v90+ | Best support |\n| Firefox | ✓ v88+ | ✓ v88+ | Full support |\n| Safari | ✓ 14+ | ✓ 14+ | Requires user interaction for audio |\n| Edge | ✓ v90+ | ✓ v90+ | Chromium-based, same as Chrome |\n| Opera | ✓ v76+ | ✓ v64+ | Full support |\n\n### WebRTC Requirements\n\n**Required Browser Features:**\n- WebRTC support (RTCPeerConnection)\n- getUserMedia API (microphone access)\n- Web Audio API (audio processing)\n- WebSockets (signaling)\n\n**Not Supported:**\n- Internet Explorer (any version)\n- Legacy Edge (pre-Chromium)\n- Very old mobile browsers (<2020)\n\n---\n\n## Performance Benchmarks\n\n### Connection Time\n\n| Metric | Standard | Optimized |\n|--------|----------|-----------|\n| Token fetch | 500ms | 0ms (pre-generated) |\n| Room connect | 1000ms | 1000ms |\n| Agent dispatch | 1000ms | 500ms (concurrent) |\n| Media establish | 1500ms | 1000ms |\n| **Total** | **4000ms** | **1500ms** |\n\n### Audio Latency\n\n| Component | Latency |\n|-----------|---------|\n| User speech → STT | 500-800ms |\n| LLM processing | 1000-2000ms |\n| TTS generation | 300-500ms |\n| Audio playback | 100-200ms |\n| **Total (first response)** | **2-3.5 seconds** |\n| **Subsequent turns** | **1.5-2.5 seconds** (streaming) |\n\n### Page Load Performance\n\n**Lighthouse Scores (agent-starter-react):**\n- Performance: 90-95\n- Accessibility: 95-100\n- Best Practices: 90-95\n- SEO: 95-100\n\n**Bundle Sizes:**\n- Initial load: ~150-200 KB (gzipped)\n- Total JavaScript: ~400-500 KB\n- First Contentful Paint: <1.5s\n- Time to Interactive: <2.5s\n\n---\n\n## Mobile Considerations\n\n### iOS Safari Quirks\n\n**Audio Autoplay:**\n- Requires user interaction before audio playback\n- Solution: Play silent audio on first user click\n\n**Microphone Access:**\n- Must request permissions on user gesture\n- Browser prompts for microphone access\n\n**Web Audio Context:**\n- May be suspended on page load\n- Resume on user interaction\n\n### Android Chrome\n\n**Generally Better Support:**\n- Fewer audio restrictions\n- Better WebRTC implementation\n- More permissive autoplay policies\n\n**PWA Support:**\n- Can be installed as app\n- Better offline handling\n- Push notifications available\n\n### Responsive Design\n\n**agent-starter-react includes:**\n- Mobile-first responsive layout\n- Touch-optimized controls\n- Adaptive font sizes\n- Mobile-friendly visualizations\n\n---\n\n## Security Best Practices\n\n### Token Security\n\n✓ **DO:**\n- Generate tokens server-side only\n- Use environment variables for secrets\n- Set appropriate token expiration (2h)\n- Validate token claims on server\n- Use HTTPS in production\n\n✗ **DON'T:**\n- Expose API secrets to browser\n- Generate tokens client-side\n- Use long-lived tokens (>24h)\n- Store secrets in code or Git\n- Use HTTP (always HTTPS)\n\n### API Security\n\n**Rate Limiting:**\n```typescript\n// Add to token endpoint\nimport rateLimit from 'express-rate-limit';\n\nconst limiter = rateLimit({\n  windowMs: 15 * 60 * 1000, // 15 minutes\n  max: 100 // limit each IP to 100 requests per windowMs\n});\n\napp.use('/api/token', limiter);\n```\n\n**CORS Configuration:**\n```typescript\n// Only allow your domain\nconst allowedOrigins = ['https://yourdomain.com'];\n\nres.setHeader('Access-Control-Allow-Origin', allowedOrigins);\n```\n\n### Content Security Policy\n\n```typescript\n// Add CSP headers\nres.setHeader('Content-Security-Policy',\n  \"default-src 'self'; \" +\n  \"connect-src 'self' wss://your-project.livekit.cloud; \" +\n  \"media-src 'self';\"\n);\n```\n\n---\n\n## Troubleshooting Guide\n\n### Common Issues\n\n**\"Failed to connect to room\"**\n- **Cause:** Invalid token or LiveKit URL\n- **Fix:** Check environment variables, verify token generation\n\n**\"Microphone access denied\"**\n- **Cause:** User denied browser permission\n- **Fix:** Prompt user to grant permission in browser settings\n\n**\"No audio from agent\"**\n- **Cause:** Agent not joining room, TTS API issues\n- **Fix:** Check agent logs (`lk agent logs`), verify Cartesia API key\n\n**\"Token expired\"**\n- **Cause:** Token TTL exceeded, user inactive too long\n- **Fix:** Increase TTL or implement token refresh\n\n**\"WebRTC connection failed\"**\n- **Cause:** Firewall blocking WebRTC ports\n- **Fix:** Check firewall rules, ensure UDP ports open\n\n### Debug Tools\n\n**Browser DevTools:**\n- Console: Check for JavaScript errors\n- Network: Inspect WebSocket connections\n- Application: View local storage/cookies\n\n**LiveKit CLI:**\n```bash\n# Monitor agent logs\nlk agent logs --follow\n\n# Check agent status\nlk agent status\n\n# List active rooms\nlk room list\n\n# View room participants\nlk room participants <room-name>\n```\n\n**Vercel Logs:**\n- Dashboard → Deployments → Functions\n- Real-time function logs\n- Error tracking\n\n---\n\n## Next Steps\n\n### Immediate Actions\n\n1. **Review implementation plan:** See `2026-01-25-web-frontend-deployment.md`\n2. **Deploy agent:** Follow Phase 1 of plan\n3. **Set up frontend:** Follow Phases 2-3 of plan\n4. **Test connection:** Follow Phase 4 of plan\n5. **Customize:** Follow Phase 5 of plan\n6. **Deploy to production:** Follow Phase 6 of plan\n\n### Learning Resources\n\n**Documentation:**\n- LiveKit Docs: https://docs.livekit.io\n- agent-starter-react README: https://github.com/livekit-examples/agent-starter-react\n- Next.js Docs: https://nextjs.org/docs\n- React Hooks: https://react.dev/reference/react\n\n**Video Tutorials:**\n- LiveKit YouTube: https://www.youtube.com/@livekit\n- Next.js Learn: https://nextjs.org/learn\n\n**Community:**\n- LiveKit Discord: https://livekit.io/discord\n- GitHub Discussions: https://github.com/livekit/agents/discussions\n\n---\n\n## Appendix: Quick Reference\n\n### Essential Commands\n\n```bash\n# Agent deployment\nlk cloud auth\nlk agent create --secrets-file .env.local\nlk agent status\nlk agent logs --follow\n\n# Frontend setup\nlk app create --template agent-starter-react\npnpm install\npnpm dev\npnpm build\n\n# Production deployment (Vercel)\nvercel\nvercel --prod\n```\n\n### Environment Variables Checklist\n\n**Backend (Agent - `.env.local`):**\n```env\nOPENAI_API_KEY=sk-...\nASSEMBLYAI_API_KEY=...\nCARTESIA_API_KEY=...\n# Note: LIVEKIT_* vars auto-injected by LiveKit Cloud\n```\n\n**Frontend (Next.js - `.env.local`):**\n```env\nLIVEKIT_API_KEY=APIxxxxxxxxxxxx\nLIVEKIT_API_SECRET=your-secret-here\nLIVEKIT_URL=wss://your-project.livekit.cloud\nNEXT_PUBLIC_LIVEKIT_URL=wss://your-project.livekit.cloud\nAGENT_NAME=\n```\n\n### URL Reference\n\n- **Agent Playground:** https://agents-playground.livekit.io/\n- **LiveKit Cloud:** https://cloud.livekit.io\n- **Vercel Dashboard:** https://vercel.com/dashboard\n- **Your Production Frontend:** https://your-app.vercel.app\n\n---\n\n**Document Version:** 1.0\n**Last Updated:** 2026-01-25\n**Related Plan:** `2026-01-25-web-frontend-deployment.md`\n","structuredPatch":[{"oldStart":434,"oldLines":18,"newStart":434,"newLines":18,"lines":[" "," ### Token Permissions"," ","-**Recommended Grants:**","+**Recommended Grants (Audio-Only):**"," ```typescript"," token.addGrant({","   room: roomName,              // Specific room","   roomJoin: true,              // Can join","-  canPublish: true,            // Can publish audio/video","-  canSubscribe: true,          // Can receive audio/video","+  canPublish: true,            // Can publish audio","+  canSubscribe: true,          // Can receive audio","   canPublishData: true,        // Can send data messages","-  canPublishSources: [         // Optional: restrict sources","-    'microphone',","-    'camera',","-    'screen_share'","+  canPublishSources: [         // Audio-only: restrict to microphone only","+    'microphone'","+    // NOTE: 'camera' and 'screen_share' are NOT included","+    // This is an audio-only application","   ],"," });"," ```"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"1d94aaf1-de38-4dc6-9e75-6b145de7e3d5"}
{"parentUuid":"06f3d94a-ae7b-42fb-836a-bada80eb54aa","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","slug":"enumerated-shimmying-starlight","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_016VF6ysnjkbZMj3aZ7SFRS7","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now let me update the deployment plan file. I'll modify the configuration section and the token generation section.","signature":"EpwCCkYICxgCKkCShTm23kjF5oL8tk+ThbMUg0KXtvJ8LRPeoeE4uT3Nz5pgKQnmE7zKbahUK+c72PAoQdzMZllu+RsQ7tp125GVEgyqfXMmsOwO7/uBNf0aDEdSZPZUA4sRhb1j2iIwQi/fHrCw+biX9F555oPzxicRMMk6z1AhrjO36WKACuAf2KVP1lCaXhThFL7PwXjuKoMBYBHCZoen2XBQd/FQCuG40dOk6QcdsfSRNrbYvOKh3er5jQcgMPFdBUlHdMYCk6/DAwtEq7NUdWR86lXydYwXOWQ4L9UTXcD0nkYcnAXRfaQiiWaSrk7f4QbE3jsBzORmaOeMXfFvW6fvtrVBXfyCao6zU+ITZ6TpSsP7ZFqzJecPo6gYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":11,"cache_creation_input_tokens":535,"cache_read_input_tokens":65187,"cache_creation":{"ephemeral_5m_input_tokens":535,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXTt64SuaBtxkxGMLJ1mL","type":"assistant","uuid":"2f29b569-1537-4a50-8b51-743c83d9e6a4","timestamp":"2026-01-25T09:45:10.900Z"}
{"parentUuid":"2f29b569-1537-4a50-8b51-743c83d9e6a4","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","slug":"enumerated-shimmying-starlight","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_016VF6ysnjkbZMj3aZ7SFRS7","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_019sbNy55mGye7EcEnemH1p2","name":"Edit","input":{"replace_all":false,"file_path":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/plan/future-plans/2026-01-25-web-frontend-deployment.md","old_string":"## Overview\n\nThis plan enables potential clients to interact with the LiveKit voice AI agent from this repository by clicking a link on a website. The implementation covers:\n\n1. Deploying the Python agent to LiveKit Cloud\n2. Setting up a Next.js/React frontend using the agent-starter-react template\n3. Implementing JWT token-based authentication\n4. Testing the connection flow\n5. Customizing the frontend with branding\n6. Deploying the frontend to production (Vercel)\n\nThe solution uses LiveKit's official starter templates and SDKs to create a production-ready web application with TypeScript/JavaScript.","new_string":"## Overview\n\nThis plan enables potential clients to interact with the LiveKit voice AI agent from this repository by clicking a link on a website. The implementation covers:\n\n1. Deploying the Python agent to LiveKit Cloud\n2. Setting up a Next.js/React frontend using the agent-starter-react template\n3. Implementing JWT token-based authentication\n4. Testing the connection flow\n5. Customizing the frontend with branding\n6. Deploying the frontend to production (Vercel)\n\nThe solution uses LiveKit's official starter templates and SDKs to create a production-ready web application with TypeScript/JavaScript.\n\n**IMPORTANT: This is an audio-only application. No video camera or screen sharing permissions should be requested from users. All configuration must disable video/screenshare features.**"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":11,"cache_creation_input_tokens":535,"cache_read_input_tokens":65187,"cache_creation":{"ephemeral_5m_input_tokens":535,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXTt64SuaBtxkxGMLJ1mL","type":"assistant","uuid":"c1a73cdd-7570-40c5-960f-92c9baf7d873","timestamp":"2026-01-25T09:45:17.790Z"}
{"type":"file-history-snapshot","messageId":"c1a73cdd-7570-40c5-960f-92c9baf7d873","snapshot":{"messageId":"ac1ff87f-25fa-45dc-8ad0-250568338495","trackedFileBackups":{"plan/future-plans/2026-01-25-web-frontend-options-summary.md":{"backupFileName":"3498d1d231e1cf55@v1","version":1,"backupTime":"2026-01-25T09:44:58.644Z"},"plan/future-plans/2026-01-25-web-frontend-deployment.md":{"backupFileName":"b475e75c80e73cc8@v1","version":1,"backupTime":"2026-01-25T09:45:17.830Z"}},"timestamp":"2026-01-25T09:44:20.011Z"},"isSnapshotUpdate":true}
{"parentUuid":"c1a73cdd-7570-40c5-960f-92c9baf7d873","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","slug":"enumerated-shimmying-starlight","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_019sbNy55mGye7EcEnemH1p2","type":"tool_result","content":"The file /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/plan/future-plans/2026-01-25-web-frontend-deployment.md has been updated successfully."}]},"uuid":"53fffdc3-a0d9-4094-bd71-7c0788822314","timestamp":"2026-01-25T09:45:17.828Z","toolUseResult":{"filePath":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/plan/future-plans/2026-01-25-web-frontend-deployment.md","oldString":"## Overview\n\nThis plan enables potential clients to interact with the LiveKit voice AI agent from this repository by clicking a link on a website. The implementation covers:\n\n1. Deploying the Python agent to LiveKit Cloud\n2. Setting up a Next.js/React frontend using the agent-starter-react template\n3. Implementing JWT token-based authentication\n4. Testing the connection flow\n5. Customizing the frontend with branding\n6. Deploying the frontend to production (Vercel)\n\nThe solution uses LiveKit's official starter templates and SDKs to create a production-ready web application with TypeScript/JavaScript.","newString":"## Overview\n\nThis plan enables potential clients to interact with the LiveKit voice AI agent from this repository by clicking a link on a website. The implementation covers:\n\n1. Deploying the Python agent to LiveKit Cloud\n2. Setting up a Next.js/React frontend using the agent-starter-react template\n3. Implementing JWT token-based authentication\n4. Testing the connection flow\n5. Customizing the frontend with branding\n6. Deploying the frontend to production (Vercel)\n\nThe solution uses LiveKit's official starter templates and SDKs to create a production-ready web application with TypeScript/JavaScript.\n\n**IMPORTANT: This is an audio-only application. No video camera or screen sharing permissions should be requested from users. All configuration must disable video/screenshare features.**","originalFile":"# Web Frontend Deployment Implementation Plan\n\n> **Status:** DRAFT\n\n## Table of Contents\n\n- [Overview](#overview)\n- [Current State Analysis](#current-state-analysis)\n- [Desired End State](#desired-end-state)\n- [What We're NOT Doing](#what-were-not-doing)\n- [Implementation Approach](#implementation-approach)\n- [Dependencies](#dependencies)\n- [Phase 1: Agent Deployment to LiveKit Cloud](#phase-1-agent-deployment-to-livekit-cloud)\n- [Phase 2: Frontend Setup (agent-starter-react)](#phase-2-frontend-setup-agent-starter-react)\n- [Phase 3: Authentication and Token Generation](#phase-3-authentication-and-token-generation)\n- [Phase 4: Connection Testing and Optimization](#phase-4-connection-testing-and-optimization)\n- [Phase 5: Frontend Customization](#phase-5-frontend-customization)\n- [Phase 6: Production Deployment](#phase-6-production-deployment)\n- [Testing Strategy](#testing-strategy)\n- [References](#references)\n\n## Overview\n\nThis plan enables potential clients to interact with the LiveKit voice AI agent from this repository by clicking a link on a website. The implementation covers:\n\n1. Deploying the Python agent to LiveKit Cloud\n2. Setting up a Next.js/React frontend using the agent-starter-react template\n3. Implementing JWT token-based authentication\n4. Testing the connection flow\n5. Customizing the frontend with branding\n6. Deploying the frontend to production (Vercel)\n\nThe solution uses LiveKit's official starter templates and SDKs to create a production-ready web application with TypeScript/JavaScript.\n\n## Current State Analysis\n\n### What Exists Now\n\n**Agent Backend:**\n- Python voice AI agent in `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1`\n- Built with LiveKit Agents SDK\n- Uses OpenAI (LLM), AssemblyAI (STT), Cartesia (TTS)\n- Configured with `uv` package manager\n- Has `Dockerfile` for containerized deployment\n- Environment variables in `.env.local` (OpenAI, AssemblyAI, Cartesia API keys)\n\n**Missing:**\n- Agent not yet deployed to LiveKit Cloud\n- No web frontend for client interaction\n- No token generation server for authentication\n- No public-facing URL for clients to access\n\n### Key Discoveries\n\nFrom `docs/DEPLOYMENT.md`:\n- LiveKit Cloud deployment uses `lk` CLI\n- Agent deployment command: `lk agent create --secrets-file .env.local`\n- Multiple frontend options available (React, Flutter, Swift, Embed)\n- Connection requires JWT tokens generated server-side\n- agent-starter-react provides production-ready Next.js template\n- Token generation uses `livekit-server-sdk` npm package\n\n### Constraints\n\n1. **Security:** API secrets (LIVEKIT_API_SECRET) must never be exposed to frontend\n2. **Architecture:** Token generation must happen server-side (Next.js API routes)\n3. **Dependencies:** Agent must be deployed and running before frontend can connect\n4. **Cost:** LiveKit Cloud charges $0.01 per agent session minute\n\n## Desired End State\n\n### Success Criteria\n\n- [ ] Agent deployed and running on LiveKit Cloud\n- [ ] Next.js frontend application running locally\n- [ ] JWT token generation working via backend API route\n- [ ] Users can click a link and connect to voice AI agent\n- [ ] Audio conversation works end-to-end (STT → LLM → TTS)\n- [ ] Frontend deployed to production URL (Vercel)\n- [ ] Customized branding (logo, colors, company name)\n- [ ] Light/dark theme support\n- [ ] Audio visualization working\n- [ ] Mobile-responsive design\n\n### How to Verify\n\n**Agent Deployment:**\n```bash\nlk agent status\n# Expected: Status: Running, Replicas: X/X ready\n```\n\n**Frontend Connection:**\n1. Visit frontend URL (local: http://localhost:3000, prod: https://your-app.vercel.app)\n2. Click \"Connect\" or \"Start Session\"\n3. Grant microphone permissions when prompted\n4. Speak to the agent\n5. Verify agent responds with natural voice\n6. Check agent logs: `lk agent logs --follow`\n\n**End-to-End Test:**\n```bash\n# Terminal 1: Monitor agent logs\nlk agent logs --follow\n\n# Terminal 2: Run frontend\ncd /path/to/frontend\npnpm dev\n\n# Browser: Visit http://localhost:3000, connect, and speak\n```\n\n## What We're NOT Doing\n\n**Out of Scope:**\n- Multiple agent types or agent selection UI\n- User authentication/login system (anonymous users only)\n- Database integration or conversation history storage\n- Multi-language support (English only initially)\n- iOS/Android native apps (web only)\n- Custom voice customization UI\n- Payment integration or usage metering\n- Advanced analytics dashboard\n- Server-side rendering (SSR) for the voice interface\n- Custom WebRTC infrastructure (using LiveKit Cloud)\n\n**Future Considerations:**\n- User accounts and saved conversations\n- Analytics and usage tracking\n- Custom domain with branding\n- A/B testing different agent configurations\n- Rate limiting and abuse prevention\n\n## Implementation Approach\n\n### High-Level Strategy\n\n1. **Deploy Agent First:** Ensure the Python agent is running on LiveKit Cloud before building frontend\n2. **Use Official Template:** Start with agent-starter-react to avoid reinventing the wheel\n3. **Iterative Testing:** Test each phase independently before proceeding\n4. **Security-First:** Never expose API secrets; use environment variables and server-side token generation\n5. **Quick Validation:** Use LiveKit Agents Playground first to verify agent works before building frontend\n\n### Technology Stack\n\n**Backend (Agent):**\n- Python 3.11+\n- LiveKit Agents SDK\n- OpenAI GPT-4 (LLM)\n- AssemblyAI (STT)\n- Cartesia (TTS)\n- Deployed to: LiveKit Cloud\n\n**Frontend:**\n- Next.js 14+ (App Router)\n- React 18+\n- TypeScript\n- Tailwind CSS\n- Shadcn/ui components\n- `livekit-client` SDK\n- `@livekit/components-react`\n- Deployed to: Vercel\n\n**Authentication:**\n- JWT tokens (livekit-server-sdk)\n- Server-side generation (Next.js API routes)\n- 2-hour token expiration\n\n## Dependencies\n\n**Execution Order:**\n\n1. Phase 1: Agent Deployment (no dependencies)\n2. Phase 2: Frontend Setup (depends on Phase 1 for credentials)\n3. Phase 3: Authentication (depends on Phase 2)\n4. Phase 4: Connection Testing (depends on Phases 1-3)\n5. Phase 5: Frontend Customization (depends on Phase 4)\n6. Phase 6: Production Deployment (depends on Phase 5)\n\n**Dependency Graph:**\n\n```\nPhase 1 (Agent Deployment)\n  └─> Phase 2 (Frontend Setup)\n        └─> Phase 3 (Authentication)\n              └─> Phase 4 (Testing)\n                    └─> Phase 5 (Customization)\n                          └─> Phase 6 (Production)\n```\n\n**Parallelization:**\n- All phases are sequential due to dependencies\n- Within each phase, independent tasks can run in parallel\n\n---\n\n## Phase 1: Agent Deployment to LiveKit Cloud\n\n### Overview\n\nDeploy the Python voice AI agent to LiveKit Cloud to make it accessible via WebRTC. This creates a running agent that can be dispatched to rooms when users connect.\n\n### Context\n\nBefore starting, ensure you have:\n- LiveKit CLI installed: `brew install livekit/livekit/livekit-cli`\n- LiveKit Cloud account at https://cloud.livekit.io\n- Agent code in `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1`\n- API keys in `.env.local` (OpenAI, AssemblyAI, Cartesia)\n\nFiles to review:\n- `docs/DEPLOYMENT.md` - Complete deployment guide\n- `.env.local` - API keys and secrets\n- `Dockerfile` - Container build configuration\n- `src/app.py` - Agent entry point\n\n### Dependencies\n\n**Depends on:** None (first phase)\n\n**Required by:** Phase 2 (Frontend needs LiveKit credentials), Phase 4 (Testing needs deployed agent)\n\n### Changes Required\n\n#### 1.1: Authenticate with LiveKit Cloud\n\n**What:** Link your CLI to your LiveKit Cloud account\n\n**Command:**\n```bash\nlk cloud auth\n```\n\n**Expected Outcome:**\n- Browser opens for authentication\n- CLI displays: \"Successfully authenticated with LiveKit Cloud\"\n- Credentials saved in `~/.livekit/credentials`\n\n**Rationale:** Required for all subsequent `lk` CLI commands\n\n---\n\n#### 1.2: Create or Select LiveKit Project\n\n**What:** Create a new project or select an existing one for the agent deployment\n\n**Commands:**\n```bash\n# List existing projects\nlk project list\n\n# Option A: Use existing project\nlk project set-default \"your-project-name\"\n\n# Option B: Create new project via dashboard\n# Visit https://cloud.livekit.io and create a new project\n# Then set as default: lk project set-default \"new-project-name\"\n\n# Verify current project\nlk project current\n```\n\n**Expected Outcome:**\n```\nNAME                 PROJECT_ID\nyour-project-name   prj_abc123\n```\n\n**Rationale:** Agent deployments are scoped to projects; need a target project first\n\n---\n\n#### 1.3: Verify Secrets File\n\n**What:** Ensure `.env.local` contains all required API keys\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/.env.local`\n\n**Verify contents:**\n```bash\ncat .env.local\n```\n\n**Required secrets:**\n```env\nOPENAI_API_KEY=sk-...\nASSEMBLYAI_API_KEY=...\nCARTESIA_API_KEY=...\n```\n\n**Important Notes:**\n- Do NOT include `LIVEKIT_URL`, `LIVEKIT_API_KEY`, or `LIVEKIT_API_SECRET` in `.env.local`\n- LiveKit Cloud auto-injects these during deployment\n- Verify `.env.local` is in `.gitignore`\n\n**Rationale:** Agent needs these API keys to function; LiveKit Cloud encrypts and injects them as environment variables\n\n---\n\n#### 1.4: Download Model Files\n\n**What:** Download required models (Silero VAD, turn detector) before deployment\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\nuv run python src/app.py download-files\n```\n\n**Expected Outcome:**\n```\nDownloading Silero VAD model...\nDownloading multilingual turn detector model...\nDownload complete.\n```\n\n**Rationale:** Models are required at runtime; downloading during build ensures faster agent startup\n\n---\n\n#### 1.5: Deploy Agent to LiveKit Cloud\n\n**What:** Create and deploy the agent container to LiveKit Cloud\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\nlk agent create --secrets-file .env.local\n```\n\n**Expected Outcome:**\n```\nRegistering agent...\nAgent ID: agent_abc123\nBuilding container image...\nUploading code...\nBuild in progress (this may take 2-5 minutes)...\nBuild complete.\nDeploying agent...\nDeployment successful.\nStatus: Running\nReplicas: 2/2 ready\n```\n\n**What Happens:**\n1. CLI registers new agent with Cloud project\n2. Assigns unique agent ID (e.g., `agent_abc123`)\n3. Creates/updates `livekit.toml` configuration file\n4. Uploads source code to LiveKit build service\n5. Builds Docker container from `Dockerfile`\n6. Deploys container to Cloud project\n7. Encrypts and injects secrets as environment variables\n8. Starts 2 replica instances\n\n**Duration:** 2-5 minutes for initial build\n\n**Rationale:** Makes agent accessible via LiveKit's global WebRTC infrastructure\n\n---\n\n#### 1.6: Verify Agent Status\n\n**What:** Confirm agent is running and ready to accept sessions\n\n**Commands:**\n```bash\n# Check agent status\nlk agent status\n\n# View live logs\nlk agent logs --tail 50\n```\n\n**Expected Status Output:**\n```\nAgent ID:     agent_abc123\nStatus:       Running\nReplicas:     2/2 ready\nVersion:      v1\nLast Deploy:  2026-01-25 10:30:00 UTC\nRegion:       us-west-2\n```\n\n**Expected Log Output:**\n- No error messages\n- Successful initialization messages\n- \"Waiting for room assignment\" or similar\n\n**Troubleshooting:**\n- If status is `CrashLoop`: Check logs for Python exceptions\n- If status is `Build Failed`: Run `lk agent logs --build` to see build errors\n- If secrets missing: Run `lk agent secrets` to verify\n\n**Rationale:** Ensures agent is healthy before proceeding to frontend setup\n\n---\n\n#### 1.7: Quick Test with Agents Playground\n\n**What:** Test agent using LiveKit Agents Playground (no code required)\n\n**Steps:**\n1. Get project credentials:\n   ```bash\n   lk project current --json\n   ```\n\n2. Visit https://agents-playground.livekit.io/\n\n3. Enter credentials:\n   - **LiveKit URL:** `wss://your-project.livekit.cloud` (from JSON output)\n   - **API Key:** Your `LIVEKIT_API_KEY` (from JSON output)\n   - **API Secret:** Your `LIVEKIT_API_SECRET` (from JSON output)\n\n4. Click \"Connect\"\n\n5. Allow microphone access when prompted\n\n6. Speak to your agent\n\n7. Monitor agent logs in terminal:\n   ```bash\n   lk agent logs --follow\n   ```\n\n**Expected Outcome:**\n- Agent responds to your voice with natural TTS\n- Logs show STT transcriptions, LLM responses, TTS generation\n- No errors in logs\n\n**Rationale:** Validates agent works end-to-end before investing in frontend development\n\n---\n\n#### 1.8: Save LiveKit Credentials\n\n**What:** Export LiveKit project credentials for frontend configuration\n\n**Command:**\n```bash\nlk project current --json > livekit-credentials.json\n```\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/livekit-credentials.json`\n\n**Expected Contents:**\n```json\n{\n  \"name\": \"your-project-name\",\n  \"url\": \"wss://your-project.livekit.cloud\",\n  \"api_key\": \"APIxxxxxxxxxxxx\",\n  \"api_secret\": \"your-secret-here\"\n}\n```\n\n**Security Note:**\n- Add `livekit-credentials.json` to `.gitignore`\n- NEVER commit this file to version control\n- This file is for local reference only\n\n**Rationale:** Frontend needs these credentials to generate tokens and connect to LiveKit\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] CLI authenticated: `lk cloud auth` successful\n- [ ] Project selected: `lk project current` shows correct project\n- [ ] Agent deployed: `lk agent status` shows `Status: Running`\n- [ ] Replicas ready: `lk agent status` shows `X/X ready` (e.g., 2/2)\n- [ ] No crash loops: `lk agent logs --tail 50` shows no errors\n- [ ] Credentials saved: `livekit-credentials.json` exists and contains valid JSON\n\n#### Manual Verification:\n\n- [ ] Agents Playground connection successful\n- [ ] Agent responds to voice input with TTS output\n- [ ] Agent logs show successful STT → LLM → TTS pipeline\n- [ ] No API key errors in logs\n- [ ] Agent state transitions visible (initializing → listening → thinking → speaking)\n\n**Verify:** After completing automated verification, test agent with Agents Playground before proceeding to Phase 2.\n\n---\n\n## Phase 2: Frontend Setup (agent-starter-react)\n\n### Overview\n\nClone and configure the agent-starter-react template to create a Next.js web application that connects users to your deployed agent.\n\n### Context\n\nBefore starting, ensure:\n- Phase 1 completed successfully\n- Agent is running on LiveKit Cloud\n- `livekit-credentials.json` file exists with credentials\n\nPrerequisites:\n- Node.js 18+ installed\n- pnpm installed: `npm install -g pnpm`\n- `lk` CLI authenticated\n\nFiles to review:\n- `livekit-credentials.json` - LiveKit project credentials\n- N/A (frontend doesn't exist yet)\n\n### Dependencies\n\n**Depends on:** Phase 1 (needs LiveKit credentials)\n\n**Required by:** Phase 3 (authentication setup), Phase 4 (connection testing)\n\n### Changes Required\n\n#### 2.1: Create Frontend Project Directory\n\n**What:** Create a directory to house the frontend application\n\n**Commands:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\nmkdir -p frontend\ncd frontend\n```\n\n**Expected Outcome:**\n```\nDirectory created: /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/\n```\n\n**Rationale:** Separates frontend code from agent backend code\n\n---\n\n#### 2.2: Clone agent-starter-react Template\n\n**What:** Use LiveKit CLI to create a new project from the official template\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend\nlk app create --template agent-starter-react\n```\n\n**Interactive Prompts:**\n- **Project name:** (Press Enter for default or enter custom name like \"voice-ai-frontend\")\n- **Install dependencies?** Yes\n\n**Alternative (Manual Clone):**\n```bash\ngit clone https://github.com/livekit-examples/agent-starter-react.git voice-ai-frontend\ncd voice-ai-frontend\npnpm install\n```\n\n**Expected Outcome:**\n```\n✓ Created project: voice-ai-frontend\n✓ Installed dependencies\n✓ Ready to configure\n```\n\n**Directory Structure:**\n```\nfrontend/voice-ai-frontend/\n├── app/\n│   ├── api/token/route.ts     # Token generation endpoint\n│   ├── page.tsx               # Main page\n│   └── layout.tsx\n├── components/\n│   ├── agents-ui/             # Agents UI components\n│   ├── app/                   # Business logic\n│   └── ui/                    # Shadcn/ui primitives\n├── hooks/\n├── lib/\n├── public/\n├── package.json\n├── .env.example\n└── next.config.js\n```\n\n**Rationale:** Official template provides production-ready structure with all necessary LiveKit integrations\n\n---\n\n#### 2.3: Configure Environment Variables\n\n**What:** Set up LiveKit credentials for the frontend\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend/.env.local`\n\n**Commands:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\ncp .env.example .env.local\n```\n\n**Edit `.env.local`:**\n```env\n# LiveKit project credentials (from livekit-credentials.json)\nLIVEKIT_API_KEY=APIxxxxxxxxxxxx\nLIVEKIT_API_SECRET=your-secret-here\nLIVEKIT_URL=wss://your-project.livekit.cloud\n\n# Public URL (exposed to browser - same as LIVEKIT_URL)\nNEXT_PUBLIC_LIVEKIT_URL=wss://your-project.livekit.cloud\n\n# Agent configuration\nAGENT_NAME=\n# Leave AGENT_NAME blank for automatic agent dispatch\n# Or set to specific agent name if you have multiple agents\n```\n\n**How to Get Values:**\n```bash\n# Copy from livekit-credentials.json\ncat /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/livekit-credentials.json\n```\n\n**Security Notes:**\n- `LIVEKIT_API_SECRET` is server-side only (never exposed to browser)\n- `NEXT_PUBLIC_*` variables are exposed to browser\n- Only `NEXT_PUBLIC_LIVEKIT_URL` should be public\n- Never expose `LIVEKIT_API_KEY` or `LIVEKIT_API_SECRET` to browser\n\n**Rationale:** Frontend needs credentials to generate tokens and connect to LiveKit rooms\n\n---\n\n#### 2.4: Verify Dependencies Installation\n\n**What:** Ensure all npm packages are installed correctly\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\npnpm install\n```\n\n**Expected Outcome:**\n```\nPackages: +XXX\nProgress: resolved XXX, reused XXX, downloaded X, added XXX, done\n```\n\n**Key Dependencies (verify in `package.json`):**\n- `next` (v14+)\n- `react` (v18+)\n- `livekit-client`\n- `@livekit/components-react`\n- `livekit-server-sdk`\n- `tailwindcss`\n- `typescript`\n\n**Troubleshooting:**\n- If pnpm not installed: `npm install -g pnpm`\n- If peer dependency warnings: Generally safe to ignore\n- If install fails: Delete `node_modules` and `pnpm-lock.yaml`, retry\n\n**Rationale:** Ensures all required packages are available for development\n\n---\n\n#### 2.5: Run Development Server\n\n**What:** Start the Next.js development server to verify basic setup\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\npnpm dev\n```\n\n**Expected Outcome:**\n```\n> next dev\n\n  ▲ Next.js 14.x.x\n  - Local:        http://localhost:3000\n  - Environments: .env.local\n\n ✓ Ready in X.Xs\n```\n\n**Verification:**\n1. Open browser to http://localhost:3000\n2. Should see agent interface with \"Connect\" button\n3. No console errors in browser DevTools\n4. Page loads without 500 errors\n\n**Expected UI:**\n- Welcome/landing view\n- \"Connect\" or \"Start Session\" button\n- Logo and branding elements\n- Theme toggle (light/dark)\n\n**Troubleshooting:**\n- If port 3000 in use: `pnpm dev -- -p 3001`\n- If env vars missing: Check `.env.local` exists and has correct values\n- If build errors: Check `pnpm install` completed successfully\n\n**Rationale:** Validates Next.js setup before proceeding to authentication\n\n---\n\n#### 2.6: Inspect Token Generation API Route\n\n**What:** Review the built-in token generation endpoint to understand how authentication works\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend/app/api/token/route.ts`\n\n**Read the file:**\n```typescript\n// Expected structure (review actual implementation)\nimport { AccessToken } from 'livekit-server-sdk';\n\nexport async function POST(request: Request) {\n  const { roomName, participantName } = await request.json();\n\n  const token = new AccessToken(\n    process.env.LIVEKIT_API_KEY,\n    process.env.LIVEKIT_API_SECRET,\n    {\n      identity: participantName,\n      ttl: '2h', // Token valid for 2 hours\n    }\n  );\n\n  token.addGrant({\n    room: roomName,\n    roomJoin: true,\n    canPublish: true,\n    canSubscribe: true,\n  });\n\n  return Response.json({ token: await token.toJwt() });\n}\n```\n\n**Key Points:**\n- Uses `livekit-server-sdk` to generate JWT tokens\n- Reads `LIVEKIT_API_KEY` and `LIVEKIT_API_SECRET` from environment\n- Grants room join, publish, and subscribe permissions\n- Returns JWT token to frontend\n- Token expires after 2 hours (LiveKit auto-refreshes for connected clients)\n\n**Security Review:**\n- ✓ API key/secret are server-side only (not exposed to browser)\n- ✓ Token generation happens on server\n- ✓ Appropriate permissions granted\n- ⚠ Consider adding rate limiting for production\n\n**Rationale:** Understanding token flow is critical for debugging connection issues\n\n---\n\n#### 2.7: Add Frontend to .gitignore (Backend Repo)\n\n**What:** Prevent frontend from being committed to agent backend repo\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/.gitignore`\n\n**Add to `.gitignore`:**\n```bash\necho \"frontend/\" >> .gitignore\n```\n\n**Verify:**\n```bash\ngit status\n# frontend/ should not appear in untracked files\n```\n\n**Alternative Approach:**\nIf you want to commit the frontend to the same repo:\n- Create a separate `.gitignore` in `frontend/voice-ai-frontend/`\n- Add standard Next.js ignores (`.next/`, `node_modules/`, `.env.local`)\n\n**Rationale:** Keep frontend and backend as separate concerns, or manage carefully if in same repo\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Frontend directory created: `ls frontend/voice-ai-frontend`\n- [ ] Dependencies installed: `pnpm list --depth=0` shows key packages\n- [ ] Environment variables configured: `cat .env.local | grep LIVEKIT_API_KEY`\n- [ ] Development server starts: `pnpm dev` runs without errors\n- [ ] No TypeScript errors: `pnpm run build` completes successfully\n\n#### Manual Verification:\n\n- [ ] Visit http://localhost:3000 in browser\n- [ ] Page loads without 500 errors\n- [ ] UI displays welcome screen with \"Connect\" button\n- [ ] No console errors in browser DevTools\n- [ ] Theme toggle works (light/dark mode)\n- [ ] Responsive design works on mobile viewport\n\n**Verify:** After completing automated verification, open the app in a browser and verify UI loads correctly before proceeding to Phase 3.\n\n---\n\n## Phase 3: Authentication and Token Generation\n\n### Overview\n\nConfigure and test the JWT token generation flow to ensure frontend can authenticate users with LiveKit and connect them to agent sessions.\n\n### Context\n\nBefore starting, ensure:\n- Phase 2 completed successfully\n- Development server running at http://localhost:3000\n- Environment variables configured in `.env.local`\n\nFiles to review:\n- `frontend/voice-ai-frontend/app/api/token/route.ts` - Token generation endpoint\n- `frontend/voice-ai-frontend/.env.local` - Environment configuration\n- `frontend/voice-ai-frontend/components/app/` - Client-side connection logic\n\n### Dependencies\n\n**Depends on:** Phase 2 (frontend setup)\n\n**Required by:** Phase 4 (connection testing)\n\n### Changes Required\n\n#### 3.1: Test Token Generation Endpoint\n\n**What:** Verify the token API endpoint works correctly\n\n**Command:**\n```bash\n# Start dev server (if not running)\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\npnpm dev\n\n# In another terminal, test the endpoint\ncurl -X POST http://localhost:3000/api/token \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"roomName\": \"test-room\", \"participantName\": \"test-user\"}'\n```\n\n**Expected Response:**\n```json\n{\n  \"token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\"\n}\n```\n\n**Validate Token:**\n```bash\n# Decode the JWT to inspect claims (copy token from response)\necho \"eyJhbGciOiJ...\" | cut -d'.' -f2 | base64 -d | jq\n```\n\n**Expected Token Payload:**\n```json\n{\n  \"exp\": 1234567890,\n  \"iss\": \"APIxxxxxxxxxxxx\",\n  \"sub\": \"test-user\",\n  \"nbf\": 1234567890,\n  \"video\": {\n    \"room\": \"test-room\",\n    \"roomJoin\": true,\n    \"canPublish\": true,\n    \"canSubscribe\": true,\n    \"canPublishData\": true\n  }\n}\n```\n\n**Troubleshooting:**\n- If 500 error: Check environment variables in `.env.local`\n- If \"api_key undefined\": Verify `LIVEKIT_API_KEY` is set\n- If \"invalid signature\": Check `LIVEKIT_API_SECRET` is correct\n- If no response: Verify dev server is running on port 3000\n\n**Rationale:** Token generation must work before attempting to connect to LiveKit\n\n---\n\n#### 3.2: Review Client-Side Connection Logic\n\n**What:** Understand how the frontend connects to LiveKit rooms\n\n**Files to Review:**\n```bash\n# Main session component\ncat frontend/voice-ai-frontend/components/app/session-view.tsx\n\n# View controller\ncat frontend/voice-ai-frontend/components/app/view-controller.tsx\n\n# Connection utilities\ncat frontend/voice-ai-frontend/lib/connection.ts\n```\n\n**Key Flow:**\n1. User clicks \"Connect\" button\n2. Frontend generates room name (random or predefined)\n3. Frontend fetches token from `/api/token` endpoint\n4. Frontend connects to LiveKit room using `livekit-client`\n5. Agent is automatically dispatched to room\n6. User and agent establish WebRTC connection\n7. Audio tracks are exchanged\n\n**Important Variables:**\n- `NEXT_PUBLIC_LIVEKIT_URL` - LiveKit server URL (browser-accessible)\n- Room name generation logic\n- Participant name/identity\n- Agent dispatch configuration\n\n**Rationale:** Understanding client-side logic helps debug connection issues\n\n---\n\n#### 3.3: Configure Agent Dispatch\n\n**What:** Ensure frontend triggers automatic agent dispatch when users connect\n\n**File:** Review `frontend/voice-ai-frontend/app/api/connection-details/route.ts` (if exists) or equivalent\n\n**Verify Agent Name Configuration:**\n\n**Option A: Automatic Dispatch (Recommended):**\n```env\n# In .env.local\nAGENT_NAME=\n# Blank means \"dispatch any available agent\"\n```\n\n**Option B: Specific Agent:**\n```env\n# In .env.local\nAGENT_NAME=agent_abc123\n# Uses specific agent by ID or name\n```\n\n**Check Token Grant Configuration:**\n```typescript\n// In app/api/token/route.ts or connection-details/route.ts\ntoken.addGrant({\n  room: roomName,\n  roomJoin: true,\n  canPublish: true,\n  canSubscribe: true,\n  // Optional: Agent dispatch configuration\n});\n```\n\n**For agent-starter-react:**\nThe template typically handles agent dispatch automatically when a participant joins a room. Verify this by checking the token generation code and connection details endpoint.\n\n**Rationale:** Agent won't join room unless dispatch is configured correctly\n\n---\n\n#### 3.4: Test Token Expiration and Refresh\n\n**What:** Verify token expiration is set correctly and LiveKit handles refresh\n\n**Check Current TTL:**\n```typescript\n// In app/api/token/route.ts\nconst token = new AccessToken(\n  process.env.LIVEKIT_API_KEY,\n  process.env.LIVEKIT_API_SECRET,\n  {\n    identity: participantName,\n    ttl: '2h', // Current setting\n  }\n);\n```\n\n**Recommended TTL:**\n- Development: `2h` (2 hours)\n- Production: `2h` (LiveKit auto-refreshes for connected clients)\n- Pre-generated tokens: `1h` (if caching tokens)\n\n**Token Refresh Behavior:**\n- LiveKit client SDK automatically refreshes tokens before expiration\n- Refresh happens for connected clients only\n- Disconnected users must request new tokens\n\n**No changes needed if TTL is already `2h`.**\n\n**Rationale:** Prevents users from being disconnected due to token expiration\n\n---\n\n#### 3.5: Add Security Headers (Optional but Recommended)\n\n**What:** Add security headers to token API route\n\n**File:** `frontend/voice-ai-frontend/middleware.ts` (create if doesn't exist)\n\n**Content:**\n```typescript\nimport { NextResponse } from 'next/server';\nimport type { NextRequest } from 'next/server';\n\nexport function middleware(request: NextRequest) {\n  const response = NextResponse.next();\n\n  // Security headers\n  response.headers.set('X-Content-Type-Options', 'nosniff');\n  response.headers.set('X-Frame-Options', 'DENY');\n  response.headers.set('X-XSS-Protection', '1; mode=block');\n\n  return response;\n}\n\nexport const config = {\n  matcher: '/api/:path*',\n};\n```\n\n**Optional Rate Limiting:**\nConsider adding rate limiting to `/api/token` endpoint to prevent abuse.\n\n**Rationale:** Basic security hardening for production deployments\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Token endpoint returns valid JWT: `curl -X POST http://localhost:3000/api/token -H \"Content-Type: application/json\" -d '{\"roomName\":\"test\",\"participantName\":\"user\"}' | jq .token`\n- [ ] Token payload contains correct claims: Decode JWT and verify `video.roomJoin: true`\n- [ ] Environment variables loaded: `console.log(process.env.LIVEKIT_API_KEY)` in token route shows value (not undefined)\n- [ ] Token has correct expiration: Decoded JWT shows `exp` timestamp 2 hours in future\n\n#### Manual Verification:\n\n- [ ] Token endpoint accessible via browser: Visit http://localhost:3000/api/token (should return 405 Method Not Allowed for GET)\n- [ ] No errors in Next.js server logs when generating tokens\n- [ ] Token decodes successfully at https://jwt.io\n- [ ] Token issuer (`iss`) matches your LiveKit API key\n- [ ] Token subject (`sub`) matches requested participant name\n\n**Verify:** After completing automated verification, test token generation with curl and decode the JWT to inspect claims before proceeding to Phase 4.\n\n---\n\n## Phase 4: Connection Testing and Optimization\n\n### Overview\n\nTest the end-to-end connection flow from frontend to agent, verify audio works correctly, and optimize the connection speed.\n\n### Context\n\nBefore starting, ensure:\n- Phase 3 completed successfully\n- Agent running on LiveKit Cloud (`lk agent status` shows Running)\n- Frontend running at http://localhost:3000\n- Token generation working\n\nFiles to review:\n- `frontend/voice-ai-frontend/components/app/session-view.tsx` - Session management\n- `frontend/voice-ai-frontend/components/agents-ui/` - UI components\n\nTools needed:\n- Browser with microphone access\n- Terminal for monitoring agent logs\n\n### Dependencies\n\n**Depends on:** Phases 1-3 (agent deployed, frontend configured, authentication working)\n\n**Required by:** Phase 5 (customization), Phase 6 (production deployment)\n\n### Changes Required\n\n#### 4.1: Monitor Agent Logs\n\n**What:** Start monitoring agent logs before testing connection\n\n**Command:**\n```bash\n# Open a dedicated terminal window for agent logs\nlk agent logs --follow\n```\n\n**Keep this terminal open during all testing.**\n\n**What to Look For:**\n- Agent initialization messages\n- Room join events\n- STT transcriptions\n- LLM requests/responses\n- TTS generation\n- WebRTC connection events\n- Any error messages\n\n**Rationale:** Real-time logs are essential for debugging connection issues\n\n---\n\n#### 4.2: Test Basic Connection Flow\n\n**What:** Connect to the agent via frontend and verify basic functionality\n\n**Steps:**\n\n1. Open browser to http://localhost:3000\n2. Open browser DevTools Console (F12 → Console tab)\n3. Click \"Connect\" or \"Start Session\" button\n4. Grant microphone permissions when prompted\n5. Observe connection states in UI:\n   - \"Initializing...\"\n   - \"Listening\" (agent ready for input)\n   - \"Thinking\" (processing speech)\n   - \"Speaking\" (agent responding)\n\n**Expected Behavior:**\n- Connection establishes within 3-5 seconds\n- Agent state transitions to \"Listening\"\n- No errors in browser console\n- Agent logs show room join event\n\n**Troubleshooting:**\n- **Connection hangs:** Check token endpoint, verify LIVEKIT_URL is correct\n- **\"Failed to connect\":** Check agent status (`lk agent status`), verify agent is Running\n- **Microphone permission denied:** Grant permission in browser settings\n- **No audio:** Check browser audio output, verify speakers are enabled\n- **WebRTC errors:** Check firewall, ensure WebRTC ports not blocked\n\n**Rationale:** Validates basic connection before testing voice interaction\n\n---\n\n#### 4.3: Test Voice Interaction\n\n**What:** Verify end-to-end voice pipeline (STT → LLM → TTS)\n\n**Steps:**\n\n1. With frontend connected and agent in \"Listening\" state\n2. Speak clearly into your microphone: \"Hello, can you hear me?\"\n3. Observe agent state transition:\n   - \"Listening\" → \"Thinking\" → \"Speaking\"\n4. Listen for agent's voice response\n5. Check agent logs for:\n   - STT transcription of your speech\n   - LLM request and response\n   - TTS generation\n\n**Expected Outcome:**\n- Agent responds with natural voice within 2-4 seconds\n- Transcription appears in logs (if logging enabled)\n- No audio dropouts or distortion\n- Agent response is contextually appropriate\n\n**Additional Test Cases:**\n- **Interruption:** Speak while agent is speaking (should handle gracefully)\n- **Silence:** Wait 10 seconds without speaking (agent should remain connected)\n- **Background Noise:** Test with ambient noise (should filter with VAD)\n- **Multiple Turns:** Have a multi-turn conversation\n\n**Troubleshooting:**\n- **No transcription:** Check AssemblyAI API key in agent secrets\n- **No LLM response:** Check OpenAI API key, verify LLM model is available\n- **No TTS audio:** Check Cartesia API key, verify TTS voice model\n- **Garbled audio:** Check network connection, reduce network congestion\n- **High latency:** Check agent logs for slow API calls, consider region optimization\n\n**Rationale:** Validates the complete voice AI pipeline works end-to-end\n\n---\n\n#### 4.4: Verify Audio Visualization\n\n**What:** Test the audio visualizer component works correctly\n\n**Steps:**\n\n1. With frontend connected\n2. Speak into microphone\n3. Observe audio visualization:\n   - Bars should animate when you speak\n   - Bars should pulse when agent speaks\n   - Different colors/states for listening vs speaking\n\n**Expected Behavior:**\n- `BarVisualizer` component shows real-time audio levels\n- Smooth animations\n- Clear visual feedback of agent state\n- No lag between audio and visualization\n\n**Check Component:**\n```bash\n# Review visualizer component\ncat frontend/voice-ai-frontend/components/agents-ui/bar-visualizer.tsx\n```\n\n**Troubleshooting:**\n- **No visualization:** Check if audio track is being passed to component\n- **Choppy animation:** Check browser performance, reduce animation complexity\n- **Wrong colors:** Review CSS/Tailwind classes\n\n**Rationale:** Visual feedback improves user experience and debugging\n\n---\n\n#### 4.5: Test Disconnection and Reconnection\n\n**What:** Verify graceful disconnect and ability to reconnect\n\n**Steps:**\n\n**Test Disconnect:**\n1. With frontend connected\n2. Click \"Disconnect\" or \"End Session\" button\n3. Observe clean disconnect:\n   - Agent logs show participant left\n   - No error messages\n   - UI returns to welcome screen\n\n**Test Reconnect:**\n1. Click \"Connect\" again\n2. Verify new session starts successfully\n3. Test voice interaction again\n\n**Test Network Interruption (Optional):**\n1. While connected, disable network (Wi-Fi off)\n2. Observe reconnection behavior\n3. Re-enable network\n4. Verify auto-reconnect or error message\n\n**Expected Behavior:**\n- Clean disconnect without errors\n- Ability to reconnect immediately\n- Each session gets unique room/token\n- No lingering WebRTC connections\n\n**Rationale:** Ensures robust connection lifecycle management\n\n---\n\n#### 4.6: Optimize Connection Speed\n\n**What:** Reduce connection time from 3-5 seconds to <1 second using optimization techniques\n\n**Current Flow (Sequential):**\n```\n1. Click Connect (0ms)\n2. Fetch token from /api/token (500ms)\n3. Connect to LiveKit room (1000ms)\n4. Agent dispatched (1000ms)\n5. Agent connects and publishes (1500ms)\nTotal: ~4000ms (4 seconds)\n```\n\n**Optimization 1: Pre-generate Tokens**\n\nCreate a \"warm token\" approach for faster connection:\n\n**File:** Create `frontend/voice-ai-frontend/hooks/use-warm-token.ts`\n\n```typescript\n'use client';\n\nimport { useState, useEffect } from 'react';\n\nexport function useWarmToken() {\n  const [token, setToken] = useState<string | null>(null);\n\n  useEffect(() => {\n    // Pre-generate token on page load\n    async function generateToken() {\n      const response = await fetch('/api/token', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          roomName: `room-${Date.now()}`,\n          participantName: `user-${Math.random().toString(36).substring(7)}`,\n        }),\n      });\n      const data = await response.json();\n      setToken(data.token);\n    }\n\n    generateToken();\n  }, []);\n\n  return token;\n}\n```\n\n**Usage in Session Component:**\n```typescript\n// In session-view.tsx or similar\nconst warmToken = useWarmToken();\n\n// Use warmToken when connecting instead of fetching on-demand\n```\n\n**Optimization 2: Concurrent Dispatch**\n\nModify connection logic to dispatch agent and connect user simultaneously:\n\n```typescript\n// Parallel connection\nconst [roomConnection, agentDispatch] = await Promise.all([\n  connectToRoom(token),\n  dispatchAgent(roomName) // If manual dispatch required\n]);\n```\n\n**Expected Improvement:**\n- Pre-generated token: -500ms (eliminates token fetch delay)\n- Concurrent dispatch: -1000ms (parallel instead of sequential)\n- **New total:** ~2500ms → ~1500ms (1.5 seconds)\n\n**Trade-offs:**\n- Pre-generated tokens have expiration (ensure 2h TTL)\n- Unused tokens waste resources (minimal cost)\n- Complexity slightly increases\n\n**Rationale:** Faster connections improve user experience and perceived performance\n\n---\n\n#### 4.7: Test on Multiple Browsers\n\n**What:** Verify cross-browser compatibility\n\n**Browsers to Test:**\n- Chrome/Chromium\n- Firefox\n- Safari (macOS/iOS)\n- Edge\n\n**Test Matrix:**\n\n| Browser | Connection | Audio Input | Audio Output | Visualization |\n|---------|-----------|-------------|--------------|---------------|\n| Chrome  | ✓         | ✓           | ✓            | ✓             |\n| Firefox | ?         | ?           | ?            | ?             |\n| Safari  | ?         | ?           | ?            | ?             |\n| Edge    | ?         | ?           | ?            | ?             |\n\n**Common Issues:**\n- **Safari:** May require user interaction before audio playback\n- **Firefox:** Different WebRTC implementation, may have quirks\n- **Mobile Safari:** Requires specific audio context handling\n- **Edge:** Generally compatible with Chrome\n\n**Rationale:** Ensures wide browser support for production deployment\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Connection establishes successfully: Monitor for \"Room connected\" event in logs\n- [ ] Agent joins room: `lk agent logs` shows room join event\n- [ ] WebRTC connection: Browser DevTools Network tab shows WebRTC connections\n- [ ] No console errors: Browser DevTools Console shows no red errors\n- [ ] Audio tracks published: Check LiveKit Cloud dashboard for active tracks\n\n#### Manual Verification:\n\n- [ ] Voice input recognized: Speak and verify agent responds\n- [ ] Voice output works: Hear agent's TTS response clearly\n- [ ] Audio visualization animates correctly\n- [ ] Agent state transitions work (initializing → listening → thinking → speaking)\n- [ ] Interruption handling works (speak during agent response)\n- [ ] Disconnect and reconnect works cleanly\n- [ ] Connection time <3 seconds (before optimization) or <1.5s (after optimization)\n- [ ] Works in Chrome, Firefox, and Safari\n\n**Verify:** After completing automated verification, have a multi-turn conversation with the agent and test all edge cases before proceeding to Phase 5.\n\n---\n\n## Phase 5: Frontend Customization\n\n### Overview\n\nCustomize the frontend with your branding, colors, logo, and company information to make it production-ready.\n\n### Context\n\nBefore starting, ensure:\n- Phase 4 completed successfully\n- Voice interaction working end-to-end\n- Frontend running at http://localhost:3000\n\nFiles to customize:\n- `frontend/voice-ai-frontend/app-config.ts` - Main configuration\n- `frontend/voice-ai-frontend/public/` - Static assets (logo, favicon)\n- `frontend/voice-ai-frontend/app/layout.tsx` - Page metadata\n- `frontend/voice-ai-frontend/tailwind.config.ts` - Theme colors\n\n### Dependencies\n\n**Depends on:** Phase 4 (connection testing completed)\n\n**Required by:** Phase 6 (production deployment)\n\n### Changes Required\n\n#### 5.1: Update App Configuration\n\n**What:** Customize company name, page title, and feature flags\n\n**File:** `frontend/voice-ai-frontend/app-config.ts`\n\n**Edit:**\n```typescript\nexport const APP_CONFIG_DEFAULTS = {\n  // Branding\n  companyName: \"Your Company Name\", // Change this\n  pageTitle: \"AI Voice Assistant | Your Company\", // Change this\n\n  // Logo URLs\n  logoUrl: \"/logo.svg\", // Update after adding logo in 5.2\n  logoUrlDark: \"/logo-dark.svg\", // Optional: separate dark mode logo\n\n  // Accent color\n  accentColor: \"#4F46E5\", // Change to your brand color (hex)\n\n  // Feature toggles\n  supportsChatInput: true, // Allow text chat alongside voice\n  supportsVideoInput: true, // Enable camera video\n  supportsScreenShare: true, // Enable screen sharing\n  isPreConnectBufferEnabled: true, // Pre-load for faster connection\n\n  // Optional: Agent configuration\n  defaultAgentName: \"\", // Leave blank for auto-dispatch\n};\n```\n\n**Example Customization:**\n```typescript\nexport const APP_CONFIG_DEFAULTS = {\n  companyName: \"Acme Voice AI\",\n  pageTitle: \"Voice AI Assistant | Acme Corp\",\n  logoUrl: \"/acme-logo.svg\",\n  accentColor: \"#FF6B35\", // Orange\n  supportsChatInput: true,\n  supportsVideoInput: false, // Disable video for voice-only\n  supportsScreenShare: false,\n  isPreConnectBufferEnabled: true,\n};\n```\n\n**Rationale:** Centralizes configuration for easy customization without code changes\n\n---\n\n#### 5.2: Add Custom Logo\n\n**What:** Replace default logo with your company logo\n\n**Steps:**\n\n1. Prepare logo files:\n   - **Format:** SVG (preferred) or PNG\n   - **Size:**\n     - SVG: Any size (scalable)\n     - PNG: 200x200px minimum, transparent background\n   - **Naming:**\n     - Light mode: `logo.svg` or `logo.png`\n     - Dark mode (optional): `logo-dark.svg` or `logo-dark.png`\n\n2. Copy to public directory:\n   ```bash\n   cp /path/to/your/logo.svg frontend/voice-ai-frontend/public/logo.svg\n   # Optional: dark mode logo\n   cp /path/to/your/logo-dark.svg frontend/voice-ai-frontend/public/logo-dark.svg\n   ```\n\n3. Update `app-config.ts`:\n   ```typescript\n   logoUrl: \"/logo.svg\",\n   logoUrlDark: \"/logo-dark.svg\", // If you have separate dark logo\n   ```\n\n4. Verify logo appears:\n   - Restart dev server: `pnpm dev`\n   - Visit http://localhost:3000\n   - Check logo displays correctly\n   - Toggle light/dark mode to test both logos\n\n**Fallback:**\nIf you don't have a logo ready, the template includes a default placeholder logo.\n\n**Rationale:** Custom logo reinforces brand identity\n\n---\n\n#### 5.3: Customize Theme Colors\n\n**What:** Update color scheme to match your brand\n\n**File:** `frontend/voice-ai-frontend/tailwind.config.ts`\n\n**Edit:**\n```typescript\nexport default {\n  theme: {\n    extend: {\n      colors: {\n        // Primary brand color\n        primary: {\n          50: '#f0f9ff',\n          100: '#e0f2fe',\n          // ... continue through 950\n          500: '#4F46E5', // Main brand color (change this)\n          600: '#4338ca',\n          // ...\n        },\n        // Accent color\n        accent: {\n          DEFAULT: '#FF6B35', // Change to your accent color\n          light: '#FF8A5B',\n          dark: '#E5501F',\n        },\n      },\n    },\n  },\n};\n```\n\n**Quick Method (Use Accent Color from app-config.ts):**\n\nThe template may automatically use `accentColor` from `app-config.ts`. If so, just update that value:\n\n```typescript\n// In app-config.ts\naccentColor: \"#FF6B35\", // Your brand color\n```\n\n**Generate Full Color Palette:**\nUse tools like https://uicolors.app/create to generate a full Tailwind color palette from your brand color.\n\n**Test Theme:**\n- Restart dev server\n- Visit http://localhost:3000\n- Check buttons, links, highlights use new colors\n- Toggle light/dark mode to verify both themes\n\n**Rationale:** Consistent color scheme creates professional, branded experience\n\n---\n\n#### 5.4: Update Page Metadata\n\n**What:** Set page title, description, and favicon for SEO and browser display\n\n**File:** `frontend/voice-ai-frontend/app/layout.tsx`\n\n**Edit:**\n```typescript\nexport const metadata: Metadata = {\n  title: \"AI Voice Assistant | Your Company\", // Change this\n  description: \"Connect with our AI voice assistant for instant help and support.\", // Change this\n  icons: {\n    icon: '/favicon.ico', // Update after adding favicon\n  },\n  openGraph: {\n    title: \"AI Voice Assistant | Your Company\",\n    description: \"Connect with our AI voice assistant for instant help and support.\",\n    images: ['/og-image.png'], // Optional: social share image\n  },\n};\n```\n\n**Add Custom Favicon:**\n\n1. Generate favicon files (use https://realfavicongenerator.net/):\n   - `favicon.ico` (16x16, 32x32, 48x48)\n   - `apple-touch-icon.png` (180x180)\n   - `favicon-16x16.png`\n   - `favicon-32x32.png`\n\n2. Copy to `public/`:\n   ```bash\n   cp /path/to/favicon.ico frontend/voice-ai-frontend/public/\n   cp /path/to/apple-touch-icon.png frontend/voice-ai-frontend/public/\n   ```\n\n3. Verify in browser:\n   - Clear browser cache\n   - Visit http://localhost:3000\n   - Check browser tab shows your favicon\n\n**Optional: Open Graph Image (Social Sharing):**\nCreate `og-image.png` (1200x630px) for social media previews.\n\n**Rationale:** Professional metadata improves SEO and user experience\n\n---\n\n#### 5.5: Customize Welcome Message\n\n**What:** Update the welcome screen text and instructions\n\n**File:** `frontend/voice-ai-frontend/components/app/welcome-view.tsx` or similar\n\n**Find and Edit:**\n```typescript\n<h1>Welcome to [Your Company] Voice AI</h1>\n<p>\n  Click the button below to start a voice conversation with our AI assistant.\n  We can help you with questions, information, and more.\n</p>\n```\n\n**Example Customization:**\n```typescript\n<h1>Welcome to Acme Voice Assistant</h1>\n<p>\n  Our AI assistant is ready to help you 24/7. Click \"Connect\" to start a\n  natural voice conversation. Just speak naturally - no keywords or commands needed.\n</p>\n<ul>\n  <li>Get instant answers to your questions</li>\n  <li>Learn about our products and services</li>\n  <li>Get personalized recommendations</li>\n</ul>\n```\n\n**Rationale:** Clear messaging helps users understand what to expect\n\n---\n\n#### 5.6: Optional - Disable Features Not Needed\n\n**What:** Hide video/screen share features if you only need voice\n\n**File:** `frontend/voice-ai-frontend/app-config.ts`\n\n**For Voice-Only App:**\n```typescript\nexport const APP_CONFIG_DEFAULTS = {\n  // ... other settings\n  supportsChatInput: false, // Disable text chat\n  supportsVideoInput: false, // Disable camera\n  supportsScreenShare: false, // Disable screen sharing\n  isPreConnectBufferEnabled: true, // Keep for faster connection\n};\n```\n\n**Effect:**\n- Video camera icon hidden\n- Screen share button removed\n- UI simplified to voice-only interface\n- Reduced complexity for users\n\n**Rationale:** Simplify UI by removing unused features\n\n---\n\n#### 5.7: Test Customizations\n\n**What:** Verify all customizations display correctly\n\n**Checklist:**\n- [ ] Company name displays on welcome screen\n- [ ] Custom logo appears (both light and dark modes)\n- [ ] Page title shows in browser tab\n- [ ] Custom favicon appears in browser tab\n- [ ] Brand colors visible on buttons and accents\n- [ ] Welcome message updated with custom text\n- [ ] Disabled features are hidden (if applicable)\n- [ ] No broken images or 404s\n- [ ] Responsive design maintained on mobile\n\n**Testing Steps:**\n1. Restart dev server: `pnpm dev`\n2. Clear browser cache (Cmd+Shift+R on Mac, Ctrl+Shift+R on Windows)\n3. Visit http://localhost:3000\n4. Toggle light/dark theme\n5. Resize browser to mobile size (375px width)\n6. Check all visual elements\n\n**Rationale:** Ensures professional, branded appearance before production deployment\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Build succeeds: `pnpm run build` completes without errors\n- [ ] No TypeScript errors: `pnpm run type-check` (if available)\n- [ ] Static assets exist: `ls public/logo.svg public/favicon.ico`\n- [ ] Config updated: `cat app-config.ts | grep companyName` shows your company\n\n#### Manual Verification:\n\n- [ ] Custom company name displays on welcome screen\n- [ ] Custom logo visible (light and dark modes)\n- [ ] Page title correct in browser tab\n- [ ] Favicon visible in browser tab\n- [ ] Brand colors applied throughout UI\n- [ ] Welcome message updated\n- [ ] Unused features hidden (if disabled)\n- [ ] Mobile responsive (test at 375px width)\n- [ ] No console errors or warnings\n- [ ] All images load correctly (no broken images)\n\n**Verify:** After completing automated verification, thoroughly test the UI on desktop and mobile, in light and dark modes, before proceeding to Phase 6.\n\n---\n\n## Phase 6: Production Deployment\n\n### Overview\n\nDeploy the customized frontend to Vercel (or another hosting provider) to make it publicly accessible via a URL that clients can visit.\n\n### Context\n\nBefore starting, ensure:\n- Phase 5 completed successfully\n- All customizations tested locally\n- Frontend builds successfully (`pnpm run build`)\n- Agent deployed and running on LiveKit Cloud\n\nFiles to review:\n- `frontend/voice-ai-frontend/.env.local` - Environment variables (will configure in Vercel)\n- `frontend/voice-ai-frontend/next.config.js` - Next.js configuration\n- `frontend/voice-ai-frontend/package.json` - Dependencies and scripts\n\nAccounts needed:\n- Vercel account (free tier sufficient): https://vercel.com\n- GitHub account (for connecting repo)\n\n### Dependencies\n\n**Depends on:** Phases 1-5 (agent deployed, frontend customized and tested)\n\n**Required by:** None (final phase)\n\n### Changes Required\n\n#### 6.1: Create Production Build\n\n**What:** Verify the production build works correctly before deploying\n\n**Commands:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\n\n# Create production build\npnpm run build\n\n# Test production build locally\npnpm start\n```\n\n**Expected Output:**\n```\n> next build\n\n✓ Compiled successfully\n✓ Linting and checking validity of types\n✓ Collecting page data\n✓ Generating static pages (X/X)\n✓ Finalizing page optimization\n\nRoute (app)                              Size     First Load JS\n┌ ○ /                                    XXX kB        XXX kB\n└ ○ /api/token                          XXX B          XXX kB\n```\n\n**Test Production Build:**\n1. Visit http://localhost:3000 (pnpm start)\n2. Connect to agent\n3. Verify voice interaction works\n4. Check for any errors in console\n\n**Troubleshooting:**\n- If build fails: Check TypeScript errors, fix before proceeding\n- If errors about environment variables: Ensure `.env.local` exists\n- If runtime errors: Check browser console for specific issues\n\n**Rationale:** Catches production-specific issues before deployment\n\n---\n\n#### 6.2: Push Frontend to GitHub (Optional but Recommended)\n\n**What:** Create a Git repository for the frontend to enable easy Vercel deployment\n\n**Option A: Separate Repository (Recommended):**\n\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\n\n# Initialize git repository\ngit init\n\n# Add .gitignore for Next.js\ncat > .gitignore << 'EOF'\n# Next.js\n.next/\nout/\nbuild/\ndist/\n\n# Dependencies\nnode_modules/\n\n# Environment variables\n.env\n.env.local\n.env.production.local\n.env.development.local\n.env.test.local\n\n# Logs\nnpm-debug.log*\nyarn-debug.log*\nyarn-error.log*\npnpm-debug.log*\n\n# OS\n.DS_Store\n*.swp\n*.swo\n\n# IDE\n.vscode/\n.idea/\n\n# Vercel\n.vercel\nEOF\n\n# Add files\ngit add .\ngit commit -m \"Initial commit: Voice AI frontend\"\n\n# Create GitHub repository (via GitHub UI or CLI)\ngh repo create voice-ai-frontend --public --source=. --remote=origin --push\n```\n\n**Option B: Same Repository as Agent:**\n\nIf you want frontend and agent in the same repo:\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\n\n# Remove frontend/ from .gitignore\nsed -i '' '/^frontend\\//d' .gitignore\n\n# Add and commit\ngit add frontend/\ngit commit -m \"Add voice AI frontend\"\ngit push\n```\n\n**Rationale:** Git repository enables continuous deployment and version control\n\n---\n\n#### 6.3: Sign Up for Vercel\n\n**What:** Create a Vercel account for hosting the frontend\n\n**Steps:**\n\n1. Visit https://vercel.com\n2. Click \"Sign Up\"\n3. Choose \"Continue with GitHub\" (recommended)\n4. Authorize Vercel to access your GitHub repositories\n\n**Pricing:**\n- **Free Tier:** Sufficient for testing and low traffic\n  - Unlimited deployments\n  - 100 GB bandwidth/month\n  - Serverless functions included\n- **Pro Tier:** $20/month (for production with higher traffic)\n\n**Rationale:** Vercel provides seamless Next.js hosting with automatic deployments\n\n---\n\n#### 6.4: Deploy Frontend to Vercel\n\n**What:** Deploy the frontend application to Vercel\n\n**Steps:**\n\n1. **From Vercel Dashboard:**\n   - Click \"Add New...\" → \"Project\"\n   - Select \"Import Git Repository\"\n   - Choose your frontend repository\n   - Configure project:\n     - **Framework Preset:** Next.js (auto-detected)\n     - **Root Directory:** `./` (or `frontend/voice-ai-frontend` if in monorepo)\n     - **Build Command:** `pnpm run build` (auto-detected)\n     - **Output Directory:** `.next` (auto-detected)\n     - **Install Command:** `pnpm install` (auto-detected)\n\n2. **Configure Environment Variables:**\n   Click \"Environment Variables\" and add:\n\n   ```\n   LIVEKIT_API_KEY=APIxxxxxxxxxxxx\n   LIVEKIT_API_SECRET=your-secret-here\n   LIVEKIT_URL=wss://your-project.livekit.cloud\n   NEXT_PUBLIC_LIVEKIT_URL=wss://your-project.livekit.cloud\n   AGENT_NAME=\n   ```\n\n   **Important:**\n   - Copy values from your local `.env.local`\n   - Apply to \"Production\", \"Preview\", and \"Development\" environments\n\n3. **Deploy:**\n   - Click \"Deploy\"\n   - Wait for build to complete (2-5 minutes)\n\n**Expected Outcome:**\n```\n✓ Build successful\n✓ Deployment successful\nYour project is now live at: https://your-app.vercel.app\n```\n\n**Rationale:** Makes frontend publicly accessible via HTTPS URL\n\n---\n\n#### 6.5: Test Production Deployment\n\n**What:** Verify the deployed frontend works correctly\n\n**Steps:**\n\n1. Visit your Vercel URL: `https://your-app.vercel.app`\n\n2. **Test Checklist:**\n   - [ ] Page loads without errors\n   - [ ] Custom branding displays correctly\n   - [ ] Click \"Connect\" button\n   - [ ] Grant microphone permissions\n   - [ ] Speak to agent\n   - [ ] Verify agent responds with voice\n   - [ ] Test on mobile device\n   - [ ] Test in different browsers\n\n3. **Monitor Logs:**\n   ```bash\n   # Monitor agent logs during production test\n   lk agent logs --follow\n   ```\n\n4. **Check Vercel Deployment Logs:**\n   - Go to Vercel dashboard → Your project → Deployments\n   - Click on latest deployment → \"Functions\" tab\n   - Check for any errors in `/api/token` function\n\n**Troubleshooting:**\n- **\"Failed to connect\":** Check environment variables in Vercel\n- **Token errors:** Verify `LIVEKIT_API_KEY` and `LIVEKIT_API_SECRET` are correct\n- **CORS errors:** Ensure `NEXT_PUBLIC_LIVEKIT_URL` is set correctly\n- **Agent not joining:** Check agent status, verify agent is Running\n\n**Rationale:** Ensures production environment works correctly\n\n---\n\n#### 6.6: Configure Custom Domain (Optional)\n\n**What:** Use a custom domain instead of `your-app.vercel.app`\n\n**Prerequisites:**\n- Own a domain name (e.g., `voiceai.yourcompany.com`)\n- Access to domain DNS settings\n\n**Steps:**\n\n1. **In Vercel Dashboard:**\n   - Go to your project → Settings → Domains\n   - Click \"Add Domain\"\n   - Enter your domain: `voiceai.yourcompany.com`\n\n2. **Configure DNS:**\n   Vercel will provide DNS configuration instructions:\n\n   **Option A: CNAME (Subdomain):**\n   ```\n   Type: CNAME\n   Name: voiceai\n   Value: cname.vercel-dns.com\n   ```\n\n   **Option B: A Record (Root Domain):**\n   ```\n   Type: A\n   Name: @\n   Value: 76.76.21.21\n   ```\n\n3. **Wait for DNS Propagation:**\n   - Usually takes 5-60 minutes\n   - Vercel will auto-configure SSL certificate (Let's Encrypt)\n\n4. **Verify:**\n   - Visit `https://voiceai.yourcompany.com`\n   - Should show your frontend with SSL (green lock icon)\n\n**Rationale:** Custom domain provides professional appearance and brand consistency\n\n---\n\n#### 6.7: Enable Automatic Deployments\n\n**What:** Configure automatic deployments when you push to GitHub\n\n**Vercel Auto-Deploys By Default:**\n- **Production:** Deploys on push to `main` branch\n- **Preview:** Deploys on push to any other branch or PR\n\n**Customize (Optional):**\n1. Go to Vercel dashboard → Your project → Settings → Git\n2. Configure:\n   - **Production Branch:** `main` (or `master`)\n   - **Ignored Build Step:** (leave blank to build on every commit)\n\n**Test Automatic Deployment:**\n```bash\ncd frontend/voice-ai-frontend\n\n# Make a small change\necho \"# Updated\" >> README.md\n\n# Commit and push\ngit add README.md\ngit commit -m \"Test automatic deployment\"\ngit push origin main\n```\n\n**Verify:**\n- Visit Vercel dashboard\n- Should see new deployment triggered automatically\n- Wait for build to complete\n- Visit production URL to see changes\n\n**Rationale:** Enables continuous deployment for easy updates\n\n---\n\n#### 6.8: Set Up Production Monitoring (Recommended)\n\n**What:** Monitor production errors and usage\n\n**Vercel Analytics (Built-in):**\n1. Go to Vercel dashboard → Your project → Analytics\n2. View:\n   - Page views\n   - Geographic distribution\n   - Performance metrics (Web Vitals)\n\n**Error Tracking (Optional):**\nConsider integrating Sentry or similar:\n```bash\npnpm add @sentry/nextjs\nnpx @sentry/wizard@latest -i nextjs\n```\n\n**LiveKit Cloud Monitoring:**\n- Visit LiveKit Cloud dashboard\n- Monitor:\n  - Active sessions\n  - Agent usage\n  - Costs (session minutes)\n\n**Rationale:** Production monitoring helps identify and resolve issues quickly\n\n---\n\n#### 6.9: Create Shareable Link\n\n**What:** Generate a clean, shareable URL for potential clients\n\n**Your Production URL:**\n```\nhttps://your-app.vercel.app\n```\n\n**Or with Custom Domain:**\n```\nhttps://voiceai.yourcompany.com\n```\n\n**Create Marketing Materials:**\n- Add link to your website\n- Share via email campaigns\n- Include in social media bios\n- Create QR code for physical materials\n\n**Example QR Code Generation:**\n```bash\n# Generate QR code (using qrencode)\nbrew install qrencode\nqrencode -o voiceai-qr.png \"https://voiceai.yourcompany.com\"\n```\n\n**Rationale:** Easy sharing enables potential clients to access your voice AI\n\n---\n\n#### 6.10: Document Production URLs and Credentials\n\n**What:** Save all production information for future reference\n\n**Create:** `frontend/voice-ai-frontend/PRODUCTION.md`\n\n**Content:**\n```markdown\n# Production Deployment Information\n\n## URLs\n- **Production Frontend:** https://your-app.vercel.app\n- **Custom Domain:** https://voiceai.yourcompany.com (if configured)\n- **LiveKit Cloud Dashboard:** https://cloud.livekit.io\n\n## Vercel\n- **Project:** voice-ai-frontend\n- **Account:** your-email@example.com\n- **Git Repository:** https://github.com/yourusername/voice-ai-frontend\n\n## LiveKit Cloud\n- **Project:** your-project-name\n- **Region:** us-west-2\n- **Agent ID:** agent_abc123\n\n## Deployment Commands\n```bash\n# Deploy agent updates\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\nlk agent deploy\n\n# Deploy frontend updates (automatic via Git)\ncd frontend/voice-ai-frontend\ngit add .\ngit commit -m \"Update frontend\"\ngit push origin main\n```\n\n## Monitoring\n- **Agent Logs:** `lk agent logs --follow`\n- **Vercel Logs:** https://vercel.com/your-project/deployments\n- **LiveKit Dashboard:** https://cloud.livekit.io/projects/your-project\n\n## Environment Variables (Vercel)\n- LIVEKIT_API_KEY=APIxxxxxxxxxxxx\n- LIVEKIT_API_SECRET=*** (not shown)\n- LIVEKIT_URL=wss://your-project.livekit.cloud\n- NEXT_PUBLIC_LIVEKIT_URL=wss://your-project.livekit.cloud\n\n## Costs\n- **LiveKit Cloud:** $0.01 per agent session minute\n- **Vercel:** Free tier (or $20/month Pro)\n\n## Support\n- **LiveKit:** https://livekit.io/discord\n- **Vercel:** https://vercel.com/support\n```\n\n**Rationale:** Documentation ensures you can manage production deployment long-term\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Production build succeeds: `pnpm run build` completes without errors\n- [ ] Vercel deployment successful: Deployment status shows \"Ready\"\n- [ ] HTTPS enabled: Visit production URL with green lock icon\n- [ ] Environment variables configured: Check Vercel dashboard\n- [ ] Custom domain configured (if applicable): DNS records set\n\n#### Manual Verification:\n\n- [ ] Visit production URL in browser\n- [ ] Page loads without errors\n- [ ] Custom branding displays correctly\n- [ ] Click \"Connect\" and grant microphone access\n- [ ] Speak to agent and verify voice response\n- [ ] Test on mobile device (iOS Safari, Android Chrome)\n- [ ] Test in incognito/private mode\n- [ ] Share URL with colleague and get confirmation it works\n- [ ] Agent logs show production sessions: `lk agent logs --follow`\n- [ ] No errors in Vercel function logs\n\n**Verify:** After completing automated verification, test the production URL on multiple devices and browsers, then share with a colleague to confirm public accessibility.\n\n---\n\n## Testing Strategy\n\n### Unit Tests\n\n**Not required for this plan.** The agent-starter-react template is a pre-built, production-ready template that doesn't require custom unit tests unless you add significant custom logic.\n\n**Optional:** Add tests if you customize components heavily:\n```bash\npnpm add -D @testing-library/react @testing-library/jest-dom jest\n```\n\n### Integration Tests\n\n**End-to-End Testing:**\n\nManually test the complete flow:\n1. User visits URL\n2. Clicks \"Connect\"\n3. Grants microphone access\n4. Speaks to agent\n5. Receives voice response\n6. Disconnects cleanly\n\n**Test Matrix:**\n\n| Scenario | Steps | Expected Outcome |\n|----------|-------|------------------|\n| First Connection | Visit URL → Click Connect → Speak | Agent responds with voice |\n| Interruption | Speak while agent is speaking | Agent handles gracefully |\n| Disconnect/Reconnect | End session → Start new session | New session works |\n| Multiple Turns | Have 3-5 turn conversation | All responses relevant |\n| Mobile Safari | Test on iPhone/iPad | Full functionality |\n| Network Interruption | Disable Wi-Fi during session | Reconnection or error message |\n\n### Manual Testing Steps\n\n**Pre-Deployment Checklist:**\n1. [ ] Agent deployed and running: `lk agent status`\n2. [ ] Local frontend works: `pnpm dev` at http://localhost:3000\n3. [ ] Voice interaction successful\n4. [ ] Audio visualization working\n5. [ ] Custom branding applied\n6. [ ] Production build succeeds: `pnpm run build`\n\n**Post-Deployment Checklist:**\n1. [ ] Production URL accessible\n2. [ ] HTTPS enabled (green lock)\n3. [ ] Voice interaction works on production\n4. [ ] Mobile responsive\n5. [ ] Cross-browser compatible\n6. [ ] Shareable link works for external users\n\n### Performance Considerations\n\n**Metrics to Monitor:**\n- **Connection Time:** Should be <3 seconds (or <1.5s with optimization)\n- **Response Latency:** STT → LLM → TTS should be 2-4 seconds\n- **Page Load Time:** Initial load <2 seconds (Lighthouse score >90)\n- **Audio Quality:** No dropouts or distortion\n\n**Optimization:**\n- Enable pre-connect buffering in `app-config.ts`\n- Use warm token approach (Phase 4.6)\n- Minimize bundle size (Next.js handles automatically)\n- Use CDN for static assets (Vercel provides automatically)\n\n## References\n\n### Original Ticket/Request\n- User request: \"I want potential clients to be able to interact with the livekit agent from this repo by clicking a link on a website.\"\n\n### Documentation\n- `docs/DEPLOYMENT.md` - Complete deployment guide for agent and frontend options\n- `README.md` - Project overview and setup instructions\n- `AGENTS.md` - Project guidelines and standards\n\n### LiveKit Resources\n- **Frontend Deployment Guide:** https://docs.livekit.io/agents/start/frontend/\n- **agent-starter-react Repository:** https://github.com/livekit-examples/agent-starter-react\n- **Token Authentication:** https://docs.livekit.io/home/get-started/authentication/\n- **Agents Playground:** https://agents-playground.livekit.io/\n- **LiveKit Cloud Dashboard:** https://cloud.livekit.io\n- **React Components Docs:** https://docs.livekit.io/reference/components/react/\n\n### NPM Packages\n- **livekit-client:** Client SDK for browser WebRTC\n- **@livekit/components-react:** React UI components\n- **livekit-server-sdk:** Server-side token generation\n\n### Vercel Resources\n- **Vercel Platform:** https://vercel.com\n- **Next.js Documentation:** https://nextjs.org/docs\n- **Deployment Docs:** https://vercel.com/docs\n\n### Related Plans\n- None (initial implementation)\n\n---\n\n**End of Implementation Plan**\n","structuredPatch":[{"oldStart":32,"oldLines":6,"newStart":32,"newLines":8,"lines":[" "," The solution uses LiveKit's official starter templates and SDKs to create a production-ready web application with TypeScript/JavaScript."," ","+**IMPORTANT: This is an audio-only application. No video camera or screen sharing permissions should be requested from users. All configuration must disable video/screenshare features.**","+"," ## Current State Analysis"," "," ### What Exists Now"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"c1a73cdd-7570-40c5-960f-92c9baf7d873"}
{"parentUuid":"53fffdc3-a0d9-4094-bd71-7c0788822314","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","slug":"enumerated-shimmying-starlight","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01HrWr5FpCruPryAjTv3EUWm","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now let me update the app configuration section to emphasize that video features should be disabled.","signature":"EowCCkYICxgCKkCtke18NfEUt67gbP/+XHrjEFAL6HKMxoOUa+zRVLvOO97QUfLoriHeLn7n2nnZeUg4qY6uP0zB8U0SEkNgQzekEgxRB03Vwr4tZ6/xCNgaDANLnzKL2uy1WdH7WiIwWW+HEQTkx2Ssx4mZhoQeDBUjLpFsusNw0p4Y9nQ02EgLiJTrN4r29KexbzsG3R7WKnSpa7VHfckU9iNb6q9GtzAgyND4hyTxE7Fc2OjzKWRjES1LX9w/XvfJ2pHaHNCDxaLD6zznPxdDblblvbU320TATIv786rS0+LLezwgXSI3l2DIq2AKSFjgKCLYRMz5vGuWx9l+eAIlCKqq4e/1iFBukNUNhhgB"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":10,"cache_creation_input_tokens":560,"cache_read_input_tokens":65722,"cache_creation":{"ephemeral_5m_input_tokens":560,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXTt6pKNfbzhAvPj9aUHR","type":"assistant","uuid":"0fb0c8e0-a4c6-4dc2-911f-655129e5fbda","timestamp":"2026-01-25T09:45:20.934Z"}
{"parentUuid":"0fb0c8e0-a4c6-4dc2-911f-655129e5fbda","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","slug":"enumerated-shimmying-starlight","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01HrWr5FpCruPryAjTv3EUWm","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01WN4RZEvmTRG6ScLdP8dafD","name":"Edit","input":{"replace_all":false,"file_path":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/plan/future-plans/2026-01-25-web-frontend-deployment.md","old_string":"**Edit:**\n```typescript\nexport const APP_CONFIG_DEFAULTS = {\n  // Branding\n  companyName: \"Your Company Name\", // Change this\n  pageTitle: \"AI Voice Assistant | Your Company\", // Change this\n\n  // Logo URLs\n  logoUrl: \"/logo.svg\", // Update after adding logo in 5.2\n  logoUrlDark: \"/logo-dark.svg\", // Optional: separate dark mode logo\n\n  // Accent color\n  accentColor: \"#4F46E5\", // Change to your brand color (hex)\n\n  // Feature toggles\n  supportsChatInput: true, // Allow text chat alongside voice\n  supportsVideoInput: true, // Enable camera video\n  supportsScreenShare: true, // Enable screen sharing\n  isPreConnectBufferEnabled: true, // Pre-load for faster connection\n\n  // Optional: Agent configuration\n  defaultAgentName: \"\", // Leave blank for auto-dispatch\n};\n```","new_string":"**Edit:**\n```typescript\nexport const APP_CONFIG_DEFAULTS = {\n  // Branding\n  companyName: \"Your Company Name\", // Change this\n  pageTitle: \"AI Voice Assistant | Your Company\", // Change this\n\n  // Logo URLs\n  logoUrl: \"/logo.svg\", // Update after adding logo in 5.2\n  logoUrlDark: \"/logo-dark.svg\", // Optional: separate dark mode logo\n\n  // Accent color\n  accentColor: \"#4F46E5\", // Change to your brand color (hex)\n\n  // Feature toggles - AUDIO-ONLY CONFIGURATION\n  supportsChatInput: false, // Disable text chat (audio-only)\n  supportsVideoInput: false, // DISABLE camera video (audio-only)\n  supportsScreenShare: false, // DISABLE screen sharing (audio-only)\n  isPreConnectBufferEnabled: true, // Pre-load for faster connection\n\n  // Optional: Agent configuration\n  defaultAgentName: \"\", // Leave blank for auto-dispatch\n};\n```"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":10,"cache_creation_input_tokens":560,"cache_read_input_tokens":65722,"cache_creation":{"ephemeral_5m_input_tokens":560,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXTt6pKNfbzhAvPj9aUHR","type":"assistant","uuid":"54cd2e3e-44bc-457d-87b9-cc3aef140fb3","timestamp":"2026-01-25T09:45:29.744Z"}
{"parentUuid":"54cd2e3e-44bc-457d-87b9-cc3aef140fb3","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","slug":"enumerated-shimmying-starlight","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01WN4RZEvmTRG6ScLdP8dafD","type":"tool_result","content":"The file /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/plan/future-plans/2026-01-25-web-frontend-deployment.md has been updated successfully."}]},"uuid":"31e19420-cfc2-4599-ade8-eea8fda0ed35","timestamp":"2026-01-25T09:45:29.783Z","toolUseResult":{"filePath":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/plan/future-plans/2026-01-25-web-frontend-deployment.md","oldString":"**Edit:**\n```typescript\nexport const APP_CONFIG_DEFAULTS = {\n  // Branding\n  companyName: \"Your Company Name\", // Change this\n  pageTitle: \"AI Voice Assistant | Your Company\", // Change this\n\n  // Logo URLs\n  logoUrl: \"/logo.svg\", // Update after adding logo in 5.2\n  logoUrlDark: \"/logo-dark.svg\", // Optional: separate dark mode logo\n\n  // Accent color\n  accentColor: \"#4F46E5\", // Change to your brand color (hex)\n\n  // Feature toggles\n  supportsChatInput: true, // Allow text chat alongside voice\n  supportsVideoInput: true, // Enable camera video\n  supportsScreenShare: true, // Enable screen sharing\n  isPreConnectBufferEnabled: true, // Pre-load for faster connection\n\n  // Optional: Agent configuration\n  defaultAgentName: \"\", // Leave blank for auto-dispatch\n};\n```","newString":"**Edit:**\n```typescript\nexport const APP_CONFIG_DEFAULTS = {\n  // Branding\n  companyName: \"Your Company Name\", // Change this\n  pageTitle: \"AI Voice Assistant | Your Company\", // Change this\n\n  // Logo URLs\n  logoUrl: \"/logo.svg\", // Update after adding logo in 5.2\n  logoUrlDark: \"/logo-dark.svg\", // Optional: separate dark mode logo\n\n  // Accent color\n  accentColor: \"#4F46E5\", // Change to your brand color (hex)\n\n  // Feature toggles - AUDIO-ONLY CONFIGURATION\n  supportsChatInput: false, // Disable text chat (audio-only)\n  supportsVideoInput: false, // DISABLE camera video (audio-only)\n  supportsScreenShare: false, // DISABLE screen sharing (audio-only)\n  isPreConnectBufferEnabled: true, // Pre-load for faster connection\n\n  // Optional: Agent configuration\n  defaultAgentName: \"\", // Leave blank for auto-dispatch\n};\n```","originalFile":"# Web Frontend Deployment Implementation Plan\n\n> **Status:** DRAFT\n\n## Table of Contents\n\n- [Overview](#overview)\n- [Current State Analysis](#current-state-analysis)\n- [Desired End State](#desired-end-state)\n- [What We're NOT Doing](#what-were-not-doing)\n- [Implementation Approach](#implementation-approach)\n- [Dependencies](#dependencies)\n- [Phase 1: Agent Deployment to LiveKit Cloud](#phase-1-agent-deployment-to-livekit-cloud)\n- [Phase 2: Frontend Setup (agent-starter-react)](#phase-2-frontend-setup-agent-starter-react)\n- [Phase 3: Authentication and Token Generation](#phase-3-authentication-and-token-generation)\n- [Phase 4: Connection Testing and Optimization](#phase-4-connection-testing-and-optimization)\n- [Phase 5: Frontend Customization](#phase-5-frontend-customization)\n- [Phase 6: Production Deployment](#phase-6-production-deployment)\n- [Testing Strategy](#testing-strategy)\n- [References](#references)\n\n## Overview\n\nThis plan enables potential clients to interact with the LiveKit voice AI agent from this repository by clicking a link on a website. The implementation covers:\n\n1. Deploying the Python agent to LiveKit Cloud\n2. Setting up a Next.js/React frontend using the agent-starter-react template\n3. Implementing JWT token-based authentication\n4. Testing the connection flow\n5. Customizing the frontend with branding\n6. Deploying the frontend to production (Vercel)\n\nThe solution uses LiveKit's official starter templates and SDKs to create a production-ready web application with TypeScript/JavaScript.\n\n**IMPORTANT: This is an audio-only application. No video camera or screen sharing permissions should be requested from users. All configuration must disable video/screenshare features.**\n\n## Current State Analysis\n\n### What Exists Now\n\n**Agent Backend:**\n- Python voice AI agent in `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1`\n- Built with LiveKit Agents SDK\n- Uses OpenAI (LLM), AssemblyAI (STT), Cartesia (TTS)\n- Configured with `uv` package manager\n- Has `Dockerfile` for containerized deployment\n- Environment variables in `.env.local` (OpenAI, AssemblyAI, Cartesia API keys)\n\n**Missing:**\n- Agent not yet deployed to LiveKit Cloud\n- No web frontend for client interaction\n- No token generation server for authentication\n- No public-facing URL for clients to access\n\n### Key Discoveries\n\nFrom `docs/DEPLOYMENT.md`:\n- LiveKit Cloud deployment uses `lk` CLI\n- Agent deployment command: `lk agent create --secrets-file .env.local`\n- Multiple frontend options available (React, Flutter, Swift, Embed)\n- Connection requires JWT tokens generated server-side\n- agent-starter-react provides production-ready Next.js template\n- Token generation uses `livekit-server-sdk` npm package\n\n### Constraints\n\n1. **Security:** API secrets (LIVEKIT_API_SECRET) must never be exposed to frontend\n2. **Architecture:** Token generation must happen server-side (Next.js API routes)\n3. **Dependencies:** Agent must be deployed and running before frontend can connect\n4. **Cost:** LiveKit Cloud charges $0.01 per agent session minute\n\n## Desired End State\n\n### Success Criteria\n\n- [ ] Agent deployed and running on LiveKit Cloud\n- [ ] Next.js frontend application running locally\n- [ ] JWT token generation working via backend API route\n- [ ] Users can click a link and connect to voice AI agent\n- [ ] Audio conversation works end-to-end (STT → LLM → TTS)\n- [ ] Frontend deployed to production URL (Vercel)\n- [ ] Customized branding (logo, colors, company name)\n- [ ] Light/dark theme support\n- [ ] Audio visualization working\n- [ ] Mobile-responsive design\n\n### How to Verify\n\n**Agent Deployment:**\n```bash\nlk agent status\n# Expected: Status: Running, Replicas: X/X ready\n```\n\n**Frontend Connection:**\n1. Visit frontend URL (local: http://localhost:3000, prod: https://your-app.vercel.app)\n2. Click \"Connect\" or \"Start Session\"\n3. Grant microphone permissions when prompted\n4. Speak to the agent\n5. Verify agent responds with natural voice\n6. Check agent logs: `lk agent logs --follow`\n\n**End-to-End Test:**\n```bash\n# Terminal 1: Monitor agent logs\nlk agent logs --follow\n\n# Terminal 2: Run frontend\ncd /path/to/frontend\npnpm dev\n\n# Browser: Visit http://localhost:3000, connect, and speak\n```\n\n## What We're NOT Doing\n\n**Out of Scope:**\n- Multiple agent types or agent selection UI\n- User authentication/login system (anonymous users only)\n- Database integration or conversation history storage\n- Multi-language support (English only initially)\n- iOS/Android native apps (web only)\n- Custom voice customization UI\n- Payment integration or usage metering\n- Advanced analytics dashboard\n- Server-side rendering (SSR) for the voice interface\n- Custom WebRTC infrastructure (using LiveKit Cloud)\n\n**Future Considerations:**\n- User accounts and saved conversations\n- Analytics and usage tracking\n- Custom domain with branding\n- A/B testing different agent configurations\n- Rate limiting and abuse prevention\n\n## Implementation Approach\n\n### High-Level Strategy\n\n1. **Deploy Agent First:** Ensure the Python agent is running on LiveKit Cloud before building frontend\n2. **Use Official Template:** Start with agent-starter-react to avoid reinventing the wheel\n3. **Iterative Testing:** Test each phase independently before proceeding\n4. **Security-First:** Never expose API secrets; use environment variables and server-side token generation\n5. **Quick Validation:** Use LiveKit Agents Playground first to verify agent works before building frontend\n\n### Technology Stack\n\n**Backend (Agent):**\n- Python 3.11+\n- LiveKit Agents SDK\n- OpenAI GPT-4 (LLM)\n- AssemblyAI (STT)\n- Cartesia (TTS)\n- Deployed to: LiveKit Cloud\n\n**Frontend:**\n- Next.js 14+ (App Router)\n- React 18+\n- TypeScript\n- Tailwind CSS\n- Shadcn/ui components\n- `livekit-client` SDK\n- `@livekit/components-react`\n- Deployed to: Vercel\n\n**Authentication:**\n- JWT tokens (livekit-server-sdk)\n- Server-side generation (Next.js API routes)\n- 2-hour token expiration\n\n## Dependencies\n\n**Execution Order:**\n\n1. Phase 1: Agent Deployment (no dependencies)\n2. Phase 2: Frontend Setup (depends on Phase 1 for credentials)\n3. Phase 3: Authentication (depends on Phase 2)\n4. Phase 4: Connection Testing (depends on Phases 1-3)\n5. Phase 5: Frontend Customization (depends on Phase 4)\n6. Phase 6: Production Deployment (depends on Phase 5)\n\n**Dependency Graph:**\n\n```\nPhase 1 (Agent Deployment)\n  └─> Phase 2 (Frontend Setup)\n        └─> Phase 3 (Authentication)\n              └─> Phase 4 (Testing)\n                    └─> Phase 5 (Customization)\n                          └─> Phase 6 (Production)\n```\n\n**Parallelization:**\n- All phases are sequential due to dependencies\n- Within each phase, independent tasks can run in parallel\n\n---\n\n## Phase 1: Agent Deployment to LiveKit Cloud\n\n### Overview\n\nDeploy the Python voice AI agent to LiveKit Cloud to make it accessible via WebRTC. This creates a running agent that can be dispatched to rooms when users connect.\n\n### Context\n\nBefore starting, ensure you have:\n- LiveKit CLI installed: `brew install livekit/livekit/livekit-cli`\n- LiveKit Cloud account at https://cloud.livekit.io\n- Agent code in `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1`\n- API keys in `.env.local` (OpenAI, AssemblyAI, Cartesia)\n\nFiles to review:\n- `docs/DEPLOYMENT.md` - Complete deployment guide\n- `.env.local` - API keys and secrets\n- `Dockerfile` - Container build configuration\n- `src/app.py` - Agent entry point\n\n### Dependencies\n\n**Depends on:** None (first phase)\n\n**Required by:** Phase 2 (Frontend needs LiveKit credentials), Phase 4 (Testing needs deployed agent)\n\n### Changes Required\n\n#### 1.1: Authenticate with LiveKit Cloud\n\n**What:** Link your CLI to your LiveKit Cloud account\n\n**Command:**\n```bash\nlk cloud auth\n```\n\n**Expected Outcome:**\n- Browser opens for authentication\n- CLI displays: \"Successfully authenticated with LiveKit Cloud\"\n- Credentials saved in `~/.livekit/credentials`\n\n**Rationale:** Required for all subsequent `lk` CLI commands\n\n---\n\n#### 1.2: Create or Select LiveKit Project\n\n**What:** Create a new project or select an existing one for the agent deployment\n\n**Commands:**\n```bash\n# List existing projects\nlk project list\n\n# Option A: Use existing project\nlk project set-default \"your-project-name\"\n\n# Option B: Create new project via dashboard\n# Visit https://cloud.livekit.io and create a new project\n# Then set as default: lk project set-default \"new-project-name\"\n\n# Verify current project\nlk project current\n```\n\n**Expected Outcome:**\n```\nNAME                 PROJECT_ID\nyour-project-name   prj_abc123\n```\n\n**Rationale:** Agent deployments are scoped to projects; need a target project first\n\n---\n\n#### 1.3: Verify Secrets File\n\n**What:** Ensure `.env.local` contains all required API keys\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/.env.local`\n\n**Verify contents:**\n```bash\ncat .env.local\n```\n\n**Required secrets:**\n```env\nOPENAI_API_KEY=sk-...\nASSEMBLYAI_API_KEY=...\nCARTESIA_API_KEY=...\n```\n\n**Important Notes:**\n- Do NOT include `LIVEKIT_URL`, `LIVEKIT_API_KEY`, or `LIVEKIT_API_SECRET` in `.env.local`\n- LiveKit Cloud auto-injects these during deployment\n- Verify `.env.local` is in `.gitignore`\n\n**Rationale:** Agent needs these API keys to function; LiveKit Cloud encrypts and injects them as environment variables\n\n---\n\n#### 1.4: Download Model Files\n\n**What:** Download required models (Silero VAD, turn detector) before deployment\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\nuv run python src/app.py download-files\n```\n\n**Expected Outcome:**\n```\nDownloading Silero VAD model...\nDownloading multilingual turn detector model...\nDownload complete.\n```\n\n**Rationale:** Models are required at runtime; downloading during build ensures faster agent startup\n\n---\n\n#### 1.5: Deploy Agent to LiveKit Cloud\n\n**What:** Create and deploy the agent container to LiveKit Cloud\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\nlk agent create --secrets-file .env.local\n```\n\n**Expected Outcome:**\n```\nRegistering agent...\nAgent ID: agent_abc123\nBuilding container image...\nUploading code...\nBuild in progress (this may take 2-5 minutes)...\nBuild complete.\nDeploying agent...\nDeployment successful.\nStatus: Running\nReplicas: 2/2 ready\n```\n\n**What Happens:**\n1. CLI registers new agent with Cloud project\n2. Assigns unique agent ID (e.g., `agent_abc123`)\n3. Creates/updates `livekit.toml` configuration file\n4. Uploads source code to LiveKit build service\n5. Builds Docker container from `Dockerfile`\n6. Deploys container to Cloud project\n7. Encrypts and injects secrets as environment variables\n8. Starts 2 replica instances\n\n**Duration:** 2-5 minutes for initial build\n\n**Rationale:** Makes agent accessible via LiveKit's global WebRTC infrastructure\n\n---\n\n#### 1.6: Verify Agent Status\n\n**What:** Confirm agent is running and ready to accept sessions\n\n**Commands:**\n```bash\n# Check agent status\nlk agent status\n\n# View live logs\nlk agent logs --tail 50\n```\n\n**Expected Status Output:**\n```\nAgent ID:     agent_abc123\nStatus:       Running\nReplicas:     2/2 ready\nVersion:      v1\nLast Deploy:  2026-01-25 10:30:00 UTC\nRegion:       us-west-2\n```\n\n**Expected Log Output:**\n- No error messages\n- Successful initialization messages\n- \"Waiting for room assignment\" or similar\n\n**Troubleshooting:**\n- If status is `CrashLoop`: Check logs for Python exceptions\n- If status is `Build Failed`: Run `lk agent logs --build` to see build errors\n- If secrets missing: Run `lk agent secrets` to verify\n\n**Rationale:** Ensures agent is healthy before proceeding to frontend setup\n\n---\n\n#### 1.7: Quick Test with Agents Playground\n\n**What:** Test agent using LiveKit Agents Playground (no code required)\n\n**Steps:**\n1. Get project credentials:\n   ```bash\n   lk project current --json\n   ```\n\n2. Visit https://agents-playground.livekit.io/\n\n3. Enter credentials:\n   - **LiveKit URL:** `wss://your-project.livekit.cloud` (from JSON output)\n   - **API Key:** Your `LIVEKIT_API_KEY` (from JSON output)\n   - **API Secret:** Your `LIVEKIT_API_SECRET` (from JSON output)\n\n4. Click \"Connect\"\n\n5. Allow microphone access when prompted\n\n6. Speak to your agent\n\n7. Monitor agent logs in terminal:\n   ```bash\n   lk agent logs --follow\n   ```\n\n**Expected Outcome:**\n- Agent responds to your voice with natural TTS\n- Logs show STT transcriptions, LLM responses, TTS generation\n- No errors in logs\n\n**Rationale:** Validates agent works end-to-end before investing in frontend development\n\n---\n\n#### 1.8: Save LiveKit Credentials\n\n**What:** Export LiveKit project credentials for frontend configuration\n\n**Command:**\n```bash\nlk project current --json > livekit-credentials.json\n```\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/livekit-credentials.json`\n\n**Expected Contents:**\n```json\n{\n  \"name\": \"your-project-name\",\n  \"url\": \"wss://your-project.livekit.cloud\",\n  \"api_key\": \"APIxxxxxxxxxxxx\",\n  \"api_secret\": \"your-secret-here\"\n}\n```\n\n**Security Note:**\n- Add `livekit-credentials.json` to `.gitignore`\n- NEVER commit this file to version control\n- This file is for local reference only\n\n**Rationale:** Frontend needs these credentials to generate tokens and connect to LiveKit\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] CLI authenticated: `lk cloud auth` successful\n- [ ] Project selected: `lk project current` shows correct project\n- [ ] Agent deployed: `lk agent status` shows `Status: Running`\n- [ ] Replicas ready: `lk agent status` shows `X/X ready` (e.g., 2/2)\n- [ ] No crash loops: `lk agent logs --tail 50` shows no errors\n- [ ] Credentials saved: `livekit-credentials.json` exists and contains valid JSON\n\n#### Manual Verification:\n\n- [ ] Agents Playground connection successful\n- [ ] Agent responds to voice input with TTS output\n- [ ] Agent logs show successful STT → LLM → TTS pipeline\n- [ ] No API key errors in logs\n- [ ] Agent state transitions visible (initializing → listening → thinking → speaking)\n\n**Verify:** After completing automated verification, test agent with Agents Playground before proceeding to Phase 2.\n\n---\n\n## Phase 2: Frontend Setup (agent-starter-react)\n\n### Overview\n\nClone and configure the agent-starter-react template to create a Next.js web application that connects users to your deployed agent.\n\n### Context\n\nBefore starting, ensure:\n- Phase 1 completed successfully\n- Agent is running on LiveKit Cloud\n- `livekit-credentials.json` file exists with credentials\n\nPrerequisites:\n- Node.js 18+ installed\n- pnpm installed: `npm install -g pnpm`\n- `lk` CLI authenticated\n\nFiles to review:\n- `livekit-credentials.json` - LiveKit project credentials\n- N/A (frontend doesn't exist yet)\n\n### Dependencies\n\n**Depends on:** Phase 1 (needs LiveKit credentials)\n\n**Required by:** Phase 3 (authentication setup), Phase 4 (connection testing)\n\n### Changes Required\n\n#### 2.1: Create Frontend Project Directory\n\n**What:** Create a directory to house the frontend application\n\n**Commands:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\nmkdir -p frontend\ncd frontend\n```\n\n**Expected Outcome:**\n```\nDirectory created: /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/\n```\n\n**Rationale:** Separates frontend code from agent backend code\n\n---\n\n#### 2.2: Clone agent-starter-react Template\n\n**What:** Use LiveKit CLI to create a new project from the official template\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend\nlk app create --template agent-starter-react\n```\n\n**Interactive Prompts:**\n- **Project name:** (Press Enter for default or enter custom name like \"voice-ai-frontend\")\n- **Install dependencies?** Yes\n\n**Alternative (Manual Clone):**\n```bash\ngit clone https://github.com/livekit-examples/agent-starter-react.git voice-ai-frontend\ncd voice-ai-frontend\npnpm install\n```\n\n**Expected Outcome:**\n```\n✓ Created project: voice-ai-frontend\n✓ Installed dependencies\n✓ Ready to configure\n```\n\n**Directory Structure:**\n```\nfrontend/voice-ai-frontend/\n├── app/\n│   ├── api/token/route.ts     # Token generation endpoint\n│   ├── page.tsx               # Main page\n│   └── layout.tsx\n├── components/\n│   ├── agents-ui/             # Agents UI components\n│   ├── app/                   # Business logic\n│   └── ui/                    # Shadcn/ui primitives\n├── hooks/\n├── lib/\n├── public/\n├── package.json\n├── .env.example\n└── next.config.js\n```\n\n**Rationale:** Official template provides production-ready structure with all necessary LiveKit integrations\n\n---\n\n#### 2.3: Configure Environment Variables\n\n**What:** Set up LiveKit credentials for the frontend\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend/.env.local`\n\n**Commands:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\ncp .env.example .env.local\n```\n\n**Edit `.env.local`:**\n```env\n# LiveKit project credentials (from livekit-credentials.json)\nLIVEKIT_API_KEY=APIxxxxxxxxxxxx\nLIVEKIT_API_SECRET=your-secret-here\nLIVEKIT_URL=wss://your-project.livekit.cloud\n\n# Public URL (exposed to browser - same as LIVEKIT_URL)\nNEXT_PUBLIC_LIVEKIT_URL=wss://your-project.livekit.cloud\n\n# Agent configuration\nAGENT_NAME=\n# Leave AGENT_NAME blank for automatic agent dispatch\n# Or set to specific agent name if you have multiple agents\n```\n\n**How to Get Values:**\n```bash\n# Copy from livekit-credentials.json\ncat /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/livekit-credentials.json\n```\n\n**Security Notes:**\n- `LIVEKIT_API_SECRET` is server-side only (never exposed to browser)\n- `NEXT_PUBLIC_*` variables are exposed to browser\n- Only `NEXT_PUBLIC_LIVEKIT_URL` should be public\n- Never expose `LIVEKIT_API_KEY` or `LIVEKIT_API_SECRET` to browser\n\n**Rationale:** Frontend needs credentials to generate tokens and connect to LiveKit rooms\n\n---\n\n#### 2.4: Verify Dependencies Installation\n\n**What:** Ensure all npm packages are installed correctly\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\npnpm install\n```\n\n**Expected Outcome:**\n```\nPackages: +XXX\nProgress: resolved XXX, reused XXX, downloaded X, added XXX, done\n```\n\n**Key Dependencies (verify in `package.json`):**\n- `next` (v14+)\n- `react` (v18+)\n- `livekit-client`\n- `@livekit/components-react`\n- `livekit-server-sdk`\n- `tailwindcss`\n- `typescript`\n\n**Troubleshooting:**\n- If pnpm not installed: `npm install -g pnpm`\n- If peer dependency warnings: Generally safe to ignore\n- If install fails: Delete `node_modules` and `pnpm-lock.yaml`, retry\n\n**Rationale:** Ensures all required packages are available for development\n\n---\n\n#### 2.5: Run Development Server\n\n**What:** Start the Next.js development server to verify basic setup\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\npnpm dev\n```\n\n**Expected Outcome:**\n```\n> next dev\n\n  ▲ Next.js 14.x.x\n  - Local:        http://localhost:3000\n  - Environments: .env.local\n\n ✓ Ready in X.Xs\n```\n\n**Verification:**\n1. Open browser to http://localhost:3000\n2. Should see agent interface with \"Connect\" button\n3. No console errors in browser DevTools\n4. Page loads without 500 errors\n\n**Expected UI:**\n- Welcome/landing view\n- \"Connect\" or \"Start Session\" button\n- Logo and branding elements\n- Theme toggle (light/dark)\n\n**Troubleshooting:**\n- If port 3000 in use: `pnpm dev -- -p 3001`\n- If env vars missing: Check `.env.local` exists and has correct values\n- If build errors: Check `pnpm install` completed successfully\n\n**Rationale:** Validates Next.js setup before proceeding to authentication\n\n---\n\n#### 2.6: Inspect Token Generation API Route\n\n**What:** Review the built-in token generation endpoint to understand how authentication works\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend/app/api/token/route.ts`\n\n**Read the file:**\n```typescript\n// Expected structure (review actual implementation)\nimport { AccessToken } from 'livekit-server-sdk';\n\nexport async function POST(request: Request) {\n  const { roomName, participantName } = await request.json();\n\n  const token = new AccessToken(\n    process.env.LIVEKIT_API_KEY,\n    process.env.LIVEKIT_API_SECRET,\n    {\n      identity: participantName,\n      ttl: '2h', // Token valid for 2 hours\n    }\n  );\n\n  token.addGrant({\n    room: roomName,\n    roomJoin: true,\n    canPublish: true,\n    canSubscribe: true,\n  });\n\n  return Response.json({ token: await token.toJwt() });\n}\n```\n\n**Key Points:**\n- Uses `livekit-server-sdk` to generate JWT tokens\n- Reads `LIVEKIT_API_KEY` and `LIVEKIT_API_SECRET` from environment\n- Grants room join, publish, and subscribe permissions\n- Returns JWT token to frontend\n- Token expires after 2 hours (LiveKit auto-refreshes for connected clients)\n\n**Security Review:**\n- ✓ API key/secret are server-side only (not exposed to browser)\n- ✓ Token generation happens on server\n- ✓ Appropriate permissions granted\n- ⚠ Consider adding rate limiting for production\n\n**Rationale:** Understanding token flow is critical for debugging connection issues\n\n---\n\n#### 2.7: Add Frontend to .gitignore (Backend Repo)\n\n**What:** Prevent frontend from being committed to agent backend repo\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/.gitignore`\n\n**Add to `.gitignore`:**\n```bash\necho \"frontend/\" >> .gitignore\n```\n\n**Verify:**\n```bash\ngit status\n# frontend/ should not appear in untracked files\n```\n\n**Alternative Approach:**\nIf you want to commit the frontend to the same repo:\n- Create a separate `.gitignore` in `frontend/voice-ai-frontend/`\n- Add standard Next.js ignores (`.next/`, `node_modules/`, `.env.local`)\n\n**Rationale:** Keep frontend and backend as separate concerns, or manage carefully if in same repo\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Frontend directory created: `ls frontend/voice-ai-frontend`\n- [ ] Dependencies installed: `pnpm list --depth=0` shows key packages\n- [ ] Environment variables configured: `cat .env.local | grep LIVEKIT_API_KEY`\n- [ ] Development server starts: `pnpm dev` runs without errors\n- [ ] No TypeScript errors: `pnpm run build` completes successfully\n\n#### Manual Verification:\n\n- [ ] Visit http://localhost:3000 in browser\n- [ ] Page loads without 500 errors\n- [ ] UI displays welcome screen with \"Connect\" button\n- [ ] No console errors in browser DevTools\n- [ ] Theme toggle works (light/dark mode)\n- [ ] Responsive design works on mobile viewport\n\n**Verify:** After completing automated verification, open the app in a browser and verify UI loads correctly before proceeding to Phase 3.\n\n---\n\n## Phase 3: Authentication and Token Generation\n\n### Overview\n\nConfigure and test the JWT token generation flow to ensure frontend can authenticate users with LiveKit and connect them to agent sessions.\n\n### Context\n\nBefore starting, ensure:\n- Phase 2 completed successfully\n- Development server running at http://localhost:3000\n- Environment variables configured in `.env.local`\n\nFiles to review:\n- `frontend/voice-ai-frontend/app/api/token/route.ts` - Token generation endpoint\n- `frontend/voice-ai-frontend/.env.local` - Environment configuration\n- `frontend/voice-ai-frontend/components/app/` - Client-side connection logic\n\n### Dependencies\n\n**Depends on:** Phase 2 (frontend setup)\n\n**Required by:** Phase 4 (connection testing)\n\n### Changes Required\n\n#### 3.1: Test Token Generation Endpoint\n\n**What:** Verify the token API endpoint works correctly\n\n**Command:**\n```bash\n# Start dev server (if not running)\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\npnpm dev\n\n# In another terminal, test the endpoint\ncurl -X POST http://localhost:3000/api/token \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"roomName\": \"test-room\", \"participantName\": \"test-user\"}'\n```\n\n**Expected Response:**\n```json\n{\n  \"token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\"\n}\n```\n\n**Validate Token:**\n```bash\n# Decode the JWT to inspect claims (copy token from response)\necho \"eyJhbGciOiJ...\" | cut -d'.' -f2 | base64 -d | jq\n```\n\n**Expected Token Payload:**\n```json\n{\n  \"exp\": 1234567890,\n  \"iss\": \"APIxxxxxxxxxxxx\",\n  \"sub\": \"test-user\",\n  \"nbf\": 1234567890,\n  \"video\": {\n    \"room\": \"test-room\",\n    \"roomJoin\": true,\n    \"canPublish\": true,\n    \"canSubscribe\": true,\n    \"canPublishData\": true\n  }\n}\n```\n\n**Troubleshooting:**\n- If 500 error: Check environment variables in `.env.local`\n- If \"api_key undefined\": Verify `LIVEKIT_API_KEY` is set\n- If \"invalid signature\": Check `LIVEKIT_API_SECRET` is correct\n- If no response: Verify dev server is running on port 3000\n\n**Rationale:** Token generation must work before attempting to connect to LiveKit\n\n---\n\n#### 3.2: Review Client-Side Connection Logic\n\n**What:** Understand how the frontend connects to LiveKit rooms\n\n**Files to Review:**\n```bash\n# Main session component\ncat frontend/voice-ai-frontend/components/app/session-view.tsx\n\n# View controller\ncat frontend/voice-ai-frontend/components/app/view-controller.tsx\n\n# Connection utilities\ncat frontend/voice-ai-frontend/lib/connection.ts\n```\n\n**Key Flow:**\n1. User clicks \"Connect\" button\n2. Frontend generates room name (random or predefined)\n3. Frontend fetches token from `/api/token` endpoint\n4. Frontend connects to LiveKit room using `livekit-client`\n5. Agent is automatically dispatched to room\n6. User and agent establish WebRTC connection\n7. Audio tracks are exchanged\n\n**Important Variables:**\n- `NEXT_PUBLIC_LIVEKIT_URL` - LiveKit server URL (browser-accessible)\n- Room name generation logic\n- Participant name/identity\n- Agent dispatch configuration\n\n**Rationale:** Understanding client-side logic helps debug connection issues\n\n---\n\n#### 3.3: Configure Agent Dispatch\n\n**What:** Ensure frontend triggers automatic agent dispatch when users connect\n\n**File:** Review `frontend/voice-ai-frontend/app/api/connection-details/route.ts` (if exists) or equivalent\n\n**Verify Agent Name Configuration:**\n\n**Option A: Automatic Dispatch (Recommended):**\n```env\n# In .env.local\nAGENT_NAME=\n# Blank means \"dispatch any available agent\"\n```\n\n**Option B: Specific Agent:**\n```env\n# In .env.local\nAGENT_NAME=agent_abc123\n# Uses specific agent by ID or name\n```\n\n**Check Token Grant Configuration:**\n```typescript\n// In app/api/token/route.ts or connection-details/route.ts\ntoken.addGrant({\n  room: roomName,\n  roomJoin: true,\n  canPublish: true,\n  canSubscribe: true,\n  // Optional: Agent dispatch configuration\n});\n```\n\n**For agent-starter-react:**\nThe template typically handles agent dispatch automatically when a participant joins a room. Verify this by checking the token generation code and connection details endpoint.\n\n**Rationale:** Agent won't join room unless dispatch is configured correctly\n\n---\n\n#### 3.4: Test Token Expiration and Refresh\n\n**What:** Verify token expiration is set correctly and LiveKit handles refresh\n\n**Check Current TTL:**\n```typescript\n// In app/api/token/route.ts\nconst token = new AccessToken(\n  process.env.LIVEKIT_API_KEY,\n  process.env.LIVEKIT_API_SECRET,\n  {\n    identity: participantName,\n    ttl: '2h', // Current setting\n  }\n);\n```\n\n**Recommended TTL:**\n- Development: `2h` (2 hours)\n- Production: `2h` (LiveKit auto-refreshes for connected clients)\n- Pre-generated tokens: `1h` (if caching tokens)\n\n**Token Refresh Behavior:**\n- LiveKit client SDK automatically refreshes tokens before expiration\n- Refresh happens for connected clients only\n- Disconnected users must request new tokens\n\n**No changes needed if TTL is already `2h`.**\n\n**Rationale:** Prevents users from being disconnected due to token expiration\n\n---\n\n#### 3.5: Add Security Headers (Optional but Recommended)\n\n**What:** Add security headers to token API route\n\n**File:** `frontend/voice-ai-frontend/middleware.ts` (create if doesn't exist)\n\n**Content:**\n```typescript\nimport { NextResponse } from 'next/server';\nimport type { NextRequest } from 'next/server';\n\nexport function middleware(request: NextRequest) {\n  const response = NextResponse.next();\n\n  // Security headers\n  response.headers.set('X-Content-Type-Options', 'nosniff');\n  response.headers.set('X-Frame-Options', 'DENY');\n  response.headers.set('X-XSS-Protection', '1; mode=block');\n\n  return response;\n}\n\nexport const config = {\n  matcher: '/api/:path*',\n};\n```\n\n**Optional Rate Limiting:**\nConsider adding rate limiting to `/api/token` endpoint to prevent abuse.\n\n**Rationale:** Basic security hardening for production deployments\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Token endpoint returns valid JWT: `curl -X POST http://localhost:3000/api/token -H \"Content-Type: application/json\" -d '{\"roomName\":\"test\",\"participantName\":\"user\"}' | jq .token`\n- [ ] Token payload contains correct claims: Decode JWT and verify `video.roomJoin: true`\n- [ ] Environment variables loaded: `console.log(process.env.LIVEKIT_API_KEY)` in token route shows value (not undefined)\n- [ ] Token has correct expiration: Decoded JWT shows `exp` timestamp 2 hours in future\n\n#### Manual Verification:\n\n- [ ] Token endpoint accessible via browser: Visit http://localhost:3000/api/token (should return 405 Method Not Allowed for GET)\n- [ ] No errors in Next.js server logs when generating tokens\n- [ ] Token decodes successfully at https://jwt.io\n- [ ] Token issuer (`iss`) matches your LiveKit API key\n- [ ] Token subject (`sub`) matches requested participant name\n\n**Verify:** After completing automated verification, test token generation with curl and decode the JWT to inspect claims before proceeding to Phase 4.\n\n---\n\n## Phase 4: Connection Testing and Optimization\n\n### Overview\n\nTest the end-to-end connection flow from frontend to agent, verify audio works correctly, and optimize the connection speed.\n\n### Context\n\nBefore starting, ensure:\n- Phase 3 completed successfully\n- Agent running on LiveKit Cloud (`lk agent status` shows Running)\n- Frontend running at http://localhost:3000\n- Token generation working\n\nFiles to review:\n- `frontend/voice-ai-frontend/components/app/session-view.tsx` - Session management\n- `frontend/voice-ai-frontend/components/agents-ui/` - UI components\n\nTools needed:\n- Browser with microphone access\n- Terminal for monitoring agent logs\n\n### Dependencies\n\n**Depends on:** Phases 1-3 (agent deployed, frontend configured, authentication working)\n\n**Required by:** Phase 5 (customization), Phase 6 (production deployment)\n\n### Changes Required\n\n#### 4.1: Monitor Agent Logs\n\n**What:** Start monitoring agent logs before testing connection\n\n**Command:**\n```bash\n# Open a dedicated terminal window for agent logs\nlk agent logs --follow\n```\n\n**Keep this terminal open during all testing.**\n\n**What to Look For:**\n- Agent initialization messages\n- Room join events\n- STT transcriptions\n- LLM requests/responses\n- TTS generation\n- WebRTC connection events\n- Any error messages\n\n**Rationale:** Real-time logs are essential for debugging connection issues\n\n---\n\n#### 4.2: Test Basic Connection Flow\n\n**What:** Connect to the agent via frontend and verify basic functionality\n\n**Steps:**\n\n1. Open browser to http://localhost:3000\n2. Open browser DevTools Console (F12 → Console tab)\n3. Click \"Connect\" or \"Start Session\" button\n4. Grant microphone permissions when prompted\n5. Observe connection states in UI:\n   - \"Initializing...\"\n   - \"Listening\" (agent ready for input)\n   - \"Thinking\" (processing speech)\n   - \"Speaking\" (agent responding)\n\n**Expected Behavior:**\n- Connection establishes within 3-5 seconds\n- Agent state transitions to \"Listening\"\n- No errors in browser console\n- Agent logs show room join event\n\n**Troubleshooting:**\n- **Connection hangs:** Check token endpoint, verify LIVEKIT_URL is correct\n- **\"Failed to connect\":** Check agent status (`lk agent status`), verify agent is Running\n- **Microphone permission denied:** Grant permission in browser settings\n- **No audio:** Check browser audio output, verify speakers are enabled\n- **WebRTC errors:** Check firewall, ensure WebRTC ports not blocked\n\n**Rationale:** Validates basic connection before testing voice interaction\n\n---\n\n#### 4.3: Test Voice Interaction\n\n**What:** Verify end-to-end voice pipeline (STT → LLM → TTS)\n\n**Steps:**\n\n1. With frontend connected and agent in \"Listening\" state\n2. Speak clearly into your microphone: \"Hello, can you hear me?\"\n3. Observe agent state transition:\n   - \"Listening\" → \"Thinking\" → \"Speaking\"\n4. Listen for agent's voice response\n5. Check agent logs for:\n   - STT transcription of your speech\n   - LLM request and response\n   - TTS generation\n\n**Expected Outcome:**\n- Agent responds with natural voice within 2-4 seconds\n- Transcription appears in logs (if logging enabled)\n- No audio dropouts or distortion\n- Agent response is contextually appropriate\n\n**Additional Test Cases:**\n- **Interruption:** Speak while agent is speaking (should handle gracefully)\n- **Silence:** Wait 10 seconds without speaking (agent should remain connected)\n- **Background Noise:** Test with ambient noise (should filter with VAD)\n- **Multiple Turns:** Have a multi-turn conversation\n\n**Troubleshooting:**\n- **No transcription:** Check AssemblyAI API key in agent secrets\n- **No LLM response:** Check OpenAI API key, verify LLM model is available\n- **No TTS audio:** Check Cartesia API key, verify TTS voice model\n- **Garbled audio:** Check network connection, reduce network congestion\n- **High latency:** Check agent logs for slow API calls, consider region optimization\n\n**Rationale:** Validates the complete voice AI pipeline works end-to-end\n\n---\n\n#### 4.4: Verify Audio Visualization\n\n**What:** Test the audio visualizer component works correctly\n\n**Steps:**\n\n1. With frontend connected\n2. Speak into microphone\n3. Observe audio visualization:\n   - Bars should animate when you speak\n   - Bars should pulse when agent speaks\n   - Different colors/states for listening vs speaking\n\n**Expected Behavior:**\n- `BarVisualizer` component shows real-time audio levels\n- Smooth animations\n- Clear visual feedback of agent state\n- No lag between audio and visualization\n\n**Check Component:**\n```bash\n# Review visualizer component\ncat frontend/voice-ai-frontend/components/agents-ui/bar-visualizer.tsx\n```\n\n**Troubleshooting:**\n- **No visualization:** Check if audio track is being passed to component\n- **Choppy animation:** Check browser performance, reduce animation complexity\n- **Wrong colors:** Review CSS/Tailwind classes\n\n**Rationale:** Visual feedback improves user experience and debugging\n\n---\n\n#### 4.5: Test Disconnection and Reconnection\n\n**What:** Verify graceful disconnect and ability to reconnect\n\n**Steps:**\n\n**Test Disconnect:**\n1. With frontend connected\n2. Click \"Disconnect\" or \"End Session\" button\n3. Observe clean disconnect:\n   - Agent logs show participant left\n   - No error messages\n   - UI returns to welcome screen\n\n**Test Reconnect:**\n1. Click \"Connect\" again\n2. Verify new session starts successfully\n3. Test voice interaction again\n\n**Test Network Interruption (Optional):**\n1. While connected, disable network (Wi-Fi off)\n2. Observe reconnection behavior\n3. Re-enable network\n4. Verify auto-reconnect or error message\n\n**Expected Behavior:**\n- Clean disconnect without errors\n- Ability to reconnect immediately\n- Each session gets unique room/token\n- No lingering WebRTC connections\n\n**Rationale:** Ensures robust connection lifecycle management\n\n---\n\n#### 4.6: Optimize Connection Speed\n\n**What:** Reduce connection time from 3-5 seconds to <1 second using optimization techniques\n\n**Current Flow (Sequential):**\n```\n1. Click Connect (0ms)\n2. Fetch token from /api/token (500ms)\n3. Connect to LiveKit room (1000ms)\n4. Agent dispatched (1000ms)\n5. Agent connects and publishes (1500ms)\nTotal: ~4000ms (4 seconds)\n```\n\n**Optimization 1: Pre-generate Tokens**\n\nCreate a \"warm token\" approach for faster connection:\n\n**File:** Create `frontend/voice-ai-frontend/hooks/use-warm-token.ts`\n\n```typescript\n'use client';\n\nimport { useState, useEffect } from 'react';\n\nexport function useWarmToken() {\n  const [token, setToken] = useState<string | null>(null);\n\n  useEffect(() => {\n    // Pre-generate token on page load\n    async function generateToken() {\n      const response = await fetch('/api/token', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          roomName: `room-${Date.now()}`,\n          participantName: `user-${Math.random().toString(36).substring(7)}`,\n        }),\n      });\n      const data = await response.json();\n      setToken(data.token);\n    }\n\n    generateToken();\n  }, []);\n\n  return token;\n}\n```\n\n**Usage in Session Component:**\n```typescript\n// In session-view.tsx or similar\nconst warmToken = useWarmToken();\n\n// Use warmToken when connecting instead of fetching on-demand\n```\n\n**Optimization 2: Concurrent Dispatch**\n\nModify connection logic to dispatch agent and connect user simultaneously:\n\n```typescript\n// Parallel connection\nconst [roomConnection, agentDispatch] = await Promise.all([\n  connectToRoom(token),\n  dispatchAgent(roomName) // If manual dispatch required\n]);\n```\n\n**Expected Improvement:**\n- Pre-generated token: -500ms (eliminates token fetch delay)\n- Concurrent dispatch: -1000ms (parallel instead of sequential)\n- **New total:** ~2500ms → ~1500ms (1.5 seconds)\n\n**Trade-offs:**\n- Pre-generated tokens have expiration (ensure 2h TTL)\n- Unused tokens waste resources (minimal cost)\n- Complexity slightly increases\n\n**Rationale:** Faster connections improve user experience and perceived performance\n\n---\n\n#### 4.7: Test on Multiple Browsers\n\n**What:** Verify cross-browser compatibility\n\n**Browsers to Test:**\n- Chrome/Chromium\n- Firefox\n- Safari (macOS/iOS)\n- Edge\n\n**Test Matrix:**\n\n| Browser | Connection | Audio Input | Audio Output | Visualization |\n|---------|-----------|-------------|--------------|---------------|\n| Chrome  | ✓         | ✓           | ✓            | ✓             |\n| Firefox | ?         | ?           | ?            | ?             |\n| Safari  | ?         | ?           | ?            | ?             |\n| Edge    | ?         | ?           | ?            | ?             |\n\n**Common Issues:**\n- **Safari:** May require user interaction before audio playback\n- **Firefox:** Different WebRTC implementation, may have quirks\n- **Mobile Safari:** Requires specific audio context handling\n- **Edge:** Generally compatible with Chrome\n\n**Rationale:** Ensures wide browser support for production deployment\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Connection establishes successfully: Monitor for \"Room connected\" event in logs\n- [ ] Agent joins room: `lk agent logs` shows room join event\n- [ ] WebRTC connection: Browser DevTools Network tab shows WebRTC connections\n- [ ] No console errors: Browser DevTools Console shows no red errors\n- [ ] Audio tracks published: Check LiveKit Cloud dashboard for active tracks\n\n#### Manual Verification:\n\n- [ ] Voice input recognized: Speak and verify agent responds\n- [ ] Voice output works: Hear agent's TTS response clearly\n- [ ] Audio visualization animates correctly\n- [ ] Agent state transitions work (initializing → listening → thinking → speaking)\n- [ ] Interruption handling works (speak during agent response)\n- [ ] Disconnect and reconnect works cleanly\n- [ ] Connection time <3 seconds (before optimization) or <1.5s (after optimization)\n- [ ] Works in Chrome, Firefox, and Safari\n\n**Verify:** After completing automated verification, have a multi-turn conversation with the agent and test all edge cases before proceeding to Phase 5.\n\n---\n\n## Phase 5: Frontend Customization\n\n### Overview\n\nCustomize the frontend with your branding, colors, logo, and company information to make it production-ready.\n\n### Context\n\nBefore starting, ensure:\n- Phase 4 completed successfully\n- Voice interaction working end-to-end\n- Frontend running at http://localhost:3000\n\nFiles to customize:\n- `frontend/voice-ai-frontend/app-config.ts` - Main configuration\n- `frontend/voice-ai-frontend/public/` - Static assets (logo, favicon)\n- `frontend/voice-ai-frontend/app/layout.tsx` - Page metadata\n- `frontend/voice-ai-frontend/tailwind.config.ts` - Theme colors\n\n### Dependencies\n\n**Depends on:** Phase 4 (connection testing completed)\n\n**Required by:** Phase 6 (production deployment)\n\n### Changes Required\n\n#### 5.1: Update App Configuration\n\n**What:** Customize company name, page title, and feature flags\n\n**File:** `frontend/voice-ai-frontend/app-config.ts`\n\n**Edit:**\n```typescript\nexport const APP_CONFIG_DEFAULTS = {\n  // Branding\n  companyName: \"Your Company Name\", // Change this\n  pageTitle: \"AI Voice Assistant | Your Company\", // Change this\n\n  // Logo URLs\n  logoUrl: \"/logo.svg\", // Update after adding logo in 5.2\n  logoUrlDark: \"/logo-dark.svg\", // Optional: separate dark mode logo\n\n  // Accent color\n  accentColor: \"#4F46E5\", // Change to your brand color (hex)\n\n  // Feature toggles\n  supportsChatInput: true, // Allow text chat alongside voice\n  supportsVideoInput: true, // Enable camera video\n  supportsScreenShare: true, // Enable screen sharing\n  isPreConnectBufferEnabled: true, // Pre-load for faster connection\n\n  // Optional: Agent configuration\n  defaultAgentName: \"\", // Leave blank for auto-dispatch\n};\n```\n\n**Example Customization:**\n```typescript\nexport const APP_CONFIG_DEFAULTS = {\n  companyName: \"Acme Voice AI\",\n  pageTitle: \"Voice AI Assistant | Acme Corp\",\n  logoUrl: \"/acme-logo.svg\",\n  accentColor: \"#FF6B35\", // Orange\n  supportsChatInput: true,\n  supportsVideoInput: false, // Disable video for voice-only\n  supportsScreenShare: false,\n  isPreConnectBufferEnabled: true,\n};\n```\n\n**Rationale:** Centralizes configuration for easy customization without code changes\n\n---\n\n#### 5.2: Add Custom Logo\n\n**What:** Replace default logo with your company logo\n\n**Steps:**\n\n1. Prepare logo files:\n   - **Format:** SVG (preferred) or PNG\n   - **Size:**\n     - SVG: Any size (scalable)\n     - PNG: 200x200px minimum, transparent background\n   - **Naming:**\n     - Light mode: `logo.svg` or `logo.png`\n     - Dark mode (optional): `logo-dark.svg` or `logo-dark.png`\n\n2. Copy to public directory:\n   ```bash\n   cp /path/to/your/logo.svg frontend/voice-ai-frontend/public/logo.svg\n   # Optional: dark mode logo\n   cp /path/to/your/logo-dark.svg frontend/voice-ai-frontend/public/logo-dark.svg\n   ```\n\n3. Update `app-config.ts`:\n   ```typescript\n   logoUrl: \"/logo.svg\",\n   logoUrlDark: \"/logo-dark.svg\", // If you have separate dark logo\n   ```\n\n4. Verify logo appears:\n   - Restart dev server: `pnpm dev`\n   - Visit http://localhost:3000\n   - Check logo displays correctly\n   - Toggle light/dark mode to test both logos\n\n**Fallback:**\nIf you don't have a logo ready, the template includes a default placeholder logo.\n\n**Rationale:** Custom logo reinforces brand identity\n\n---\n\n#### 5.3: Customize Theme Colors\n\n**What:** Update color scheme to match your brand\n\n**File:** `frontend/voice-ai-frontend/tailwind.config.ts`\n\n**Edit:**\n```typescript\nexport default {\n  theme: {\n    extend: {\n      colors: {\n        // Primary brand color\n        primary: {\n          50: '#f0f9ff',\n          100: '#e0f2fe',\n          // ... continue through 950\n          500: '#4F46E5', // Main brand color (change this)\n          600: '#4338ca',\n          // ...\n        },\n        // Accent color\n        accent: {\n          DEFAULT: '#FF6B35', // Change to your accent color\n          light: '#FF8A5B',\n          dark: '#E5501F',\n        },\n      },\n    },\n  },\n};\n```\n\n**Quick Method (Use Accent Color from app-config.ts):**\n\nThe template may automatically use `accentColor` from `app-config.ts`. If so, just update that value:\n\n```typescript\n// In app-config.ts\naccentColor: \"#FF6B35\", // Your brand color\n```\n\n**Generate Full Color Palette:**\nUse tools like https://uicolors.app/create to generate a full Tailwind color palette from your brand color.\n\n**Test Theme:**\n- Restart dev server\n- Visit http://localhost:3000\n- Check buttons, links, highlights use new colors\n- Toggle light/dark mode to verify both themes\n\n**Rationale:** Consistent color scheme creates professional, branded experience\n\n---\n\n#### 5.4: Update Page Metadata\n\n**What:** Set page title, description, and favicon for SEO and browser display\n\n**File:** `frontend/voice-ai-frontend/app/layout.tsx`\n\n**Edit:**\n```typescript\nexport const metadata: Metadata = {\n  title: \"AI Voice Assistant | Your Company\", // Change this\n  description: \"Connect with our AI voice assistant for instant help and support.\", // Change this\n  icons: {\n    icon: '/favicon.ico', // Update after adding favicon\n  },\n  openGraph: {\n    title: \"AI Voice Assistant | Your Company\",\n    description: \"Connect with our AI voice assistant for instant help and support.\",\n    images: ['/og-image.png'], // Optional: social share image\n  },\n};\n```\n\n**Add Custom Favicon:**\n\n1. Generate favicon files (use https://realfavicongenerator.net/):\n   - `favicon.ico` (16x16, 32x32, 48x48)\n   - `apple-touch-icon.png` (180x180)\n   - `favicon-16x16.png`\n   - `favicon-32x32.png`\n\n2. Copy to `public/`:\n   ```bash\n   cp /path/to/favicon.ico frontend/voice-ai-frontend/public/\n   cp /path/to/apple-touch-icon.png frontend/voice-ai-frontend/public/\n   ```\n\n3. Verify in browser:\n   - Clear browser cache\n   - Visit http://localhost:3000\n   - Check browser tab shows your favicon\n\n**Optional: Open Graph Image (Social Sharing):**\nCreate `og-image.png` (1200x630px) for social media previews.\n\n**Rationale:** Professional metadata improves SEO and user experience\n\n---\n\n#### 5.5: Customize Welcome Message\n\n**What:** Update the welcome screen text and instructions\n\n**File:** `frontend/voice-ai-frontend/components/app/welcome-view.tsx` or similar\n\n**Find and Edit:**\n```typescript\n<h1>Welcome to [Your Company] Voice AI</h1>\n<p>\n  Click the button below to start a voice conversation with our AI assistant.\n  We can help you with questions, information, and more.\n</p>\n```\n\n**Example Customization:**\n```typescript\n<h1>Welcome to Acme Voice Assistant</h1>\n<p>\n  Our AI assistant is ready to help you 24/7. Click \"Connect\" to start a\n  natural voice conversation. Just speak naturally - no keywords or commands needed.\n</p>\n<ul>\n  <li>Get instant answers to your questions</li>\n  <li>Learn about our products and services</li>\n  <li>Get personalized recommendations</li>\n</ul>\n```\n\n**Rationale:** Clear messaging helps users understand what to expect\n\n---\n\n#### 5.6: Optional - Disable Features Not Needed\n\n**What:** Hide video/screen share features if you only need voice\n\n**File:** `frontend/voice-ai-frontend/app-config.ts`\n\n**For Voice-Only App:**\n```typescript\nexport const APP_CONFIG_DEFAULTS = {\n  // ... other settings\n  supportsChatInput: false, // Disable text chat\n  supportsVideoInput: false, // Disable camera\n  supportsScreenShare: false, // Disable screen sharing\n  isPreConnectBufferEnabled: true, // Keep for faster connection\n};\n```\n\n**Effect:**\n- Video camera icon hidden\n- Screen share button removed\n- UI simplified to voice-only interface\n- Reduced complexity for users\n\n**Rationale:** Simplify UI by removing unused features\n\n---\n\n#### 5.7: Test Customizations\n\n**What:** Verify all customizations display correctly\n\n**Checklist:**\n- [ ] Company name displays on welcome screen\n- [ ] Custom logo appears (both light and dark modes)\n- [ ] Page title shows in browser tab\n- [ ] Custom favicon appears in browser tab\n- [ ] Brand colors visible on buttons and accents\n- [ ] Welcome message updated with custom text\n- [ ] Disabled features are hidden (if applicable)\n- [ ] No broken images or 404s\n- [ ] Responsive design maintained on mobile\n\n**Testing Steps:**\n1. Restart dev server: `pnpm dev`\n2. Clear browser cache (Cmd+Shift+R on Mac, Ctrl+Shift+R on Windows)\n3. Visit http://localhost:3000\n4. Toggle light/dark theme\n5. Resize browser to mobile size (375px width)\n6. Check all visual elements\n\n**Rationale:** Ensures professional, branded appearance before production deployment\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Build succeeds: `pnpm run build` completes without errors\n- [ ] No TypeScript errors: `pnpm run type-check` (if available)\n- [ ] Static assets exist: `ls public/logo.svg public/favicon.ico`\n- [ ] Config updated: `cat app-config.ts | grep companyName` shows your company\n\n#### Manual Verification:\n\n- [ ] Custom company name displays on welcome screen\n- [ ] Custom logo visible (light and dark modes)\n- [ ] Page title correct in browser tab\n- [ ] Favicon visible in browser tab\n- [ ] Brand colors applied throughout UI\n- [ ] Welcome message updated\n- [ ] Unused features hidden (if disabled)\n- [ ] Mobile responsive (test at 375px width)\n- [ ] No console errors or warnings\n- [ ] All images load correctly (no broken images)\n\n**Verify:** After completing automated verification, thoroughly test the UI on desktop and mobile, in light and dark modes, before proceeding to Phase 6.\n\n---\n\n## Phase 6: Production Deployment\n\n### Overview\n\nDeploy the customized frontend to Vercel (or another hosting provider) to make it publicly accessible via a URL that clients can visit.\n\n### Context\n\nBefore starting, ensure:\n- Phase 5 completed successfully\n- All customizations tested locally\n- Frontend builds successfully (`pnpm run build`)\n- Agent deployed and running on LiveKit Cloud\n\nFiles to review:\n- `frontend/voice-ai-frontend/.env.local` - Environment variables (will configure in Vercel)\n- `frontend/voice-ai-frontend/next.config.js` - Next.js configuration\n- `frontend/voice-ai-frontend/package.json` - Dependencies and scripts\n\nAccounts needed:\n- Vercel account (free tier sufficient): https://vercel.com\n- GitHub account (for connecting repo)\n\n### Dependencies\n\n**Depends on:** Phases 1-5 (agent deployed, frontend customized and tested)\n\n**Required by:** None (final phase)\n\n### Changes Required\n\n#### 6.1: Create Production Build\n\n**What:** Verify the production build works correctly before deploying\n\n**Commands:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\n\n# Create production build\npnpm run build\n\n# Test production build locally\npnpm start\n```\n\n**Expected Output:**\n```\n> next build\n\n✓ Compiled successfully\n✓ Linting and checking validity of types\n✓ Collecting page data\n✓ Generating static pages (X/X)\n✓ Finalizing page optimization\n\nRoute (app)                              Size     First Load JS\n┌ ○ /                                    XXX kB        XXX kB\n└ ○ /api/token                          XXX B          XXX kB\n```\n\n**Test Production Build:**\n1. Visit http://localhost:3000 (pnpm start)\n2. Connect to agent\n3. Verify voice interaction works\n4. Check for any errors in console\n\n**Troubleshooting:**\n- If build fails: Check TypeScript errors, fix before proceeding\n- If errors about environment variables: Ensure `.env.local` exists\n- If runtime errors: Check browser console for specific issues\n\n**Rationale:** Catches production-specific issues before deployment\n\n---\n\n#### 6.2: Push Frontend to GitHub (Optional but Recommended)\n\n**What:** Create a Git repository for the frontend to enable easy Vercel deployment\n\n**Option A: Separate Repository (Recommended):**\n\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\n\n# Initialize git repository\ngit init\n\n# Add .gitignore for Next.js\ncat > .gitignore << 'EOF'\n# Next.js\n.next/\nout/\nbuild/\ndist/\n\n# Dependencies\nnode_modules/\n\n# Environment variables\n.env\n.env.local\n.env.production.local\n.env.development.local\n.env.test.local\n\n# Logs\nnpm-debug.log*\nyarn-debug.log*\nyarn-error.log*\npnpm-debug.log*\n\n# OS\n.DS_Store\n*.swp\n*.swo\n\n# IDE\n.vscode/\n.idea/\n\n# Vercel\n.vercel\nEOF\n\n# Add files\ngit add .\ngit commit -m \"Initial commit: Voice AI frontend\"\n\n# Create GitHub repository (via GitHub UI or CLI)\ngh repo create voice-ai-frontend --public --source=. --remote=origin --push\n```\n\n**Option B: Same Repository as Agent:**\n\nIf you want frontend and agent in the same repo:\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\n\n# Remove frontend/ from .gitignore\nsed -i '' '/^frontend\\//d' .gitignore\n\n# Add and commit\ngit add frontend/\ngit commit -m \"Add voice AI frontend\"\ngit push\n```\n\n**Rationale:** Git repository enables continuous deployment and version control\n\n---\n\n#### 6.3: Sign Up for Vercel\n\n**What:** Create a Vercel account for hosting the frontend\n\n**Steps:**\n\n1. Visit https://vercel.com\n2. Click \"Sign Up\"\n3. Choose \"Continue with GitHub\" (recommended)\n4. Authorize Vercel to access your GitHub repositories\n\n**Pricing:**\n- **Free Tier:** Sufficient for testing and low traffic\n  - Unlimited deployments\n  - 100 GB bandwidth/month\n  - Serverless functions included\n- **Pro Tier:** $20/month (for production with higher traffic)\n\n**Rationale:** Vercel provides seamless Next.js hosting with automatic deployments\n\n---\n\n#### 6.4: Deploy Frontend to Vercel\n\n**What:** Deploy the frontend application to Vercel\n\n**Steps:**\n\n1. **From Vercel Dashboard:**\n   - Click \"Add New...\" → \"Project\"\n   - Select \"Import Git Repository\"\n   - Choose your frontend repository\n   - Configure project:\n     - **Framework Preset:** Next.js (auto-detected)\n     - **Root Directory:** `./` (or `frontend/voice-ai-frontend` if in monorepo)\n     - **Build Command:** `pnpm run build` (auto-detected)\n     - **Output Directory:** `.next` (auto-detected)\n     - **Install Command:** `pnpm install` (auto-detected)\n\n2. **Configure Environment Variables:**\n   Click \"Environment Variables\" and add:\n\n   ```\n   LIVEKIT_API_KEY=APIxxxxxxxxxxxx\n   LIVEKIT_API_SECRET=your-secret-here\n   LIVEKIT_URL=wss://your-project.livekit.cloud\n   NEXT_PUBLIC_LIVEKIT_URL=wss://your-project.livekit.cloud\n   AGENT_NAME=\n   ```\n\n   **Important:**\n   - Copy values from your local `.env.local`\n   - Apply to \"Production\", \"Preview\", and \"Development\" environments\n\n3. **Deploy:**\n   - Click \"Deploy\"\n   - Wait for build to complete (2-5 minutes)\n\n**Expected Outcome:**\n```\n✓ Build successful\n✓ Deployment successful\nYour project is now live at: https://your-app.vercel.app\n```\n\n**Rationale:** Makes frontend publicly accessible via HTTPS URL\n\n---\n\n#### 6.5: Test Production Deployment\n\n**What:** Verify the deployed frontend works correctly\n\n**Steps:**\n\n1. Visit your Vercel URL: `https://your-app.vercel.app`\n\n2. **Test Checklist:**\n   - [ ] Page loads without errors\n   - [ ] Custom branding displays correctly\n   - [ ] Click \"Connect\" button\n   - [ ] Grant microphone permissions\n   - [ ] Speak to agent\n   - [ ] Verify agent responds with voice\n   - [ ] Test on mobile device\n   - [ ] Test in different browsers\n\n3. **Monitor Logs:**\n   ```bash\n   # Monitor agent logs during production test\n   lk agent logs --follow\n   ```\n\n4. **Check Vercel Deployment Logs:**\n   - Go to Vercel dashboard → Your project → Deployments\n   - Click on latest deployment → \"Functions\" tab\n   - Check for any errors in `/api/token` function\n\n**Troubleshooting:**\n- **\"Failed to connect\":** Check environment variables in Vercel\n- **Token errors:** Verify `LIVEKIT_API_KEY` and `LIVEKIT_API_SECRET` are correct\n- **CORS errors:** Ensure `NEXT_PUBLIC_LIVEKIT_URL` is set correctly\n- **Agent not joining:** Check agent status, verify agent is Running\n\n**Rationale:** Ensures production environment works correctly\n\n---\n\n#### 6.6: Configure Custom Domain (Optional)\n\n**What:** Use a custom domain instead of `your-app.vercel.app`\n\n**Prerequisites:**\n- Own a domain name (e.g., `voiceai.yourcompany.com`)\n- Access to domain DNS settings\n\n**Steps:**\n\n1. **In Vercel Dashboard:**\n   - Go to your project → Settings → Domains\n   - Click \"Add Domain\"\n   - Enter your domain: `voiceai.yourcompany.com`\n\n2. **Configure DNS:**\n   Vercel will provide DNS configuration instructions:\n\n   **Option A: CNAME (Subdomain):**\n   ```\n   Type: CNAME\n   Name: voiceai\n   Value: cname.vercel-dns.com\n   ```\n\n   **Option B: A Record (Root Domain):**\n   ```\n   Type: A\n   Name: @\n   Value: 76.76.21.21\n   ```\n\n3. **Wait for DNS Propagation:**\n   - Usually takes 5-60 minutes\n   - Vercel will auto-configure SSL certificate (Let's Encrypt)\n\n4. **Verify:**\n   - Visit `https://voiceai.yourcompany.com`\n   - Should show your frontend with SSL (green lock icon)\n\n**Rationale:** Custom domain provides professional appearance and brand consistency\n\n---\n\n#### 6.7: Enable Automatic Deployments\n\n**What:** Configure automatic deployments when you push to GitHub\n\n**Vercel Auto-Deploys By Default:**\n- **Production:** Deploys on push to `main` branch\n- **Preview:** Deploys on push to any other branch or PR\n\n**Customize (Optional):**\n1. Go to Vercel dashboard → Your project → Settings → Git\n2. Configure:\n   - **Production Branch:** `main` (or `master`)\n   - **Ignored Build Step:** (leave blank to build on every commit)\n\n**Test Automatic Deployment:**\n```bash\ncd frontend/voice-ai-frontend\n\n# Make a small change\necho \"# Updated\" >> README.md\n\n# Commit and push\ngit add README.md\ngit commit -m \"Test automatic deployment\"\ngit push origin main\n```\n\n**Verify:**\n- Visit Vercel dashboard\n- Should see new deployment triggered automatically\n- Wait for build to complete\n- Visit production URL to see changes\n\n**Rationale:** Enables continuous deployment for easy updates\n\n---\n\n#### 6.8: Set Up Production Monitoring (Recommended)\n\n**What:** Monitor production errors and usage\n\n**Vercel Analytics (Built-in):**\n1. Go to Vercel dashboard → Your project → Analytics\n2. View:\n   - Page views\n   - Geographic distribution\n   - Performance metrics (Web Vitals)\n\n**Error Tracking (Optional):**\nConsider integrating Sentry or similar:\n```bash\npnpm add @sentry/nextjs\nnpx @sentry/wizard@latest -i nextjs\n```\n\n**LiveKit Cloud Monitoring:**\n- Visit LiveKit Cloud dashboard\n- Monitor:\n  - Active sessions\n  - Agent usage\n  - Costs (session minutes)\n\n**Rationale:** Production monitoring helps identify and resolve issues quickly\n\n---\n\n#### 6.9: Create Shareable Link\n\n**What:** Generate a clean, shareable URL for potential clients\n\n**Your Production URL:**\n```\nhttps://your-app.vercel.app\n```\n\n**Or with Custom Domain:**\n```\nhttps://voiceai.yourcompany.com\n```\n\n**Create Marketing Materials:**\n- Add link to your website\n- Share via email campaigns\n- Include in social media bios\n- Create QR code for physical materials\n\n**Example QR Code Generation:**\n```bash\n# Generate QR code (using qrencode)\nbrew install qrencode\nqrencode -o voiceai-qr.png \"https://voiceai.yourcompany.com\"\n```\n\n**Rationale:** Easy sharing enables potential clients to access your voice AI\n\n---\n\n#### 6.10: Document Production URLs and Credentials\n\n**What:** Save all production information for future reference\n\n**Create:** `frontend/voice-ai-frontend/PRODUCTION.md`\n\n**Content:**\n```markdown\n# Production Deployment Information\n\n## URLs\n- **Production Frontend:** https://your-app.vercel.app\n- **Custom Domain:** https://voiceai.yourcompany.com (if configured)\n- **LiveKit Cloud Dashboard:** https://cloud.livekit.io\n\n## Vercel\n- **Project:** voice-ai-frontend\n- **Account:** your-email@example.com\n- **Git Repository:** https://github.com/yourusername/voice-ai-frontend\n\n## LiveKit Cloud\n- **Project:** your-project-name\n- **Region:** us-west-2\n- **Agent ID:** agent_abc123\n\n## Deployment Commands\n```bash\n# Deploy agent updates\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\nlk agent deploy\n\n# Deploy frontend updates (automatic via Git)\ncd frontend/voice-ai-frontend\ngit add .\ngit commit -m \"Update frontend\"\ngit push origin main\n```\n\n## Monitoring\n- **Agent Logs:** `lk agent logs --follow`\n- **Vercel Logs:** https://vercel.com/your-project/deployments\n- **LiveKit Dashboard:** https://cloud.livekit.io/projects/your-project\n\n## Environment Variables (Vercel)\n- LIVEKIT_API_KEY=APIxxxxxxxxxxxx\n- LIVEKIT_API_SECRET=*** (not shown)\n- LIVEKIT_URL=wss://your-project.livekit.cloud\n- NEXT_PUBLIC_LIVEKIT_URL=wss://your-project.livekit.cloud\n\n## Costs\n- **LiveKit Cloud:** $0.01 per agent session minute\n- **Vercel:** Free tier (or $20/month Pro)\n\n## Support\n- **LiveKit:** https://livekit.io/discord\n- **Vercel:** https://vercel.com/support\n```\n\n**Rationale:** Documentation ensures you can manage production deployment long-term\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Production build succeeds: `pnpm run build` completes without errors\n- [ ] Vercel deployment successful: Deployment status shows \"Ready\"\n- [ ] HTTPS enabled: Visit production URL with green lock icon\n- [ ] Environment variables configured: Check Vercel dashboard\n- [ ] Custom domain configured (if applicable): DNS records set\n\n#### Manual Verification:\n\n- [ ] Visit production URL in browser\n- [ ] Page loads without errors\n- [ ] Custom branding displays correctly\n- [ ] Click \"Connect\" and grant microphone access\n- [ ] Speak to agent and verify voice response\n- [ ] Test on mobile device (iOS Safari, Android Chrome)\n- [ ] Test in incognito/private mode\n- [ ] Share URL with colleague and get confirmation it works\n- [ ] Agent logs show production sessions: `lk agent logs --follow`\n- [ ] No errors in Vercel function logs\n\n**Verify:** After completing automated verification, test the production URL on multiple devices and browsers, then share with a colleague to confirm public accessibility.\n\n---\n\n## Testing Strategy\n\n### Unit Tests\n\n**Not required for this plan.** The agent-starter-react template is a pre-built, production-ready template that doesn't require custom unit tests unless you add significant custom logic.\n\n**Optional:** Add tests if you customize components heavily:\n```bash\npnpm add -D @testing-library/react @testing-library/jest-dom jest\n```\n\n### Integration Tests\n\n**End-to-End Testing:**\n\nManually test the complete flow:\n1. User visits URL\n2. Clicks \"Connect\"\n3. Grants microphone access\n4. Speaks to agent\n5. Receives voice response\n6. Disconnects cleanly\n\n**Test Matrix:**\n\n| Scenario | Steps | Expected Outcome |\n|----------|-------|------------------|\n| First Connection | Visit URL → Click Connect → Speak | Agent responds with voice |\n| Interruption | Speak while agent is speaking | Agent handles gracefully |\n| Disconnect/Reconnect | End session → Start new session | New session works |\n| Multiple Turns | Have 3-5 turn conversation | All responses relevant |\n| Mobile Safari | Test on iPhone/iPad | Full functionality |\n| Network Interruption | Disable Wi-Fi during session | Reconnection or error message |\n\n### Manual Testing Steps\n\n**Pre-Deployment Checklist:**\n1. [ ] Agent deployed and running: `lk agent status`\n2. [ ] Local frontend works: `pnpm dev` at http://localhost:3000\n3. [ ] Voice interaction successful\n4. [ ] Audio visualization working\n5. [ ] Custom branding applied\n6. [ ] Production build succeeds: `pnpm run build`\n\n**Post-Deployment Checklist:**\n1. [ ] Production URL accessible\n2. [ ] HTTPS enabled (green lock)\n3. [ ] Voice interaction works on production\n4. [ ] Mobile responsive\n5. [ ] Cross-browser compatible\n6. [ ] Shareable link works for external users\n\n### Performance Considerations\n\n**Metrics to Monitor:**\n- **Connection Time:** Should be <3 seconds (or <1.5s with optimization)\n- **Response Latency:** STT → LLM → TTS should be 2-4 seconds\n- **Page Load Time:** Initial load <2 seconds (Lighthouse score >90)\n- **Audio Quality:** No dropouts or distortion\n\n**Optimization:**\n- Enable pre-connect buffering in `app-config.ts`\n- Use warm token approach (Phase 4.6)\n- Minimize bundle size (Next.js handles automatically)\n- Use CDN for static assets (Vercel provides automatically)\n\n## References\n\n### Original Ticket/Request\n- User request: \"I want potential clients to be able to interact with the livekit agent from this repo by clicking a link on a website.\"\n\n### Documentation\n- `docs/DEPLOYMENT.md` - Complete deployment guide for agent and frontend options\n- `README.md` - Project overview and setup instructions\n- `AGENTS.md` - Project guidelines and standards\n\n### LiveKit Resources\n- **Frontend Deployment Guide:** https://docs.livekit.io/agents/start/frontend/\n- **agent-starter-react Repository:** https://github.com/livekit-examples/agent-starter-react\n- **Token Authentication:** https://docs.livekit.io/home/get-started/authentication/\n- **Agents Playground:** https://agents-playground.livekit.io/\n- **LiveKit Cloud Dashboard:** https://cloud.livekit.io\n- **React Components Docs:** https://docs.livekit.io/reference/components/react/\n\n### NPM Packages\n- **livekit-client:** Client SDK for browser WebRTC\n- **@livekit/components-react:** React UI components\n- **livekit-server-sdk:** Server-side token generation\n\n### Vercel Resources\n- **Vercel Platform:** https://vercel.com\n- **Next.js Documentation:** https://nextjs.org/docs\n- **Deployment Docs:** https://vercel.com/docs\n\n### Related Plans\n- None (initial implementation)\n\n---\n\n**End of Implementation Plan**\n","structuredPatch":[{"oldStart":1435,"oldLines":10,"newStart":1435,"newLines":10,"lines":["   // Accent color","   accentColor: \"#4F46E5\", // Change to your brand color (hex)"," ","-  // Feature toggles","-  supportsChatInput: true, // Allow text chat alongside voice","-  supportsVideoInput: true, // Enable camera video","-  supportsScreenShare: true, // Enable screen sharing","+  // Feature toggles - AUDIO-ONLY CONFIGURATION","+  supportsChatInput: false, // Disable text chat (audio-only)","+  supportsVideoInput: false, // DISABLE camera video (audio-only)","+  supportsScreenShare: false, // DISABLE screen sharing (audio-only)","   isPreConnectBufferEnabled: true, // Pre-load for faster connection"," ","   // Optional: Agent configuration"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"54cd2e3e-44bc-457d-87b9-cc3aef140fb3"}
{"parentUuid":"31e19420-cfc2-4599-ade8-eea8fda0ed35","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","slug":"enumerated-shimmying-starlight","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_018SCanhCZzNZQk6tL6bzMXM","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now let me update the example customization to also show audio-only configuration:","signature":"EvoBCkYICxgCKkDiojkQFnRVjU7bN+wvcVGr4JOOYfyb/m3j0cokoybdOrIqcopghxI1BaYsry5jlx3wFd4rg0umIp3rvuF1EZiZEgyS096AbaiOIL+GXvkaDAWVInC8A590eUhJZCIw0mRSgJk8YS5zVG3oDteN4eEpT6mOeFyyZvbhwTFSJPmqouVVCCBLKV1QShm58qcWKmLfhztgXu0mpnXQmwyHUcqumkwjEqrG/RCaJXOJt4JjuhmN/C6m9xRAO6D+tWxgORcXAFwgnI6q+lhU2s5+qZZcdfOa19G1PPZBIgArYYPlX5K4/14GKvk0vcoI0kxCgsNpDRgB"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":9,"cache_creation_input_tokens":711,"cache_read_input_tokens":66282,"cache_creation":{"ephemeral_5m_input_tokens":711,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXTt7hRRUyxdZZUG1tGVc","type":"assistant","uuid":"4c487d86-4ecb-4179-bb99-d154f84d62f0","timestamp":"2026-01-25T09:45:33.427Z"}
{"parentUuid":"4c487d86-4ecb-4179-bb99-d154f84d62f0","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","slug":"enumerated-shimmying-starlight","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_018SCanhCZzNZQk6tL6bzMXM","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01YTe2Q11EV96rjh38BLwSEy","name":"Edit","input":{"replace_all":false,"file_path":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/plan/future-plans/2026-01-25-web-frontend-deployment.md","old_string":"**Example Customization:**\n```typescript\nexport const APP_CONFIG_DEFAULTS = {\n  companyName: \"Acme Voice AI\",\n  pageTitle: \"Voice AI Assistant | Acme Corp\",\n  logoUrl: \"/acme-logo.svg\",\n  accentColor: \"#FF6B35\", // Orange\n  supportsChatInput: true,\n  supportsVideoInput: false, // Disable video for voice-only\n  supportsScreenShare: false,\n  isPreConnectBufferEnabled: true,\n};\n```","new_string":"**Example Customization (Audio-Only):**\n```typescript\nexport const APP_CONFIG_DEFAULTS = {\n  companyName: \"Acme Voice AI\",\n  pageTitle: \"Voice AI Assistant | Acme Corp\",\n  logoUrl: \"/acme-logo.svg\",\n  accentColor: \"#FF6B35\", // Orange\n  supportsChatInput: false, // Audio-only: no text chat\n  supportsVideoInput: false, // Audio-only: no camera\n  supportsScreenShare: false, // Audio-only: no screen share\n  isPreConnectBufferEnabled: true,\n};\n```"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":9,"cache_creation_input_tokens":711,"cache_read_input_tokens":66282,"cache_creation":{"ephemeral_5m_input_tokens":711,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXTt7hRRUyxdZZUG1tGVc","type":"assistant","uuid":"52b8e0cb-e29a-4903-9e4d-11259664c0a9","timestamp":"2026-01-25T09:45:37.631Z"}
{"parentUuid":"52b8e0cb-e29a-4903-9e4d-11259664c0a9","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","slug":"enumerated-shimmying-starlight","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01YTe2Q11EV96rjh38BLwSEy","type":"tool_result","content":"The file /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/plan/future-plans/2026-01-25-web-frontend-deployment.md has been updated successfully."}]},"uuid":"27c25156-a7ed-4e1b-a57f-bbd175bf14e1","timestamp":"2026-01-25T09:45:37.675Z","toolUseResult":{"filePath":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/plan/future-plans/2026-01-25-web-frontend-deployment.md","oldString":"**Example Customization:**\n```typescript\nexport const APP_CONFIG_DEFAULTS = {\n  companyName: \"Acme Voice AI\",\n  pageTitle: \"Voice AI Assistant | Acme Corp\",\n  logoUrl: \"/acme-logo.svg\",\n  accentColor: \"#FF6B35\", // Orange\n  supportsChatInput: true,\n  supportsVideoInput: false, // Disable video for voice-only\n  supportsScreenShare: false,\n  isPreConnectBufferEnabled: true,\n};\n```","newString":"**Example Customization (Audio-Only):**\n```typescript\nexport const APP_CONFIG_DEFAULTS = {\n  companyName: \"Acme Voice AI\",\n  pageTitle: \"Voice AI Assistant | Acme Corp\",\n  logoUrl: \"/acme-logo.svg\",\n  accentColor: \"#FF6B35\", // Orange\n  supportsChatInput: false, // Audio-only: no text chat\n  supportsVideoInput: false, // Audio-only: no camera\n  supportsScreenShare: false, // Audio-only: no screen share\n  isPreConnectBufferEnabled: true,\n};\n```","originalFile":"# Web Frontend Deployment Implementation Plan\n\n> **Status:** DRAFT\n\n## Table of Contents\n\n- [Overview](#overview)\n- [Current State Analysis](#current-state-analysis)\n- [Desired End State](#desired-end-state)\n- [What We're NOT Doing](#what-were-not-doing)\n- [Implementation Approach](#implementation-approach)\n- [Dependencies](#dependencies)\n- [Phase 1: Agent Deployment to LiveKit Cloud](#phase-1-agent-deployment-to-livekit-cloud)\n- [Phase 2: Frontend Setup (agent-starter-react)](#phase-2-frontend-setup-agent-starter-react)\n- [Phase 3: Authentication and Token Generation](#phase-3-authentication-and-token-generation)\n- [Phase 4: Connection Testing and Optimization](#phase-4-connection-testing-and-optimization)\n- [Phase 5: Frontend Customization](#phase-5-frontend-customization)\n- [Phase 6: Production Deployment](#phase-6-production-deployment)\n- [Testing Strategy](#testing-strategy)\n- [References](#references)\n\n## Overview\n\nThis plan enables potential clients to interact with the LiveKit voice AI agent from this repository by clicking a link on a website. The implementation covers:\n\n1. Deploying the Python agent to LiveKit Cloud\n2. Setting up a Next.js/React frontend using the agent-starter-react template\n3. Implementing JWT token-based authentication\n4. Testing the connection flow\n5. Customizing the frontend with branding\n6. Deploying the frontend to production (Vercel)\n\nThe solution uses LiveKit's official starter templates and SDKs to create a production-ready web application with TypeScript/JavaScript.\n\n**IMPORTANT: This is an audio-only application. No video camera or screen sharing permissions should be requested from users. All configuration must disable video/screenshare features.**\n\n## Current State Analysis\n\n### What Exists Now\n\n**Agent Backend:**\n- Python voice AI agent in `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1`\n- Built with LiveKit Agents SDK\n- Uses OpenAI (LLM), AssemblyAI (STT), Cartesia (TTS)\n- Configured with `uv` package manager\n- Has `Dockerfile` for containerized deployment\n- Environment variables in `.env.local` (OpenAI, AssemblyAI, Cartesia API keys)\n\n**Missing:**\n- Agent not yet deployed to LiveKit Cloud\n- No web frontend for client interaction\n- No token generation server for authentication\n- No public-facing URL for clients to access\n\n### Key Discoveries\n\nFrom `docs/DEPLOYMENT.md`:\n- LiveKit Cloud deployment uses `lk` CLI\n- Agent deployment command: `lk agent create --secrets-file .env.local`\n- Multiple frontend options available (React, Flutter, Swift, Embed)\n- Connection requires JWT tokens generated server-side\n- agent-starter-react provides production-ready Next.js template\n- Token generation uses `livekit-server-sdk` npm package\n\n### Constraints\n\n1. **Security:** API secrets (LIVEKIT_API_SECRET) must never be exposed to frontend\n2. **Architecture:** Token generation must happen server-side (Next.js API routes)\n3. **Dependencies:** Agent must be deployed and running before frontend can connect\n4. **Cost:** LiveKit Cloud charges $0.01 per agent session minute\n\n## Desired End State\n\n### Success Criteria\n\n- [ ] Agent deployed and running on LiveKit Cloud\n- [ ] Next.js frontend application running locally\n- [ ] JWT token generation working via backend API route\n- [ ] Users can click a link and connect to voice AI agent\n- [ ] Audio conversation works end-to-end (STT → LLM → TTS)\n- [ ] Frontend deployed to production URL (Vercel)\n- [ ] Customized branding (logo, colors, company name)\n- [ ] Light/dark theme support\n- [ ] Audio visualization working\n- [ ] Mobile-responsive design\n\n### How to Verify\n\n**Agent Deployment:**\n```bash\nlk agent status\n# Expected: Status: Running, Replicas: X/X ready\n```\n\n**Frontend Connection:**\n1. Visit frontend URL (local: http://localhost:3000, prod: https://your-app.vercel.app)\n2. Click \"Connect\" or \"Start Session\"\n3. Grant microphone permissions when prompted\n4. Speak to the agent\n5. Verify agent responds with natural voice\n6. Check agent logs: `lk agent logs --follow`\n\n**End-to-End Test:**\n```bash\n# Terminal 1: Monitor agent logs\nlk agent logs --follow\n\n# Terminal 2: Run frontend\ncd /path/to/frontend\npnpm dev\n\n# Browser: Visit http://localhost:3000, connect, and speak\n```\n\n## What We're NOT Doing\n\n**Out of Scope:**\n- Multiple agent types or agent selection UI\n- User authentication/login system (anonymous users only)\n- Database integration or conversation history storage\n- Multi-language support (English only initially)\n- iOS/Android native apps (web only)\n- Custom voice customization UI\n- Payment integration or usage metering\n- Advanced analytics dashboard\n- Server-side rendering (SSR) for the voice interface\n- Custom WebRTC infrastructure (using LiveKit Cloud)\n\n**Future Considerations:**\n- User accounts and saved conversations\n- Analytics and usage tracking\n- Custom domain with branding\n- A/B testing different agent configurations\n- Rate limiting and abuse prevention\n\n## Implementation Approach\n\n### High-Level Strategy\n\n1. **Deploy Agent First:** Ensure the Python agent is running on LiveKit Cloud before building frontend\n2. **Use Official Template:** Start with agent-starter-react to avoid reinventing the wheel\n3. **Iterative Testing:** Test each phase independently before proceeding\n4. **Security-First:** Never expose API secrets; use environment variables and server-side token generation\n5. **Quick Validation:** Use LiveKit Agents Playground first to verify agent works before building frontend\n\n### Technology Stack\n\n**Backend (Agent):**\n- Python 3.11+\n- LiveKit Agents SDK\n- OpenAI GPT-4 (LLM)\n- AssemblyAI (STT)\n- Cartesia (TTS)\n- Deployed to: LiveKit Cloud\n\n**Frontend:**\n- Next.js 14+ (App Router)\n- React 18+\n- TypeScript\n- Tailwind CSS\n- Shadcn/ui components\n- `livekit-client` SDK\n- `@livekit/components-react`\n- Deployed to: Vercel\n\n**Authentication:**\n- JWT tokens (livekit-server-sdk)\n- Server-side generation (Next.js API routes)\n- 2-hour token expiration\n\n## Dependencies\n\n**Execution Order:**\n\n1. Phase 1: Agent Deployment (no dependencies)\n2. Phase 2: Frontend Setup (depends on Phase 1 for credentials)\n3. Phase 3: Authentication (depends on Phase 2)\n4. Phase 4: Connection Testing (depends on Phases 1-3)\n5. Phase 5: Frontend Customization (depends on Phase 4)\n6. Phase 6: Production Deployment (depends on Phase 5)\n\n**Dependency Graph:**\n\n```\nPhase 1 (Agent Deployment)\n  └─> Phase 2 (Frontend Setup)\n        └─> Phase 3 (Authentication)\n              └─> Phase 4 (Testing)\n                    └─> Phase 5 (Customization)\n                          └─> Phase 6 (Production)\n```\n\n**Parallelization:**\n- All phases are sequential due to dependencies\n- Within each phase, independent tasks can run in parallel\n\n---\n\n## Phase 1: Agent Deployment to LiveKit Cloud\n\n### Overview\n\nDeploy the Python voice AI agent to LiveKit Cloud to make it accessible via WebRTC. This creates a running agent that can be dispatched to rooms when users connect.\n\n### Context\n\nBefore starting, ensure you have:\n- LiveKit CLI installed: `brew install livekit/livekit/livekit-cli`\n- LiveKit Cloud account at https://cloud.livekit.io\n- Agent code in `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1`\n- API keys in `.env.local` (OpenAI, AssemblyAI, Cartesia)\n\nFiles to review:\n- `docs/DEPLOYMENT.md` - Complete deployment guide\n- `.env.local` - API keys and secrets\n- `Dockerfile` - Container build configuration\n- `src/app.py` - Agent entry point\n\n### Dependencies\n\n**Depends on:** None (first phase)\n\n**Required by:** Phase 2 (Frontend needs LiveKit credentials), Phase 4 (Testing needs deployed agent)\n\n### Changes Required\n\n#### 1.1: Authenticate with LiveKit Cloud\n\n**What:** Link your CLI to your LiveKit Cloud account\n\n**Command:**\n```bash\nlk cloud auth\n```\n\n**Expected Outcome:**\n- Browser opens for authentication\n- CLI displays: \"Successfully authenticated with LiveKit Cloud\"\n- Credentials saved in `~/.livekit/credentials`\n\n**Rationale:** Required for all subsequent `lk` CLI commands\n\n---\n\n#### 1.2: Create or Select LiveKit Project\n\n**What:** Create a new project or select an existing one for the agent deployment\n\n**Commands:**\n```bash\n# List existing projects\nlk project list\n\n# Option A: Use existing project\nlk project set-default \"your-project-name\"\n\n# Option B: Create new project via dashboard\n# Visit https://cloud.livekit.io and create a new project\n# Then set as default: lk project set-default \"new-project-name\"\n\n# Verify current project\nlk project current\n```\n\n**Expected Outcome:**\n```\nNAME                 PROJECT_ID\nyour-project-name   prj_abc123\n```\n\n**Rationale:** Agent deployments are scoped to projects; need a target project first\n\n---\n\n#### 1.3: Verify Secrets File\n\n**What:** Ensure `.env.local` contains all required API keys\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/.env.local`\n\n**Verify contents:**\n```bash\ncat .env.local\n```\n\n**Required secrets:**\n```env\nOPENAI_API_KEY=sk-...\nASSEMBLYAI_API_KEY=...\nCARTESIA_API_KEY=...\n```\n\n**Important Notes:**\n- Do NOT include `LIVEKIT_URL`, `LIVEKIT_API_KEY`, or `LIVEKIT_API_SECRET` in `.env.local`\n- LiveKit Cloud auto-injects these during deployment\n- Verify `.env.local` is in `.gitignore`\n\n**Rationale:** Agent needs these API keys to function; LiveKit Cloud encrypts and injects them as environment variables\n\n---\n\n#### 1.4: Download Model Files\n\n**What:** Download required models (Silero VAD, turn detector) before deployment\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\nuv run python src/app.py download-files\n```\n\n**Expected Outcome:**\n```\nDownloading Silero VAD model...\nDownloading multilingual turn detector model...\nDownload complete.\n```\n\n**Rationale:** Models are required at runtime; downloading during build ensures faster agent startup\n\n---\n\n#### 1.5: Deploy Agent to LiveKit Cloud\n\n**What:** Create and deploy the agent container to LiveKit Cloud\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\nlk agent create --secrets-file .env.local\n```\n\n**Expected Outcome:**\n```\nRegistering agent...\nAgent ID: agent_abc123\nBuilding container image...\nUploading code...\nBuild in progress (this may take 2-5 minutes)...\nBuild complete.\nDeploying agent...\nDeployment successful.\nStatus: Running\nReplicas: 2/2 ready\n```\n\n**What Happens:**\n1. CLI registers new agent with Cloud project\n2. Assigns unique agent ID (e.g., `agent_abc123`)\n3. Creates/updates `livekit.toml` configuration file\n4. Uploads source code to LiveKit build service\n5. Builds Docker container from `Dockerfile`\n6. Deploys container to Cloud project\n7. Encrypts and injects secrets as environment variables\n8. Starts 2 replica instances\n\n**Duration:** 2-5 minutes for initial build\n\n**Rationale:** Makes agent accessible via LiveKit's global WebRTC infrastructure\n\n---\n\n#### 1.6: Verify Agent Status\n\n**What:** Confirm agent is running and ready to accept sessions\n\n**Commands:**\n```bash\n# Check agent status\nlk agent status\n\n# View live logs\nlk agent logs --tail 50\n```\n\n**Expected Status Output:**\n```\nAgent ID:     agent_abc123\nStatus:       Running\nReplicas:     2/2 ready\nVersion:      v1\nLast Deploy:  2026-01-25 10:30:00 UTC\nRegion:       us-west-2\n```\n\n**Expected Log Output:**\n- No error messages\n- Successful initialization messages\n- \"Waiting for room assignment\" or similar\n\n**Troubleshooting:**\n- If status is `CrashLoop`: Check logs for Python exceptions\n- If status is `Build Failed`: Run `lk agent logs --build` to see build errors\n- If secrets missing: Run `lk agent secrets` to verify\n\n**Rationale:** Ensures agent is healthy before proceeding to frontend setup\n\n---\n\n#### 1.7: Quick Test with Agents Playground\n\n**What:** Test agent using LiveKit Agents Playground (no code required)\n\n**Steps:**\n1. Get project credentials:\n   ```bash\n   lk project current --json\n   ```\n\n2. Visit https://agents-playground.livekit.io/\n\n3. Enter credentials:\n   - **LiveKit URL:** `wss://your-project.livekit.cloud` (from JSON output)\n   - **API Key:** Your `LIVEKIT_API_KEY` (from JSON output)\n   - **API Secret:** Your `LIVEKIT_API_SECRET` (from JSON output)\n\n4. Click \"Connect\"\n\n5. Allow microphone access when prompted\n\n6. Speak to your agent\n\n7. Monitor agent logs in terminal:\n   ```bash\n   lk agent logs --follow\n   ```\n\n**Expected Outcome:**\n- Agent responds to your voice with natural TTS\n- Logs show STT transcriptions, LLM responses, TTS generation\n- No errors in logs\n\n**Rationale:** Validates agent works end-to-end before investing in frontend development\n\n---\n\n#### 1.8: Save LiveKit Credentials\n\n**What:** Export LiveKit project credentials for frontend configuration\n\n**Command:**\n```bash\nlk project current --json > livekit-credentials.json\n```\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/livekit-credentials.json`\n\n**Expected Contents:**\n```json\n{\n  \"name\": \"your-project-name\",\n  \"url\": \"wss://your-project.livekit.cloud\",\n  \"api_key\": \"APIxxxxxxxxxxxx\",\n  \"api_secret\": \"your-secret-here\"\n}\n```\n\n**Security Note:**\n- Add `livekit-credentials.json` to `.gitignore`\n- NEVER commit this file to version control\n- This file is for local reference only\n\n**Rationale:** Frontend needs these credentials to generate tokens and connect to LiveKit\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] CLI authenticated: `lk cloud auth` successful\n- [ ] Project selected: `lk project current` shows correct project\n- [ ] Agent deployed: `lk agent status` shows `Status: Running`\n- [ ] Replicas ready: `lk agent status` shows `X/X ready` (e.g., 2/2)\n- [ ] No crash loops: `lk agent logs --tail 50` shows no errors\n- [ ] Credentials saved: `livekit-credentials.json` exists and contains valid JSON\n\n#### Manual Verification:\n\n- [ ] Agents Playground connection successful\n- [ ] Agent responds to voice input with TTS output\n- [ ] Agent logs show successful STT → LLM → TTS pipeline\n- [ ] No API key errors in logs\n- [ ] Agent state transitions visible (initializing → listening → thinking → speaking)\n\n**Verify:** After completing automated verification, test agent with Agents Playground before proceeding to Phase 2.\n\n---\n\n## Phase 2: Frontend Setup (agent-starter-react)\n\n### Overview\n\nClone and configure the agent-starter-react template to create a Next.js web application that connects users to your deployed agent.\n\n### Context\n\nBefore starting, ensure:\n- Phase 1 completed successfully\n- Agent is running on LiveKit Cloud\n- `livekit-credentials.json` file exists with credentials\n\nPrerequisites:\n- Node.js 18+ installed\n- pnpm installed: `npm install -g pnpm`\n- `lk` CLI authenticated\n\nFiles to review:\n- `livekit-credentials.json` - LiveKit project credentials\n- N/A (frontend doesn't exist yet)\n\n### Dependencies\n\n**Depends on:** Phase 1 (needs LiveKit credentials)\n\n**Required by:** Phase 3 (authentication setup), Phase 4 (connection testing)\n\n### Changes Required\n\n#### 2.1: Create Frontend Project Directory\n\n**What:** Create a directory to house the frontend application\n\n**Commands:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\nmkdir -p frontend\ncd frontend\n```\n\n**Expected Outcome:**\n```\nDirectory created: /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/\n```\n\n**Rationale:** Separates frontend code from agent backend code\n\n---\n\n#### 2.2: Clone agent-starter-react Template\n\n**What:** Use LiveKit CLI to create a new project from the official template\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend\nlk app create --template agent-starter-react\n```\n\n**Interactive Prompts:**\n- **Project name:** (Press Enter for default or enter custom name like \"voice-ai-frontend\")\n- **Install dependencies?** Yes\n\n**Alternative (Manual Clone):**\n```bash\ngit clone https://github.com/livekit-examples/agent-starter-react.git voice-ai-frontend\ncd voice-ai-frontend\npnpm install\n```\n\n**Expected Outcome:**\n```\n✓ Created project: voice-ai-frontend\n✓ Installed dependencies\n✓ Ready to configure\n```\n\n**Directory Structure:**\n```\nfrontend/voice-ai-frontend/\n├── app/\n│   ├── api/token/route.ts     # Token generation endpoint\n│   ├── page.tsx               # Main page\n│   └── layout.tsx\n├── components/\n│   ├── agents-ui/             # Agents UI components\n│   ├── app/                   # Business logic\n│   └── ui/                    # Shadcn/ui primitives\n├── hooks/\n├── lib/\n├── public/\n├── package.json\n├── .env.example\n└── next.config.js\n```\n\n**Rationale:** Official template provides production-ready structure with all necessary LiveKit integrations\n\n---\n\n#### 2.3: Configure Environment Variables\n\n**What:** Set up LiveKit credentials for the frontend\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend/.env.local`\n\n**Commands:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\ncp .env.example .env.local\n```\n\n**Edit `.env.local`:**\n```env\n# LiveKit project credentials (from livekit-credentials.json)\nLIVEKIT_API_KEY=APIxxxxxxxxxxxx\nLIVEKIT_API_SECRET=your-secret-here\nLIVEKIT_URL=wss://your-project.livekit.cloud\n\n# Public URL (exposed to browser - same as LIVEKIT_URL)\nNEXT_PUBLIC_LIVEKIT_URL=wss://your-project.livekit.cloud\n\n# Agent configuration\nAGENT_NAME=\n# Leave AGENT_NAME blank for automatic agent dispatch\n# Or set to specific agent name if you have multiple agents\n```\n\n**How to Get Values:**\n```bash\n# Copy from livekit-credentials.json\ncat /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/livekit-credentials.json\n```\n\n**Security Notes:**\n- `LIVEKIT_API_SECRET` is server-side only (never exposed to browser)\n- `NEXT_PUBLIC_*` variables are exposed to browser\n- Only `NEXT_PUBLIC_LIVEKIT_URL` should be public\n- Never expose `LIVEKIT_API_KEY` or `LIVEKIT_API_SECRET` to browser\n\n**Rationale:** Frontend needs credentials to generate tokens and connect to LiveKit rooms\n\n---\n\n#### 2.4: Verify Dependencies Installation\n\n**What:** Ensure all npm packages are installed correctly\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\npnpm install\n```\n\n**Expected Outcome:**\n```\nPackages: +XXX\nProgress: resolved XXX, reused XXX, downloaded X, added XXX, done\n```\n\n**Key Dependencies (verify in `package.json`):**\n- `next` (v14+)\n- `react` (v18+)\n- `livekit-client`\n- `@livekit/components-react`\n- `livekit-server-sdk`\n- `tailwindcss`\n- `typescript`\n\n**Troubleshooting:**\n- If pnpm not installed: `npm install -g pnpm`\n- If peer dependency warnings: Generally safe to ignore\n- If install fails: Delete `node_modules` and `pnpm-lock.yaml`, retry\n\n**Rationale:** Ensures all required packages are available for development\n\n---\n\n#### 2.5: Run Development Server\n\n**What:** Start the Next.js development server to verify basic setup\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\npnpm dev\n```\n\n**Expected Outcome:**\n```\n> next dev\n\n  ▲ Next.js 14.x.x\n  - Local:        http://localhost:3000\n  - Environments: .env.local\n\n ✓ Ready in X.Xs\n```\n\n**Verification:**\n1. Open browser to http://localhost:3000\n2. Should see agent interface with \"Connect\" button\n3. No console errors in browser DevTools\n4. Page loads without 500 errors\n\n**Expected UI:**\n- Welcome/landing view\n- \"Connect\" or \"Start Session\" button\n- Logo and branding elements\n- Theme toggle (light/dark)\n\n**Troubleshooting:**\n- If port 3000 in use: `pnpm dev -- -p 3001`\n- If env vars missing: Check `.env.local` exists and has correct values\n- If build errors: Check `pnpm install` completed successfully\n\n**Rationale:** Validates Next.js setup before proceeding to authentication\n\n---\n\n#### 2.6: Inspect Token Generation API Route\n\n**What:** Review the built-in token generation endpoint to understand how authentication works\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend/app/api/token/route.ts`\n\n**Read the file:**\n```typescript\n// Expected structure (review actual implementation)\nimport { AccessToken } from 'livekit-server-sdk';\n\nexport async function POST(request: Request) {\n  const { roomName, participantName } = await request.json();\n\n  const token = new AccessToken(\n    process.env.LIVEKIT_API_KEY,\n    process.env.LIVEKIT_API_SECRET,\n    {\n      identity: participantName,\n      ttl: '2h', // Token valid for 2 hours\n    }\n  );\n\n  token.addGrant({\n    room: roomName,\n    roomJoin: true,\n    canPublish: true,\n    canSubscribe: true,\n  });\n\n  return Response.json({ token: await token.toJwt() });\n}\n```\n\n**Key Points:**\n- Uses `livekit-server-sdk` to generate JWT tokens\n- Reads `LIVEKIT_API_KEY` and `LIVEKIT_API_SECRET` from environment\n- Grants room join, publish, and subscribe permissions\n- Returns JWT token to frontend\n- Token expires after 2 hours (LiveKit auto-refreshes for connected clients)\n\n**Security Review:**\n- ✓ API key/secret are server-side only (not exposed to browser)\n- ✓ Token generation happens on server\n- ✓ Appropriate permissions granted\n- ⚠ Consider adding rate limiting for production\n\n**Rationale:** Understanding token flow is critical for debugging connection issues\n\n---\n\n#### 2.7: Add Frontend to .gitignore (Backend Repo)\n\n**What:** Prevent frontend from being committed to agent backend repo\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/.gitignore`\n\n**Add to `.gitignore`:**\n```bash\necho \"frontend/\" >> .gitignore\n```\n\n**Verify:**\n```bash\ngit status\n# frontend/ should not appear in untracked files\n```\n\n**Alternative Approach:**\nIf you want to commit the frontend to the same repo:\n- Create a separate `.gitignore` in `frontend/voice-ai-frontend/`\n- Add standard Next.js ignores (`.next/`, `node_modules/`, `.env.local`)\n\n**Rationale:** Keep frontend and backend as separate concerns, or manage carefully if in same repo\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Frontend directory created: `ls frontend/voice-ai-frontend`\n- [ ] Dependencies installed: `pnpm list --depth=0` shows key packages\n- [ ] Environment variables configured: `cat .env.local | grep LIVEKIT_API_KEY`\n- [ ] Development server starts: `pnpm dev` runs without errors\n- [ ] No TypeScript errors: `pnpm run build` completes successfully\n\n#### Manual Verification:\n\n- [ ] Visit http://localhost:3000 in browser\n- [ ] Page loads without 500 errors\n- [ ] UI displays welcome screen with \"Connect\" button\n- [ ] No console errors in browser DevTools\n- [ ] Theme toggle works (light/dark mode)\n- [ ] Responsive design works on mobile viewport\n\n**Verify:** After completing automated verification, open the app in a browser and verify UI loads correctly before proceeding to Phase 3.\n\n---\n\n## Phase 3: Authentication and Token Generation\n\n### Overview\n\nConfigure and test the JWT token generation flow to ensure frontend can authenticate users with LiveKit and connect them to agent sessions.\n\n### Context\n\nBefore starting, ensure:\n- Phase 2 completed successfully\n- Development server running at http://localhost:3000\n- Environment variables configured in `.env.local`\n\nFiles to review:\n- `frontend/voice-ai-frontend/app/api/token/route.ts` - Token generation endpoint\n- `frontend/voice-ai-frontend/.env.local` - Environment configuration\n- `frontend/voice-ai-frontend/components/app/` - Client-side connection logic\n\n### Dependencies\n\n**Depends on:** Phase 2 (frontend setup)\n\n**Required by:** Phase 4 (connection testing)\n\n### Changes Required\n\n#### 3.1: Test Token Generation Endpoint\n\n**What:** Verify the token API endpoint works correctly\n\n**Command:**\n```bash\n# Start dev server (if not running)\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\npnpm dev\n\n# In another terminal, test the endpoint\ncurl -X POST http://localhost:3000/api/token \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"roomName\": \"test-room\", \"participantName\": \"test-user\"}'\n```\n\n**Expected Response:**\n```json\n{\n  \"token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\"\n}\n```\n\n**Validate Token:**\n```bash\n# Decode the JWT to inspect claims (copy token from response)\necho \"eyJhbGciOiJ...\" | cut -d'.' -f2 | base64 -d | jq\n```\n\n**Expected Token Payload:**\n```json\n{\n  \"exp\": 1234567890,\n  \"iss\": \"APIxxxxxxxxxxxx\",\n  \"sub\": \"test-user\",\n  \"nbf\": 1234567890,\n  \"video\": {\n    \"room\": \"test-room\",\n    \"roomJoin\": true,\n    \"canPublish\": true,\n    \"canSubscribe\": true,\n    \"canPublishData\": true\n  }\n}\n```\n\n**Troubleshooting:**\n- If 500 error: Check environment variables in `.env.local`\n- If \"api_key undefined\": Verify `LIVEKIT_API_KEY` is set\n- If \"invalid signature\": Check `LIVEKIT_API_SECRET` is correct\n- If no response: Verify dev server is running on port 3000\n\n**Rationale:** Token generation must work before attempting to connect to LiveKit\n\n---\n\n#### 3.2: Review Client-Side Connection Logic\n\n**What:** Understand how the frontend connects to LiveKit rooms\n\n**Files to Review:**\n```bash\n# Main session component\ncat frontend/voice-ai-frontend/components/app/session-view.tsx\n\n# View controller\ncat frontend/voice-ai-frontend/components/app/view-controller.tsx\n\n# Connection utilities\ncat frontend/voice-ai-frontend/lib/connection.ts\n```\n\n**Key Flow:**\n1. User clicks \"Connect\" button\n2. Frontend generates room name (random or predefined)\n3. Frontend fetches token from `/api/token` endpoint\n4. Frontend connects to LiveKit room using `livekit-client`\n5. Agent is automatically dispatched to room\n6. User and agent establish WebRTC connection\n7. Audio tracks are exchanged\n\n**Important Variables:**\n- `NEXT_PUBLIC_LIVEKIT_URL` - LiveKit server URL (browser-accessible)\n- Room name generation logic\n- Participant name/identity\n- Agent dispatch configuration\n\n**Rationale:** Understanding client-side logic helps debug connection issues\n\n---\n\n#### 3.3: Configure Agent Dispatch\n\n**What:** Ensure frontend triggers automatic agent dispatch when users connect\n\n**File:** Review `frontend/voice-ai-frontend/app/api/connection-details/route.ts` (if exists) or equivalent\n\n**Verify Agent Name Configuration:**\n\n**Option A: Automatic Dispatch (Recommended):**\n```env\n# In .env.local\nAGENT_NAME=\n# Blank means \"dispatch any available agent\"\n```\n\n**Option B: Specific Agent:**\n```env\n# In .env.local\nAGENT_NAME=agent_abc123\n# Uses specific agent by ID or name\n```\n\n**Check Token Grant Configuration:**\n```typescript\n// In app/api/token/route.ts or connection-details/route.ts\ntoken.addGrant({\n  room: roomName,\n  roomJoin: true,\n  canPublish: true,\n  canSubscribe: true,\n  // Optional: Agent dispatch configuration\n});\n```\n\n**For agent-starter-react:**\nThe template typically handles agent dispatch automatically when a participant joins a room. Verify this by checking the token generation code and connection details endpoint.\n\n**Rationale:** Agent won't join room unless dispatch is configured correctly\n\n---\n\n#### 3.4: Test Token Expiration and Refresh\n\n**What:** Verify token expiration is set correctly and LiveKit handles refresh\n\n**Check Current TTL:**\n```typescript\n// In app/api/token/route.ts\nconst token = new AccessToken(\n  process.env.LIVEKIT_API_KEY,\n  process.env.LIVEKIT_API_SECRET,\n  {\n    identity: participantName,\n    ttl: '2h', // Current setting\n  }\n);\n```\n\n**Recommended TTL:**\n- Development: `2h` (2 hours)\n- Production: `2h` (LiveKit auto-refreshes for connected clients)\n- Pre-generated tokens: `1h` (if caching tokens)\n\n**Token Refresh Behavior:**\n- LiveKit client SDK automatically refreshes tokens before expiration\n- Refresh happens for connected clients only\n- Disconnected users must request new tokens\n\n**No changes needed if TTL is already `2h`.**\n\n**Rationale:** Prevents users from being disconnected due to token expiration\n\n---\n\n#### 3.5: Add Security Headers (Optional but Recommended)\n\n**What:** Add security headers to token API route\n\n**File:** `frontend/voice-ai-frontend/middleware.ts` (create if doesn't exist)\n\n**Content:**\n```typescript\nimport { NextResponse } from 'next/server';\nimport type { NextRequest } from 'next/server';\n\nexport function middleware(request: NextRequest) {\n  const response = NextResponse.next();\n\n  // Security headers\n  response.headers.set('X-Content-Type-Options', 'nosniff');\n  response.headers.set('X-Frame-Options', 'DENY');\n  response.headers.set('X-XSS-Protection', '1; mode=block');\n\n  return response;\n}\n\nexport const config = {\n  matcher: '/api/:path*',\n};\n```\n\n**Optional Rate Limiting:**\nConsider adding rate limiting to `/api/token` endpoint to prevent abuse.\n\n**Rationale:** Basic security hardening for production deployments\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Token endpoint returns valid JWT: `curl -X POST http://localhost:3000/api/token -H \"Content-Type: application/json\" -d '{\"roomName\":\"test\",\"participantName\":\"user\"}' | jq .token`\n- [ ] Token payload contains correct claims: Decode JWT and verify `video.roomJoin: true`\n- [ ] Environment variables loaded: `console.log(process.env.LIVEKIT_API_KEY)` in token route shows value (not undefined)\n- [ ] Token has correct expiration: Decoded JWT shows `exp` timestamp 2 hours in future\n\n#### Manual Verification:\n\n- [ ] Token endpoint accessible via browser: Visit http://localhost:3000/api/token (should return 405 Method Not Allowed for GET)\n- [ ] No errors in Next.js server logs when generating tokens\n- [ ] Token decodes successfully at https://jwt.io\n- [ ] Token issuer (`iss`) matches your LiveKit API key\n- [ ] Token subject (`sub`) matches requested participant name\n\n**Verify:** After completing automated verification, test token generation with curl and decode the JWT to inspect claims before proceeding to Phase 4.\n\n---\n\n## Phase 4: Connection Testing and Optimization\n\n### Overview\n\nTest the end-to-end connection flow from frontend to agent, verify audio works correctly, and optimize the connection speed.\n\n### Context\n\nBefore starting, ensure:\n- Phase 3 completed successfully\n- Agent running on LiveKit Cloud (`lk agent status` shows Running)\n- Frontend running at http://localhost:3000\n- Token generation working\n\nFiles to review:\n- `frontend/voice-ai-frontend/components/app/session-view.tsx` - Session management\n- `frontend/voice-ai-frontend/components/agents-ui/` - UI components\n\nTools needed:\n- Browser with microphone access\n- Terminal for monitoring agent logs\n\n### Dependencies\n\n**Depends on:** Phases 1-3 (agent deployed, frontend configured, authentication working)\n\n**Required by:** Phase 5 (customization), Phase 6 (production deployment)\n\n### Changes Required\n\n#### 4.1: Monitor Agent Logs\n\n**What:** Start monitoring agent logs before testing connection\n\n**Command:**\n```bash\n# Open a dedicated terminal window for agent logs\nlk agent logs --follow\n```\n\n**Keep this terminal open during all testing.**\n\n**What to Look For:**\n- Agent initialization messages\n- Room join events\n- STT transcriptions\n- LLM requests/responses\n- TTS generation\n- WebRTC connection events\n- Any error messages\n\n**Rationale:** Real-time logs are essential for debugging connection issues\n\n---\n\n#### 4.2: Test Basic Connection Flow\n\n**What:** Connect to the agent via frontend and verify basic functionality\n\n**Steps:**\n\n1. Open browser to http://localhost:3000\n2. Open browser DevTools Console (F12 → Console tab)\n3. Click \"Connect\" or \"Start Session\" button\n4. Grant microphone permissions when prompted\n5. Observe connection states in UI:\n   - \"Initializing...\"\n   - \"Listening\" (agent ready for input)\n   - \"Thinking\" (processing speech)\n   - \"Speaking\" (agent responding)\n\n**Expected Behavior:**\n- Connection establishes within 3-5 seconds\n- Agent state transitions to \"Listening\"\n- No errors in browser console\n- Agent logs show room join event\n\n**Troubleshooting:**\n- **Connection hangs:** Check token endpoint, verify LIVEKIT_URL is correct\n- **\"Failed to connect\":** Check agent status (`lk agent status`), verify agent is Running\n- **Microphone permission denied:** Grant permission in browser settings\n- **No audio:** Check browser audio output, verify speakers are enabled\n- **WebRTC errors:** Check firewall, ensure WebRTC ports not blocked\n\n**Rationale:** Validates basic connection before testing voice interaction\n\n---\n\n#### 4.3: Test Voice Interaction\n\n**What:** Verify end-to-end voice pipeline (STT → LLM → TTS)\n\n**Steps:**\n\n1. With frontend connected and agent in \"Listening\" state\n2. Speak clearly into your microphone: \"Hello, can you hear me?\"\n3. Observe agent state transition:\n   - \"Listening\" → \"Thinking\" → \"Speaking\"\n4. Listen for agent's voice response\n5. Check agent logs for:\n   - STT transcription of your speech\n   - LLM request and response\n   - TTS generation\n\n**Expected Outcome:**\n- Agent responds with natural voice within 2-4 seconds\n- Transcription appears in logs (if logging enabled)\n- No audio dropouts or distortion\n- Agent response is contextually appropriate\n\n**Additional Test Cases:**\n- **Interruption:** Speak while agent is speaking (should handle gracefully)\n- **Silence:** Wait 10 seconds without speaking (agent should remain connected)\n- **Background Noise:** Test with ambient noise (should filter with VAD)\n- **Multiple Turns:** Have a multi-turn conversation\n\n**Troubleshooting:**\n- **No transcription:** Check AssemblyAI API key in agent secrets\n- **No LLM response:** Check OpenAI API key, verify LLM model is available\n- **No TTS audio:** Check Cartesia API key, verify TTS voice model\n- **Garbled audio:** Check network connection, reduce network congestion\n- **High latency:** Check agent logs for slow API calls, consider region optimization\n\n**Rationale:** Validates the complete voice AI pipeline works end-to-end\n\n---\n\n#### 4.4: Verify Audio Visualization\n\n**What:** Test the audio visualizer component works correctly\n\n**Steps:**\n\n1. With frontend connected\n2. Speak into microphone\n3. Observe audio visualization:\n   - Bars should animate when you speak\n   - Bars should pulse when agent speaks\n   - Different colors/states for listening vs speaking\n\n**Expected Behavior:**\n- `BarVisualizer` component shows real-time audio levels\n- Smooth animations\n- Clear visual feedback of agent state\n- No lag between audio and visualization\n\n**Check Component:**\n```bash\n# Review visualizer component\ncat frontend/voice-ai-frontend/components/agents-ui/bar-visualizer.tsx\n```\n\n**Troubleshooting:**\n- **No visualization:** Check if audio track is being passed to component\n- **Choppy animation:** Check browser performance, reduce animation complexity\n- **Wrong colors:** Review CSS/Tailwind classes\n\n**Rationale:** Visual feedback improves user experience and debugging\n\n---\n\n#### 4.5: Test Disconnection and Reconnection\n\n**What:** Verify graceful disconnect and ability to reconnect\n\n**Steps:**\n\n**Test Disconnect:**\n1. With frontend connected\n2. Click \"Disconnect\" or \"End Session\" button\n3. Observe clean disconnect:\n   - Agent logs show participant left\n   - No error messages\n   - UI returns to welcome screen\n\n**Test Reconnect:**\n1. Click \"Connect\" again\n2. Verify new session starts successfully\n3. Test voice interaction again\n\n**Test Network Interruption (Optional):**\n1. While connected, disable network (Wi-Fi off)\n2. Observe reconnection behavior\n3. Re-enable network\n4. Verify auto-reconnect or error message\n\n**Expected Behavior:**\n- Clean disconnect without errors\n- Ability to reconnect immediately\n- Each session gets unique room/token\n- No lingering WebRTC connections\n\n**Rationale:** Ensures robust connection lifecycle management\n\n---\n\n#### 4.6: Optimize Connection Speed\n\n**What:** Reduce connection time from 3-5 seconds to <1 second using optimization techniques\n\n**Current Flow (Sequential):**\n```\n1. Click Connect (0ms)\n2. Fetch token from /api/token (500ms)\n3. Connect to LiveKit room (1000ms)\n4. Agent dispatched (1000ms)\n5. Agent connects and publishes (1500ms)\nTotal: ~4000ms (4 seconds)\n```\n\n**Optimization 1: Pre-generate Tokens**\n\nCreate a \"warm token\" approach for faster connection:\n\n**File:** Create `frontend/voice-ai-frontend/hooks/use-warm-token.ts`\n\n```typescript\n'use client';\n\nimport { useState, useEffect } from 'react';\n\nexport function useWarmToken() {\n  const [token, setToken] = useState<string | null>(null);\n\n  useEffect(() => {\n    // Pre-generate token on page load\n    async function generateToken() {\n      const response = await fetch('/api/token', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          roomName: `room-${Date.now()}`,\n          participantName: `user-${Math.random().toString(36).substring(7)}`,\n        }),\n      });\n      const data = await response.json();\n      setToken(data.token);\n    }\n\n    generateToken();\n  }, []);\n\n  return token;\n}\n```\n\n**Usage in Session Component:**\n```typescript\n// In session-view.tsx or similar\nconst warmToken = useWarmToken();\n\n// Use warmToken when connecting instead of fetching on-demand\n```\n\n**Optimization 2: Concurrent Dispatch**\n\nModify connection logic to dispatch agent and connect user simultaneously:\n\n```typescript\n// Parallel connection\nconst [roomConnection, agentDispatch] = await Promise.all([\n  connectToRoom(token),\n  dispatchAgent(roomName) // If manual dispatch required\n]);\n```\n\n**Expected Improvement:**\n- Pre-generated token: -500ms (eliminates token fetch delay)\n- Concurrent dispatch: -1000ms (parallel instead of sequential)\n- **New total:** ~2500ms → ~1500ms (1.5 seconds)\n\n**Trade-offs:**\n- Pre-generated tokens have expiration (ensure 2h TTL)\n- Unused tokens waste resources (minimal cost)\n- Complexity slightly increases\n\n**Rationale:** Faster connections improve user experience and perceived performance\n\n---\n\n#### 4.7: Test on Multiple Browsers\n\n**What:** Verify cross-browser compatibility\n\n**Browsers to Test:**\n- Chrome/Chromium\n- Firefox\n- Safari (macOS/iOS)\n- Edge\n\n**Test Matrix:**\n\n| Browser | Connection | Audio Input | Audio Output | Visualization |\n|---------|-----------|-------------|--------------|---------------|\n| Chrome  | ✓         | ✓           | ✓            | ✓             |\n| Firefox | ?         | ?           | ?            | ?             |\n| Safari  | ?         | ?           | ?            | ?             |\n| Edge    | ?         | ?           | ?            | ?             |\n\n**Common Issues:**\n- **Safari:** May require user interaction before audio playback\n- **Firefox:** Different WebRTC implementation, may have quirks\n- **Mobile Safari:** Requires specific audio context handling\n- **Edge:** Generally compatible with Chrome\n\n**Rationale:** Ensures wide browser support for production deployment\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Connection establishes successfully: Monitor for \"Room connected\" event in logs\n- [ ] Agent joins room: `lk agent logs` shows room join event\n- [ ] WebRTC connection: Browser DevTools Network tab shows WebRTC connections\n- [ ] No console errors: Browser DevTools Console shows no red errors\n- [ ] Audio tracks published: Check LiveKit Cloud dashboard for active tracks\n\n#### Manual Verification:\n\n- [ ] Voice input recognized: Speak and verify agent responds\n- [ ] Voice output works: Hear agent's TTS response clearly\n- [ ] Audio visualization animates correctly\n- [ ] Agent state transitions work (initializing → listening → thinking → speaking)\n- [ ] Interruption handling works (speak during agent response)\n- [ ] Disconnect and reconnect works cleanly\n- [ ] Connection time <3 seconds (before optimization) or <1.5s (after optimization)\n- [ ] Works in Chrome, Firefox, and Safari\n\n**Verify:** After completing automated verification, have a multi-turn conversation with the agent and test all edge cases before proceeding to Phase 5.\n\n---\n\n## Phase 5: Frontend Customization\n\n### Overview\n\nCustomize the frontend with your branding, colors, logo, and company information to make it production-ready.\n\n### Context\n\nBefore starting, ensure:\n- Phase 4 completed successfully\n- Voice interaction working end-to-end\n- Frontend running at http://localhost:3000\n\nFiles to customize:\n- `frontend/voice-ai-frontend/app-config.ts` - Main configuration\n- `frontend/voice-ai-frontend/public/` - Static assets (logo, favicon)\n- `frontend/voice-ai-frontend/app/layout.tsx` - Page metadata\n- `frontend/voice-ai-frontend/tailwind.config.ts` - Theme colors\n\n### Dependencies\n\n**Depends on:** Phase 4 (connection testing completed)\n\n**Required by:** Phase 6 (production deployment)\n\n### Changes Required\n\n#### 5.1: Update App Configuration\n\n**What:** Customize company name, page title, and feature flags\n\n**File:** `frontend/voice-ai-frontend/app-config.ts`\n\n**Edit:**\n```typescript\nexport const APP_CONFIG_DEFAULTS = {\n  // Branding\n  companyName: \"Your Company Name\", // Change this\n  pageTitle: \"AI Voice Assistant | Your Company\", // Change this\n\n  // Logo URLs\n  logoUrl: \"/logo.svg\", // Update after adding logo in 5.2\n  logoUrlDark: \"/logo-dark.svg\", // Optional: separate dark mode logo\n\n  // Accent color\n  accentColor: \"#4F46E5\", // Change to your brand color (hex)\n\n  // Feature toggles - AUDIO-ONLY CONFIGURATION\n  supportsChatInput: false, // Disable text chat (audio-only)\n  supportsVideoInput: false, // DISABLE camera video (audio-only)\n  supportsScreenShare: false, // DISABLE screen sharing (audio-only)\n  isPreConnectBufferEnabled: true, // Pre-load for faster connection\n\n  // Optional: Agent configuration\n  defaultAgentName: \"\", // Leave blank for auto-dispatch\n};\n```\n\n**Example Customization:**\n```typescript\nexport const APP_CONFIG_DEFAULTS = {\n  companyName: \"Acme Voice AI\",\n  pageTitle: \"Voice AI Assistant | Acme Corp\",\n  logoUrl: \"/acme-logo.svg\",\n  accentColor: \"#FF6B35\", // Orange\n  supportsChatInput: true,\n  supportsVideoInput: false, // Disable video for voice-only\n  supportsScreenShare: false,\n  isPreConnectBufferEnabled: true,\n};\n```\n\n**Rationale:** Centralizes configuration for easy customization without code changes\n\n---\n\n#### 5.2: Add Custom Logo\n\n**What:** Replace default logo with your company logo\n\n**Steps:**\n\n1. Prepare logo files:\n   - **Format:** SVG (preferred) or PNG\n   - **Size:**\n     - SVG: Any size (scalable)\n     - PNG: 200x200px minimum, transparent background\n   - **Naming:**\n     - Light mode: `logo.svg` or `logo.png`\n     - Dark mode (optional): `logo-dark.svg` or `logo-dark.png`\n\n2. Copy to public directory:\n   ```bash\n   cp /path/to/your/logo.svg frontend/voice-ai-frontend/public/logo.svg\n   # Optional: dark mode logo\n   cp /path/to/your/logo-dark.svg frontend/voice-ai-frontend/public/logo-dark.svg\n   ```\n\n3. Update `app-config.ts`:\n   ```typescript\n   logoUrl: \"/logo.svg\",\n   logoUrlDark: \"/logo-dark.svg\", // If you have separate dark logo\n   ```\n\n4. Verify logo appears:\n   - Restart dev server: `pnpm dev`\n   - Visit http://localhost:3000\n   - Check logo displays correctly\n   - Toggle light/dark mode to test both logos\n\n**Fallback:**\nIf you don't have a logo ready, the template includes a default placeholder logo.\n\n**Rationale:** Custom logo reinforces brand identity\n\n---\n\n#### 5.3: Customize Theme Colors\n\n**What:** Update color scheme to match your brand\n\n**File:** `frontend/voice-ai-frontend/tailwind.config.ts`\n\n**Edit:**\n```typescript\nexport default {\n  theme: {\n    extend: {\n      colors: {\n        // Primary brand color\n        primary: {\n          50: '#f0f9ff',\n          100: '#e0f2fe',\n          // ... continue through 950\n          500: '#4F46E5', // Main brand color (change this)\n          600: '#4338ca',\n          // ...\n        },\n        // Accent color\n        accent: {\n          DEFAULT: '#FF6B35', // Change to your accent color\n          light: '#FF8A5B',\n          dark: '#E5501F',\n        },\n      },\n    },\n  },\n};\n```\n\n**Quick Method (Use Accent Color from app-config.ts):**\n\nThe template may automatically use `accentColor` from `app-config.ts`. If so, just update that value:\n\n```typescript\n// In app-config.ts\naccentColor: \"#FF6B35\", // Your brand color\n```\n\n**Generate Full Color Palette:**\nUse tools like https://uicolors.app/create to generate a full Tailwind color palette from your brand color.\n\n**Test Theme:**\n- Restart dev server\n- Visit http://localhost:3000\n- Check buttons, links, highlights use new colors\n- Toggle light/dark mode to verify both themes\n\n**Rationale:** Consistent color scheme creates professional, branded experience\n\n---\n\n#### 5.4: Update Page Metadata\n\n**What:** Set page title, description, and favicon for SEO and browser display\n\n**File:** `frontend/voice-ai-frontend/app/layout.tsx`\n\n**Edit:**\n```typescript\nexport const metadata: Metadata = {\n  title: \"AI Voice Assistant | Your Company\", // Change this\n  description: \"Connect with our AI voice assistant for instant help and support.\", // Change this\n  icons: {\n    icon: '/favicon.ico', // Update after adding favicon\n  },\n  openGraph: {\n    title: \"AI Voice Assistant | Your Company\",\n    description: \"Connect with our AI voice assistant for instant help and support.\",\n    images: ['/og-image.png'], // Optional: social share image\n  },\n};\n```\n\n**Add Custom Favicon:**\n\n1. Generate favicon files (use https://realfavicongenerator.net/):\n   - `favicon.ico` (16x16, 32x32, 48x48)\n   - `apple-touch-icon.png` (180x180)\n   - `favicon-16x16.png`\n   - `favicon-32x32.png`\n\n2. Copy to `public/`:\n   ```bash\n   cp /path/to/favicon.ico frontend/voice-ai-frontend/public/\n   cp /path/to/apple-touch-icon.png frontend/voice-ai-frontend/public/\n   ```\n\n3. Verify in browser:\n   - Clear browser cache\n   - Visit http://localhost:3000\n   - Check browser tab shows your favicon\n\n**Optional: Open Graph Image (Social Sharing):**\nCreate `og-image.png` (1200x630px) for social media previews.\n\n**Rationale:** Professional metadata improves SEO and user experience\n\n---\n\n#### 5.5: Customize Welcome Message\n\n**What:** Update the welcome screen text and instructions\n\n**File:** `frontend/voice-ai-frontend/components/app/welcome-view.tsx` or similar\n\n**Find and Edit:**\n```typescript\n<h1>Welcome to [Your Company] Voice AI</h1>\n<p>\n  Click the button below to start a voice conversation with our AI assistant.\n  We can help you with questions, information, and more.\n</p>\n```\n\n**Example Customization:**\n```typescript\n<h1>Welcome to Acme Voice Assistant</h1>\n<p>\n  Our AI assistant is ready to help you 24/7. Click \"Connect\" to start a\n  natural voice conversation. Just speak naturally - no keywords or commands needed.\n</p>\n<ul>\n  <li>Get instant answers to your questions</li>\n  <li>Learn about our products and services</li>\n  <li>Get personalized recommendations</li>\n</ul>\n```\n\n**Rationale:** Clear messaging helps users understand what to expect\n\n---\n\n#### 5.6: Optional - Disable Features Not Needed\n\n**What:** Hide video/screen share features if you only need voice\n\n**File:** `frontend/voice-ai-frontend/app-config.ts`\n\n**For Voice-Only App:**\n```typescript\nexport const APP_CONFIG_DEFAULTS = {\n  // ... other settings\n  supportsChatInput: false, // Disable text chat\n  supportsVideoInput: false, // Disable camera\n  supportsScreenShare: false, // Disable screen sharing\n  isPreConnectBufferEnabled: true, // Keep for faster connection\n};\n```\n\n**Effect:**\n- Video camera icon hidden\n- Screen share button removed\n- UI simplified to voice-only interface\n- Reduced complexity for users\n\n**Rationale:** Simplify UI by removing unused features\n\n---\n\n#### 5.7: Test Customizations\n\n**What:** Verify all customizations display correctly\n\n**Checklist:**\n- [ ] Company name displays on welcome screen\n- [ ] Custom logo appears (both light and dark modes)\n- [ ] Page title shows in browser tab\n- [ ] Custom favicon appears in browser tab\n- [ ] Brand colors visible on buttons and accents\n- [ ] Welcome message updated with custom text\n- [ ] Disabled features are hidden (if applicable)\n- [ ] No broken images or 404s\n- [ ] Responsive design maintained on mobile\n\n**Testing Steps:**\n1. Restart dev server: `pnpm dev`\n2. Clear browser cache (Cmd+Shift+R on Mac, Ctrl+Shift+R on Windows)\n3. Visit http://localhost:3000\n4. Toggle light/dark theme\n5. Resize browser to mobile size (375px width)\n6. Check all visual elements\n\n**Rationale:** Ensures professional, branded appearance before production deployment\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Build succeeds: `pnpm run build` completes without errors\n- [ ] No TypeScript errors: `pnpm run type-check` (if available)\n- [ ] Static assets exist: `ls public/logo.svg public/favicon.ico`\n- [ ] Config updated: `cat app-config.ts | grep companyName` shows your company\n\n#### Manual Verification:\n\n- [ ] Custom company name displays on welcome screen\n- [ ] Custom logo visible (light and dark modes)\n- [ ] Page title correct in browser tab\n- [ ] Favicon visible in browser tab\n- [ ] Brand colors applied throughout UI\n- [ ] Welcome message updated\n- [ ] Unused features hidden (if disabled)\n- [ ] Mobile responsive (test at 375px width)\n- [ ] No console errors or warnings\n- [ ] All images load correctly (no broken images)\n\n**Verify:** After completing automated verification, thoroughly test the UI on desktop and mobile, in light and dark modes, before proceeding to Phase 6.\n\n---\n\n## Phase 6: Production Deployment\n\n### Overview\n\nDeploy the customized frontend to Vercel (or another hosting provider) to make it publicly accessible via a URL that clients can visit.\n\n### Context\n\nBefore starting, ensure:\n- Phase 5 completed successfully\n- All customizations tested locally\n- Frontend builds successfully (`pnpm run build`)\n- Agent deployed and running on LiveKit Cloud\n\nFiles to review:\n- `frontend/voice-ai-frontend/.env.local` - Environment variables (will configure in Vercel)\n- `frontend/voice-ai-frontend/next.config.js` - Next.js configuration\n- `frontend/voice-ai-frontend/package.json` - Dependencies and scripts\n\nAccounts needed:\n- Vercel account (free tier sufficient): https://vercel.com\n- GitHub account (for connecting repo)\n\n### Dependencies\n\n**Depends on:** Phases 1-5 (agent deployed, frontend customized and tested)\n\n**Required by:** None (final phase)\n\n### Changes Required\n\n#### 6.1: Create Production Build\n\n**What:** Verify the production build works correctly before deploying\n\n**Commands:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\n\n# Create production build\npnpm run build\n\n# Test production build locally\npnpm start\n```\n\n**Expected Output:**\n```\n> next build\n\n✓ Compiled successfully\n✓ Linting and checking validity of types\n✓ Collecting page data\n✓ Generating static pages (X/X)\n✓ Finalizing page optimization\n\nRoute (app)                              Size     First Load JS\n┌ ○ /                                    XXX kB        XXX kB\n└ ○ /api/token                          XXX B          XXX kB\n```\n\n**Test Production Build:**\n1. Visit http://localhost:3000 (pnpm start)\n2. Connect to agent\n3. Verify voice interaction works\n4. Check for any errors in console\n\n**Troubleshooting:**\n- If build fails: Check TypeScript errors, fix before proceeding\n- If errors about environment variables: Ensure `.env.local` exists\n- If runtime errors: Check browser console for specific issues\n\n**Rationale:** Catches production-specific issues before deployment\n\n---\n\n#### 6.2: Push Frontend to GitHub (Optional but Recommended)\n\n**What:** Create a Git repository for the frontend to enable easy Vercel deployment\n\n**Option A: Separate Repository (Recommended):**\n\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\n\n# Initialize git repository\ngit init\n\n# Add .gitignore for Next.js\ncat > .gitignore << 'EOF'\n# Next.js\n.next/\nout/\nbuild/\ndist/\n\n# Dependencies\nnode_modules/\n\n# Environment variables\n.env\n.env.local\n.env.production.local\n.env.development.local\n.env.test.local\n\n# Logs\nnpm-debug.log*\nyarn-debug.log*\nyarn-error.log*\npnpm-debug.log*\n\n# OS\n.DS_Store\n*.swp\n*.swo\n\n# IDE\n.vscode/\n.idea/\n\n# Vercel\n.vercel\nEOF\n\n# Add files\ngit add .\ngit commit -m \"Initial commit: Voice AI frontend\"\n\n# Create GitHub repository (via GitHub UI or CLI)\ngh repo create voice-ai-frontend --public --source=. --remote=origin --push\n```\n\n**Option B: Same Repository as Agent:**\n\nIf you want frontend and agent in the same repo:\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\n\n# Remove frontend/ from .gitignore\nsed -i '' '/^frontend\\//d' .gitignore\n\n# Add and commit\ngit add frontend/\ngit commit -m \"Add voice AI frontend\"\ngit push\n```\n\n**Rationale:** Git repository enables continuous deployment and version control\n\n---\n\n#### 6.3: Sign Up for Vercel\n\n**What:** Create a Vercel account for hosting the frontend\n\n**Steps:**\n\n1. Visit https://vercel.com\n2. Click \"Sign Up\"\n3. Choose \"Continue with GitHub\" (recommended)\n4. Authorize Vercel to access your GitHub repositories\n\n**Pricing:**\n- **Free Tier:** Sufficient for testing and low traffic\n  - Unlimited deployments\n  - 100 GB bandwidth/month\n  - Serverless functions included\n- **Pro Tier:** $20/month (for production with higher traffic)\n\n**Rationale:** Vercel provides seamless Next.js hosting with automatic deployments\n\n---\n\n#### 6.4: Deploy Frontend to Vercel\n\n**What:** Deploy the frontend application to Vercel\n\n**Steps:**\n\n1. **From Vercel Dashboard:**\n   - Click \"Add New...\" → \"Project\"\n   - Select \"Import Git Repository\"\n   - Choose your frontend repository\n   - Configure project:\n     - **Framework Preset:** Next.js (auto-detected)\n     - **Root Directory:** `./` (or `frontend/voice-ai-frontend` if in monorepo)\n     - **Build Command:** `pnpm run build` (auto-detected)\n     - **Output Directory:** `.next` (auto-detected)\n     - **Install Command:** `pnpm install` (auto-detected)\n\n2. **Configure Environment Variables:**\n   Click \"Environment Variables\" and add:\n\n   ```\n   LIVEKIT_API_KEY=APIxxxxxxxxxxxx\n   LIVEKIT_API_SECRET=your-secret-here\n   LIVEKIT_URL=wss://your-project.livekit.cloud\n   NEXT_PUBLIC_LIVEKIT_URL=wss://your-project.livekit.cloud\n   AGENT_NAME=\n   ```\n\n   **Important:**\n   - Copy values from your local `.env.local`\n   - Apply to \"Production\", \"Preview\", and \"Development\" environments\n\n3. **Deploy:**\n   - Click \"Deploy\"\n   - Wait for build to complete (2-5 minutes)\n\n**Expected Outcome:**\n```\n✓ Build successful\n✓ Deployment successful\nYour project is now live at: https://your-app.vercel.app\n```\n\n**Rationale:** Makes frontend publicly accessible via HTTPS URL\n\n---\n\n#### 6.5: Test Production Deployment\n\n**What:** Verify the deployed frontend works correctly\n\n**Steps:**\n\n1. Visit your Vercel URL: `https://your-app.vercel.app`\n\n2. **Test Checklist:**\n   - [ ] Page loads without errors\n   - [ ] Custom branding displays correctly\n   - [ ] Click \"Connect\" button\n   - [ ] Grant microphone permissions\n   - [ ] Speak to agent\n   - [ ] Verify agent responds with voice\n   - [ ] Test on mobile device\n   - [ ] Test in different browsers\n\n3. **Monitor Logs:**\n   ```bash\n   # Monitor agent logs during production test\n   lk agent logs --follow\n   ```\n\n4. **Check Vercel Deployment Logs:**\n   - Go to Vercel dashboard → Your project → Deployments\n   - Click on latest deployment → \"Functions\" tab\n   - Check for any errors in `/api/token` function\n\n**Troubleshooting:**\n- **\"Failed to connect\":** Check environment variables in Vercel\n- **Token errors:** Verify `LIVEKIT_API_KEY` and `LIVEKIT_API_SECRET` are correct\n- **CORS errors:** Ensure `NEXT_PUBLIC_LIVEKIT_URL` is set correctly\n- **Agent not joining:** Check agent status, verify agent is Running\n\n**Rationale:** Ensures production environment works correctly\n\n---\n\n#### 6.6: Configure Custom Domain (Optional)\n\n**What:** Use a custom domain instead of `your-app.vercel.app`\n\n**Prerequisites:**\n- Own a domain name (e.g., `voiceai.yourcompany.com`)\n- Access to domain DNS settings\n\n**Steps:**\n\n1. **In Vercel Dashboard:**\n   - Go to your project → Settings → Domains\n   - Click \"Add Domain\"\n   - Enter your domain: `voiceai.yourcompany.com`\n\n2. **Configure DNS:**\n   Vercel will provide DNS configuration instructions:\n\n   **Option A: CNAME (Subdomain):**\n   ```\n   Type: CNAME\n   Name: voiceai\n   Value: cname.vercel-dns.com\n   ```\n\n   **Option B: A Record (Root Domain):**\n   ```\n   Type: A\n   Name: @\n   Value: 76.76.21.21\n   ```\n\n3. **Wait for DNS Propagation:**\n   - Usually takes 5-60 minutes\n   - Vercel will auto-configure SSL certificate (Let's Encrypt)\n\n4. **Verify:**\n   - Visit `https://voiceai.yourcompany.com`\n   - Should show your frontend with SSL (green lock icon)\n\n**Rationale:** Custom domain provides professional appearance and brand consistency\n\n---\n\n#### 6.7: Enable Automatic Deployments\n\n**What:** Configure automatic deployments when you push to GitHub\n\n**Vercel Auto-Deploys By Default:**\n- **Production:** Deploys on push to `main` branch\n- **Preview:** Deploys on push to any other branch or PR\n\n**Customize (Optional):**\n1. Go to Vercel dashboard → Your project → Settings → Git\n2. Configure:\n   - **Production Branch:** `main` (or `master`)\n   - **Ignored Build Step:** (leave blank to build on every commit)\n\n**Test Automatic Deployment:**\n```bash\ncd frontend/voice-ai-frontend\n\n# Make a small change\necho \"# Updated\" >> README.md\n\n# Commit and push\ngit add README.md\ngit commit -m \"Test automatic deployment\"\ngit push origin main\n```\n\n**Verify:**\n- Visit Vercel dashboard\n- Should see new deployment triggered automatically\n- Wait for build to complete\n- Visit production URL to see changes\n\n**Rationale:** Enables continuous deployment for easy updates\n\n---\n\n#### 6.8: Set Up Production Monitoring (Recommended)\n\n**What:** Monitor production errors and usage\n\n**Vercel Analytics (Built-in):**\n1. Go to Vercel dashboard → Your project → Analytics\n2. View:\n   - Page views\n   - Geographic distribution\n   - Performance metrics (Web Vitals)\n\n**Error Tracking (Optional):**\nConsider integrating Sentry or similar:\n```bash\npnpm add @sentry/nextjs\nnpx @sentry/wizard@latest -i nextjs\n```\n\n**LiveKit Cloud Monitoring:**\n- Visit LiveKit Cloud dashboard\n- Monitor:\n  - Active sessions\n  - Agent usage\n  - Costs (session minutes)\n\n**Rationale:** Production monitoring helps identify and resolve issues quickly\n\n---\n\n#### 6.9: Create Shareable Link\n\n**What:** Generate a clean, shareable URL for potential clients\n\n**Your Production URL:**\n```\nhttps://your-app.vercel.app\n```\n\n**Or with Custom Domain:**\n```\nhttps://voiceai.yourcompany.com\n```\n\n**Create Marketing Materials:**\n- Add link to your website\n- Share via email campaigns\n- Include in social media bios\n- Create QR code for physical materials\n\n**Example QR Code Generation:**\n```bash\n# Generate QR code (using qrencode)\nbrew install qrencode\nqrencode -o voiceai-qr.png \"https://voiceai.yourcompany.com\"\n```\n\n**Rationale:** Easy sharing enables potential clients to access your voice AI\n\n---\n\n#### 6.10: Document Production URLs and Credentials\n\n**What:** Save all production information for future reference\n\n**Create:** `frontend/voice-ai-frontend/PRODUCTION.md`\n\n**Content:**\n```markdown\n# Production Deployment Information\n\n## URLs\n- **Production Frontend:** https://your-app.vercel.app\n- **Custom Domain:** https://voiceai.yourcompany.com (if configured)\n- **LiveKit Cloud Dashboard:** https://cloud.livekit.io\n\n## Vercel\n- **Project:** voice-ai-frontend\n- **Account:** your-email@example.com\n- **Git Repository:** https://github.com/yourusername/voice-ai-frontend\n\n## LiveKit Cloud\n- **Project:** your-project-name\n- **Region:** us-west-2\n- **Agent ID:** agent_abc123\n\n## Deployment Commands\n```bash\n# Deploy agent updates\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\nlk agent deploy\n\n# Deploy frontend updates (automatic via Git)\ncd frontend/voice-ai-frontend\ngit add .\ngit commit -m \"Update frontend\"\ngit push origin main\n```\n\n## Monitoring\n- **Agent Logs:** `lk agent logs --follow`\n- **Vercel Logs:** https://vercel.com/your-project/deployments\n- **LiveKit Dashboard:** https://cloud.livekit.io/projects/your-project\n\n## Environment Variables (Vercel)\n- LIVEKIT_API_KEY=APIxxxxxxxxxxxx\n- LIVEKIT_API_SECRET=*** (not shown)\n- LIVEKIT_URL=wss://your-project.livekit.cloud\n- NEXT_PUBLIC_LIVEKIT_URL=wss://your-project.livekit.cloud\n\n## Costs\n- **LiveKit Cloud:** $0.01 per agent session minute\n- **Vercel:** Free tier (or $20/month Pro)\n\n## Support\n- **LiveKit:** https://livekit.io/discord\n- **Vercel:** https://vercel.com/support\n```\n\n**Rationale:** Documentation ensures you can manage production deployment long-term\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Production build succeeds: `pnpm run build` completes without errors\n- [ ] Vercel deployment successful: Deployment status shows \"Ready\"\n- [ ] HTTPS enabled: Visit production URL with green lock icon\n- [ ] Environment variables configured: Check Vercel dashboard\n- [ ] Custom domain configured (if applicable): DNS records set\n\n#### Manual Verification:\n\n- [ ] Visit production URL in browser\n- [ ] Page loads without errors\n- [ ] Custom branding displays correctly\n- [ ] Click \"Connect\" and grant microphone access\n- [ ] Speak to agent and verify voice response\n- [ ] Test on mobile device (iOS Safari, Android Chrome)\n- [ ] Test in incognito/private mode\n- [ ] Share URL with colleague and get confirmation it works\n- [ ] Agent logs show production sessions: `lk agent logs --follow`\n- [ ] No errors in Vercel function logs\n\n**Verify:** After completing automated verification, test the production URL on multiple devices and browsers, then share with a colleague to confirm public accessibility.\n\n---\n\n## Testing Strategy\n\n### Unit Tests\n\n**Not required for this plan.** The agent-starter-react template is a pre-built, production-ready template that doesn't require custom unit tests unless you add significant custom logic.\n\n**Optional:** Add tests if you customize components heavily:\n```bash\npnpm add -D @testing-library/react @testing-library/jest-dom jest\n```\n\n### Integration Tests\n\n**End-to-End Testing:**\n\nManually test the complete flow:\n1. User visits URL\n2. Clicks \"Connect\"\n3. Grants microphone access\n4. Speaks to agent\n5. Receives voice response\n6. Disconnects cleanly\n\n**Test Matrix:**\n\n| Scenario | Steps | Expected Outcome |\n|----------|-------|------------------|\n| First Connection | Visit URL → Click Connect → Speak | Agent responds with voice |\n| Interruption | Speak while agent is speaking | Agent handles gracefully |\n| Disconnect/Reconnect | End session → Start new session | New session works |\n| Multiple Turns | Have 3-5 turn conversation | All responses relevant |\n| Mobile Safari | Test on iPhone/iPad | Full functionality |\n| Network Interruption | Disable Wi-Fi during session | Reconnection or error message |\n\n### Manual Testing Steps\n\n**Pre-Deployment Checklist:**\n1. [ ] Agent deployed and running: `lk agent status`\n2. [ ] Local frontend works: `pnpm dev` at http://localhost:3000\n3. [ ] Voice interaction successful\n4. [ ] Audio visualization working\n5. [ ] Custom branding applied\n6. [ ] Production build succeeds: `pnpm run build`\n\n**Post-Deployment Checklist:**\n1. [ ] Production URL accessible\n2. [ ] HTTPS enabled (green lock)\n3. [ ] Voice interaction works on production\n4. [ ] Mobile responsive\n5. [ ] Cross-browser compatible\n6. [ ] Shareable link works for external users\n\n### Performance Considerations\n\n**Metrics to Monitor:**\n- **Connection Time:** Should be <3 seconds (or <1.5s with optimization)\n- **Response Latency:** STT → LLM → TTS should be 2-4 seconds\n- **Page Load Time:** Initial load <2 seconds (Lighthouse score >90)\n- **Audio Quality:** No dropouts or distortion\n\n**Optimization:**\n- Enable pre-connect buffering in `app-config.ts`\n- Use warm token approach (Phase 4.6)\n- Minimize bundle size (Next.js handles automatically)\n- Use CDN for static assets (Vercel provides automatically)\n\n## References\n\n### Original Ticket/Request\n- User request: \"I want potential clients to be able to interact with the livekit agent from this repo by clicking a link on a website.\"\n\n### Documentation\n- `docs/DEPLOYMENT.md` - Complete deployment guide for agent and frontend options\n- `README.md` - Project overview and setup instructions\n- `AGENTS.md` - Project guidelines and standards\n\n### LiveKit Resources\n- **Frontend Deployment Guide:** https://docs.livekit.io/agents/start/frontend/\n- **agent-starter-react Repository:** https://github.com/livekit-examples/agent-starter-react\n- **Token Authentication:** https://docs.livekit.io/home/get-started/authentication/\n- **Agents Playground:** https://agents-playground.livekit.io/\n- **LiveKit Cloud Dashboard:** https://cloud.livekit.io\n- **React Components Docs:** https://docs.livekit.io/reference/components/react/\n\n### NPM Packages\n- **livekit-client:** Client SDK for browser WebRTC\n- **@livekit/components-react:** React UI components\n- **livekit-server-sdk:** Server-side token generation\n\n### Vercel Resources\n- **Vercel Platform:** https://vercel.com\n- **Next.js Documentation:** https://nextjs.org/docs\n- **Deployment Docs:** https://vercel.com/docs\n\n### Related Plans\n- None (initial implementation)\n\n---\n\n**End of Implementation Plan**\n","structuredPatch":[{"oldStart":1446,"oldLines":16,"newStart":1446,"newLines":16,"lines":[" };"," ```"," ","-**Example Customization:**","+**Example Customization (Audio-Only):**"," ```typescript"," export const APP_CONFIG_DEFAULTS = {","   companyName: \"Acme Voice AI\",","   pageTitle: \"Voice AI Assistant | Acme Corp\",","   logoUrl: \"/acme-logo.svg\",","   accentColor: \"#FF6B35\", // Orange","-  supportsChatInput: true,","-  supportsVideoInput: false, // Disable video for voice-only","-  supportsScreenShare: false,","+  supportsChatInput: false, // Audio-only: no text chat","+  supportsVideoInput: false, // Audio-only: no camera","+  supportsScreenShare: false, // Audio-only: no screen share","   isPreConnectBufferEnabled: true,"," };"," ```"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"52b8e0cb-e29a-4903-9e4d-11259664c0a9"}
{"parentUuid":"27c25156-a7ed-4e1b-a57f-bbd175bf14e1","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","slug":"enumerated-shimmying-starlight","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01G6Sz5sN326v9eLgfUNrpum","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now let me update the section about disabling features to make it clearer that this is required, not optional.","signature":"EpYCCkYICxgCKkArC2SszdqwUaIaDQ0X2wofrbegDdwRArD7aD6uefL1aNxKCfytQPnQOnhs09w1/l1llA6v5gOrEEAfLIDHOjCfEgyQvYr/pTuZHAr6FGIaDFTAlDkTjMOTojhAcSIw21WuPaYLbE1eYRFdlf3dnRxvl7H/H3A3dkZ1/aS4dVbpGJE9XkrYewMoHXHhxHjKKn6VH5FXfcbPBaZpAKNUXujHYY2QXsv6PKYeA8ohaPk5wycdZKkQcgKHX6+CH9O7+p75rDRpqktpR6fXFUPkd+oPM/IHuoFMGJQ1alxUzEwvM7YWopxqJ90JzYXqOd4C7HYeBZE4T+1r5QHsw82GK4yzjTH+QlzewqylhFbGIiAYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":630,"cache_read_input_tokens":66993,"cache_creation":{"ephemeral_5m_input_tokens":630,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXTt8HBRrFQaJzsAXJx2C","type":"assistant","uuid":"6d924cc7-11c2-4069-9ecc-d304ac7eb304","timestamp":"2026-01-25T09:45:40.920Z"}
{"parentUuid":"6d924cc7-11c2-4069-9ecc-d304ac7eb304","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","slug":"enumerated-shimmying-starlight","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01G6Sz5sN326v9eLgfUNrpum","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_011QmYZr13yL93XqKr9UdFZr","name":"Edit","input":{"replace_all":false,"file_path":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/plan/future-plans/2026-01-25-web-frontend-deployment.md","old_string":"#### 5.6: Optional - Disable Features Not Needed\n\n**What:** Hide video/screen share features if you only need voice\n\n**File:** `frontend/voice-ai-frontend/app-config.ts`\n\n**For Voice-Only App:**\n```typescript\nexport const APP_CONFIG_DEFAULTS = {\n  // ... other settings\n  supportsChatInput: false, // Disable text chat\n  supportsVideoInput: false, // Disable camera\n  supportsScreenShare: false, // Disable screen sharing\n  isPreConnectBufferEnabled: true, // Keep for faster connection\n};\n```\n\n**Effect:**\n- Video camera icon hidden\n- Screen share button removed\n- UI simplified to voice-only interface\n- Reduced complexity for users\n\n**Rationale:** Simplify UI by removing unused features","new_string":"#### 5.6: Configure Audio-Only Mode (REQUIRED)\n\n**What:** Disable video/screen share features for audio-only application\n\n**File:** `frontend/voice-ai-frontend/app-config.ts`\n\n**REQUIRED Configuration for Audio-Only App:**\n```typescript\nexport const APP_CONFIG_DEFAULTS = {\n  // ... other settings\n  supportsChatInput: false, // Audio-only: disable text chat\n  supportsVideoInput: false, // REQUIRED: disable camera\n  supportsScreenShare: false, // REQUIRED: disable screen sharing\n  isPreConnectBufferEnabled: true, // Keep for faster connection\n};\n```\n\n**Effect:**\n- Video camera icon hidden\n- Screen share button removed\n- UI simplified to voice-only interface\n- No video/screenshare permission requests to users\n- Browser only requests microphone permission\n\n**IMPORTANT:** This is a required configuration for this audio-only application. Do NOT enable video or screen sharing features.\n\n**Rationale:** This application is designed for audio-only interaction. No video capabilities should be exposed to users."}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8,"cache_creation_input_tokens":630,"cache_read_input_tokens":66993,"cache_creation":{"ephemeral_5m_input_tokens":630,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard"}},"requestId":"req_011CXTt8HBRrFQaJzsAXJx2C","type":"assistant","uuid":"3d5c0514-7796-4319-8117-f806e8e92758","timestamp":"2026-01-25T09:45:50.240Z"}
{"parentUuid":"3d5c0514-7796-4319-8117-f806e8e92758","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","slug":"enumerated-shimmying-starlight","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_011QmYZr13yL93XqKr9UdFZr","type":"tool_result","content":"The file /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/plan/future-plans/2026-01-25-web-frontend-deployment.md has been updated successfully."}]},"uuid":"2283ca15-a619-414f-9a0c-3ea746d0c19c","timestamp":"2026-01-25T09:45:50.282Z","toolUseResult":{"filePath":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/plan/future-plans/2026-01-25-web-frontend-deployment.md","oldString":"#### 5.6: Optional - Disable Features Not Needed\n\n**What:** Hide video/screen share features if you only need voice\n\n**File:** `frontend/voice-ai-frontend/app-config.ts`\n\n**For Voice-Only App:**\n```typescript\nexport const APP_CONFIG_DEFAULTS = {\n  // ... other settings\n  supportsChatInput: false, // Disable text chat\n  supportsVideoInput: false, // Disable camera\n  supportsScreenShare: false, // Disable screen sharing\n  isPreConnectBufferEnabled: true, // Keep for faster connection\n};\n```\n\n**Effect:**\n- Video camera icon hidden\n- Screen share button removed\n- UI simplified to voice-only interface\n- Reduced complexity for users\n\n**Rationale:** Simplify UI by removing unused features","newString":"#### 5.6: Configure Audio-Only Mode (REQUIRED)\n\n**What:** Disable video/screen share features for audio-only application\n\n**File:** `frontend/voice-ai-frontend/app-config.ts`\n\n**REQUIRED Configuration for Audio-Only App:**\n```typescript\nexport const APP_CONFIG_DEFAULTS = {\n  // ... other settings\n  supportsChatInput: false, // Audio-only: disable text chat\n  supportsVideoInput: false, // REQUIRED: disable camera\n  supportsScreenShare: false, // REQUIRED: disable screen sharing\n  isPreConnectBufferEnabled: true, // Keep for faster connection\n};\n```\n\n**Effect:**\n- Video camera icon hidden\n- Screen share button removed\n- UI simplified to voice-only interface\n- No video/screenshare permission requests to users\n- Browser only requests microphone permission\n\n**IMPORTANT:** This is a required configuration for this audio-only application. Do NOT enable video or screen sharing features.\n\n**Rationale:** This application is designed for audio-only interaction. No video capabilities should be exposed to users.","originalFile":"# Web Frontend Deployment Implementation Plan\n\n> **Status:** DRAFT\n\n## Table of Contents\n\n- [Overview](#overview)\n- [Current State Analysis](#current-state-analysis)\n- [Desired End State](#desired-end-state)\n- [What We're NOT Doing](#what-were-not-doing)\n- [Implementation Approach](#implementation-approach)\n- [Dependencies](#dependencies)\n- [Phase 1: Agent Deployment to LiveKit Cloud](#phase-1-agent-deployment-to-livekit-cloud)\n- [Phase 2: Frontend Setup (agent-starter-react)](#phase-2-frontend-setup-agent-starter-react)\n- [Phase 3: Authentication and Token Generation](#phase-3-authentication-and-token-generation)\n- [Phase 4: Connection Testing and Optimization](#phase-4-connection-testing-and-optimization)\n- [Phase 5: Frontend Customization](#phase-5-frontend-customization)\n- [Phase 6: Production Deployment](#phase-6-production-deployment)\n- [Testing Strategy](#testing-strategy)\n- [References](#references)\n\n## Overview\n\nThis plan enables potential clients to interact with the LiveKit voice AI agent from this repository by clicking a link on a website. The implementation covers:\n\n1. Deploying the Python agent to LiveKit Cloud\n2. Setting up a Next.js/React frontend using the agent-starter-react template\n3. Implementing JWT token-based authentication\n4. Testing the connection flow\n5. Customizing the frontend with branding\n6. Deploying the frontend to production (Vercel)\n\nThe solution uses LiveKit's official starter templates and SDKs to create a production-ready web application with TypeScript/JavaScript.\n\n**IMPORTANT: This is an audio-only application. No video camera or screen sharing permissions should be requested from users. All configuration must disable video/screenshare features.**\n\n## Current State Analysis\n\n### What Exists Now\n\n**Agent Backend:**\n- Python voice AI agent in `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1`\n- Built with LiveKit Agents SDK\n- Uses OpenAI (LLM), AssemblyAI (STT), Cartesia (TTS)\n- Configured with `uv` package manager\n- Has `Dockerfile` for containerized deployment\n- Environment variables in `.env.local` (OpenAI, AssemblyAI, Cartesia API keys)\n\n**Missing:**\n- Agent not yet deployed to LiveKit Cloud\n- No web frontend for client interaction\n- No token generation server for authentication\n- No public-facing URL for clients to access\n\n### Key Discoveries\n\nFrom `docs/DEPLOYMENT.md`:\n- LiveKit Cloud deployment uses `lk` CLI\n- Agent deployment command: `lk agent create --secrets-file .env.local`\n- Multiple frontend options available (React, Flutter, Swift, Embed)\n- Connection requires JWT tokens generated server-side\n- agent-starter-react provides production-ready Next.js template\n- Token generation uses `livekit-server-sdk` npm package\n\n### Constraints\n\n1. **Security:** API secrets (LIVEKIT_API_SECRET) must never be exposed to frontend\n2. **Architecture:** Token generation must happen server-side (Next.js API routes)\n3. **Dependencies:** Agent must be deployed and running before frontend can connect\n4. **Cost:** LiveKit Cloud charges $0.01 per agent session minute\n\n## Desired End State\n\n### Success Criteria\n\n- [ ] Agent deployed and running on LiveKit Cloud\n- [ ] Next.js frontend application running locally\n- [ ] JWT token generation working via backend API route\n- [ ] Users can click a link and connect to voice AI agent\n- [ ] Audio conversation works end-to-end (STT → LLM → TTS)\n- [ ] Frontend deployed to production URL (Vercel)\n- [ ] Customized branding (logo, colors, company name)\n- [ ] Light/dark theme support\n- [ ] Audio visualization working\n- [ ] Mobile-responsive design\n\n### How to Verify\n\n**Agent Deployment:**\n```bash\nlk agent status\n# Expected: Status: Running, Replicas: X/X ready\n```\n\n**Frontend Connection:**\n1. Visit frontend URL (local: http://localhost:3000, prod: https://your-app.vercel.app)\n2. Click \"Connect\" or \"Start Session\"\n3. Grant microphone permissions when prompted\n4. Speak to the agent\n5. Verify agent responds with natural voice\n6. Check agent logs: `lk agent logs --follow`\n\n**End-to-End Test:**\n```bash\n# Terminal 1: Monitor agent logs\nlk agent logs --follow\n\n# Terminal 2: Run frontend\ncd /path/to/frontend\npnpm dev\n\n# Browser: Visit http://localhost:3000, connect, and speak\n```\n\n## What We're NOT Doing\n\n**Out of Scope:**\n- Multiple agent types or agent selection UI\n- User authentication/login system (anonymous users only)\n- Database integration or conversation history storage\n- Multi-language support (English only initially)\n- iOS/Android native apps (web only)\n- Custom voice customization UI\n- Payment integration or usage metering\n- Advanced analytics dashboard\n- Server-side rendering (SSR) for the voice interface\n- Custom WebRTC infrastructure (using LiveKit Cloud)\n\n**Future Considerations:**\n- User accounts and saved conversations\n- Analytics and usage tracking\n- Custom domain with branding\n- A/B testing different agent configurations\n- Rate limiting and abuse prevention\n\n## Implementation Approach\n\n### High-Level Strategy\n\n1. **Deploy Agent First:** Ensure the Python agent is running on LiveKit Cloud before building frontend\n2. **Use Official Template:** Start with agent-starter-react to avoid reinventing the wheel\n3. **Iterative Testing:** Test each phase independently before proceeding\n4. **Security-First:** Never expose API secrets; use environment variables and server-side token generation\n5. **Quick Validation:** Use LiveKit Agents Playground first to verify agent works before building frontend\n\n### Technology Stack\n\n**Backend (Agent):**\n- Python 3.11+\n- LiveKit Agents SDK\n- OpenAI GPT-4 (LLM)\n- AssemblyAI (STT)\n- Cartesia (TTS)\n- Deployed to: LiveKit Cloud\n\n**Frontend:**\n- Next.js 14+ (App Router)\n- React 18+\n- TypeScript\n- Tailwind CSS\n- Shadcn/ui components\n- `livekit-client` SDK\n- `@livekit/components-react`\n- Deployed to: Vercel\n\n**Authentication:**\n- JWT tokens (livekit-server-sdk)\n- Server-side generation (Next.js API routes)\n- 2-hour token expiration\n\n## Dependencies\n\n**Execution Order:**\n\n1. Phase 1: Agent Deployment (no dependencies)\n2. Phase 2: Frontend Setup (depends on Phase 1 for credentials)\n3. Phase 3: Authentication (depends on Phase 2)\n4. Phase 4: Connection Testing (depends on Phases 1-3)\n5. Phase 5: Frontend Customization (depends on Phase 4)\n6. Phase 6: Production Deployment (depends on Phase 5)\n\n**Dependency Graph:**\n\n```\nPhase 1 (Agent Deployment)\n  └─> Phase 2 (Frontend Setup)\n        └─> Phase 3 (Authentication)\n              └─> Phase 4 (Testing)\n                    └─> Phase 5 (Customization)\n                          └─> Phase 6 (Production)\n```\n\n**Parallelization:**\n- All phases are sequential due to dependencies\n- Within each phase, independent tasks can run in parallel\n\n---\n\n## Phase 1: Agent Deployment to LiveKit Cloud\n\n### Overview\n\nDeploy the Python voice AI agent to LiveKit Cloud to make it accessible via WebRTC. This creates a running agent that can be dispatched to rooms when users connect.\n\n### Context\n\nBefore starting, ensure you have:\n- LiveKit CLI installed: `brew install livekit/livekit/livekit-cli`\n- LiveKit Cloud account at https://cloud.livekit.io\n- Agent code in `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1`\n- API keys in `.env.local` (OpenAI, AssemblyAI, Cartesia)\n\nFiles to review:\n- `docs/DEPLOYMENT.md` - Complete deployment guide\n- `.env.local` - API keys and secrets\n- `Dockerfile` - Container build configuration\n- `src/app.py` - Agent entry point\n\n### Dependencies\n\n**Depends on:** None (first phase)\n\n**Required by:** Phase 2 (Frontend needs LiveKit credentials), Phase 4 (Testing needs deployed agent)\n\n### Changes Required\n\n#### 1.1: Authenticate with LiveKit Cloud\n\n**What:** Link your CLI to your LiveKit Cloud account\n\n**Command:**\n```bash\nlk cloud auth\n```\n\n**Expected Outcome:**\n- Browser opens for authentication\n- CLI displays: \"Successfully authenticated with LiveKit Cloud\"\n- Credentials saved in `~/.livekit/credentials`\n\n**Rationale:** Required for all subsequent `lk` CLI commands\n\n---\n\n#### 1.2: Create or Select LiveKit Project\n\n**What:** Create a new project or select an existing one for the agent deployment\n\n**Commands:**\n```bash\n# List existing projects\nlk project list\n\n# Option A: Use existing project\nlk project set-default \"your-project-name\"\n\n# Option B: Create new project via dashboard\n# Visit https://cloud.livekit.io and create a new project\n# Then set as default: lk project set-default \"new-project-name\"\n\n# Verify current project\nlk project current\n```\n\n**Expected Outcome:**\n```\nNAME                 PROJECT_ID\nyour-project-name   prj_abc123\n```\n\n**Rationale:** Agent deployments are scoped to projects; need a target project first\n\n---\n\n#### 1.3: Verify Secrets File\n\n**What:** Ensure `.env.local` contains all required API keys\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/.env.local`\n\n**Verify contents:**\n```bash\ncat .env.local\n```\n\n**Required secrets:**\n```env\nOPENAI_API_KEY=sk-...\nASSEMBLYAI_API_KEY=...\nCARTESIA_API_KEY=...\n```\n\n**Important Notes:**\n- Do NOT include `LIVEKIT_URL`, `LIVEKIT_API_KEY`, or `LIVEKIT_API_SECRET` in `.env.local`\n- LiveKit Cloud auto-injects these during deployment\n- Verify `.env.local` is in `.gitignore`\n\n**Rationale:** Agent needs these API keys to function; LiveKit Cloud encrypts and injects them as environment variables\n\n---\n\n#### 1.4: Download Model Files\n\n**What:** Download required models (Silero VAD, turn detector) before deployment\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\nuv run python src/app.py download-files\n```\n\n**Expected Outcome:**\n```\nDownloading Silero VAD model...\nDownloading multilingual turn detector model...\nDownload complete.\n```\n\n**Rationale:** Models are required at runtime; downloading during build ensures faster agent startup\n\n---\n\n#### 1.5: Deploy Agent to LiveKit Cloud\n\n**What:** Create and deploy the agent container to LiveKit Cloud\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\nlk agent create --secrets-file .env.local\n```\n\n**Expected Outcome:**\n```\nRegistering agent...\nAgent ID: agent_abc123\nBuilding container image...\nUploading code...\nBuild in progress (this may take 2-5 minutes)...\nBuild complete.\nDeploying agent...\nDeployment successful.\nStatus: Running\nReplicas: 2/2 ready\n```\n\n**What Happens:**\n1. CLI registers new agent with Cloud project\n2. Assigns unique agent ID (e.g., `agent_abc123`)\n3. Creates/updates `livekit.toml` configuration file\n4. Uploads source code to LiveKit build service\n5. Builds Docker container from `Dockerfile`\n6. Deploys container to Cloud project\n7. Encrypts and injects secrets as environment variables\n8. Starts 2 replica instances\n\n**Duration:** 2-5 minutes for initial build\n\n**Rationale:** Makes agent accessible via LiveKit's global WebRTC infrastructure\n\n---\n\n#### 1.6: Verify Agent Status\n\n**What:** Confirm agent is running and ready to accept sessions\n\n**Commands:**\n```bash\n# Check agent status\nlk agent status\n\n# View live logs\nlk agent logs --tail 50\n```\n\n**Expected Status Output:**\n```\nAgent ID:     agent_abc123\nStatus:       Running\nReplicas:     2/2 ready\nVersion:      v1\nLast Deploy:  2026-01-25 10:30:00 UTC\nRegion:       us-west-2\n```\n\n**Expected Log Output:**\n- No error messages\n- Successful initialization messages\n- \"Waiting for room assignment\" or similar\n\n**Troubleshooting:**\n- If status is `CrashLoop`: Check logs for Python exceptions\n- If status is `Build Failed`: Run `lk agent logs --build` to see build errors\n- If secrets missing: Run `lk agent secrets` to verify\n\n**Rationale:** Ensures agent is healthy before proceeding to frontend setup\n\n---\n\n#### 1.7: Quick Test with Agents Playground\n\n**What:** Test agent using LiveKit Agents Playground (no code required)\n\n**Steps:**\n1. Get project credentials:\n   ```bash\n   lk project current --json\n   ```\n\n2. Visit https://agents-playground.livekit.io/\n\n3. Enter credentials:\n   - **LiveKit URL:** `wss://your-project.livekit.cloud` (from JSON output)\n   - **API Key:** Your `LIVEKIT_API_KEY` (from JSON output)\n   - **API Secret:** Your `LIVEKIT_API_SECRET` (from JSON output)\n\n4. Click \"Connect\"\n\n5. Allow microphone access when prompted\n\n6. Speak to your agent\n\n7. Monitor agent logs in terminal:\n   ```bash\n   lk agent logs --follow\n   ```\n\n**Expected Outcome:**\n- Agent responds to your voice with natural TTS\n- Logs show STT transcriptions, LLM responses, TTS generation\n- No errors in logs\n\n**Rationale:** Validates agent works end-to-end before investing in frontend development\n\n---\n\n#### 1.8: Save LiveKit Credentials\n\n**What:** Export LiveKit project credentials for frontend configuration\n\n**Command:**\n```bash\nlk project current --json > livekit-credentials.json\n```\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/livekit-credentials.json`\n\n**Expected Contents:**\n```json\n{\n  \"name\": \"your-project-name\",\n  \"url\": \"wss://your-project.livekit.cloud\",\n  \"api_key\": \"APIxxxxxxxxxxxx\",\n  \"api_secret\": \"your-secret-here\"\n}\n```\n\n**Security Note:**\n- Add `livekit-credentials.json` to `.gitignore`\n- NEVER commit this file to version control\n- This file is for local reference only\n\n**Rationale:** Frontend needs these credentials to generate tokens and connect to LiveKit\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] CLI authenticated: `lk cloud auth` successful\n- [ ] Project selected: `lk project current` shows correct project\n- [ ] Agent deployed: `lk agent status` shows `Status: Running`\n- [ ] Replicas ready: `lk agent status` shows `X/X ready` (e.g., 2/2)\n- [ ] No crash loops: `lk agent logs --tail 50` shows no errors\n- [ ] Credentials saved: `livekit-credentials.json` exists and contains valid JSON\n\n#### Manual Verification:\n\n- [ ] Agents Playground connection successful\n- [ ] Agent responds to voice input with TTS output\n- [ ] Agent logs show successful STT → LLM → TTS pipeline\n- [ ] No API key errors in logs\n- [ ] Agent state transitions visible (initializing → listening → thinking → speaking)\n\n**Verify:** After completing automated verification, test agent with Agents Playground before proceeding to Phase 2.\n\n---\n\n## Phase 2: Frontend Setup (agent-starter-react)\n\n### Overview\n\nClone and configure the agent-starter-react template to create a Next.js web application that connects users to your deployed agent.\n\n### Context\n\nBefore starting, ensure:\n- Phase 1 completed successfully\n- Agent is running on LiveKit Cloud\n- `livekit-credentials.json` file exists with credentials\n\nPrerequisites:\n- Node.js 18+ installed\n- pnpm installed: `npm install -g pnpm`\n- `lk` CLI authenticated\n\nFiles to review:\n- `livekit-credentials.json` - LiveKit project credentials\n- N/A (frontend doesn't exist yet)\n\n### Dependencies\n\n**Depends on:** Phase 1 (needs LiveKit credentials)\n\n**Required by:** Phase 3 (authentication setup), Phase 4 (connection testing)\n\n### Changes Required\n\n#### 2.1: Create Frontend Project Directory\n\n**What:** Create a directory to house the frontend application\n\n**Commands:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\nmkdir -p frontend\ncd frontend\n```\n\n**Expected Outcome:**\n```\nDirectory created: /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/\n```\n\n**Rationale:** Separates frontend code from agent backend code\n\n---\n\n#### 2.2: Clone agent-starter-react Template\n\n**What:** Use LiveKit CLI to create a new project from the official template\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend\nlk app create --template agent-starter-react\n```\n\n**Interactive Prompts:**\n- **Project name:** (Press Enter for default or enter custom name like \"voice-ai-frontend\")\n- **Install dependencies?** Yes\n\n**Alternative (Manual Clone):**\n```bash\ngit clone https://github.com/livekit-examples/agent-starter-react.git voice-ai-frontend\ncd voice-ai-frontend\npnpm install\n```\n\n**Expected Outcome:**\n```\n✓ Created project: voice-ai-frontend\n✓ Installed dependencies\n✓ Ready to configure\n```\n\n**Directory Structure:**\n```\nfrontend/voice-ai-frontend/\n├── app/\n│   ├── api/token/route.ts     # Token generation endpoint\n│   ├── page.tsx               # Main page\n│   └── layout.tsx\n├── components/\n│   ├── agents-ui/             # Agents UI components\n│   ├── app/                   # Business logic\n│   └── ui/                    # Shadcn/ui primitives\n├── hooks/\n├── lib/\n├── public/\n├── package.json\n├── .env.example\n└── next.config.js\n```\n\n**Rationale:** Official template provides production-ready structure with all necessary LiveKit integrations\n\n---\n\n#### 2.3: Configure Environment Variables\n\n**What:** Set up LiveKit credentials for the frontend\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend/.env.local`\n\n**Commands:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\ncp .env.example .env.local\n```\n\n**Edit `.env.local`:**\n```env\n# LiveKit project credentials (from livekit-credentials.json)\nLIVEKIT_API_KEY=APIxxxxxxxxxxxx\nLIVEKIT_API_SECRET=your-secret-here\nLIVEKIT_URL=wss://your-project.livekit.cloud\n\n# Public URL (exposed to browser - same as LIVEKIT_URL)\nNEXT_PUBLIC_LIVEKIT_URL=wss://your-project.livekit.cloud\n\n# Agent configuration\nAGENT_NAME=\n# Leave AGENT_NAME blank for automatic agent dispatch\n# Or set to specific agent name if you have multiple agents\n```\n\n**How to Get Values:**\n```bash\n# Copy from livekit-credentials.json\ncat /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/livekit-credentials.json\n```\n\n**Security Notes:**\n- `LIVEKIT_API_SECRET` is server-side only (never exposed to browser)\n- `NEXT_PUBLIC_*` variables are exposed to browser\n- Only `NEXT_PUBLIC_LIVEKIT_URL` should be public\n- Never expose `LIVEKIT_API_KEY` or `LIVEKIT_API_SECRET` to browser\n\n**Rationale:** Frontend needs credentials to generate tokens and connect to LiveKit rooms\n\n---\n\n#### 2.4: Verify Dependencies Installation\n\n**What:** Ensure all npm packages are installed correctly\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\npnpm install\n```\n\n**Expected Outcome:**\n```\nPackages: +XXX\nProgress: resolved XXX, reused XXX, downloaded X, added XXX, done\n```\n\n**Key Dependencies (verify in `package.json`):**\n- `next` (v14+)\n- `react` (v18+)\n- `livekit-client`\n- `@livekit/components-react`\n- `livekit-server-sdk`\n- `tailwindcss`\n- `typescript`\n\n**Troubleshooting:**\n- If pnpm not installed: `npm install -g pnpm`\n- If peer dependency warnings: Generally safe to ignore\n- If install fails: Delete `node_modules` and `pnpm-lock.yaml`, retry\n\n**Rationale:** Ensures all required packages are available for development\n\n---\n\n#### 2.5: Run Development Server\n\n**What:** Start the Next.js development server to verify basic setup\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\npnpm dev\n```\n\n**Expected Outcome:**\n```\n> next dev\n\n  ▲ Next.js 14.x.x\n  - Local:        http://localhost:3000\n  - Environments: .env.local\n\n ✓ Ready in X.Xs\n```\n\n**Verification:**\n1. Open browser to http://localhost:3000\n2. Should see agent interface with \"Connect\" button\n3. No console errors in browser DevTools\n4. Page loads without 500 errors\n\n**Expected UI:**\n- Welcome/landing view\n- \"Connect\" or \"Start Session\" button\n- Logo and branding elements\n- Theme toggle (light/dark)\n\n**Troubleshooting:**\n- If port 3000 in use: `pnpm dev -- -p 3001`\n- If env vars missing: Check `.env.local` exists and has correct values\n- If build errors: Check `pnpm install` completed successfully\n\n**Rationale:** Validates Next.js setup before proceeding to authentication\n\n---\n\n#### 2.6: Inspect Token Generation API Route\n\n**What:** Review the built-in token generation endpoint to understand how authentication works\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend/app/api/token/route.ts`\n\n**Read the file:**\n```typescript\n// Expected structure (review actual implementation)\nimport { AccessToken } from 'livekit-server-sdk';\n\nexport async function POST(request: Request) {\n  const { roomName, participantName } = await request.json();\n\n  const token = new AccessToken(\n    process.env.LIVEKIT_API_KEY,\n    process.env.LIVEKIT_API_SECRET,\n    {\n      identity: participantName,\n      ttl: '2h', // Token valid for 2 hours\n    }\n  );\n\n  token.addGrant({\n    room: roomName,\n    roomJoin: true,\n    canPublish: true,\n    canSubscribe: true,\n  });\n\n  return Response.json({ token: await token.toJwt() });\n}\n```\n\n**Key Points:**\n- Uses `livekit-server-sdk` to generate JWT tokens\n- Reads `LIVEKIT_API_KEY` and `LIVEKIT_API_SECRET` from environment\n- Grants room join, publish, and subscribe permissions\n- Returns JWT token to frontend\n- Token expires after 2 hours (LiveKit auto-refreshes for connected clients)\n\n**Security Review:**\n- ✓ API key/secret are server-side only (not exposed to browser)\n- ✓ Token generation happens on server\n- ✓ Appropriate permissions granted\n- ⚠ Consider adding rate limiting for production\n\n**Rationale:** Understanding token flow is critical for debugging connection issues\n\n---\n\n#### 2.7: Add Frontend to .gitignore (Backend Repo)\n\n**What:** Prevent frontend from being committed to agent backend repo\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/.gitignore`\n\n**Add to `.gitignore`:**\n```bash\necho \"frontend/\" >> .gitignore\n```\n\n**Verify:**\n```bash\ngit status\n# frontend/ should not appear in untracked files\n```\n\n**Alternative Approach:**\nIf you want to commit the frontend to the same repo:\n- Create a separate `.gitignore` in `frontend/voice-ai-frontend/`\n- Add standard Next.js ignores (`.next/`, `node_modules/`, `.env.local`)\n\n**Rationale:** Keep frontend and backend as separate concerns, or manage carefully if in same repo\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Frontend directory created: `ls frontend/voice-ai-frontend`\n- [ ] Dependencies installed: `pnpm list --depth=0` shows key packages\n- [ ] Environment variables configured: `cat .env.local | grep LIVEKIT_API_KEY`\n- [ ] Development server starts: `pnpm dev` runs without errors\n- [ ] No TypeScript errors: `pnpm run build` completes successfully\n\n#### Manual Verification:\n\n- [ ] Visit http://localhost:3000 in browser\n- [ ] Page loads without 500 errors\n- [ ] UI displays welcome screen with \"Connect\" button\n- [ ] No console errors in browser DevTools\n- [ ] Theme toggle works (light/dark mode)\n- [ ] Responsive design works on mobile viewport\n\n**Verify:** After completing automated verification, open the app in a browser and verify UI loads correctly before proceeding to Phase 3.\n\n---\n\n## Phase 3: Authentication and Token Generation\n\n### Overview\n\nConfigure and test the JWT token generation flow to ensure frontend can authenticate users with LiveKit and connect them to agent sessions.\n\n### Context\n\nBefore starting, ensure:\n- Phase 2 completed successfully\n- Development server running at http://localhost:3000\n- Environment variables configured in `.env.local`\n\nFiles to review:\n- `frontend/voice-ai-frontend/app/api/token/route.ts` - Token generation endpoint\n- `frontend/voice-ai-frontend/.env.local` - Environment configuration\n- `frontend/voice-ai-frontend/components/app/` - Client-side connection logic\n\n### Dependencies\n\n**Depends on:** Phase 2 (frontend setup)\n\n**Required by:** Phase 4 (connection testing)\n\n### Changes Required\n\n#### 3.1: Test Token Generation Endpoint\n\n**What:** Verify the token API endpoint works correctly\n\n**Command:**\n```bash\n# Start dev server (if not running)\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\npnpm dev\n\n# In another terminal, test the endpoint\ncurl -X POST http://localhost:3000/api/token \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"roomName\": \"test-room\", \"participantName\": \"test-user\"}'\n```\n\n**Expected Response:**\n```json\n{\n  \"token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\"\n}\n```\n\n**Validate Token:**\n```bash\n# Decode the JWT to inspect claims (copy token from response)\necho \"eyJhbGciOiJ...\" | cut -d'.' -f2 | base64 -d | jq\n```\n\n**Expected Token Payload:**\n```json\n{\n  \"exp\": 1234567890,\n  \"iss\": \"APIxxxxxxxxxxxx\",\n  \"sub\": \"test-user\",\n  \"nbf\": 1234567890,\n  \"video\": {\n    \"room\": \"test-room\",\n    \"roomJoin\": true,\n    \"canPublish\": true,\n    \"canSubscribe\": true,\n    \"canPublishData\": true\n  }\n}\n```\n\n**Troubleshooting:**\n- If 500 error: Check environment variables in `.env.local`\n- If \"api_key undefined\": Verify `LIVEKIT_API_KEY` is set\n- If \"invalid signature\": Check `LIVEKIT_API_SECRET` is correct\n- If no response: Verify dev server is running on port 3000\n\n**Rationale:** Token generation must work before attempting to connect to LiveKit\n\n---\n\n#### 3.2: Review Client-Side Connection Logic\n\n**What:** Understand how the frontend connects to LiveKit rooms\n\n**Files to Review:**\n```bash\n# Main session component\ncat frontend/voice-ai-frontend/components/app/session-view.tsx\n\n# View controller\ncat frontend/voice-ai-frontend/components/app/view-controller.tsx\n\n# Connection utilities\ncat frontend/voice-ai-frontend/lib/connection.ts\n```\n\n**Key Flow:**\n1. User clicks \"Connect\" button\n2. Frontend generates room name (random or predefined)\n3. Frontend fetches token from `/api/token` endpoint\n4. Frontend connects to LiveKit room using `livekit-client`\n5. Agent is automatically dispatched to room\n6. User and agent establish WebRTC connection\n7. Audio tracks are exchanged\n\n**Important Variables:**\n- `NEXT_PUBLIC_LIVEKIT_URL` - LiveKit server URL (browser-accessible)\n- Room name generation logic\n- Participant name/identity\n- Agent dispatch configuration\n\n**Rationale:** Understanding client-side logic helps debug connection issues\n\n---\n\n#### 3.3: Configure Agent Dispatch\n\n**What:** Ensure frontend triggers automatic agent dispatch when users connect\n\n**File:** Review `frontend/voice-ai-frontend/app/api/connection-details/route.ts` (if exists) or equivalent\n\n**Verify Agent Name Configuration:**\n\n**Option A: Automatic Dispatch (Recommended):**\n```env\n# In .env.local\nAGENT_NAME=\n# Blank means \"dispatch any available agent\"\n```\n\n**Option B: Specific Agent:**\n```env\n# In .env.local\nAGENT_NAME=agent_abc123\n# Uses specific agent by ID or name\n```\n\n**Check Token Grant Configuration:**\n```typescript\n// In app/api/token/route.ts or connection-details/route.ts\ntoken.addGrant({\n  room: roomName,\n  roomJoin: true,\n  canPublish: true,\n  canSubscribe: true,\n  // Optional: Agent dispatch configuration\n});\n```\n\n**For agent-starter-react:**\nThe template typically handles agent dispatch automatically when a participant joins a room. Verify this by checking the token generation code and connection details endpoint.\n\n**Rationale:** Agent won't join room unless dispatch is configured correctly\n\n---\n\n#### 3.4: Test Token Expiration and Refresh\n\n**What:** Verify token expiration is set correctly and LiveKit handles refresh\n\n**Check Current TTL:**\n```typescript\n// In app/api/token/route.ts\nconst token = new AccessToken(\n  process.env.LIVEKIT_API_KEY,\n  process.env.LIVEKIT_API_SECRET,\n  {\n    identity: participantName,\n    ttl: '2h', // Current setting\n  }\n);\n```\n\n**Recommended TTL:**\n- Development: `2h` (2 hours)\n- Production: `2h` (LiveKit auto-refreshes for connected clients)\n- Pre-generated tokens: `1h` (if caching tokens)\n\n**Token Refresh Behavior:**\n- LiveKit client SDK automatically refreshes tokens before expiration\n- Refresh happens for connected clients only\n- Disconnected users must request new tokens\n\n**No changes needed if TTL is already `2h`.**\n\n**Rationale:** Prevents users from being disconnected due to token expiration\n\n---\n\n#### 3.5: Add Security Headers (Optional but Recommended)\n\n**What:** Add security headers to token API route\n\n**File:** `frontend/voice-ai-frontend/middleware.ts` (create if doesn't exist)\n\n**Content:**\n```typescript\nimport { NextResponse } from 'next/server';\nimport type { NextRequest } from 'next/server';\n\nexport function middleware(request: NextRequest) {\n  const response = NextResponse.next();\n\n  // Security headers\n  response.headers.set('X-Content-Type-Options', 'nosniff');\n  response.headers.set('X-Frame-Options', 'DENY');\n  response.headers.set('X-XSS-Protection', '1; mode=block');\n\n  return response;\n}\n\nexport const config = {\n  matcher: '/api/:path*',\n};\n```\n\n**Optional Rate Limiting:**\nConsider adding rate limiting to `/api/token` endpoint to prevent abuse.\n\n**Rationale:** Basic security hardening for production deployments\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Token endpoint returns valid JWT: `curl -X POST http://localhost:3000/api/token -H \"Content-Type: application/json\" -d '{\"roomName\":\"test\",\"participantName\":\"user\"}' | jq .token`\n- [ ] Token payload contains correct claims: Decode JWT and verify `video.roomJoin: true`\n- [ ] Environment variables loaded: `console.log(process.env.LIVEKIT_API_KEY)` in token route shows value (not undefined)\n- [ ] Token has correct expiration: Decoded JWT shows `exp` timestamp 2 hours in future\n\n#### Manual Verification:\n\n- [ ] Token endpoint accessible via browser: Visit http://localhost:3000/api/token (should return 405 Method Not Allowed for GET)\n- [ ] No errors in Next.js server logs when generating tokens\n- [ ] Token decodes successfully at https://jwt.io\n- [ ] Token issuer (`iss`) matches your LiveKit API key\n- [ ] Token subject (`sub`) matches requested participant name\n\n**Verify:** After completing automated verification, test token generation with curl and decode the JWT to inspect claims before proceeding to Phase 4.\n\n---\n\n## Phase 4: Connection Testing and Optimization\n\n### Overview\n\nTest the end-to-end connection flow from frontend to agent, verify audio works correctly, and optimize the connection speed.\n\n### Context\n\nBefore starting, ensure:\n- Phase 3 completed successfully\n- Agent running on LiveKit Cloud (`lk agent status` shows Running)\n- Frontend running at http://localhost:3000\n- Token generation working\n\nFiles to review:\n- `frontend/voice-ai-frontend/components/app/session-view.tsx` - Session management\n- `frontend/voice-ai-frontend/components/agents-ui/` - UI components\n\nTools needed:\n- Browser with microphone access\n- Terminal for monitoring agent logs\n\n### Dependencies\n\n**Depends on:** Phases 1-3 (agent deployed, frontend configured, authentication working)\n\n**Required by:** Phase 5 (customization), Phase 6 (production deployment)\n\n### Changes Required\n\n#### 4.1: Monitor Agent Logs\n\n**What:** Start monitoring agent logs before testing connection\n\n**Command:**\n```bash\n# Open a dedicated terminal window for agent logs\nlk agent logs --follow\n```\n\n**Keep this terminal open during all testing.**\n\n**What to Look For:**\n- Agent initialization messages\n- Room join events\n- STT transcriptions\n- LLM requests/responses\n- TTS generation\n- WebRTC connection events\n- Any error messages\n\n**Rationale:** Real-time logs are essential for debugging connection issues\n\n---\n\n#### 4.2: Test Basic Connection Flow\n\n**What:** Connect to the agent via frontend and verify basic functionality\n\n**Steps:**\n\n1. Open browser to http://localhost:3000\n2. Open browser DevTools Console (F12 → Console tab)\n3. Click \"Connect\" or \"Start Session\" button\n4. Grant microphone permissions when prompted\n5. Observe connection states in UI:\n   - \"Initializing...\"\n   - \"Listening\" (agent ready for input)\n   - \"Thinking\" (processing speech)\n   - \"Speaking\" (agent responding)\n\n**Expected Behavior:**\n- Connection establishes within 3-5 seconds\n- Agent state transitions to \"Listening\"\n- No errors in browser console\n- Agent logs show room join event\n\n**Troubleshooting:**\n- **Connection hangs:** Check token endpoint, verify LIVEKIT_URL is correct\n- **\"Failed to connect\":** Check agent status (`lk agent status`), verify agent is Running\n- **Microphone permission denied:** Grant permission in browser settings\n- **No audio:** Check browser audio output, verify speakers are enabled\n- **WebRTC errors:** Check firewall, ensure WebRTC ports not blocked\n\n**Rationale:** Validates basic connection before testing voice interaction\n\n---\n\n#### 4.3: Test Voice Interaction\n\n**What:** Verify end-to-end voice pipeline (STT → LLM → TTS)\n\n**Steps:**\n\n1. With frontend connected and agent in \"Listening\" state\n2. Speak clearly into your microphone: \"Hello, can you hear me?\"\n3. Observe agent state transition:\n   - \"Listening\" → \"Thinking\" → \"Speaking\"\n4. Listen for agent's voice response\n5. Check agent logs for:\n   - STT transcription of your speech\n   - LLM request and response\n   - TTS generation\n\n**Expected Outcome:**\n- Agent responds with natural voice within 2-4 seconds\n- Transcription appears in logs (if logging enabled)\n- No audio dropouts or distortion\n- Agent response is contextually appropriate\n\n**Additional Test Cases:**\n- **Interruption:** Speak while agent is speaking (should handle gracefully)\n- **Silence:** Wait 10 seconds without speaking (agent should remain connected)\n- **Background Noise:** Test with ambient noise (should filter with VAD)\n- **Multiple Turns:** Have a multi-turn conversation\n\n**Troubleshooting:**\n- **No transcription:** Check AssemblyAI API key in agent secrets\n- **No LLM response:** Check OpenAI API key, verify LLM model is available\n- **No TTS audio:** Check Cartesia API key, verify TTS voice model\n- **Garbled audio:** Check network connection, reduce network congestion\n- **High latency:** Check agent logs for slow API calls, consider region optimization\n\n**Rationale:** Validates the complete voice AI pipeline works end-to-end\n\n---\n\n#### 4.4: Verify Audio Visualization\n\n**What:** Test the audio visualizer component works correctly\n\n**Steps:**\n\n1. With frontend connected\n2. Speak into microphone\n3. Observe audio visualization:\n   - Bars should animate when you speak\n   - Bars should pulse when agent speaks\n   - Different colors/states for listening vs speaking\n\n**Expected Behavior:**\n- `BarVisualizer` component shows real-time audio levels\n- Smooth animations\n- Clear visual feedback of agent state\n- No lag between audio and visualization\n\n**Check Component:**\n```bash\n# Review visualizer component\ncat frontend/voice-ai-frontend/components/agents-ui/bar-visualizer.tsx\n```\n\n**Troubleshooting:**\n- **No visualization:** Check if audio track is being passed to component\n- **Choppy animation:** Check browser performance, reduce animation complexity\n- **Wrong colors:** Review CSS/Tailwind classes\n\n**Rationale:** Visual feedback improves user experience and debugging\n\n---\n\n#### 4.5: Test Disconnection and Reconnection\n\n**What:** Verify graceful disconnect and ability to reconnect\n\n**Steps:**\n\n**Test Disconnect:**\n1. With frontend connected\n2. Click \"Disconnect\" or \"End Session\" button\n3. Observe clean disconnect:\n   - Agent logs show participant left\n   - No error messages\n   - UI returns to welcome screen\n\n**Test Reconnect:**\n1. Click \"Connect\" again\n2. Verify new session starts successfully\n3. Test voice interaction again\n\n**Test Network Interruption (Optional):**\n1. While connected, disable network (Wi-Fi off)\n2. Observe reconnection behavior\n3. Re-enable network\n4. Verify auto-reconnect or error message\n\n**Expected Behavior:**\n- Clean disconnect without errors\n- Ability to reconnect immediately\n- Each session gets unique room/token\n- No lingering WebRTC connections\n\n**Rationale:** Ensures robust connection lifecycle management\n\n---\n\n#### 4.6: Optimize Connection Speed\n\n**What:** Reduce connection time from 3-5 seconds to <1 second using optimization techniques\n\n**Current Flow (Sequential):**\n```\n1. Click Connect (0ms)\n2. Fetch token from /api/token (500ms)\n3. Connect to LiveKit room (1000ms)\n4. Agent dispatched (1000ms)\n5. Agent connects and publishes (1500ms)\nTotal: ~4000ms (4 seconds)\n```\n\n**Optimization 1: Pre-generate Tokens**\n\nCreate a \"warm token\" approach for faster connection:\n\n**File:** Create `frontend/voice-ai-frontend/hooks/use-warm-token.ts`\n\n```typescript\n'use client';\n\nimport { useState, useEffect } from 'react';\n\nexport function useWarmToken() {\n  const [token, setToken] = useState<string | null>(null);\n\n  useEffect(() => {\n    // Pre-generate token on page load\n    async function generateToken() {\n      const response = await fetch('/api/token', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          roomName: `room-${Date.now()}`,\n          participantName: `user-${Math.random().toString(36).substring(7)}`,\n        }),\n      });\n      const data = await response.json();\n      setToken(data.token);\n    }\n\n    generateToken();\n  }, []);\n\n  return token;\n}\n```\n\n**Usage in Session Component:**\n```typescript\n// In session-view.tsx or similar\nconst warmToken = useWarmToken();\n\n// Use warmToken when connecting instead of fetching on-demand\n```\n\n**Optimization 2: Concurrent Dispatch**\n\nModify connection logic to dispatch agent and connect user simultaneously:\n\n```typescript\n// Parallel connection\nconst [roomConnection, agentDispatch] = await Promise.all([\n  connectToRoom(token),\n  dispatchAgent(roomName) // If manual dispatch required\n]);\n```\n\n**Expected Improvement:**\n- Pre-generated token: -500ms (eliminates token fetch delay)\n- Concurrent dispatch: -1000ms (parallel instead of sequential)\n- **New total:** ~2500ms → ~1500ms (1.5 seconds)\n\n**Trade-offs:**\n- Pre-generated tokens have expiration (ensure 2h TTL)\n- Unused tokens waste resources (minimal cost)\n- Complexity slightly increases\n\n**Rationale:** Faster connections improve user experience and perceived performance\n\n---\n\n#### 4.7: Test on Multiple Browsers\n\n**What:** Verify cross-browser compatibility\n\n**Browsers to Test:**\n- Chrome/Chromium\n- Firefox\n- Safari (macOS/iOS)\n- Edge\n\n**Test Matrix:**\n\n| Browser | Connection | Audio Input | Audio Output | Visualization |\n|---------|-----------|-------------|--------------|---------------|\n| Chrome  | ✓         | ✓           | ✓            | ✓             |\n| Firefox | ?         | ?           | ?            | ?             |\n| Safari  | ?         | ?           | ?            | ?             |\n| Edge    | ?         | ?           | ?            | ?             |\n\n**Common Issues:**\n- **Safari:** May require user interaction before audio playback\n- **Firefox:** Different WebRTC implementation, may have quirks\n- **Mobile Safari:** Requires specific audio context handling\n- **Edge:** Generally compatible with Chrome\n\n**Rationale:** Ensures wide browser support for production deployment\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Connection establishes successfully: Monitor for \"Room connected\" event in logs\n- [ ] Agent joins room: `lk agent logs` shows room join event\n- [ ] WebRTC connection: Browser DevTools Network tab shows WebRTC connections\n- [ ] No console errors: Browser DevTools Console shows no red errors\n- [ ] Audio tracks published: Check LiveKit Cloud dashboard for active tracks\n\n#### Manual Verification:\n\n- [ ] Voice input recognized: Speak and verify agent responds\n- [ ] Voice output works: Hear agent's TTS response clearly\n- [ ] Audio visualization animates correctly\n- [ ] Agent state transitions work (initializing → listening → thinking → speaking)\n- [ ] Interruption handling works (speak during agent response)\n- [ ] Disconnect and reconnect works cleanly\n- [ ] Connection time <3 seconds (before optimization) or <1.5s (after optimization)\n- [ ] Works in Chrome, Firefox, and Safari\n\n**Verify:** After completing automated verification, have a multi-turn conversation with the agent and test all edge cases before proceeding to Phase 5.\n\n---\n\n## Phase 5: Frontend Customization\n\n### Overview\n\nCustomize the frontend with your branding, colors, logo, and company information to make it production-ready.\n\n### Context\n\nBefore starting, ensure:\n- Phase 4 completed successfully\n- Voice interaction working end-to-end\n- Frontend running at http://localhost:3000\n\nFiles to customize:\n- `frontend/voice-ai-frontend/app-config.ts` - Main configuration\n- `frontend/voice-ai-frontend/public/` - Static assets (logo, favicon)\n- `frontend/voice-ai-frontend/app/layout.tsx` - Page metadata\n- `frontend/voice-ai-frontend/tailwind.config.ts` - Theme colors\n\n### Dependencies\n\n**Depends on:** Phase 4 (connection testing completed)\n\n**Required by:** Phase 6 (production deployment)\n\n### Changes Required\n\n#### 5.1: Update App Configuration\n\n**What:** Customize company name, page title, and feature flags\n\n**File:** `frontend/voice-ai-frontend/app-config.ts`\n\n**Edit:**\n```typescript\nexport const APP_CONFIG_DEFAULTS = {\n  // Branding\n  companyName: \"Your Company Name\", // Change this\n  pageTitle: \"AI Voice Assistant | Your Company\", // Change this\n\n  // Logo URLs\n  logoUrl: \"/logo.svg\", // Update after adding logo in 5.2\n  logoUrlDark: \"/logo-dark.svg\", // Optional: separate dark mode logo\n\n  // Accent color\n  accentColor: \"#4F46E5\", // Change to your brand color (hex)\n\n  // Feature toggles - AUDIO-ONLY CONFIGURATION\n  supportsChatInput: false, // Disable text chat (audio-only)\n  supportsVideoInput: false, // DISABLE camera video (audio-only)\n  supportsScreenShare: false, // DISABLE screen sharing (audio-only)\n  isPreConnectBufferEnabled: true, // Pre-load for faster connection\n\n  // Optional: Agent configuration\n  defaultAgentName: \"\", // Leave blank for auto-dispatch\n};\n```\n\n**Example Customization (Audio-Only):**\n```typescript\nexport const APP_CONFIG_DEFAULTS = {\n  companyName: \"Acme Voice AI\",\n  pageTitle: \"Voice AI Assistant | Acme Corp\",\n  logoUrl: \"/acme-logo.svg\",\n  accentColor: \"#FF6B35\", // Orange\n  supportsChatInput: false, // Audio-only: no text chat\n  supportsVideoInput: false, // Audio-only: no camera\n  supportsScreenShare: false, // Audio-only: no screen share\n  isPreConnectBufferEnabled: true,\n};\n```\n\n**Rationale:** Centralizes configuration for easy customization without code changes\n\n---\n\n#### 5.2: Add Custom Logo\n\n**What:** Replace default logo with your company logo\n\n**Steps:**\n\n1. Prepare logo files:\n   - **Format:** SVG (preferred) or PNG\n   - **Size:**\n     - SVG: Any size (scalable)\n     - PNG: 200x200px minimum, transparent background\n   - **Naming:**\n     - Light mode: `logo.svg` or `logo.png`\n     - Dark mode (optional): `logo-dark.svg` or `logo-dark.png`\n\n2. Copy to public directory:\n   ```bash\n   cp /path/to/your/logo.svg frontend/voice-ai-frontend/public/logo.svg\n   # Optional: dark mode logo\n   cp /path/to/your/logo-dark.svg frontend/voice-ai-frontend/public/logo-dark.svg\n   ```\n\n3. Update `app-config.ts`:\n   ```typescript\n   logoUrl: \"/logo.svg\",\n   logoUrlDark: \"/logo-dark.svg\", // If you have separate dark logo\n   ```\n\n4. Verify logo appears:\n   - Restart dev server: `pnpm dev`\n   - Visit http://localhost:3000\n   - Check logo displays correctly\n   - Toggle light/dark mode to test both logos\n\n**Fallback:**\nIf you don't have a logo ready, the template includes a default placeholder logo.\n\n**Rationale:** Custom logo reinforces brand identity\n\n---\n\n#### 5.3: Customize Theme Colors\n\n**What:** Update color scheme to match your brand\n\n**File:** `frontend/voice-ai-frontend/tailwind.config.ts`\n\n**Edit:**\n```typescript\nexport default {\n  theme: {\n    extend: {\n      colors: {\n        // Primary brand color\n        primary: {\n          50: '#f0f9ff',\n          100: '#e0f2fe',\n          // ... continue through 950\n          500: '#4F46E5', // Main brand color (change this)\n          600: '#4338ca',\n          // ...\n        },\n        // Accent color\n        accent: {\n          DEFAULT: '#FF6B35', // Change to your accent color\n          light: '#FF8A5B',\n          dark: '#E5501F',\n        },\n      },\n    },\n  },\n};\n```\n\n**Quick Method (Use Accent Color from app-config.ts):**\n\nThe template may automatically use `accentColor` from `app-config.ts`. If so, just update that value:\n\n```typescript\n// In app-config.ts\naccentColor: \"#FF6B35\", // Your brand color\n```\n\n**Generate Full Color Palette:**\nUse tools like https://uicolors.app/create to generate a full Tailwind color palette from your brand color.\n\n**Test Theme:**\n- Restart dev server\n- Visit http://localhost:3000\n- Check buttons, links, highlights use new colors\n- Toggle light/dark mode to verify both themes\n\n**Rationale:** Consistent color scheme creates professional, branded experience\n\n---\n\n#### 5.4: Update Page Metadata\n\n**What:** Set page title, description, and favicon for SEO and browser display\n\n**File:** `frontend/voice-ai-frontend/app/layout.tsx`\n\n**Edit:**\n```typescript\nexport const metadata: Metadata = {\n  title: \"AI Voice Assistant | Your Company\", // Change this\n  description: \"Connect with our AI voice assistant for instant help and support.\", // Change this\n  icons: {\n    icon: '/favicon.ico', // Update after adding favicon\n  },\n  openGraph: {\n    title: \"AI Voice Assistant | Your Company\",\n    description: \"Connect with our AI voice assistant for instant help and support.\",\n    images: ['/og-image.png'], // Optional: social share image\n  },\n};\n```\n\n**Add Custom Favicon:**\n\n1. Generate favicon files (use https://realfavicongenerator.net/):\n   - `favicon.ico` (16x16, 32x32, 48x48)\n   - `apple-touch-icon.png` (180x180)\n   - `favicon-16x16.png`\n   - `favicon-32x32.png`\n\n2. Copy to `public/`:\n   ```bash\n   cp /path/to/favicon.ico frontend/voice-ai-frontend/public/\n   cp /path/to/apple-touch-icon.png frontend/voice-ai-frontend/public/\n   ```\n\n3. Verify in browser:\n   - Clear browser cache\n   - Visit http://localhost:3000\n   - Check browser tab shows your favicon\n\n**Optional: Open Graph Image (Social Sharing):**\nCreate `og-image.png` (1200x630px) for social media previews.\n\n**Rationale:** Professional metadata improves SEO and user experience\n\n---\n\n#### 5.5: Customize Welcome Message\n\n**What:** Update the welcome screen text and instructions\n\n**File:** `frontend/voice-ai-frontend/components/app/welcome-view.tsx` or similar\n\n**Find and Edit:**\n```typescript\n<h1>Welcome to [Your Company] Voice AI</h1>\n<p>\n  Click the button below to start a voice conversation with our AI assistant.\n  We can help you with questions, information, and more.\n</p>\n```\n\n**Example Customization:**\n```typescript\n<h1>Welcome to Acme Voice Assistant</h1>\n<p>\n  Our AI assistant is ready to help you 24/7. Click \"Connect\" to start a\n  natural voice conversation. Just speak naturally - no keywords or commands needed.\n</p>\n<ul>\n  <li>Get instant answers to your questions</li>\n  <li>Learn about our products and services</li>\n  <li>Get personalized recommendations</li>\n</ul>\n```\n\n**Rationale:** Clear messaging helps users understand what to expect\n\n---\n\n#### 5.6: Optional - Disable Features Not Needed\n\n**What:** Hide video/screen share features if you only need voice\n\n**File:** `frontend/voice-ai-frontend/app-config.ts`\n\n**For Voice-Only App:**\n```typescript\nexport const APP_CONFIG_DEFAULTS = {\n  // ... other settings\n  supportsChatInput: false, // Disable text chat\n  supportsVideoInput: false, // Disable camera\n  supportsScreenShare: false, // Disable screen sharing\n  isPreConnectBufferEnabled: true, // Keep for faster connection\n};\n```\n\n**Effect:**\n- Video camera icon hidden\n- Screen share button removed\n- UI simplified to voice-only interface\n- Reduced complexity for users\n\n**Rationale:** Simplify UI by removing unused features\n\n---\n\n#### 5.7: Test Customizations\n\n**What:** Verify all customizations display correctly\n\n**Checklist:**\n- [ ] Company name displays on welcome screen\n- [ ] Custom logo appears (both light and dark modes)\n- [ ] Page title shows in browser tab\n- [ ] Custom favicon appears in browser tab\n- [ ] Brand colors visible on buttons and accents\n- [ ] Welcome message updated with custom text\n- [ ] Disabled features are hidden (if applicable)\n- [ ] No broken images or 404s\n- [ ] Responsive design maintained on mobile\n\n**Testing Steps:**\n1. Restart dev server: `pnpm dev`\n2. Clear browser cache (Cmd+Shift+R on Mac, Ctrl+Shift+R on Windows)\n3. Visit http://localhost:3000\n4. Toggle light/dark theme\n5. Resize browser to mobile size (375px width)\n6. Check all visual elements\n\n**Rationale:** Ensures professional, branded appearance before production deployment\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Build succeeds: `pnpm run build` completes without errors\n- [ ] No TypeScript errors: `pnpm run type-check` (if available)\n- [ ] Static assets exist: `ls public/logo.svg public/favicon.ico`\n- [ ] Config updated: `cat app-config.ts | grep companyName` shows your company\n\n#### Manual Verification:\n\n- [ ] Custom company name displays on welcome screen\n- [ ] Custom logo visible (light and dark modes)\n- [ ] Page title correct in browser tab\n- [ ] Favicon visible in browser tab\n- [ ] Brand colors applied throughout UI\n- [ ] Welcome message updated\n- [ ] Unused features hidden (if disabled)\n- [ ] Mobile responsive (test at 375px width)\n- [ ] No console errors or warnings\n- [ ] All images load correctly (no broken images)\n\n**Verify:** After completing automated verification, thoroughly test the UI on desktop and mobile, in light and dark modes, before proceeding to Phase 6.\n\n---\n\n## Phase 6: Production Deployment\n\n### Overview\n\nDeploy the customized frontend to Vercel (or another hosting provider) to make it publicly accessible via a URL that clients can visit.\n\n### Context\n\nBefore starting, ensure:\n- Phase 5 completed successfully\n- All customizations tested locally\n- Frontend builds successfully (`pnpm run build`)\n- Agent deployed and running on LiveKit Cloud\n\nFiles to review:\n- `frontend/voice-ai-frontend/.env.local` - Environment variables (will configure in Vercel)\n- `frontend/voice-ai-frontend/next.config.js` - Next.js configuration\n- `frontend/voice-ai-frontend/package.json` - Dependencies and scripts\n\nAccounts needed:\n- Vercel account (free tier sufficient): https://vercel.com\n- GitHub account (for connecting repo)\n\n### Dependencies\n\n**Depends on:** Phases 1-5 (agent deployed, frontend customized and tested)\n\n**Required by:** None (final phase)\n\n### Changes Required\n\n#### 6.1: Create Production Build\n\n**What:** Verify the production build works correctly before deploying\n\n**Commands:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\n\n# Create production build\npnpm run build\n\n# Test production build locally\npnpm start\n```\n\n**Expected Output:**\n```\n> next build\n\n✓ Compiled successfully\n✓ Linting and checking validity of types\n✓ Collecting page data\n✓ Generating static pages (X/X)\n✓ Finalizing page optimization\n\nRoute (app)                              Size     First Load JS\n┌ ○ /                                    XXX kB        XXX kB\n└ ○ /api/token                          XXX B          XXX kB\n```\n\n**Test Production Build:**\n1. Visit http://localhost:3000 (pnpm start)\n2. Connect to agent\n3. Verify voice interaction works\n4. Check for any errors in console\n\n**Troubleshooting:**\n- If build fails: Check TypeScript errors, fix before proceeding\n- If errors about environment variables: Ensure `.env.local` exists\n- If runtime errors: Check browser console for specific issues\n\n**Rationale:** Catches production-specific issues before deployment\n\n---\n\n#### 6.2: Push Frontend to GitHub (Optional but Recommended)\n\n**What:** Create a Git repository for the frontend to enable easy Vercel deployment\n\n**Option A: Separate Repository (Recommended):**\n\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\n\n# Initialize git repository\ngit init\n\n# Add .gitignore for Next.js\ncat > .gitignore << 'EOF'\n# Next.js\n.next/\nout/\nbuild/\ndist/\n\n# Dependencies\nnode_modules/\n\n# Environment variables\n.env\n.env.local\n.env.production.local\n.env.development.local\n.env.test.local\n\n# Logs\nnpm-debug.log*\nyarn-debug.log*\nyarn-error.log*\npnpm-debug.log*\n\n# OS\n.DS_Store\n*.swp\n*.swo\n\n# IDE\n.vscode/\n.idea/\n\n# Vercel\n.vercel\nEOF\n\n# Add files\ngit add .\ngit commit -m \"Initial commit: Voice AI frontend\"\n\n# Create GitHub repository (via GitHub UI or CLI)\ngh repo create voice-ai-frontend --public --source=. --remote=origin --push\n```\n\n**Option B: Same Repository as Agent:**\n\nIf you want frontend and agent in the same repo:\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\n\n# Remove frontend/ from .gitignore\nsed -i '' '/^frontend\\//d' .gitignore\n\n# Add and commit\ngit add frontend/\ngit commit -m \"Add voice AI frontend\"\ngit push\n```\n\n**Rationale:** Git repository enables continuous deployment and version control\n\n---\n\n#### 6.3: Sign Up for Vercel\n\n**What:** Create a Vercel account for hosting the frontend\n\n**Steps:**\n\n1. Visit https://vercel.com\n2. Click \"Sign Up\"\n3. Choose \"Continue with GitHub\" (recommended)\n4. Authorize Vercel to access your GitHub repositories\n\n**Pricing:**\n- **Free Tier:** Sufficient for testing and low traffic\n  - Unlimited deployments\n  - 100 GB bandwidth/month\n  - Serverless functions included\n- **Pro Tier:** $20/month (for production with higher traffic)\n\n**Rationale:** Vercel provides seamless Next.js hosting with automatic deployments\n\n---\n\n#### 6.4: Deploy Frontend to Vercel\n\n**What:** Deploy the frontend application to Vercel\n\n**Steps:**\n\n1. **From Vercel Dashboard:**\n   - Click \"Add New...\" → \"Project\"\n   - Select \"Import Git Repository\"\n   - Choose your frontend repository\n   - Configure project:\n     - **Framework Preset:** Next.js (auto-detected)\n     - **Root Directory:** `./` (or `frontend/voice-ai-frontend` if in monorepo)\n     - **Build Command:** `pnpm run build` (auto-detected)\n     - **Output Directory:** `.next` (auto-detected)\n     - **Install Command:** `pnpm install` (auto-detected)\n\n2. **Configure Environment Variables:**\n   Click \"Environment Variables\" and add:\n\n   ```\n   LIVEKIT_API_KEY=APIxxxxxxxxxxxx\n   LIVEKIT_API_SECRET=your-secret-here\n   LIVEKIT_URL=wss://your-project.livekit.cloud\n   NEXT_PUBLIC_LIVEKIT_URL=wss://your-project.livekit.cloud\n   AGENT_NAME=\n   ```\n\n   **Important:**\n   - Copy values from your local `.env.local`\n   - Apply to \"Production\", \"Preview\", and \"Development\" environments\n\n3. **Deploy:**\n   - Click \"Deploy\"\n   - Wait for build to complete (2-5 minutes)\n\n**Expected Outcome:**\n```\n✓ Build successful\n✓ Deployment successful\nYour project is now live at: https://your-app.vercel.app\n```\n\n**Rationale:** Makes frontend publicly accessible via HTTPS URL\n\n---\n\n#### 6.5: Test Production Deployment\n\n**What:** Verify the deployed frontend works correctly\n\n**Steps:**\n\n1. Visit your Vercel URL: `https://your-app.vercel.app`\n\n2. **Test Checklist:**\n   - [ ] Page loads without errors\n   - [ ] Custom branding displays correctly\n   - [ ] Click \"Connect\" button\n   - [ ] Grant microphone permissions\n   - [ ] Speak to agent\n   - [ ] Verify agent responds with voice\n   - [ ] Test on mobile device\n   - [ ] Test in different browsers\n\n3. **Monitor Logs:**\n   ```bash\n   # Monitor agent logs during production test\n   lk agent logs --follow\n   ```\n\n4. **Check Vercel Deployment Logs:**\n   - Go to Vercel dashboard → Your project → Deployments\n   - Click on latest deployment → \"Functions\" tab\n   - Check for any errors in `/api/token` function\n\n**Troubleshooting:**\n- **\"Failed to connect\":** Check environment variables in Vercel\n- **Token errors:** Verify `LIVEKIT_API_KEY` and `LIVEKIT_API_SECRET` are correct\n- **CORS errors:** Ensure `NEXT_PUBLIC_LIVEKIT_URL` is set correctly\n- **Agent not joining:** Check agent status, verify agent is Running\n\n**Rationale:** Ensures production environment works correctly\n\n---\n\n#### 6.6: Configure Custom Domain (Optional)\n\n**What:** Use a custom domain instead of `your-app.vercel.app`\n\n**Prerequisites:**\n- Own a domain name (e.g., `voiceai.yourcompany.com`)\n- Access to domain DNS settings\n\n**Steps:**\n\n1. **In Vercel Dashboard:**\n   - Go to your project → Settings → Domains\n   - Click \"Add Domain\"\n   - Enter your domain: `voiceai.yourcompany.com`\n\n2. **Configure DNS:**\n   Vercel will provide DNS configuration instructions:\n\n   **Option A: CNAME (Subdomain):**\n   ```\n   Type: CNAME\n   Name: voiceai\n   Value: cname.vercel-dns.com\n   ```\n\n   **Option B: A Record (Root Domain):**\n   ```\n   Type: A\n   Name: @\n   Value: 76.76.21.21\n   ```\n\n3. **Wait for DNS Propagation:**\n   - Usually takes 5-60 minutes\n   - Vercel will auto-configure SSL certificate (Let's Encrypt)\n\n4. **Verify:**\n   - Visit `https://voiceai.yourcompany.com`\n   - Should show your frontend with SSL (green lock icon)\n\n**Rationale:** Custom domain provides professional appearance and brand consistency\n\n---\n\n#### 6.7: Enable Automatic Deployments\n\n**What:** Configure automatic deployments when you push to GitHub\n\n**Vercel Auto-Deploys By Default:**\n- **Production:** Deploys on push to `main` branch\n- **Preview:** Deploys on push to any other branch or PR\n\n**Customize (Optional):**\n1. Go to Vercel dashboard → Your project → Settings → Git\n2. Configure:\n   - **Production Branch:** `main` (or `master`)\n   - **Ignored Build Step:** (leave blank to build on every commit)\n\n**Test Automatic Deployment:**\n```bash\ncd frontend/voice-ai-frontend\n\n# Make a small change\necho \"# Updated\" >> README.md\n\n# Commit and push\ngit add README.md\ngit commit -m \"Test automatic deployment\"\ngit push origin main\n```\n\n**Verify:**\n- Visit Vercel dashboard\n- Should see new deployment triggered automatically\n- Wait for build to complete\n- Visit production URL to see changes\n\n**Rationale:** Enables continuous deployment for easy updates\n\n---\n\n#### 6.8: Set Up Production Monitoring (Recommended)\n\n**What:** Monitor production errors and usage\n\n**Vercel Analytics (Built-in):**\n1. Go to Vercel dashboard → Your project → Analytics\n2. View:\n   - Page views\n   - Geographic distribution\n   - Performance metrics (Web Vitals)\n\n**Error Tracking (Optional):**\nConsider integrating Sentry or similar:\n```bash\npnpm add @sentry/nextjs\nnpx @sentry/wizard@latest -i nextjs\n```\n\n**LiveKit Cloud Monitoring:**\n- Visit LiveKit Cloud dashboard\n- Monitor:\n  - Active sessions\n  - Agent usage\n  - Costs (session minutes)\n\n**Rationale:** Production monitoring helps identify and resolve issues quickly\n\n---\n\n#### 6.9: Create Shareable Link\n\n**What:** Generate a clean, shareable URL for potential clients\n\n**Your Production URL:**\n```\nhttps://your-app.vercel.app\n```\n\n**Or with Custom Domain:**\n```\nhttps://voiceai.yourcompany.com\n```\n\n**Create Marketing Materials:**\n- Add link to your website\n- Share via email campaigns\n- Include in social media bios\n- Create QR code for physical materials\n\n**Example QR Code Generation:**\n```bash\n# Generate QR code (using qrencode)\nbrew install qrencode\nqrencode -o voiceai-qr.png \"https://voiceai.yourcompany.com\"\n```\n\n**Rationale:** Easy sharing enables potential clients to access your voice AI\n\n---\n\n#### 6.10: Document Production URLs and Credentials\n\n**What:** Save all production information for future reference\n\n**Create:** `frontend/voice-ai-frontend/PRODUCTION.md`\n\n**Content:**\n```markdown\n# Production Deployment Information\n\n## URLs\n- **Production Frontend:** https://your-app.vercel.app\n- **Custom Domain:** https://voiceai.yourcompany.com (if configured)\n- **LiveKit Cloud Dashboard:** https://cloud.livekit.io\n\n## Vercel\n- **Project:** voice-ai-frontend\n- **Account:** your-email@example.com\n- **Git Repository:** https://github.com/yourusername/voice-ai-frontend\n\n## LiveKit Cloud\n- **Project:** your-project-name\n- **Region:** us-west-2\n- **Agent ID:** agent_abc123\n\n## Deployment Commands\n```bash\n# Deploy agent updates\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\nlk agent deploy\n\n# Deploy frontend updates (automatic via Git)\ncd frontend/voice-ai-frontend\ngit add .\ngit commit -m \"Update frontend\"\ngit push origin main\n```\n\n## Monitoring\n- **Agent Logs:** `lk agent logs --follow`\n- **Vercel Logs:** https://vercel.com/your-project/deployments\n- **LiveKit Dashboard:** https://cloud.livekit.io/projects/your-project\n\n## Environment Variables (Vercel)\n- LIVEKIT_API_KEY=APIxxxxxxxxxxxx\n- LIVEKIT_API_SECRET=*** (not shown)\n- LIVEKIT_URL=wss://your-project.livekit.cloud\n- NEXT_PUBLIC_LIVEKIT_URL=wss://your-project.livekit.cloud\n\n## Costs\n- **LiveKit Cloud:** $0.01 per agent session minute\n- **Vercel:** Free tier (or $20/month Pro)\n\n## Support\n- **LiveKit:** https://livekit.io/discord\n- **Vercel:** https://vercel.com/support\n```\n\n**Rationale:** Documentation ensures you can manage production deployment long-term\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Production build succeeds: `pnpm run build` completes without errors\n- [ ] Vercel deployment successful: Deployment status shows \"Ready\"\n- [ ] HTTPS enabled: Visit production URL with green lock icon\n- [ ] Environment variables configured: Check Vercel dashboard\n- [ ] Custom domain configured (if applicable): DNS records set\n\n#### Manual Verification:\n\n- [ ] Visit production URL in browser\n- [ ] Page loads without errors\n- [ ] Custom branding displays correctly\n- [ ] Click \"Connect\" and grant microphone access\n- [ ] Speak to agent and verify voice response\n- [ ] Test on mobile device (iOS Safari, Android Chrome)\n- [ ] Test in incognito/private mode\n- [ ] Share URL with colleague and get confirmation it works\n- [ ] Agent logs show production sessions: `lk agent logs --follow`\n- [ ] No errors in Vercel function logs\n\n**Verify:** After completing automated verification, test the production URL on multiple devices and browsers, then share with a colleague to confirm public accessibility.\n\n---\n\n## Testing Strategy\n\n### Unit Tests\n\n**Not required for this plan.** The agent-starter-react template is a pre-built, production-ready template that doesn't require custom unit tests unless you add significant custom logic.\n\n**Optional:** Add tests if you customize components heavily:\n```bash\npnpm add -D @testing-library/react @testing-library/jest-dom jest\n```\n\n### Integration Tests\n\n**End-to-End Testing:**\n\nManually test the complete flow:\n1. User visits URL\n2. Clicks \"Connect\"\n3. Grants microphone access\n4. Speaks to agent\n5. Receives voice response\n6. Disconnects cleanly\n\n**Test Matrix:**\n\n| Scenario | Steps | Expected Outcome |\n|----------|-------|------------------|\n| First Connection | Visit URL → Click Connect → Speak | Agent responds with voice |\n| Interruption | Speak while agent is speaking | Agent handles gracefully |\n| Disconnect/Reconnect | End session → Start new session | New session works |\n| Multiple Turns | Have 3-5 turn conversation | All responses relevant |\n| Mobile Safari | Test on iPhone/iPad | Full functionality |\n| Network Interruption | Disable Wi-Fi during session | Reconnection or error message |\n\n### Manual Testing Steps\n\n**Pre-Deployment Checklist:**\n1. [ ] Agent deployed and running: `lk agent status`\n2. [ ] Local frontend works: `pnpm dev` at http://localhost:3000\n3. [ ] Voice interaction successful\n4. [ ] Audio visualization working\n5. [ ] Custom branding applied\n6. [ ] Production build succeeds: `pnpm run build`\n\n**Post-Deployment Checklist:**\n1. [ ] Production URL accessible\n2. [ ] HTTPS enabled (green lock)\n3. [ ] Voice interaction works on production\n4. [ ] Mobile responsive\n5. [ ] Cross-browser compatible\n6. [ ] Shareable link works for external users\n\n### Performance Considerations\n\n**Metrics to Monitor:**\n- **Connection Time:** Should be <3 seconds (or <1.5s with optimization)\n- **Response Latency:** STT → LLM → TTS should be 2-4 seconds\n- **Page Load Time:** Initial load <2 seconds (Lighthouse score >90)\n- **Audio Quality:** No dropouts or distortion\n\n**Optimization:**\n- Enable pre-connect buffering in `app-config.ts`\n- Use warm token approach (Phase 4.6)\n- Minimize bundle size (Next.js handles automatically)\n- Use CDN for static assets (Vercel provides automatically)\n\n## References\n\n### Original Ticket/Request\n- User request: \"I want potential clients to be able to interact with the livekit agent from this repo by clicking a link on a website.\"\n\n### Documentation\n- `docs/DEPLOYMENT.md` - Complete deployment guide for agent and frontend options\n- `README.md` - Project overview and setup instructions\n- `AGENTS.md` - Project guidelines and standards\n\n### LiveKit Resources\n- **Frontend Deployment Guide:** https://docs.livekit.io/agents/start/frontend/\n- **agent-starter-react Repository:** https://github.com/livekit-examples/agent-starter-react\n- **Token Authentication:** https://docs.livekit.io/home/get-started/authentication/\n- **Agents Playground:** https://agents-playground.livekit.io/\n- **LiveKit Cloud Dashboard:** https://cloud.livekit.io\n- **React Components Docs:** https://docs.livekit.io/reference/components/react/\n\n### NPM Packages\n- **livekit-client:** Client SDK for browser WebRTC\n- **@livekit/components-react:** React UI components\n- **livekit-server-sdk:** Server-side token generation\n\n### Vercel Resources\n- **Vercel Platform:** https://vercel.com\n- **Next.js Documentation:** https://nextjs.org/docs\n- **Deployment Docs:** https://vercel.com/docs\n\n### Related Plans\n- None (initial implementation)\n\n---\n\n**End of Implementation Plan**\n","structuredPatch":[{"oldStart":1641,"oldLines":19,"newStart":1641,"newLines":19,"lines":[" "," ---"," ","-#### 5.6: Optional - Disable Features Not Needed","+#### 5.6: Configure Audio-Only Mode (REQUIRED)"," ","-**What:** Hide video/screen share features if you only need voice","+**What:** Disable video/screen share features for audio-only application"," "," **File:** `frontend/voice-ai-frontend/app-config.ts`"," ","-**For Voice-Only App:**","+**REQUIRED Configuration for Audio-Only App:**"," ```typescript"," export const APP_CONFIG_DEFAULTS = {","   // ... other settings","-  supportsChatInput: false, // Disable text chat","-  supportsVideoInput: false, // Disable camera","-  supportsScreenShare: false, // Disable screen sharing","+  supportsChatInput: false, // Audio-only: disable text chat","+  supportsVideoInput: false, // REQUIRED: disable camera","+  supportsScreenShare: false, // REQUIRED: disable screen sharing","   isPreConnectBufferEnabled: true, // Keep for faster connection"," };"," ```"]},{"oldStart":1662,"oldLines":10,"newStart":1662,"newLines":13,"lines":[" - Video camera icon hidden"," - Screen share button removed"," - UI simplified to voice-only interface","-- Reduced complexity for users","+- No video/screenshare permission requests to users","+- Browser only requests microphone permission"," ","-**Rationale:** Simplify UI by removing unused features","+**IMPORTANT:** This is a required configuration for this audio-only application. Do NOT enable video or screen sharing features."," ","+**Rationale:** This application is designed for audio-only interaction. No video capabilities should be exposed to users.","+"," ---"," "," #### 5.7: Test Customizations"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"3d5c0514-7796-4319-8117-f806e8e92758"}
{"parentUuid":"2283ca15-a619-414f-9a0c-3ea746d0c19c","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","slug":"enumerated-shimmying-starlight","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_014Q4dGyoDE8jmUzfCjoAPDm","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now let me update the token generation section to show the correct permissions for audio-only:","signature":"EoYCCkYICxgCKkCSSo9xfvFstQGLLPFaCiJfxSwHdQWoVy/6e9f08WEYL8Sw0T1xxfar4v905p7W/EcYm4HIotwbNZ0Vk0g/GrWsEgx+QqNYVTcr6loZSFwaDHMB9XktTMCqDwZu7SIw5j2yoAxF//m/fx2JcwdVe988aarm1CeqRDmMNLC4ybp8TDsGnHSd80YLNu6JxbBPKm7jiL48adEzh/FGpby5mxKgk9Z4cFsqC8i0C4S/0TQ6Zz3mxgjPsIDh5LCvjNwahcMMnKRCdwjPvZqcEp8ZM3jYiaN7Ur+5ogq4QsqmtkVqFSmVHVKWB5/syngnUxfXajNKOjjcGznbPwY04SeS9hgB"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":683,"cache_read_input_tokens":67623,"cache_creation":{"ephemeral_5m_input_tokens":683,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXTt9D88YtRaqPDpVEumF","type":"assistant","uuid":"4bc2d641-4c06-4a1a-a649-24a646a91c6c","timestamp":"2026-01-25T09:45:53.311Z"}
{"parentUuid":"4bc2d641-4c06-4a1a-a649-24a646a91c6c","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","slug":"enumerated-shimmying-starlight","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_014Q4dGyoDE8jmUzfCjoAPDm","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01TK7bbKEFJD7GPuDJQ4iJ8j","name":"Edit","input":{"replace_all":false,"file_path":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/plan/future-plans/2026-01-25-web-frontend-deployment.md","old_string":"**Check Token Grant Configuration:**\n```typescript\n// In app/api/token/route.ts or connection-details/route.ts\ntoken.addGrant({\n  room: roomName,\n  roomJoin: true,\n  canPublish: true,\n  canSubscribe: true,\n  // Optional: Agent dispatch configuration\n});\n```","new_string":"**Check Token Grant Configuration (Audio-Only):**\n```typescript\n// In app/api/token/route.ts or connection-details/route.ts\ntoken.addGrant({\n  room: roomName,\n  roomJoin: true,\n  canPublish: true,      // Allow publishing audio\n  canSubscribe: true,    // Allow receiving audio\n  canPublishSources: [   // AUDIO-ONLY: restrict to microphone\n    'microphone'\n    // NOTE: 'camera' and 'screen_share' are NOT included\n  ],\n});\n```"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":683,"cache_read_input_tokens":67623,"cache_creation":{"ephemeral_5m_input_tokens":683,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXTt9D88YtRaqPDpVEumF","type":"assistant","uuid":"788e7f7d-7733-43e1-9e90-2358a63cfbd6","timestamp":"2026-01-25T09:45:58.374Z"}
{"parentUuid":"788e7f7d-7733-43e1-9e90-2358a63cfbd6","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","slug":"enumerated-shimmying-starlight","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01TK7bbKEFJD7GPuDJQ4iJ8j","type":"tool_result","content":"The file /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/plan/future-plans/2026-01-25-web-frontend-deployment.md has been updated successfully."}]},"uuid":"2adb2926-4c3f-4ea6-bd98-a35a4facc82f","timestamp":"2026-01-25T09:45:58.425Z","toolUseResult":{"filePath":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/plan/future-plans/2026-01-25-web-frontend-deployment.md","oldString":"**Check Token Grant Configuration:**\n```typescript\n// In app/api/token/route.ts or connection-details/route.ts\ntoken.addGrant({\n  room: roomName,\n  roomJoin: true,\n  canPublish: true,\n  canSubscribe: true,\n  // Optional: Agent dispatch configuration\n});\n```","newString":"**Check Token Grant Configuration (Audio-Only):**\n```typescript\n// In app/api/token/route.ts or connection-details/route.ts\ntoken.addGrant({\n  room: roomName,\n  roomJoin: true,\n  canPublish: true,      // Allow publishing audio\n  canSubscribe: true,    // Allow receiving audio\n  canPublishSources: [   // AUDIO-ONLY: restrict to microphone\n    'microphone'\n    // NOTE: 'camera' and 'screen_share' are NOT included\n  ],\n});\n```","originalFile":"# Web Frontend Deployment Implementation Plan\n\n> **Status:** DRAFT\n\n## Table of Contents\n\n- [Overview](#overview)\n- [Current State Analysis](#current-state-analysis)\n- [Desired End State](#desired-end-state)\n- [What We're NOT Doing](#what-were-not-doing)\n- [Implementation Approach](#implementation-approach)\n- [Dependencies](#dependencies)\n- [Phase 1: Agent Deployment to LiveKit Cloud](#phase-1-agent-deployment-to-livekit-cloud)\n- [Phase 2: Frontend Setup (agent-starter-react)](#phase-2-frontend-setup-agent-starter-react)\n- [Phase 3: Authentication and Token Generation](#phase-3-authentication-and-token-generation)\n- [Phase 4: Connection Testing and Optimization](#phase-4-connection-testing-and-optimization)\n- [Phase 5: Frontend Customization](#phase-5-frontend-customization)\n- [Phase 6: Production Deployment](#phase-6-production-deployment)\n- [Testing Strategy](#testing-strategy)\n- [References](#references)\n\n## Overview\n\nThis plan enables potential clients to interact with the LiveKit voice AI agent from this repository by clicking a link on a website. The implementation covers:\n\n1. Deploying the Python agent to LiveKit Cloud\n2. Setting up a Next.js/React frontend using the agent-starter-react template\n3. Implementing JWT token-based authentication\n4. Testing the connection flow\n5. Customizing the frontend with branding\n6. Deploying the frontend to production (Vercel)\n\nThe solution uses LiveKit's official starter templates and SDKs to create a production-ready web application with TypeScript/JavaScript.\n\n**IMPORTANT: This is an audio-only application. No video camera or screen sharing permissions should be requested from users. All configuration must disable video/screenshare features.**\n\n## Current State Analysis\n\n### What Exists Now\n\n**Agent Backend:**\n- Python voice AI agent in `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1`\n- Built with LiveKit Agents SDK\n- Uses OpenAI (LLM), AssemblyAI (STT), Cartesia (TTS)\n- Configured with `uv` package manager\n- Has `Dockerfile` for containerized deployment\n- Environment variables in `.env.local` (OpenAI, AssemblyAI, Cartesia API keys)\n\n**Missing:**\n- Agent not yet deployed to LiveKit Cloud\n- No web frontend for client interaction\n- No token generation server for authentication\n- No public-facing URL for clients to access\n\n### Key Discoveries\n\nFrom `docs/DEPLOYMENT.md`:\n- LiveKit Cloud deployment uses `lk` CLI\n- Agent deployment command: `lk agent create --secrets-file .env.local`\n- Multiple frontend options available (React, Flutter, Swift, Embed)\n- Connection requires JWT tokens generated server-side\n- agent-starter-react provides production-ready Next.js template\n- Token generation uses `livekit-server-sdk` npm package\n\n### Constraints\n\n1. **Security:** API secrets (LIVEKIT_API_SECRET) must never be exposed to frontend\n2. **Architecture:** Token generation must happen server-side (Next.js API routes)\n3. **Dependencies:** Agent must be deployed and running before frontend can connect\n4. **Cost:** LiveKit Cloud charges $0.01 per agent session minute\n\n## Desired End State\n\n### Success Criteria\n\n- [ ] Agent deployed and running on LiveKit Cloud\n- [ ] Next.js frontend application running locally\n- [ ] JWT token generation working via backend API route\n- [ ] Users can click a link and connect to voice AI agent\n- [ ] Audio conversation works end-to-end (STT → LLM → TTS)\n- [ ] Frontend deployed to production URL (Vercel)\n- [ ] Customized branding (logo, colors, company name)\n- [ ] Light/dark theme support\n- [ ] Audio visualization working\n- [ ] Mobile-responsive design\n\n### How to Verify\n\n**Agent Deployment:**\n```bash\nlk agent status\n# Expected: Status: Running, Replicas: X/X ready\n```\n\n**Frontend Connection:**\n1. Visit frontend URL (local: http://localhost:3000, prod: https://your-app.vercel.app)\n2. Click \"Connect\" or \"Start Session\"\n3. Grant microphone permissions when prompted\n4. Speak to the agent\n5. Verify agent responds with natural voice\n6. Check agent logs: `lk agent logs --follow`\n\n**End-to-End Test:**\n```bash\n# Terminal 1: Monitor agent logs\nlk agent logs --follow\n\n# Terminal 2: Run frontend\ncd /path/to/frontend\npnpm dev\n\n# Browser: Visit http://localhost:3000, connect, and speak\n```\n\n## What We're NOT Doing\n\n**Out of Scope:**\n- Multiple agent types or agent selection UI\n- User authentication/login system (anonymous users only)\n- Database integration or conversation history storage\n- Multi-language support (English only initially)\n- iOS/Android native apps (web only)\n- Custom voice customization UI\n- Payment integration or usage metering\n- Advanced analytics dashboard\n- Server-side rendering (SSR) for the voice interface\n- Custom WebRTC infrastructure (using LiveKit Cloud)\n\n**Future Considerations:**\n- User accounts and saved conversations\n- Analytics and usage tracking\n- Custom domain with branding\n- A/B testing different agent configurations\n- Rate limiting and abuse prevention\n\n## Implementation Approach\n\n### High-Level Strategy\n\n1. **Deploy Agent First:** Ensure the Python agent is running on LiveKit Cloud before building frontend\n2. **Use Official Template:** Start with agent-starter-react to avoid reinventing the wheel\n3. **Iterative Testing:** Test each phase independently before proceeding\n4. **Security-First:** Never expose API secrets; use environment variables and server-side token generation\n5. **Quick Validation:** Use LiveKit Agents Playground first to verify agent works before building frontend\n\n### Technology Stack\n\n**Backend (Agent):**\n- Python 3.11+\n- LiveKit Agents SDK\n- OpenAI GPT-4 (LLM)\n- AssemblyAI (STT)\n- Cartesia (TTS)\n- Deployed to: LiveKit Cloud\n\n**Frontend:**\n- Next.js 14+ (App Router)\n- React 18+\n- TypeScript\n- Tailwind CSS\n- Shadcn/ui components\n- `livekit-client` SDK\n- `@livekit/components-react`\n- Deployed to: Vercel\n\n**Authentication:**\n- JWT tokens (livekit-server-sdk)\n- Server-side generation (Next.js API routes)\n- 2-hour token expiration\n\n## Dependencies\n\n**Execution Order:**\n\n1. Phase 1: Agent Deployment (no dependencies)\n2. Phase 2: Frontend Setup (depends on Phase 1 for credentials)\n3. Phase 3: Authentication (depends on Phase 2)\n4. Phase 4: Connection Testing (depends on Phases 1-3)\n5. Phase 5: Frontend Customization (depends on Phase 4)\n6. Phase 6: Production Deployment (depends on Phase 5)\n\n**Dependency Graph:**\n\n```\nPhase 1 (Agent Deployment)\n  └─> Phase 2 (Frontend Setup)\n        └─> Phase 3 (Authentication)\n              └─> Phase 4 (Testing)\n                    └─> Phase 5 (Customization)\n                          └─> Phase 6 (Production)\n```\n\n**Parallelization:**\n- All phases are sequential due to dependencies\n- Within each phase, independent tasks can run in parallel\n\n---\n\n## Phase 1: Agent Deployment to LiveKit Cloud\n\n### Overview\n\nDeploy the Python voice AI agent to LiveKit Cloud to make it accessible via WebRTC. This creates a running agent that can be dispatched to rooms when users connect.\n\n### Context\n\nBefore starting, ensure you have:\n- LiveKit CLI installed: `brew install livekit/livekit/livekit-cli`\n- LiveKit Cloud account at https://cloud.livekit.io\n- Agent code in `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1`\n- API keys in `.env.local` (OpenAI, AssemblyAI, Cartesia)\n\nFiles to review:\n- `docs/DEPLOYMENT.md` - Complete deployment guide\n- `.env.local` - API keys and secrets\n- `Dockerfile` - Container build configuration\n- `src/app.py` - Agent entry point\n\n### Dependencies\n\n**Depends on:** None (first phase)\n\n**Required by:** Phase 2 (Frontend needs LiveKit credentials), Phase 4 (Testing needs deployed agent)\n\n### Changes Required\n\n#### 1.1: Authenticate with LiveKit Cloud\n\n**What:** Link your CLI to your LiveKit Cloud account\n\n**Command:**\n```bash\nlk cloud auth\n```\n\n**Expected Outcome:**\n- Browser opens for authentication\n- CLI displays: \"Successfully authenticated with LiveKit Cloud\"\n- Credentials saved in `~/.livekit/credentials`\n\n**Rationale:** Required for all subsequent `lk` CLI commands\n\n---\n\n#### 1.2: Create or Select LiveKit Project\n\n**What:** Create a new project or select an existing one for the agent deployment\n\n**Commands:**\n```bash\n# List existing projects\nlk project list\n\n# Option A: Use existing project\nlk project set-default \"your-project-name\"\n\n# Option B: Create new project via dashboard\n# Visit https://cloud.livekit.io and create a new project\n# Then set as default: lk project set-default \"new-project-name\"\n\n# Verify current project\nlk project current\n```\n\n**Expected Outcome:**\n```\nNAME                 PROJECT_ID\nyour-project-name   prj_abc123\n```\n\n**Rationale:** Agent deployments are scoped to projects; need a target project first\n\n---\n\n#### 1.3: Verify Secrets File\n\n**What:** Ensure `.env.local` contains all required API keys\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/.env.local`\n\n**Verify contents:**\n```bash\ncat .env.local\n```\n\n**Required secrets:**\n```env\nOPENAI_API_KEY=sk-...\nASSEMBLYAI_API_KEY=...\nCARTESIA_API_KEY=...\n```\n\n**Important Notes:**\n- Do NOT include `LIVEKIT_URL`, `LIVEKIT_API_KEY`, or `LIVEKIT_API_SECRET` in `.env.local`\n- LiveKit Cloud auto-injects these during deployment\n- Verify `.env.local` is in `.gitignore`\n\n**Rationale:** Agent needs these API keys to function; LiveKit Cloud encrypts and injects them as environment variables\n\n---\n\n#### 1.4: Download Model Files\n\n**What:** Download required models (Silero VAD, turn detector) before deployment\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\nuv run python src/app.py download-files\n```\n\n**Expected Outcome:**\n```\nDownloading Silero VAD model...\nDownloading multilingual turn detector model...\nDownload complete.\n```\n\n**Rationale:** Models are required at runtime; downloading during build ensures faster agent startup\n\n---\n\n#### 1.5: Deploy Agent to LiveKit Cloud\n\n**What:** Create and deploy the agent container to LiveKit Cloud\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\nlk agent create --secrets-file .env.local\n```\n\n**Expected Outcome:**\n```\nRegistering agent...\nAgent ID: agent_abc123\nBuilding container image...\nUploading code...\nBuild in progress (this may take 2-5 minutes)...\nBuild complete.\nDeploying agent...\nDeployment successful.\nStatus: Running\nReplicas: 2/2 ready\n```\n\n**What Happens:**\n1. CLI registers new agent with Cloud project\n2. Assigns unique agent ID (e.g., `agent_abc123`)\n3. Creates/updates `livekit.toml` configuration file\n4. Uploads source code to LiveKit build service\n5. Builds Docker container from `Dockerfile`\n6. Deploys container to Cloud project\n7. Encrypts and injects secrets as environment variables\n8. Starts 2 replica instances\n\n**Duration:** 2-5 minutes for initial build\n\n**Rationale:** Makes agent accessible via LiveKit's global WebRTC infrastructure\n\n---\n\n#### 1.6: Verify Agent Status\n\n**What:** Confirm agent is running and ready to accept sessions\n\n**Commands:**\n```bash\n# Check agent status\nlk agent status\n\n# View live logs\nlk agent logs --tail 50\n```\n\n**Expected Status Output:**\n```\nAgent ID:     agent_abc123\nStatus:       Running\nReplicas:     2/2 ready\nVersion:      v1\nLast Deploy:  2026-01-25 10:30:00 UTC\nRegion:       us-west-2\n```\n\n**Expected Log Output:**\n- No error messages\n- Successful initialization messages\n- \"Waiting for room assignment\" or similar\n\n**Troubleshooting:**\n- If status is `CrashLoop`: Check logs for Python exceptions\n- If status is `Build Failed`: Run `lk agent logs --build` to see build errors\n- If secrets missing: Run `lk agent secrets` to verify\n\n**Rationale:** Ensures agent is healthy before proceeding to frontend setup\n\n---\n\n#### 1.7: Quick Test with Agents Playground\n\n**What:** Test agent using LiveKit Agents Playground (no code required)\n\n**Steps:**\n1. Get project credentials:\n   ```bash\n   lk project current --json\n   ```\n\n2. Visit https://agents-playground.livekit.io/\n\n3. Enter credentials:\n   - **LiveKit URL:** `wss://your-project.livekit.cloud` (from JSON output)\n   - **API Key:** Your `LIVEKIT_API_KEY` (from JSON output)\n   - **API Secret:** Your `LIVEKIT_API_SECRET` (from JSON output)\n\n4. Click \"Connect\"\n\n5. Allow microphone access when prompted\n\n6. Speak to your agent\n\n7. Monitor agent logs in terminal:\n   ```bash\n   lk agent logs --follow\n   ```\n\n**Expected Outcome:**\n- Agent responds to your voice with natural TTS\n- Logs show STT transcriptions, LLM responses, TTS generation\n- No errors in logs\n\n**Rationale:** Validates agent works end-to-end before investing in frontend development\n\n---\n\n#### 1.8: Save LiveKit Credentials\n\n**What:** Export LiveKit project credentials for frontend configuration\n\n**Command:**\n```bash\nlk project current --json > livekit-credentials.json\n```\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/livekit-credentials.json`\n\n**Expected Contents:**\n```json\n{\n  \"name\": \"your-project-name\",\n  \"url\": \"wss://your-project.livekit.cloud\",\n  \"api_key\": \"APIxxxxxxxxxxxx\",\n  \"api_secret\": \"your-secret-here\"\n}\n```\n\n**Security Note:**\n- Add `livekit-credentials.json` to `.gitignore`\n- NEVER commit this file to version control\n- This file is for local reference only\n\n**Rationale:** Frontend needs these credentials to generate tokens and connect to LiveKit\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] CLI authenticated: `lk cloud auth` successful\n- [ ] Project selected: `lk project current` shows correct project\n- [ ] Agent deployed: `lk agent status` shows `Status: Running`\n- [ ] Replicas ready: `lk agent status` shows `X/X ready` (e.g., 2/2)\n- [ ] No crash loops: `lk agent logs --tail 50` shows no errors\n- [ ] Credentials saved: `livekit-credentials.json` exists and contains valid JSON\n\n#### Manual Verification:\n\n- [ ] Agents Playground connection successful\n- [ ] Agent responds to voice input with TTS output\n- [ ] Agent logs show successful STT → LLM → TTS pipeline\n- [ ] No API key errors in logs\n- [ ] Agent state transitions visible (initializing → listening → thinking → speaking)\n\n**Verify:** After completing automated verification, test agent with Agents Playground before proceeding to Phase 2.\n\n---\n\n## Phase 2: Frontend Setup (agent-starter-react)\n\n### Overview\n\nClone and configure the agent-starter-react template to create a Next.js web application that connects users to your deployed agent.\n\n### Context\n\nBefore starting, ensure:\n- Phase 1 completed successfully\n- Agent is running on LiveKit Cloud\n- `livekit-credentials.json` file exists with credentials\n\nPrerequisites:\n- Node.js 18+ installed\n- pnpm installed: `npm install -g pnpm`\n- `lk` CLI authenticated\n\nFiles to review:\n- `livekit-credentials.json` - LiveKit project credentials\n- N/A (frontend doesn't exist yet)\n\n### Dependencies\n\n**Depends on:** Phase 1 (needs LiveKit credentials)\n\n**Required by:** Phase 3 (authentication setup), Phase 4 (connection testing)\n\n### Changes Required\n\n#### 2.1: Create Frontend Project Directory\n\n**What:** Create a directory to house the frontend application\n\n**Commands:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\nmkdir -p frontend\ncd frontend\n```\n\n**Expected Outcome:**\n```\nDirectory created: /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/\n```\n\n**Rationale:** Separates frontend code from agent backend code\n\n---\n\n#### 2.2: Clone agent-starter-react Template\n\n**What:** Use LiveKit CLI to create a new project from the official template\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend\nlk app create --template agent-starter-react\n```\n\n**Interactive Prompts:**\n- **Project name:** (Press Enter for default or enter custom name like \"voice-ai-frontend\")\n- **Install dependencies?** Yes\n\n**Alternative (Manual Clone):**\n```bash\ngit clone https://github.com/livekit-examples/agent-starter-react.git voice-ai-frontend\ncd voice-ai-frontend\npnpm install\n```\n\n**Expected Outcome:**\n```\n✓ Created project: voice-ai-frontend\n✓ Installed dependencies\n✓ Ready to configure\n```\n\n**Directory Structure:**\n```\nfrontend/voice-ai-frontend/\n├── app/\n│   ├── api/token/route.ts     # Token generation endpoint\n│   ├── page.tsx               # Main page\n│   └── layout.tsx\n├── components/\n│   ├── agents-ui/             # Agents UI components\n│   ├── app/                   # Business logic\n│   └── ui/                    # Shadcn/ui primitives\n├── hooks/\n├── lib/\n├── public/\n├── package.json\n├── .env.example\n└── next.config.js\n```\n\n**Rationale:** Official template provides production-ready structure with all necessary LiveKit integrations\n\n---\n\n#### 2.3: Configure Environment Variables\n\n**What:** Set up LiveKit credentials for the frontend\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend/.env.local`\n\n**Commands:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\ncp .env.example .env.local\n```\n\n**Edit `.env.local`:**\n```env\n# LiveKit project credentials (from livekit-credentials.json)\nLIVEKIT_API_KEY=APIxxxxxxxxxxxx\nLIVEKIT_API_SECRET=your-secret-here\nLIVEKIT_URL=wss://your-project.livekit.cloud\n\n# Public URL (exposed to browser - same as LIVEKIT_URL)\nNEXT_PUBLIC_LIVEKIT_URL=wss://your-project.livekit.cloud\n\n# Agent configuration\nAGENT_NAME=\n# Leave AGENT_NAME blank for automatic agent dispatch\n# Or set to specific agent name if you have multiple agents\n```\n\n**How to Get Values:**\n```bash\n# Copy from livekit-credentials.json\ncat /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/livekit-credentials.json\n```\n\n**Security Notes:**\n- `LIVEKIT_API_SECRET` is server-side only (never exposed to browser)\n- `NEXT_PUBLIC_*` variables are exposed to browser\n- Only `NEXT_PUBLIC_LIVEKIT_URL` should be public\n- Never expose `LIVEKIT_API_KEY` or `LIVEKIT_API_SECRET` to browser\n\n**Rationale:** Frontend needs credentials to generate tokens and connect to LiveKit rooms\n\n---\n\n#### 2.4: Verify Dependencies Installation\n\n**What:** Ensure all npm packages are installed correctly\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\npnpm install\n```\n\n**Expected Outcome:**\n```\nPackages: +XXX\nProgress: resolved XXX, reused XXX, downloaded X, added XXX, done\n```\n\n**Key Dependencies (verify in `package.json`):**\n- `next` (v14+)\n- `react` (v18+)\n- `livekit-client`\n- `@livekit/components-react`\n- `livekit-server-sdk`\n- `tailwindcss`\n- `typescript`\n\n**Troubleshooting:**\n- If pnpm not installed: `npm install -g pnpm`\n- If peer dependency warnings: Generally safe to ignore\n- If install fails: Delete `node_modules` and `pnpm-lock.yaml`, retry\n\n**Rationale:** Ensures all required packages are available for development\n\n---\n\n#### 2.5: Run Development Server\n\n**What:** Start the Next.js development server to verify basic setup\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\npnpm dev\n```\n\n**Expected Outcome:**\n```\n> next dev\n\n  ▲ Next.js 14.x.x\n  - Local:        http://localhost:3000\n  - Environments: .env.local\n\n ✓ Ready in X.Xs\n```\n\n**Verification:**\n1. Open browser to http://localhost:3000\n2. Should see agent interface with \"Connect\" button\n3. No console errors in browser DevTools\n4. Page loads without 500 errors\n\n**Expected UI:**\n- Welcome/landing view\n- \"Connect\" or \"Start Session\" button\n- Logo and branding elements\n- Theme toggle (light/dark)\n\n**Troubleshooting:**\n- If port 3000 in use: `pnpm dev -- -p 3001`\n- If env vars missing: Check `.env.local` exists and has correct values\n- If build errors: Check `pnpm install` completed successfully\n\n**Rationale:** Validates Next.js setup before proceeding to authentication\n\n---\n\n#### 2.6: Inspect Token Generation API Route\n\n**What:** Review the built-in token generation endpoint to understand how authentication works\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend/app/api/token/route.ts`\n\n**Read the file:**\n```typescript\n// Expected structure (review actual implementation)\nimport { AccessToken } from 'livekit-server-sdk';\n\nexport async function POST(request: Request) {\n  const { roomName, participantName } = await request.json();\n\n  const token = new AccessToken(\n    process.env.LIVEKIT_API_KEY,\n    process.env.LIVEKIT_API_SECRET,\n    {\n      identity: participantName,\n      ttl: '2h', // Token valid for 2 hours\n    }\n  );\n\n  token.addGrant({\n    room: roomName,\n    roomJoin: true,\n    canPublish: true,\n    canSubscribe: true,\n  });\n\n  return Response.json({ token: await token.toJwt() });\n}\n```\n\n**Key Points:**\n- Uses `livekit-server-sdk` to generate JWT tokens\n- Reads `LIVEKIT_API_KEY` and `LIVEKIT_API_SECRET` from environment\n- Grants room join, publish, and subscribe permissions\n- Returns JWT token to frontend\n- Token expires after 2 hours (LiveKit auto-refreshes for connected clients)\n\n**Security Review:**\n- ✓ API key/secret are server-side only (not exposed to browser)\n- ✓ Token generation happens on server\n- ✓ Appropriate permissions granted\n- ⚠ Consider adding rate limiting for production\n\n**Rationale:** Understanding token flow is critical for debugging connection issues\n\n---\n\n#### 2.7: Add Frontend to .gitignore (Backend Repo)\n\n**What:** Prevent frontend from being committed to agent backend repo\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/.gitignore`\n\n**Add to `.gitignore`:**\n```bash\necho \"frontend/\" >> .gitignore\n```\n\n**Verify:**\n```bash\ngit status\n# frontend/ should not appear in untracked files\n```\n\n**Alternative Approach:**\nIf you want to commit the frontend to the same repo:\n- Create a separate `.gitignore` in `frontend/voice-ai-frontend/`\n- Add standard Next.js ignores (`.next/`, `node_modules/`, `.env.local`)\n\n**Rationale:** Keep frontend and backend as separate concerns, or manage carefully if in same repo\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Frontend directory created: `ls frontend/voice-ai-frontend`\n- [ ] Dependencies installed: `pnpm list --depth=0` shows key packages\n- [ ] Environment variables configured: `cat .env.local | grep LIVEKIT_API_KEY`\n- [ ] Development server starts: `pnpm dev` runs without errors\n- [ ] No TypeScript errors: `pnpm run build` completes successfully\n\n#### Manual Verification:\n\n- [ ] Visit http://localhost:3000 in browser\n- [ ] Page loads without 500 errors\n- [ ] UI displays welcome screen with \"Connect\" button\n- [ ] No console errors in browser DevTools\n- [ ] Theme toggle works (light/dark mode)\n- [ ] Responsive design works on mobile viewport\n\n**Verify:** After completing automated verification, open the app in a browser and verify UI loads correctly before proceeding to Phase 3.\n\n---\n\n## Phase 3: Authentication and Token Generation\n\n### Overview\n\nConfigure and test the JWT token generation flow to ensure frontend can authenticate users with LiveKit and connect them to agent sessions.\n\n### Context\n\nBefore starting, ensure:\n- Phase 2 completed successfully\n- Development server running at http://localhost:3000\n- Environment variables configured in `.env.local`\n\nFiles to review:\n- `frontend/voice-ai-frontend/app/api/token/route.ts` - Token generation endpoint\n- `frontend/voice-ai-frontend/.env.local` - Environment configuration\n- `frontend/voice-ai-frontend/components/app/` - Client-side connection logic\n\n### Dependencies\n\n**Depends on:** Phase 2 (frontend setup)\n\n**Required by:** Phase 4 (connection testing)\n\n### Changes Required\n\n#### 3.1: Test Token Generation Endpoint\n\n**What:** Verify the token API endpoint works correctly\n\n**Command:**\n```bash\n# Start dev server (if not running)\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\npnpm dev\n\n# In another terminal, test the endpoint\ncurl -X POST http://localhost:3000/api/token \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"roomName\": \"test-room\", \"participantName\": \"test-user\"}'\n```\n\n**Expected Response:**\n```json\n{\n  \"token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\"\n}\n```\n\n**Validate Token:**\n```bash\n# Decode the JWT to inspect claims (copy token from response)\necho \"eyJhbGciOiJ...\" | cut -d'.' -f2 | base64 -d | jq\n```\n\n**Expected Token Payload:**\n```json\n{\n  \"exp\": 1234567890,\n  \"iss\": \"APIxxxxxxxxxxxx\",\n  \"sub\": \"test-user\",\n  \"nbf\": 1234567890,\n  \"video\": {\n    \"room\": \"test-room\",\n    \"roomJoin\": true,\n    \"canPublish\": true,\n    \"canSubscribe\": true,\n    \"canPublishData\": true\n  }\n}\n```\n\n**Troubleshooting:**\n- If 500 error: Check environment variables in `.env.local`\n- If \"api_key undefined\": Verify `LIVEKIT_API_KEY` is set\n- If \"invalid signature\": Check `LIVEKIT_API_SECRET` is correct\n- If no response: Verify dev server is running on port 3000\n\n**Rationale:** Token generation must work before attempting to connect to LiveKit\n\n---\n\n#### 3.2: Review Client-Side Connection Logic\n\n**What:** Understand how the frontend connects to LiveKit rooms\n\n**Files to Review:**\n```bash\n# Main session component\ncat frontend/voice-ai-frontend/components/app/session-view.tsx\n\n# View controller\ncat frontend/voice-ai-frontend/components/app/view-controller.tsx\n\n# Connection utilities\ncat frontend/voice-ai-frontend/lib/connection.ts\n```\n\n**Key Flow:**\n1. User clicks \"Connect\" button\n2. Frontend generates room name (random or predefined)\n3. Frontend fetches token from `/api/token` endpoint\n4. Frontend connects to LiveKit room using `livekit-client`\n5. Agent is automatically dispatched to room\n6. User and agent establish WebRTC connection\n7. Audio tracks are exchanged\n\n**Important Variables:**\n- `NEXT_PUBLIC_LIVEKIT_URL` - LiveKit server URL (browser-accessible)\n- Room name generation logic\n- Participant name/identity\n- Agent dispatch configuration\n\n**Rationale:** Understanding client-side logic helps debug connection issues\n\n---\n\n#### 3.3: Configure Agent Dispatch\n\n**What:** Ensure frontend triggers automatic agent dispatch when users connect\n\n**File:** Review `frontend/voice-ai-frontend/app/api/connection-details/route.ts` (if exists) or equivalent\n\n**Verify Agent Name Configuration:**\n\n**Option A: Automatic Dispatch (Recommended):**\n```env\n# In .env.local\nAGENT_NAME=\n# Blank means \"dispatch any available agent\"\n```\n\n**Option B: Specific Agent:**\n```env\n# In .env.local\nAGENT_NAME=agent_abc123\n# Uses specific agent by ID or name\n```\n\n**Check Token Grant Configuration:**\n```typescript\n// In app/api/token/route.ts or connection-details/route.ts\ntoken.addGrant({\n  room: roomName,\n  roomJoin: true,\n  canPublish: true,\n  canSubscribe: true,\n  // Optional: Agent dispatch configuration\n});\n```\n\n**For agent-starter-react:**\nThe template typically handles agent dispatch automatically when a participant joins a room. Verify this by checking the token generation code and connection details endpoint.\n\n**Rationale:** Agent won't join room unless dispatch is configured correctly\n\n---\n\n#### 3.4: Test Token Expiration and Refresh\n\n**What:** Verify token expiration is set correctly and LiveKit handles refresh\n\n**Check Current TTL:**\n```typescript\n// In app/api/token/route.ts\nconst token = new AccessToken(\n  process.env.LIVEKIT_API_KEY,\n  process.env.LIVEKIT_API_SECRET,\n  {\n    identity: participantName,\n    ttl: '2h', // Current setting\n  }\n);\n```\n\n**Recommended TTL:**\n- Development: `2h` (2 hours)\n- Production: `2h` (LiveKit auto-refreshes for connected clients)\n- Pre-generated tokens: `1h` (if caching tokens)\n\n**Token Refresh Behavior:**\n- LiveKit client SDK automatically refreshes tokens before expiration\n- Refresh happens for connected clients only\n- Disconnected users must request new tokens\n\n**No changes needed if TTL is already `2h`.**\n\n**Rationale:** Prevents users from being disconnected due to token expiration\n\n---\n\n#### 3.5: Add Security Headers (Optional but Recommended)\n\n**What:** Add security headers to token API route\n\n**File:** `frontend/voice-ai-frontend/middleware.ts` (create if doesn't exist)\n\n**Content:**\n```typescript\nimport { NextResponse } from 'next/server';\nimport type { NextRequest } from 'next/server';\n\nexport function middleware(request: NextRequest) {\n  const response = NextResponse.next();\n\n  // Security headers\n  response.headers.set('X-Content-Type-Options', 'nosniff');\n  response.headers.set('X-Frame-Options', 'DENY');\n  response.headers.set('X-XSS-Protection', '1; mode=block');\n\n  return response;\n}\n\nexport const config = {\n  matcher: '/api/:path*',\n};\n```\n\n**Optional Rate Limiting:**\nConsider adding rate limiting to `/api/token` endpoint to prevent abuse.\n\n**Rationale:** Basic security hardening for production deployments\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Token endpoint returns valid JWT: `curl -X POST http://localhost:3000/api/token -H \"Content-Type: application/json\" -d '{\"roomName\":\"test\",\"participantName\":\"user\"}' | jq .token`\n- [ ] Token payload contains correct claims: Decode JWT and verify `video.roomJoin: true`\n- [ ] Environment variables loaded: `console.log(process.env.LIVEKIT_API_KEY)` in token route shows value (not undefined)\n- [ ] Token has correct expiration: Decoded JWT shows `exp` timestamp 2 hours in future\n\n#### Manual Verification:\n\n- [ ] Token endpoint accessible via browser: Visit http://localhost:3000/api/token (should return 405 Method Not Allowed for GET)\n- [ ] No errors in Next.js server logs when generating tokens\n- [ ] Token decodes successfully at https://jwt.io\n- [ ] Token issuer (`iss`) matches your LiveKit API key\n- [ ] Token subject (`sub`) matches requested participant name\n\n**Verify:** After completing automated verification, test token generation with curl and decode the JWT to inspect claims before proceeding to Phase 4.\n\n---\n\n## Phase 4: Connection Testing and Optimization\n\n### Overview\n\nTest the end-to-end connection flow from frontend to agent, verify audio works correctly, and optimize the connection speed.\n\n### Context\n\nBefore starting, ensure:\n- Phase 3 completed successfully\n- Agent running on LiveKit Cloud (`lk agent status` shows Running)\n- Frontend running at http://localhost:3000\n- Token generation working\n\nFiles to review:\n- `frontend/voice-ai-frontend/components/app/session-view.tsx` - Session management\n- `frontend/voice-ai-frontend/components/agents-ui/` - UI components\n\nTools needed:\n- Browser with microphone access\n- Terminal for monitoring agent logs\n\n### Dependencies\n\n**Depends on:** Phases 1-3 (agent deployed, frontend configured, authentication working)\n\n**Required by:** Phase 5 (customization), Phase 6 (production deployment)\n\n### Changes Required\n\n#### 4.1: Monitor Agent Logs\n\n**What:** Start monitoring agent logs before testing connection\n\n**Command:**\n```bash\n# Open a dedicated terminal window for agent logs\nlk agent logs --follow\n```\n\n**Keep this terminal open during all testing.**\n\n**What to Look For:**\n- Agent initialization messages\n- Room join events\n- STT transcriptions\n- LLM requests/responses\n- TTS generation\n- WebRTC connection events\n- Any error messages\n\n**Rationale:** Real-time logs are essential for debugging connection issues\n\n---\n\n#### 4.2: Test Basic Connection Flow\n\n**What:** Connect to the agent via frontend and verify basic functionality\n\n**Steps:**\n\n1. Open browser to http://localhost:3000\n2. Open browser DevTools Console (F12 → Console tab)\n3. Click \"Connect\" or \"Start Session\" button\n4. Grant microphone permissions when prompted\n5. Observe connection states in UI:\n   - \"Initializing...\"\n   - \"Listening\" (agent ready for input)\n   - \"Thinking\" (processing speech)\n   - \"Speaking\" (agent responding)\n\n**Expected Behavior:**\n- Connection establishes within 3-5 seconds\n- Agent state transitions to \"Listening\"\n- No errors in browser console\n- Agent logs show room join event\n\n**Troubleshooting:**\n- **Connection hangs:** Check token endpoint, verify LIVEKIT_URL is correct\n- **\"Failed to connect\":** Check agent status (`lk agent status`), verify agent is Running\n- **Microphone permission denied:** Grant permission in browser settings\n- **No audio:** Check browser audio output, verify speakers are enabled\n- **WebRTC errors:** Check firewall, ensure WebRTC ports not blocked\n\n**Rationale:** Validates basic connection before testing voice interaction\n\n---\n\n#### 4.3: Test Voice Interaction\n\n**What:** Verify end-to-end voice pipeline (STT → LLM → TTS)\n\n**Steps:**\n\n1. With frontend connected and agent in \"Listening\" state\n2. Speak clearly into your microphone: \"Hello, can you hear me?\"\n3. Observe agent state transition:\n   - \"Listening\" → \"Thinking\" → \"Speaking\"\n4. Listen for agent's voice response\n5. Check agent logs for:\n   - STT transcription of your speech\n   - LLM request and response\n   - TTS generation\n\n**Expected Outcome:**\n- Agent responds with natural voice within 2-4 seconds\n- Transcription appears in logs (if logging enabled)\n- No audio dropouts or distortion\n- Agent response is contextually appropriate\n\n**Additional Test Cases:**\n- **Interruption:** Speak while agent is speaking (should handle gracefully)\n- **Silence:** Wait 10 seconds without speaking (agent should remain connected)\n- **Background Noise:** Test with ambient noise (should filter with VAD)\n- **Multiple Turns:** Have a multi-turn conversation\n\n**Troubleshooting:**\n- **No transcription:** Check AssemblyAI API key in agent secrets\n- **No LLM response:** Check OpenAI API key, verify LLM model is available\n- **No TTS audio:** Check Cartesia API key, verify TTS voice model\n- **Garbled audio:** Check network connection, reduce network congestion\n- **High latency:** Check agent logs for slow API calls, consider region optimization\n\n**Rationale:** Validates the complete voice AI pipeline works end-to-end\n\n---\n\n#### 4.4: Verify Audio Visualization\n\n**What:** Test the audio visualizer component works correctly\n\n**Steps:**\n\n1. With frontend connected\n2. Speak into microphone\n3. Observe audio visualization:\n   - Bars should animate when you speak\n   - Bars should pulse when agent speaks\n   - Different colors/states for listening vs speaking\n\n**Expected Behavior:**\n- `BarVisualizer` component shows real-time audio levels\n- Smooth animations\n- Clear visual feedback of agent state\n- No lag between audio and visualization\n\n**Check Component:**\n```bash\n# Review visualizer component\ncat frontend/voice-ai-frontend/components/agents-ui/bar-visualizer.tsx\n```\n\n**Troubleshooting:**\n- **No visualization:** Check if audio track is being passed to component\n- **Choppy animation:** Check browser performance, reduce animation complexity\n- **Wrong colors:** Review CSS/Tailwind classes\n\n**Rationale:** Visual feedback improves user experience and debugging\n\n---\n\n#### 4.5: Test Disconnection and Reconnection\n\n**What:** Verify graceful disconnect and ability to reconnect\n\n**Steps:**\n\n**Test Disconnect:**\n1. With frontend connected\n2. Click \"Disconnect\" or \"End Session\" button\n3. Observe clean disconnect:\n   - Agent logs show participant left\n   - No error messages\n   - UI returns to welcome screen\n\n**Test Reconnect:**\n1. Click \"Connect\" again\n2. Verify new session starts successfully\n3. Test voice interaction again\n\n**Test Network Interruption (Optional):**\n1. While connected, disable network (Wi-Fi off)\n2. Observe reconnection behavior\n3. Re-enable network\n4. Verify auto-reconnect or error message\n\n**Expected Behavior:**\n- Clean disconnect without errors\n- Ability to reconnect immediately\n- Each session gets unique room/token\n- No lingering WebRTC connections\n\n**Rationale:** Ensures robust connection lifecycle management\n\n---\n\n#### 4.6: Optimize Connection Speed\n\n**What:** Reduce connection time from 3-5 seconds to <1 second using optimization techniques\n\n**Current Flow (Sequential):**\n```\n1. Click Connect (0ms)\n2. Fetch token from /api/token (500ms)\n3. Connect to LiveKit room (1000ms)\n4. Agent dispatched (1000ms)\n5. Agent connects and publishes (1500ms)\nTotal: ~4000ms (4 seconds)\n```\n\n**Optimization 1: Pre-generate Tokens**\n\nCreate a \"warm token\" approach for faster connection:\n\n**File:** Create `frontend/voice-ai-frontend/hooks/use-warm-token.ts`\n\n```typescript\n'use client';\n\nimport { useState, useEffect } from 'react';\n\nexport function useWarmToken() {\n  const [token, setToken] = useState<string | null>(null);\n\n  useEffect(() => {\n    // Pre-generate token on page load\n    async function generateToken() {\n      const response = await fetch('/api/token', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          roomName: `room-${Date.now()}`,\n          participantName: `user-${Math.random().toString(36).substring(7)}`,\n        }),\n      });\n      const data = await response.json();\n      setToken(data.token);\n    }\n\n    generateToken();\n  }, []);\n\n  return token;\n}\n```\n\n**Usage in Session Component:**\n```typescript\n// In session-view.tsx or similar\nconst warmToken = useWarmToken();\n\n// Use warmToken when connecting instead of fetching on-demand\n```\n\n**Optimization 2: Concurrent Dispatch**\n\nModify connection logic to dispatch agent and connect user simultaneously:\n\n```typescript\n// Parallel connection\nconst [roomConnection, agentDispatch] = await Promise.all([\n  connectToRoom(token),\n  dispatchAgent(roomName) // If manual dispatch required\n]);\n```\n\n**Expected Improvement:**\n- Pre-generated token: -500ms (eliminates token fetch delay)\n- Concurrent dispatch: -1000ms (parallel instead of sequential)\n- **New total:** ~2500ms → ~1500ms (1.5 seconds)\n\n**Trade-offs:**\n- Pre-generated tokens have expiration (ensure 2h TTL)\n- Unused tokens waste resources (minimal cost)\n- Complexity slightly increases\n\n**Rationale:** Faster connections improve user experience and perceived performance\n\n---\n\n#### 4.7: Test on Multiple Browsers\n\n**What:** Verify cross-browser compatibility\n\n**Browsers to Test:**\n- Chrome/Chromium\n- Firefox\n- Safari (macOS/iOS)\n- Edge\n\n**Test Matrix:**\n\n| Browser | Connection | Audio Input | Audio Output | Visualization |\n|---------|-----------|-------------|--------------|---------------|\n| Chrome  | ✓         | ✓           | ✓            | ✓             |\n| Firefox | ?         | ?           | ?            | ?             |\n| Safari  | ?         | ?           | ?            | ?             |\n| Edge    | ?         | ?           | ?            | ?             |\n\n**Common Issues:**\n- **Safari:** May require user interaction before audio playback\n- **Firefox:** Different WebRTC implementation, may have quirks\n- **Mobile Safari:** Requires specific audio context handling\n- **Edge:** Generally compatible with Chrome\n\n**Rationale:** Ensures wide browser support for production deployment\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Connection establishes successfully: Monitor for \"Room connected\" event in logs\n- [ ] Agent joins room: `lk agent logs` shows room join event\n- [ ] WebRTC connection: Browser DevTools Network tab shows WebRTC connections\n- [ ] No console errors: Browser DevTools Console shows no red errors\n- [ ] Audio tracks published: Check LiveKit Cloud dashboard for active tracks\n\n#### Manual Verification:\n\n- [ ] Voice input recognized: Speak and verify agent responds\n- [ ] Voice output works: Hear agent's TTS response clearly\n- [ ] Audio visualization animates correctly\n- [ ] Agent state transitions work (initializing → listening → thinking → speaking)\n- [ ] Interruption handling works (speak during agent response)\n- [ ] Disconnect and reconnect works cleanly\n- [ ] Connection time <3 seconds (before optimization) or <1.5s (after optimization)\n- [ ] Works in Chrome, Firefox, and Safari\n\n**Verify:** After completing automated verification, have a multi-turn conversation with the agent and test all edge cases before proceeding to Phase 5.\n\n---\n\n## Phase 5: Frontend Customization\n\n### Overview\n\nCustomize the frontend with your branding, colors, logo, and company information to make it production-ready.\n\n### Context\n\nBefore starting, ensure:\n- Phase 4 completed successfully\n- Voice interaction working end-to-end\n- Frontend running at http://localhost:3000\n\nFiles to customize:\n- `frontend/voice-ai-frontend/app-config.ts` - Main configuration\n- `frontend/voice-ai-frontend/public/` - Static assets (logo, favicon)\n- `frontend/voice-ai-frontend/app/layout.tsx` - Page metadata\n- `frontend/voice-ai-frontend/tailwind.config.ts` - Theme colors\n\n### Dependencies\n\n**Depends on:** Phase 4 (connection testing completed)\n\n**Required by:** Phase 6 (production deployment)\n\n### Changes Required\n\n#### 5.1: Update App Configuration\n\n**What:** Customize company name, page title, and feature flags\n\n**File:** `frontend/voice-ai-frontend/app-config.ts`\n\n**Edit:**\n```typescript\nexport const APP_CONFIG_DEFAULTS = {\n  // Branding\n  companyName: \"Your Company Name\", // Change this\n  pageTitle: \"AI Voice Assistant | Your Company\", // Change this\n\n  // Logo URLs\n  logoUrl: \"/logo.svg\", // Update after adding logo in 5.2\n  logoUrlDark: \"/logo-dark.svg\", // Optional: separate dark mode logo\n\n  // Accent color\n  accentColor: \"#4F46E5\", // Change to your brand color (hex)\n\n  // Feature toggles - AUDIO-ONLY CONFIGURATION\n  supportsChatInput: false, // Disable text chat (audio-only)\n  supportsVideoInput: false, // DISABLE camera video (audio-only)\n  supportsScreenShare: false, // DISABLE screen sharing (audio-only)\n  isPreConnectBufferEnabled: true, // Pre-load for faster connection\n\n  // Optional: Agent configuration\n  defaultAgentName: \"\", // Leave blank for auto-dispatch\n};\n```\n\n**Example Customization (Audio-Only):**\n```typescript\nexport const APP_CONFIG_DEFAULTS = {\n  companyName: \"Acme Voice AI\",\n  pageTitle: \"Voice AI Assistant | Acme Corp\",\n  logoUrl: \"/acme-logo.svg\",\n  accentColor: \"#FF6B35\", // Orange\n  supportsChatInput: false, // Audio-only: no text chat\n  supportsVideoInput: false, // Audio-only: no camera\n  supportsScreenShare: false, // Audio-only: no screen share\n  isPreConnectBufferEnabled: true,\n};\n```\n\n**Rationale:** Centralizes configuration for easy customization without code changes\n\n---\n\n#### 5.2: Add Custom Logo\n\n**What:** Replace default logo with your company logo\n\n**Steps:**\n\n1. Prepare logo files:\n   - **Format:** SVG (preferred) or PNG\n   - **Size:**\n     - SVG: Any size (scalable)\n     - PNG: 200x200px minimum, transparent background\n   - **Naming:**\n     - Light mode: `logo.svg` or `logo.png`\n     - Dark mode (optional): `logo-dark.svg` or `logo-dark.png`\n\n2. Copy to public directory:\n   ```bash\n   cp /path/to/your/logo.svg frontend/voice-ai-frontend/public/logo.svg\n   # Optional: dark mode logo\n   cp /path/to/your/logo-dark.svg frontend/voice-ai-frontend/public/logo-dark.svg\n   ```\n\n3. Update `app-config.ts`:\n   ```typescript\n   logoUrl: \"/logo.svg\",\n   logoUrlDark: \"/logo-dark.svg\", // If you have separate dark logo\n   ```\n\n4. Verify logo appears:\n   - Restart dev server: `pnpm dev`\n   - Visit http://localhost:3000\n   - Check logo displays correctly\n   - Toggle light/dark mode to test both logos\n\n**Fallback:**\nIf you don't have a logo ready, the template includes a default placeholder logo.\n\n**Rationale:** Custom logo reinforces brand identity\n\n---\n\n#### 5.3: Customize Theme Colors\n\n**What:** Update color scheme to match your brand\n\n**File:** `frontend/voice-ai-frontend/tailwind.config.ts`\n\n**Edit:**\n```typescript\nexport default {\n  theme: {\n    extend: {\n      colors: {\n        // Primary brand color\n        primary: {\n          50: '#f0f9ff',\n          100: '#e0f2fe',\n          // ... continue through 950\n          500: '#4F46E5', // Main brand color (change this)\n          600: '#4338ca',\n          // ...\n        },\n        // Accent color\n        accent: {\n          DEFAULT: '#FF6B35', // Change to your accent color\n          light: '#FF8A5B',\n          dark: '#E5501F',\n        },\n      },\n    },\n  },\n};\n```\n\n**Quick Method (Use Accent Color from app-config.ts):**\n\nThe template may automatically use `accentColor` from `app-config.ts`. If so, just update that value:\n\n```typescript\n// In app-config.ts\naccentColor: \"#FF6B35\", // Your brand color\n```\n\n**Generate Full Color Palette:**\nUse tools like https://uicolors.app/create to generate a full Tailwind color palette from your brand color.\n\n**Test Theme:**\n- Restart dev server\n- Visit http://localhost:3000\n- Check buttons, links, highlights use new colors\n- Toggle light/dark mode to verify both themes\n\n**Rationale:** Consistent color scheme creates professional, branded experience\n\n---\n\n#### 5.4: Update Page Metadata\n\n**What:** Set page title, description, and favicon for SEO and browser display\n\n**File:** `frontend/voice-ai-frontend/app/layout.tsx`\n\n**Edit:**\n```typescript\nexport const metadata: Metadata = {\n  title: \"AI Voice Assistant | Your Company\", // Change this\n  description: \"Connect with our AI voice assistant for instant help and support.\", // Change this\n  icons: {\n    icon: '/favicon.ico', // Update after adding favicon\n  },\n  openGraph: {\n    title: \"AI Voice Assistant | Your Company\",\n    description: \"Connect with our AI voice assistant for instant help and support.\",\n    images: ['/og-image.png'], // Optional: social share image\n  },\n};\n```\n\n**Add Custom Favicon:**\n\n1. Generate favicon files (use https://realfavicongenerator.net/):\n   - `favicon.ico` (16x16, 32x32, 48x48)\n   - `apple-touch-icon.png` (180x180)\n   - `favicon-16x16.png`\n   - `favicon-32x32.png`\n\n2. Copy to `public/`:\n   ```bash\n   cp /path/to/favicon.ico frontend/voice-ai-frontend/public/\n   cp /path/to/apple-touch-icon.png frontend/voice-ai-frontend/public/\n   ```\n\n3. Verify in browser:\n   - Clear browser cache\n   - Visit http://localhost:3000\n   - Check browser tab shows your favicon\n\n**Optional: Open Graph Image (Social Sharing):**\nCreate `og-image.png` (1200x630px) for social media previews.\n\n**Rationale:** Professional metadata improves SEO and user experience\n\n---\n\n#### 5.5: Customize Welcome Message\n\n**What:** Update the welcome screen text and instructions\n\n**File:** `frontend/voice-ai-frontend/components/app/welcome-view.tsx` or similar\n\n**Find and Edit:**\n```typescript\n<h1>Welcome to [Your Company] Voice AI</h1>\n<p>\n  Click the button below to start a voice conversation with our AI assistant.\n  We can help you with questions, information, and more.\n</p>\n```\n\n**Example Customization:**\n```typescript\n<h1>Welcome to Acme Voice Assistant</h1>\n<p>\n  Our AI assistant is ready to help you 24/7. Click \"Connect\" to start a\n  natural voice conversation. Just speak naturally - no keywords or commands needed.\n</p>\n<ul>\n  <li>Get instant answers to your questions</li>\n  <li>Learn about our products and services</li>\n  <li>Get personalized recommendations</li>\n</ul>\n```\n\n**Rationale:** Clear messaging helps users understand what to expect\n\n---\n\n#### 5.6: Configure Audio-Only Mode (REQUIRED)\n\n**What:** Disable video/screen share features for audio-only application\n\n**File:** `frontend/voice-ai-frontend/app-config.ts`\n\n**REQUIRED Configuration for Audio-Only App:**\n```typescript\nexport const APP_CONFIG_DEFAULTS = {\n  // ... other settings\n  supportsChatInput: false, // Audio-only: disable text chat\n  supportsVideoInput: false, // REQUIRED: disable camera\n  supportsScreenShare: false, // REQUIRED: disable screen sharing\n  isPreConnectBufferEnabled: true, // Keep for faster connection\n};\n```\n\n**Effect:**\n- Video camera icon hidden\n- Screen share button removed\n- UI simplified to voice-only interface\n- No video/screenshare permission requests to users\n- Browser only requests microphone permission\n\n**IMPORTANT:** This is a required configuration for this audio-only application. Do NOT enable video or screen sharing features.\n\n**Rationale:** This application is designed for audio-only interaction. No video capabilities should be exposed to users.\n\n---\n\n#### 5.7: Test Customizations\n\n**What:** Verify all customizations display correctly\n\n**Checklist:**\n- [ ] Company name displays on welcome screen\n- [ ] Custom logo appears (both light and dark modes)\n- [ ] Page title shows in browser tab\n- [ ] Custom favicon appears in browser tab\n- [ ] Brand colors visible on buttons and accents\n- [ ] Welcome message updated with custom text\n- [ ] Disabled features are hidden (if applicable)\n- [ ] No broken images or 404s\n- [ ] Responsive design maintained on mobile\n\n**Testing Steps:**\n1. Restart dev server: `pnpm dev`\n2. Clear browser cache (Cmd+Shift+R on Mac, Ctrl+Shift+R on Windows)\n3. Visit http://localhost:3000\n4. Toggle light/dark theme\n5. Resize browser to mobile size (375px width)\n6. Check all visual elements\n\n**Rationale:** Ensures professional, branded appearance before production deployment\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Build succeeds: `pnpm run build` completes without errors\n- [ ] No TypeScript errors: `pnpm run type-check` (if available)\n- [ ] Static assets exist: `ls public/logo.svg public/favicon.ico`\n- [ ] Config updated: `cat app-config.ts | grep companyName` shows your company\n\n#### Manual Verification:\n\n- [ ] Custom company name displays on welcome screen\n- [ ] Custom logo visible (light and dark modes)\n- [ ] Page title correct in browser tab\n- [ ] Favicon visible in browser tab\n- [ ] Brand colors applied throughout UI\n- [ ] Welcome message updated\n- [ ] Unused features hidden (if disabled)\n- [ ] Mobile responsive (test at 375px width)\n- [ ] No console errors or warnings\n- [ ] All images load correctly (no broken images)\n\n**Verify:** After completing automated verification, thoroughly test the UI on desktop and mobile, in light and dark modes, before proceeding to Phase 6.\n\n---\n\n## Phase 6: Production Deployment\n\n### Overview\n\nDeploy the customized frontend to Vercel (or another hosting provider) to make it publicly accessible via a URL that clients can visit.\n\n### Context\n\nBefore starting, ensure:\n- Phase 5 completed successfully\n- All customizations tested locally\n- Frontend builds successfully (`pnpm run build`)\n- Agent deployed and running on LiveKit Cloud\n\nFiles to review:\n- `frontend/voice-ai-frontend/.env.local` - Environment variables (will configure in Vercel)\n- `frontend/voice-ai-frontend/next.config.js` - Next.js configuration\n- `frontend/voice-ai-frontend/package.json` - Dependencies and scripts\n\nAccounts needed:\n- Vercel account (free tier sufficient): https://vercel.com\n- GitHub account (for connecting repo)\n\n### Dependencies\n\n**Depends on:** Phases 1-5 (agent deployed, frontend customized and tested)\n\n**Required by:** None (final phase)\n\n### Changes Required\n\n#### 6.1: Create Production Build\n\n**What:** Verify the production build works correctly before deploying\n\n**Commands:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\n\n# Create production build\npnpm run build\n\n# Test production build locally\npnpm start\n```\n\n**Expected Output:**\n```\n> next build\n\n✓ Compiled successfully\n✓ Linting and checking validity of types\n✓ Collecting page data\n✓ Generating static pages (X/X)\n✓ Finalizing page optimization\n\nRoute (app)                              Size     First Load JS\n┌ ○ /                                    XXX kB        XXX kB\n└ ○ /api/token                          XXX B          XXX kB\n```\n\n**Test Production Build:**\n1. Visit http://localhost:3000 (pnpm start)\n2. Connect to agent\n3. Verify voice interaction works\n4. Check for any errors in console\n\n**Troubleshooting:**\n- If build fails: Check TypeScript errors, fix before proceeding\n- If errors about environment variables: Ensure `.env.local` exists\n- If runtime errors: Check browser console for specific issues\n\n**Rationale:** Catches production-specific issues before deployment\n\n---\n\n#### 6.2: Push Frontend to GitHub (Optional but Recommended)\n\n**What:** Create a Git repository for the frontend to enable easy Vercel deployment\n\n**Option A: Separate Repository (Recommended):**\n\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\n\n# Initialize git repository\ngit init\n\n# Add .gitignore for Next.js\ncat > .gitignore << 'EOF'\n# Next.js\n.next/\nout/\nbuild/\ndist/\n\n# Dependencies\nnode_modules/\n\n# Environment variables\n.env\n.env.local\n.env.production.local\n.env.development.local\n.env.test.local\n\n# Logs\nnpm-debug.log*\nyarn-debug.log*\nyarn-error.log*\npnpm-debug.log*\n\n# OS\n.DS_Store\n*.swp\n*.swo\n\n# IDE\n.vscode/\n.idea/\n\n# Vercel\n.vercel\nEOF\n\n# Add files\ngit add .\ngit commit -m \"Initial commit: Voice AI frontend\"\n\n# Create GitHub repository (via GitHub UI or CLI)\ngh repo create voice-ai-frontend --public --source=. --remote=origin --push\n```\n\n**Option B: Same Repository as Agent:**\n\nIf you want frontend and agent in the same repo:\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\n\n# Remove frontend/ from .gitignore\nsed -i '' '/^frontend\\//d' .gitignore\n\n# Add and commit\ngit add frontend/\ngit commit -m \"Add voice AI frontend\"\ngit push\n```\n\n**Rationale:** Git repository enables continuous deployment and version control\n\n---\n\n#### 6.3: Sign Up for Vercel\n\n**What:** Create a Vercel account for hosting the frontend\n\n**Steps:**\n\n1. Visit https://vercel.com\n2. Click \"Sign Up\"\n3. Choose \"Continue with GitHub\" (recommended)\n4. Authorize Vercel to access your GitHub repositories\n\n**Pricing:**\n- **Free Tier:** Sufficient for testing and low traffic\n  - Unlimited deployments\n  - 100 GB bandwidth/month\n  - Serverless functions included\n- **Pro Tier:** $20/month (for production with higher traffic)\n\n**Rationale:** Vercel provides seamless Next.js hosting with automatic deployments\n\n---\n\n#### 6.4: Deploy Frontend to Vercel\n\n**What:** Deploy the frontend application to Vercel\n\n**Steps:**\n\n1. **From Vercel Dashboard:**\n   - Click \"Add New...\" → \"Project\"\n   - Select \"Import Git Repository\"\n   - Choose your frontend repository\n   - Configure project:\n     - **Framework Preset:** Next.js (auto-detected)\n     - **Root Directory:** `./` (or `frontend/voice-ai-frontend` if in monorepo)\n     - **Build Command:** `pnpm run build` (auto-detected)\n     - **Output Directory:** `.next` (auto-detected)\n     - **Install Command:** `pnpm install` (auto-detected)\n\n2. **Configure Environment Variables:**\n   Click \"Environment Variables\" and add:\n\n   ```\n   LIVEKIT_API_KEY=APIxxxxxxxxxxxx\n   LIVEKIT_API_SECRET=your-secret-here\n   LIVEKIT_URL=wss://your-project.livekit.cloud\n   NEXT_PUBLIC_LIVEKIT_URL=wss://your-project.livekit.cloud\n   AGENT_NAME=\n   ```\n\n   **Important:**\n   - Copy values from your local `.env.local`\n   - Apply to \"Production\", \"Preview\", and \"Development\" environments\n\n3. **Deploy:**\n   - Click \"Deploy\"\n   - Wait for build to complete (2-5 minutes)\n\n**Expected Outcome:**\n```\n✓ Build successful\n✓ Deployment successful\nYour project is now live at: https://your-app.vercel.app\n```\n\n**Rationale:** Makes frontend publicly accessible via HTTPS URL\n\n---\n\n#### 6.5: Test Production Deployment\n\n**What:** Verify the deployed frontend works correctly\n\n**Steps:**\n\n1. Visit your Vercel URL: `https://your-app.vercel.app`\n\n2. **Test Checklist:**\n   - [ ] Page loads without errors\n   - [ ] Custom branding displays correctly\n   - [ ] Click \"Connect\" button\n   - [ ] Grant microphone permissions\n   - [ ] Speak to agent\n   - [ ] Verify agent responds with voice\n   - [ ] Test on mobile device\n   - [ ] Test in different browsers\n\n3. **Monitor Logs:**\n   ```bash\n   # Monitor agent logs during production test\n   lk agent logs --follow\n   ```\n\n4. **Check Vercel Deployment Logs:**\n   - Go to Vercel dashboard → Your project → Deployments\n   - Click on latest deployment → \"Functions\" tab\n   - Check for any errors in `/api/token` function\n\n**Troubleshooting:**\n- **\"Failed to connect\":** Check environment variables in Vercel\n- **Token errors:** Verify `LIVEKIT_API_KEY` and `LIVEKIT_API_SECRET` are correct\n- **CORS errors:** Ensure `NEXT_PUBLIC_LIVEKIT_URL` is set correctly\n- **Agent not joining:** Check agent status, verify agent is Running\n\n**Rationale:** Ensures production environment works correctly\n\n---\n\n#### 6.6: Configure Custom Domain (Optional)\n\n**What:** Use a custom domain instead of `your-app.vercel.app`\n\n**Prerequisites:**\n- Own a domain name (e.g., `voiceai.yourcompany.com`)\n- Access to domain DNS settings\n\n**Steps:**\n\n1. **In Vercel Dashboard:**\n   - Go to your project → Settings → Domains\n   - Click \"Add Domain\"\n   - Enter your domain: `voiceai.yourcompany.com`\n\n2. **Configure DNS:**\n   Vercel will provide DNS configuration instructions:\n\n   **Option A: CNAME (Subdomain):**\n   ```\n   Type: CNAME\n   Name: voiceai\n   Value: cname.vercel-dns.com\n   ```\n\n   **Option B: A Record (Root Domain):**\n   ```\n   Type: A\n   Name: @\n   Value: 76.76.21.21\n   ```\n\n3. **Wait for DNS Propagation:**\n   - Usually takes 5-60 minutes\n   - Vercel will auto-configure SSL certificate (Let's Encrypt)\n\n4. **Verify:**\n   - Visit `https://voiceai.yourcompany.com`\n   - Should show your frontend with SSL (green lock icon)\n\n**Rationale:** Custom domain provides professional appearance and brand consistency\n\n---\n\n#### 6.7: Enable Automatic Deployments\n\n**What:** Configure automatic deployments when you push to GitHub\n\n**Vercel Auto-Deploys By Default:**\n- **Production:** Deploys on push to `main` branch\n- **Preview:** Deploys on push to any other branch or PR\n\n**Customize (Optional):**\n1. Go to Vercel dashboard → Your project → Settings → Git\n2. Configure:\n   - **Production Branch:** `main` (or `master`)\n   - **Ignored Build Step:** (leave blank to build on every commit)\n\n**Test Automatic Deployment:**\n```bash\ncd frontend/voice-ai-frontend\n\n# Make a small change\necho \"# Updated\" >> README.md\n\n# Commit and push\ngit add README.md\ngit commit -m \"Test automatic deployment\"\ngit push origin main\n```\n\n**Verify:**\n- Visit Vercel dashboard\n- Should see new deployment triggered automatically\n- Wait for build to complete\n- Visit production URL to see changes\n\n**Rationale:** Enables continuous deployment for easy updates\n\n---\n\n#### 6.8: Set Up Production Monitoring (Recommended)\n\n**What:** Monitor production errors and usage\n\n**Vercel Analytics (Built-in):**\n1. Go to Vercel dashboard → Your project → Analytics\n2. View:\n   - Page views\n   - Geographic distribution\n   - Performance metrics (Web Vitals)\n\n**Error Tracking (Optional):**\nConsider integrating Sentry or similar:\n```bash\npnpm add @sentry/nextjs\nnpx @sentry/wizard@latest -i nextjs\n```\n\n**LiveKit Cloud Monitoring:**\n- Visit LiveKit Cloud dashboard\n- Monitor:\n  - Active sessions\n  - Agent usage\n  - Costs (session minutes)\n\n**Rationale:** Production monitoring helps identify and resolve issues quickly\n\n---\n\n#### 6.9: Create Shareable Link\n\n**What:** Generate a clean, shareable URL for potential clients\n\n**Your Production URL:**\n```\nhttps://your-app.vercel.app\n```\n\n**Or with Custom Domain:**\n```\nhttps://voiceai.yourcompany.com\n```\n\n**Create Marketing Materials:**\n- Add link to your website\n- Share via email campaigns\n- Include in social media bios\n- Create QR code for physical materials\n\n**Example QR Code Generation:**\n```bash\n# Generate QR code (using qrencode)\nbrew install qrencode\nqrencode -o voiceai-qr.png \"https://voiceai.yourcompany.com\"\n```\n\n**Rationale:** Easy sharing enables potential clients to access your voice AI\n\n---\n\n#### 6.10: Document Production URLs and Credentials\n\n**What:** Save all production information for future reference\n\n**Create:** `frontend/voice-ai-frontend/PRODUCTION.md`\n\n**Content:**\n```markdown\n# Production Deployment Information\n\n## URLs\n- **Production Frontend:** https://your-app.vercel.app\n- **Custom Domain:** https://voiceai.yourcompany.com (if configured)\n- **LiveKit Cloud Dashboard:** https://cloud.livekit.io\n\n## Vercel\n- **Project:** voice-ai-frontend\n- **Account:** your-email@example.com\n- **Git Repository:** https://github.com/yourusername/voice-ai-frontend\n\n## LiveKit Cloud\n- **Project:** your-project-name\n- **Region:** us-west-2\n- **Agent ID:** agent_abc123\n\n## Deployment Commands\n```bash\n# Deploy agent updates\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\nlk agent deploy\n\n# Deploy frontend updates (automatic via Git)\ncd frontend/voice-ai-frontend\ngit add .\ngit commit -m \"Update frontend\"\ngit push origin main\n```\n\n## Monitoring\n- **Agent Logs:** `lk agent logs --follow`\n- **Vercel Logs:** https://vercel.com/your-project/deployments\n- **LiveKit Dashboard:** https://cloud.livekit.io/projects/your-project\n\n## Environment Variables (Vercel)\n- LIVEKIT_API_KEY=APIxxxxxxxxxxxx\n- LIVEKIT_API_SECRET=*** (not shown)\n- LIVEKIT_URL=wss://your-project.livekit.cloud\n- NEXT_PUBLIC_LIVEKIT_URL=wss://your-project.livekit.cloud\n\n## Costs\n- **LiveKit Cloud:** $0.01 per agent session minute\n- **Vercel:** Free tier (or $20/month Pro)\n\n## Support\n- **LiveKit:** https://livekit.io/discord\n- **Vercel:** https://vercel.com/support\n```\n\n**Rationale:** Documentation ensures you can manage production deployment long-term\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Production build succeeds: `pnpm run build` completes without errors\n- [ ] Vercel deployment successful: Deployment status shows \"Ready\"\n- [ ] HTTPS enabled: Visit production URL with green lock icon\n- [ ] Environment variables configured: Check Vercel dashboard\n- [ ] Custom domain configured (if applicable): DNS records set\n\n#### Manual Verification:\n\n- [ ] Visit production URL in browser\n- [ ] Page loads without errors\n- [ ] Custom branding displays correctly\n- [ ] Click \"Connect\" and grant microphone access\n- [ ] Speak to agent and verify voice response\n- [ ] Test on mobile device (iOS Safari, Android Chrome)\n- [ ] Test in incognito/private mode\n- [ ] Share URL with colleague and get confirmation it works\n- [ ] Agent logs show production sessions: `lk agent logs --follow`\n- [ ] No errors in Vercel function logs\n\n**Verify:** After completing automated verification, test the production URL on multiple devices and browsers, then share with a colleague to confirm public accessibility.\n\n---\n\n## Testing Strategy\n\n### Unit Tests\n\n**Not required for this plan.** The agent-starter-react template is a pre-built, production-ready template that doesn't require custom unit tests unless you add significant custom logic.\n\n**Optional:** Add tests if you customize components heavily:\n```bash\npnpm add -D @testing-library/react @testing-library/jest-dom jest\n```\n\n### Integration Tests\n\n**End-to-End Testing:**\n\nManually test the complete flow:\n1. User visits URL\n2. Clicks \"Connect\"\n3. Grants microphone access\n4. Speaks to agent\n5. Receives voice response\n6. Disconnects cleanly\n\n**Test Matrix:**\n\n| Scenario | Steps | Expected Outcome |\n|----------|-------|------------------|\n| First Connection | Visit URL → Click Connect → Speak | Agent responds with voice |\n| Interruption | Speak while agent is speaking | Agent handles gracefully |\n| Disconnect/Reconnect | End session → Start new session | New session works |\n| Multiple Turns | Have 3-5 turn conversation | All responses relevant |\n| Mobile Safari | Test on iPhone/iPad | Full functionality |\n| Network Interruption | Disable Wi-Fi during session | Reconnection or error message |\n\n### Manual Testing Steps\n\n**Pre-Deployment Checklist:**\n1. [ ] Agent deployed and running: `lk agent status`\n2. [ ] Local frontend works: `pnpm dev` at http://localhost:3000\n3. [ ] Voice interaction successful\n4. [ ] Audio visualization working\n5. [ ] Custom branding applied\n6. [ ] Production build succeeds: `pnpm run build`\n\n**Post-Deployment Checklist:**\n1. [ ] Production URL accessible\n2. [ ] HTTPS enabled (green lock)\n3. [ ] Voice interaction works on production\n4. [ ] Mobile responsive\n5. [ ] Cross-browser compatible\n6. [ ] Shareable link works for external users\n\n### Performance Considerations\n\n**Metrics to Monitor:**\n- **Connection Time:** Should be <3 seconds (or <1.5s with optimization)\n- **Response Latency:** STT → LLM → TTS should be 2-4 seconds\n- **Page Load Time:** Initial load <2 seconds (Lighthouse score >90)\n- **Audio Quality:** No dropouts or distortion\n\n**Optimization:**\n- Enable pre-connect buffering in `app-config.ts`\n- Use warm token approach (Phase 4.6)\n- Minimize bundle size (Next.js handles automatically)\n- Use CDN for static assets (Vercel provides automatically)\n\n## References\n\n### Original Ticket/Request\n- User request: \"I want potential clients to be able to interact with the livekit agent from this repo by clicking a link on a website.\"\n\n### Documentation\n- `docs/DEPLOYMENT.md` - Complete deployment guide for agent and frontend options\n- `README.md` - Project overview and setup instructions\n- `AGENTS.md` - Project guidelines and standards\n\n### LiveKit Resources\n- **Frontend Deployment Guide:** https://docs.livekit.io/agents/start/frontend/\n- **agent-starter-react Repository:** https://github.com/livekit-examples/agent-starter-react\n- **Token Authentication:** https://docs.livekit.io/home/get-started/authentication/\n- **Agents Playground:** https://agents-playground.livekit.io/\n- **LiveKit Cloud Dashboard:** https://cloud.livekit.io\n- **React Components Docs:** https://docs.livekit.io/reference/components/react/\n\n### NPM Packages\n- **livekit-client:** Client SDK for browser WebRTC\n- **@livekit/components-react:** React UI components\n- **livekit-server-sdk:** Server-side token generation\n\n### Vercel Resources\n- **Vercel Platform:** https://vercel.com\n- **Next.js Documentation:** https://nextjs.org/docs\n- **Deployment Docs:** https://vercel.com/docs\n\n### Related Plans\n- None (initial implementation)\n\n---\n\n**End of Implementation Plan**\n","structuredPatch":[{"oldStart":947,"oldLines":15,"newStart":947,"newLines":18,"lines":[" # Uses specific agent by ID or name"," ```"," ","-**Check Token Grant Configuration:**","+**Check Token Grant Configuration (Audio-Only):**"," ```typescript"," // In app/api/token/route.ts or connection-details/route.ts"," token.addGrant({","   room: roomName,","   roomJoin: true,","-  canPublish: true,","-  canSubscribe: true,","-  // Optional: Agent dispatch configuration","+  canPublish: true,      // Allow publishing audio","+  canSubscribe: true,    // Allow receiving audio","+  canPublishSources: [   // AUDIO-ONLY: restrict to microphone","+    'microphone'","+    // NOTE: 'camera' and 'screen_share' are NOT included","+  ],"," });"," ```"," "]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"788e7f7d-7733-43e1-9e90-2358a63cfbd6"}
{"parentUuid":"2adb2926-4c3f-4ea6-bd98-a35a4facc82f","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","slug":"enumerated-shimmying-starlight","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01WjSAezvRNobybwmM7Ektax","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now let me update the verification steps to include checking that video is disabled:","signature":"EvwBCkYICxgCKkD4qZa/FFgG15CbbrwKvn3magWQFyd/xBEJwGJUFVVbGtzHLxVbb0sJ2Ude2pgLcEQ/+A/Cn2XtfpV61k4YLFeGEgxxq1h7LkAOlzceJeYaDHOvPkmQKy7YKsqWiiIw1jOXjVcviIaWcVBLe1+syAN/oCindXEjeNDUXAZrJgVAMI7tnIrqMqxr3rkHT529KmQr1nQKmw0Z6f4o3fm6VIiNYqj7NvhbJ3sQ19cR/BhWzAiCVa9hXutVzAe3LqJnROOPW5bosrM1TZcC+QAFWe8nWKxD4F8WSOVlh+9LwIcjOWH3rgEOydcxH4Zqxl4pfqn0GdRFGAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":6,"cache_creation_input_tokens":463,"cache_read_input_tokens":68306,"cache_creation":{"ephemeral_5m_input_tokens":463,"ephemeral_1h_input_tokens":0},"output_tokens":6,"service_tier":"standard"}},"requestId":"req_011CXTt9ovPrs6yBu3Y5Sbns","type":"assistant","uuid":"cb7a21a2-a45a-4012-93e9-f8a94189493f","timestamp":"2026-01-25T09:46:01.181Z"}
{"parentUuid":"cb7a21a2-a45a-4012-93e9-f8a94189493f","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","slug":"enumerated-shimmying-starlight","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01WjSAezvRNobybwmM7Ektax","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01NA6CQXaZipiVYPqP9qSAgf","name":"Edit","input":{"replace_all":false,"file_path":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/plan/future-plans/2026-01-25-web-frontend-deployment.md","old_string":"**Checklist:**\n- [ ] Company name displays on welcome screen\n- [ ] Custom logo appears (both light and dark modes)\n- [ ] Page title shows in browser tab\n- [ ] Custom favicon appears in browser tab\n- [ ] Brand colors visible on buttons and accents\n- [ ] Welcome message updated with custom text\n- [ ] Disabled features are hidden (if applicable)\n- [ ] No broken images or 404s\n- [ ] Responsive design maintained on mobile","new_string":"**Checklist:**\n- [ ] Company name displays on welcome screen\n- [ ] Custom logo appears (both light and dark modes)\n- [ ] Page title shows in browser tab\n- [ ] Custom favicon appears in browser tab\n- [ ] Brand colors visible on buttons and accents\n- [ ] Welcome message updated with custom text\n- [ ] Video/screenshare features are hidden (REQUIRED for audio-only)\n- [ ] Only microphone permission requested (no camera/screenshare)\n- [ ] No broken images or 404s\n- [ ] Responsive design maintained on mobile"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":6,"cache_creation_input_tokens":463,"cache_read_input_tokens":68306,"cache_creation":{"ephemeral_5m_input_tokens":463,"ephemeral_1h_input_tokens":0},"output_tokens":6,"service_tier":"standard"}},"requestId":"req_011CXTt9ovPrs6yBu3Y5Sbns","type":"assistant","uuid":"6cdc3be7-2cc4-47d8-9cc0-43c882fd18a1","timestamp":"2026-01-25T09:46:06.157Z"}
{"parentUuid":"6cdc3be7-2cc4-47d8-9cc0-43c882fd18a1","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","slug":"enumerated-shimmying-starlight","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01NA6CQXaZipiVYPqP9qSAgf","type":"tool_result","content":"The file /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/plan/future-plans/2026-01-25-web-frontend-deployment.md has been updated successfully."}]},"uuid":"97fff288-9b57-42f8-aee4-e625f3318b24","timestamp":"2026-01-25T09:46:06.203Z","toolUseResult":{"filePath":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/plan/future-plans/2026-01-25-web-frontend-deployment.md","oldString":"**Checklist:**\n- [ ] Company name displays on welcome screen\n- [ ] Custom logo appears (both light and dark modes)\n- [ ] Page title shows in browser tab\n- [ ] Custom favicon appears in browser tab\n- [ ] Brand colors visible on buttons and accents\n- [ ] Welcome message updated with custom text\n- [ ] Disabled features are hidden (if applicable)\n- [ ] No broken images or 404s\n- [ ] Responsive design maintained on mobile","newString":"**Checklist:**\n- [ ] Company name displays on welcome screen\n- [ ] Custom logo appears (both light and dark modes)\n- [ ] Page title shows in browser tab\n- [ ] Custom favicon appears in browser tab\n- [ ] Brand colors visible on buttons and accents\n- [ ] Welcome message updated with custom text\n- [ ] Video/screenshare features are hidden (REQUIRED for audio-only)\n- [ ] Only microphone permission requested (no camera/screenshare)\n- [ ] No broken images or 404s\n- [ ] Responsive design maintained on mobile","originalFile":"# Web Frontend Deployment Implementation Plan\n\n> **Status:** DRAFT\n\n## Table of Contents\n\n- [Overview](#overview)\n- [Current State Analysis](#current-state-analysis)\n- [Desired End State](#desired-end-state)\n- [What We're NOT Doing](#what-were-not-doing)\n- [Implementation Approach](#implementation-approach)\n- [Dependencies](#dependencies)\n- [Phase 1: Agent Deployment to LiveKit Cloud](#phase-1-agent-deployment-to-livekit-cloud)\n- [Phase 2: Frontend Setup (agent-starter-react)](#phase-2-frontend-setup-agent-starter-react)\n- [Phase 3: Authentication and Token Generation](#phase-3-authentication-and-token-generation)\n- [Phase 4: Connection Testing and Optimization](#phase-4-connection-testing-and-optimization)\n- [Phase 5: Frontend Customization](#phase-5-frontend-customization)\n- [Phase 6: Production Deployment](#phase-6-production-deployment)\n- [Testing Strategy](#testing-strategy)\n- [References](#references)\n\n## Overview\n\nThis plan enables potential clients to interact with the LiveKit voice AI agent from this repository by clicking a link on a website. The implementation covers:\n\n1. Deploying the Python agent to LiveKit Cloud\n2. Setting up a Next.js/React frontend using the agent-starter-react template\n3. Implementing JWT token-based authentication\n4. Testing the connection flow\n5. Customizing the frontend with branding\n6. Deploying the frontend to production (Vercel)\n\nThe solution uses LiveKit's official starter templates and SDKs to create a production-ready web application with TypeScript/JavaScript.\n\n**IMPORTANT: This is an audio-only application. No video camera or screen sharing permissions should be requested from users. All configuration must disable video/screenshare features.**\n\n## Current State Analysis\n\n### What Exists Now\n\n**Agent Backend:**\n- Python voice AI agent in `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1`\n- Built with LiveKit Agents SDK\n- Uses OpenAI (LLM), AssemblyAI (STT), Cartesia (TTS)\n- Configured with `uv` package manager\n- Has `Dockerfile` for containerized deployment\n- Environment variables in `.env.local` (OpenAI, AssemblyAI, Cartesia API keys)\n\n**Missing:**\n- Agent not yet deployed to LiveKit Cloud\n- No web frontend for client interaction\n- No token generation server for authentication\n- No public-facing URL for clients to access\n\n### Key Discoveries\n\nFrom `docs/DEPLOYMENT.md`:\n- LiveKit Cloud deployment uses `lk` CLI\n- Agent deployment command: `lk agent create --secrets-file .env.local`\n- Multiple frontend options available (React, Flutter, Swift, Embed)\n- Connection requires JWT tokens generated server-side\n- agent-starter-react provides production-ready Next.js template\n- Token generation uses `livekit-server-sdk` npm package\n\n### Constraints\n\n1. **Security:** API secrets (LIVEKIT_API_SECRET) must never be exposed to frontend\n2. **Architecture:** Token generation must happen server-side (Next.js API routes)\n3. **Dependencies:** Agent must be deployed and running before frontend can connect\n4. **Cost:** LiveKit Cloud charges $0.01 per agent session minute\n\n## Desired End State\n\n### Success Criteria\n\n- [ ] Agent deployed and running on LiveKit Cloud\n- [ ] Next.js frontend application running locally\n- [ ] JWT token generation working via backend API route\n- [ ] Users can click a link and connect to voice AI agent\n- [ ] Audio conversation works end-to-end (STT → LLM → TTS)\n- [ ] Frontend deployed to production URL (Vercel)\n- [ ] Customized branding (logo, colors, company name)\n- [ ] Light/dark theme support\n- [ ] Audio visualization working\n- [ ] Mobile-responsive design\n\n### How to Verify\n\n**Agent Deployment:**\n```bash\nlk agent status\n# Expected: Status: Running, Replicas: X/X ready\n```\n\n**Frontend Connection:**\n1. Visit frontend URL (local: http://localhost:3000, prod: https://your-app.vercel.app)\n2. Click \"Connect\" or \"Start Session\"\n3. Grant microphone permissions when prompted\n4. Speak to the agent\n5. Verify agent responds with natural voice\n6. Check agent logs: `lk agent logs --follow`\n\n**End-to-End Test:**\n```bash\n# Terminal 1: Monitor agent logs\nlk agent logs --follow\n\n# Terminal 2: Run frontend\ncd /path/to/frontend\npnpm dev\n\n# Browser: Visit http://localhost:3000, connect, and speak\n```\n\n## What We're NOT Doing\n\n**Out of Scope:**\n- Multiple agent types or agent selection UI\n- User authentication/login system (anonymous users only)\n- Database integration or conversation history storage\n- Multi-language support (English only initially)\n- iOS/Android native apps (web only)\n- Custom voice customization UI\n- Payment integration or usage metering\n- Advanced analytics dashboard\n- Server-side rendering (SSR) for the voice interface\n- Custom WebRTC infrastructure (using LiveKit Cloud)\n\n**Future Considerations:**\n- User accounts and saved conversations\n- Analytics and usage tracking\n- Custom domain with branding\n- A/B testing different agent configurations\n- Rate limiting and abuse prevention\n\n## Implementation Approach\n\n### High-Level Strategy\n\n1. **Deploy Agent First:** Ensure the Python agent is running on LiveKit Cloud before building frontend\n2. **Use Official Template:** Start with agent-starter-react to avoid reinventing the wheel\n3. **Iterative Testing:** Test each phase independently before proceeding\n4. **Security-First:** Never expose API secrets; use environment variables and server-side token generation\n5. **Quick Validation:** Use LiveKit Agents Playground first to verify agent works before building frontend\n\n### Technology Stack\n\n**Backend (Agent):**\n- Python 3.11+\n- LiveKit Agents SDK\n- OpenAI GPT-4 (LLM)\n- AssemblyAI (STT)\n- Cartesia (TTS)\n- Deployed to: LiveKit Cloud\n\n**Frontend:**\n- Next.js 14+ (App Router)\n- React 18+\n- TypeScript\n- Tailwind CSS\n- Shadcn/ui components\n- `livekit-client` SDK\n- `@livekit/components-react`\n- Deployed to: Vercel\n\n**Authentication:**\n- JWT tokens (livekit-server-sdk)\n- Server-side generation (Next.js API routes)\n- 2-hour token expiration\n\n## Dependencies\n\n**Execution Order:**\n\n1. Phase 1: Agent Deployment (no dependencies)\n2. Phase 2: Frontend Setup (depends on Phase 1 for credentials)\n3. Phase 3: Authentication (depends on Phase 2)\n4. Phase 4: Connection Testing (depends on Phases 1-3)\n5. Phase 5: Frontend Customization (depends on Phase 4)\n6. Phase 6: Production Deployment (depends on Phase 5)\n\n**Dependency Graph:**\n\n```\nPhase 1 (Agent Deployment)\n  └─> Phase 2 (Frontend Setup)\n        └─> Phase 3 (Authentication)\n              └─> Phase 4 (Testing)\n                    └─> Phase 5 (Customization)\n                          └─> Phase 6 (Production)\n```\n\n**Parallelization:**\n- All phases are sequential due to dependencies\n- Within each phase, independent tasks can run in parallel\n\n---\n\n## Phase 1: Agent Deployment to LiveKit Cloud\n\n### Overview\n\nDeploy the Python voice AI agent to LiveKit Cloud to make it accessible via WebRTC. This creates a running agent that can be dispatched to rooms when users connect.\n\n### Context\n\nBefore starting, ensure you have:\n- LiveKit CLI installed: `brew install livekit/livekit/livekit-cli`\n- LiveKit Cloud account at https://cloud.livekit.io\n- Agent code in `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1`\n- API keys in `.env.local` (OpenAI, AssemblyAI, Cartesia)\n\nFiles to review:\n- `docs/DEPLOYMENT.md` - Complete deployment guide\n- `.env.local` - API keys and secrets\n- `Dockerfile` - Container build configuration\n- `src/app.py` - Agent entry point\n\n### Dependencies\n\n**Depends on:** None (first phase)\n\n**Required by:** Phase 2 (Frontend needs LiveKit credentials), Phase 4 (Testing needs deployed agent)\n\n### Changes Required\n\n#### 1.1: Authenticate with LiveKit Cloud\n\n**What:** Link your CLI to your LiveKit Cloud account\n\n**Command:**\n```bash\nlk cloud auth\n```\n\n**Expected Outcome:**\n- Browser opens for authentication\n- CLI displays: \"Successfully authenticated with LiveKit Cloud\"\n- Credentials saved in `~/.livekit/credentials`\n\n**Rationale:** Required for all subsequent `lk` CLI commands\n\n---\n\n#### 1.2: Create or Select LiveKit Project\n\n**What:** Create a new project or select an existing one for the agent deployment\n\n**Commands:**\n```bash\n# List existing projects\nlk project list\n\n# Option A: Use existing project\nlk project set-default \"your-project-name\"\n\n# Option B: Create new project via dashboard\n# Visit https://cloud.livekit.io and create a new project\n# Then set as default: lk project set-default \"new-project-name\"\n\n# Verify current project\nlk project current\n```\n\n**Expected Outcome:**\n```\nNAME                 PROJECT_ID\nyour-project-name   prj_abc123\n```\n\n**Rationale:** Agent deployments are scoped to projects; need a target project first\n\n---\n\n#### 1.3: Verify Secrets File\n\n**What:** Ensure `.env.local` contains all required API keys\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/.env.local`\n\n**Verify contents:**\n```bash\ncat .env.local\n```\n\n**Required secrets:**\n```env\nOPENAI_API_KEY=sk-...\nASSEMBLYAI_API_KEY=...\nCARTESIA_API_KEY=...\n```\n\n**Important Notes:**\n- Do NOT include `LIVEKIT_URL`, `LIVEKIT_API_KEY`, or `LIVEKIT_API_SECRET` in `.env.local`\n- LiveKit Cloud auto-injects these during deployment\n- Verify `.env.local` is in `.gitignore`\n\n**Rationale:** Agent needs these API keys to function; LiveKit Cloud encrypts and injects them as environment variables\n\n---\n\n#### 1.4: Download Model Files\n\n**What:** Download required models (Silero VAD, turn detector) before deployment\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\nuv run python src/app.py download-files\n```\n\n**Expected Outcome:**\n```\nDownloading Silero VAD model...\nDownloading multilingual turn detector model...\nDownload complete.\n```\n\n**Rationale:** Models are required at runtime; downloading during build ensures faster agent startup\n\n---\n\n#### 1.5: Deploy Agent to LiveKit Cloud\n\n**What:** Create and deploy the agent container to LiveKit Cloud\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\nlk agent create --secrets-file .env.local\n```\n\n**Expected Outcome:**\n```\nRegistering agent...\nAgent ID: agent_abc123\nBuilding container image...\nUploading code...\nBuild in progress (this may take 2-5 minutes)...\nBuild complete.\nDeploying agent...\nDeployment successful.\nStatus: Running\nReplicas: 2/2 ready\n```\n\n**What Happens:**\n1. CLI registers new agent with Cloud project\n2. Assigns unique agent ID (e.g., `agent_abc123`)\n3. Creates/updates `livekit.toml` configuration file\n4. Uploads source code to LiveKit build service\n5. Builds Docker container from `Dockerfile`\n6. Deploys container to Cloud project\n7. Encrypts and injects secrets as environment variables\n8. Starts 2 replica instances\n\n**Duration:** 2-5 minutes for initial build\n\n**Rationale:** Makes agent accessible via LiveKit's global WebRTC infrastructure\n\n---\n\n#### 1.6: Verify Agent Status\n\n**What:** Confirm agent is running and ready to accept sessions\n\n**Commands:**\n```bash\n# Check agent status\nlk agent status\n\n# View live logs\nlk agent logs --tail 50\n```\n\n**Expected Status Output:**\n```\nAgent ID:     agent_abc123\nStatus:       Running\nReplicas:     2/2 ready\nVersion:      v1\nLast Deploy:  2026-01-25 10:30:00 UTC\nRegion:       us-west-2\n```\n\n**Expected Log Output:**\n- No error messages\n- Successful initialization messages\n- \"Waiting for room assignment\" or similar\n\n**Troubleshooting:**\n- If status is `CrashLoop`: Check logs for Python exceptions\n- If status is `Build Failed`: Run `lk agent logs --build` to see build errors\n- If secrets missing: Run `lk agent secrets` to verify\n\n**Rationale:** Ensures agent is healthy before proceeding to frontend setup\n\n---\n\n#### 1.7: Quick Test with Agents Playground\n\n**What:** Test agent using LiveKit Agents Playground (no code required)\n\n**Steps:**\n1. Get project credentials:\n   ```bash\n   lk project current --json\n   ```\n\n2. Visit https://agents-playground.livekit.io/\n\n3. Enter credentials:\n   - **LiveKit URL:** `wss://your-project.livekit.cloud` (from JSON output)\n   - **API Key:** Your `LIVEKIT_API_KEY` (from JSON output)\n   - **API Secret:** Your `LIVEKIT_API_SECRET` (from JSON output)\n\n4. Click \"Connect\"\n\n5. Allow microphone access when prompted\n\n6. Speak to your agent\n\n7. Monitor agent logs in terminal:\n   ```bash\n   lk agent logs --follow\n   ```\n\n**Expected Outcome:**\n- Agent responds to your voice with natural TTS\n- Logs show STT transcriptions, LLM responses, TTS generation\n- No errors in logs\n\n**Rationale:** Validates agent works end-to-end before investing in frontend development\n\n---\n\n#### 1.8: Save LiveKit Credentials\n\n**What:** Export LiveKit project credentials for frontend configuration\n\n**Command:**\n```bash\nlk project current --json > livekit-credentials.json\n```\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/livekit-credentials.json`\n\n**Expected Contents:**\n```json\n{\n  \"name\": \"your-project-name\",\n  \"url\": \"wss://your-project.livekit.cloud\",\n  \"api_key\": \"APIxxxxxxxxxxxx\",\n  \"api_secret\": \"your-secret-here\"\n}\n```\n\n**Security Note:**\n- Add `livekit-credentials.json` to `.gitignore`\n- NEVER commit this file to version control\n- This file is for local reference only\n\n**Rationale:** Frontend needs these credentials to generate tokens and connect to LiveKit\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] CLI authenticated: `lk cloud auth` successful\n- [ ] Project selected: `lk project current` shows correct project\n- [ ] Agent deployed: `lk agent status` shows `Status: Running`\n- [ ] Replicas ready: `lk agent status` shows `X/X ready` (e.g., 2/2)\n- [ ] No crash loops: `lk agent logs --tail 50` shows no errors\n- [ ] Credentials saved: `livekit-credentials.json` exists and contains valid JSON\n\n#### Manual Verification:\n\n- [ ] Agents Playground connection successful\n- [ ] Agent responds to voice input with TTS output\n- [ ] Agent logs show successful STT → LLM → TTS pipeline\n- [ ] No API key errors in logs\n- [ ] Agent state transitions visible (initializing → listening → thinking → speaking)\n\n**Verify:** After completing automated verification, test agent with Agents Playground before proceeding to Phase 2.\n\n---\n\n## Phase 2: Frontend Setup (agent-starter-react)\n\n### Overview\n\nClone and configure the agent-starter-react template to create a Next.js web application that connects users to your deployed agent.\n\n### Context\n\nBefore starting, ensure:\n- Phase 1 completed successfully\n- Agent is running on LiveKit Cloud\n- `livekit-credentials.json` file exists with credentials\n\nPrerequisites:\n- Node.js 18+ installed\n- pnpm installed: `npm install -g pnpm`\n- `lk` CLI authenticated\n\nFiles to review:\n- `livekit-credentials.json` - LiveKit project credentials\n- N/A (frontend doesn't exist yet)\n\n### Dependencies\n\n**Depends on:** Phase 1 (needs LiveKit credentials)\n\n**Required by:** Phase 3 (authentication setup), Phase 4 (connection testing)\n\n### Changes Required\n\n#### 2.1: Create Frontend Project Directory\n\n**What:** Create a directory to house the frontend application\n\n**Commands:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\nmkdir -p frontend\ncd frontend\n```\n\n**Expected Outcome:**\n```\nDirectory created: /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/\n```\n\n**Rationale:** Separates frontend code from agent backend code\n\n---\n\n#### 2.2: Clone agent-starter-react Template\n\n**What:** Use LiveKit CLI to create a new project from the official template\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend\nlk app create --template agent-starter-react\n```\n\n**Interactive Prompts:**\n- **Project name:** (Press Enter for default or enter custom name like \"voice-ai-frontend\")\n- **Install dependencies?** Yes\n\n**Alternative (Manual Clone):**\n```bash\ngit clone https://github.com/livekit-examples/agent-starter-react.git voice-ai-frontend\ncd voice-ai-frontend\npnpm install\n```\n\n**Expected Outcome:**\n```\n✓ Created project: voice-ai-frontend\n✓ Installed dependencies\n✓ Ready to configure\n```\n\n**Directory Structure:**\n```\nfrontend/voice-ai-frontend/\n├── app/\n│   ├── api/token/route.ts     # Token generation endpoint\n│   ├── page.tsx               # Main page\n│   └── layout.tsx\n├── components/\n│   ├── agents-ui/             # Agents UI components\n│   ├── app/                   # Business logic\n│   └── ui/                    # Shadcn/ui primitives\n├── hooks/\n├── lib/\n├── public/\n├── package.json\n├── .env.example\n└── next.config.js\n```\n\n**Rationale:** Official template provides production-ready structure with all necessary LiveKit integrations\n\n---\n\n#### 2.3: Configure Environment Variables\n\n**What:** Set up LiveKit credentials for the frontend\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend/.env.local`\n\n**Commands:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\ncp .env.example .env.local\n```\n\n**Edit `.env.local`:**\n```env\n# LiveKit project credentials (from livekit-credentials.json)\nLIVEKIT_API_KEY=APIxxxxxxxxxxxx\nLIVEKIT_API_SECRET=your-secret-here\nLIVEKIT_URL=wss://your-project.livekit.cloud\n\n# Public URL (exposed to browser - same as LIVEKIT_URL)\nNEXT_PUBLIC_LIVEKIT_URL=wss://your-project.livekit.cloud\n\n# Agent configuration\nAGENT_NAME=\n# Leave AGENT_NAME blank for automatic agent dispatch\n# Or set to specific agent name if you have multiple agents\n```\n\n**How to Get Values:**\n```bash\n# Copy from livekit-credentials.json\ncat /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/livekit-credentials.json\n```\n\n**Security Notes:**\n- `LIVEKIT_API_SECRET` is server-side only (never exposed to browser)\n- `NEXT_PUBLIC_*` variables are exposed to browser\n- Only `NEXT_PUBLIC_LIVEKIT_URL` should be public\n- Never expose `LIVEKIT_API_KEY` or `LIVEKIT_API_SECRET` to browser\n\n**Rationale:** Frontend needs credentials to generate tokens and connect to LiveKit rooms\n\n---\n\n#### 2.4: Verify Dependencies Installation\n\n**What:** Ensure all npm packages are installed correctly\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\npnpm install\n```\n\n**Expected Outcome:**\n```\nPackages: +XXX\nProgress: resolved XXX, reused XXX, downloaded X, added XXX, done\n```\n\n**Key Dependencies (verify in `package.json`):**\n- `next` (v14+)\n- `react` (v18+)\n- `livekit-client`\n- `@livekit/components-react`\n- `livekit-server-sdk`\n- `tailwindcss`\n- `typescript`\n\n**Troubleshooting:**\n- If pnpm not installed: `npm install -g pnpm`\n- If peer dependency warnings: Generally safe to ignore\n- If install fails: Delete `node_modules` and `pnpm-lock.yaml`, retry\n\n**Rationale:** Ensures all required packages are available for development\n\n---\n\n#### 2.5: Run Development Server\n\n**What:** Start the Next.js development server to verify basic setup\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\npnpm dev\n```\n\n**Expected Outcome:**\n```\n> next dev\n\n  ▲ Next.js 14.x.x\n  - Local:        http://localhost:3000\n  - Environments: .env.local\n\n ✓ Ready in X.Xs\n```\n\n**Verification:**\n1. Open browser to http://localhost:3000\n2. Should see agent interface with \"Connect\" button\n3. No console errors in browser DevTools\n4. Page loads without 500 errors\n\n**Expected UI:**\n- Welcome/landing view\n- \"Connect\" or \"Start Session\" button\n- Logo and branding elements\n- Theme toggle (light/dark)\n\n**Troubleshooting:**\n- If port 3000 in use: `pnpm dev -- -p 3001`\n- If env vars missing: Check `.env.local` exists and has correct values\n- If build errors: Check `pnpm install` completed successfully\n\n**Rationale:** Validates Next.js setup before proceeding to authentication\n\n---\n\n#### 2.6: Inspect Token Generation API Route\n\n**What:** Review the built-in token generation endpoint to understand how authentication works\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend/app/api/token/route.ts`\n\n**Read the file:**\n```typescript\n// Expected structure (review actual implementation)\nimport { AccessToken } from 'livekit-server-sdk';\n\nexport async function POST(request: Request) {\n  const { roomName, participantName } = await request.json();\n\n  const token = new AccessToken(\n    process.env.LIVEKIT_API_KEY,\n    process.env.LIVEKIT_API_SECRET,\n    {\n      identity: participantName,\n      ttl: '2h', // Token valid for 2 hours\n    }\n  );\n\n  token.addGrant({\n    room: roomName,\n    roomJoin: true,\n    canPublish: true,\n    canSubscribe: true,\n  });\n\n  return Response.json({ token: await token.toJwt() });\n}\n```\n\n**Key Points:**\n- Uses `livekit-server-sdk` to generate JWT tokens\n- Reads `LIVEKIT_API_KEY` and `LIVEKIT_API_SECRET` from environment\n- Grants room join, publish, and subscribe permissions\n- Returns JWT token to frontend\n- Token expires after 2 hours (LiveKit auto-refreshes for connected clients)\n\n**Security Review:**\n- ✓ API key/secret are server-side only (not exposed to browser)\n- ✓ Token generation happens on server\n- ✓ Appropriate permissions granted\n- ⚠ Consider adding rate limiting for production\n\n**Rationale:** Understanding token flow is critical for debugging connection issues\n\n---\n\n#### 2.7: Add Frontend to .gitignore (Backend Repo)\n\n**What:** Prevent frontend from being committed to agent backend repo\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/.gitignore`\n\n**Add to `.gitignore`:**\n```bash\necho \"frontend/\" >> .gitignore\n```\n\n**Verify:**\n```bash\ngit status\n# frontend/ should not appear in untracked files\n```\n\n**Alternative Approach:**\nIf you want to commit the frontend to the same repo:\n- Create a separate `.gitignore` in `frontend/voice-ai-frontend/`\n- Add standard Next.js ignores (`.next/`, `node_modules/`, `.env.local`)\n\n**Rationale:** Keep frontend and backend as separate concerns, or manage carefully if in same repo\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Frontend directory created: `ls frontend/voice-ai-frontend`\n- [ ] Dependencies installed: `pnpm list --depth=0` shows key packages\n- [ ] Environment variables configured: `cat .env.local | grep LIVEKIT_API_KEY`\n- [ ] Development server starts: `pnpm dev` runs without errors\n- [ ] No TypeScript errors: `pnpm run build` completes successfully\n\n#### Manual Verification:\n\n- [ ] Visit http://localhost:3000 in browser\n- [ ] Page loads without 500 errors\n- [ ] UI displays welcome screen with \"Connect\" button\n- [ ] No console errors in browser DevTools\n- [ ] Theme toggle works (light/dark mode)\n- [ ] Responsive design works on mobile viewport\n\n**Verify:** After completing automated verification, open the app in a browser and verify UI loads correctly before proceeding to Phase 3.\n\n---\n\n## Phase 3: Authentication and Token Generation\n\n### Overview\n\nConfigure and test the JWT token generation flow to ensure frontend can authenticate users with LiveKit and connect them to agent sessions.\n\n### Context\n\nBefore starting, ensure:\n- Phase 2 completed successfully\n- Development server running at http://localhost:3000\n- Environment variables configured in `.env.local`\n\nFiles to review:\n- `frontend/voice-ai-frontend/app/api/token/route.ts` - Token generation endpoint\n- `frontend/voice-ai-frontend/.env.local` - Environment configuration\n- `frontend/voice-ai-frontend/components/app/` - Client-side connection logic\n\n### Dependencies\n\n**Depends on:** Phase 2 (frontend setup)\n\n**Required by:** Phase 4 (connection testing)\n\n### Changes Required\n\n#### 3.1: Test Token Generation Endpoint\n\n**What:** Verify the token API endpoint works correctly\n\n**Command:**\n```bash\n# Start dev server (if not running)\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\npnpm dev\n\n# In another terminal, test the endpoint\ncurl -X POST http://localhost:3000/api/token \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"roomName\": \"test-room\", \"participantName\": \"test-user\"}'\n```\n\n**Expected Response:**\n```json\n{\n  \"token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\"\n}\n```\n\n**Validate Token:**\n```bash\n# Decode the JWT to inspect claims (copy token from response)\necho \"eyJhbGciOiJ...\" | cut -d'.' -f2 | base64 -d | jq\n```\n\n**Expected Token Payload:**\n```json\n{\n  \"exp\": 1234567890,\n  \"iss\": \"APIxxxxxxxxxxxx\",\n  \"sub\": \"test-user\",\n  \"nbf\": 1234567890,\n  \"video\": {\n    \"room\": \"test-room\",\n    \"roomJoin\": true,\n    \"canPublish\": true,\n    \"canSubscribe\": true,\n    \"canPublishData\": true\n  }\n}\n```\n\n**Troubleshooting:**\n- If 500 error: Check environment variables in `.env.local`\n- If \"api_key undefined\": Verify `LIVEKIT_API_KEY` is set\n- If \"invalid signature\": Check `LIVEKIT_API_SECRET` is correct\n- If no response: Verify dev server is running on port 3000\n\n**Rationale:** Token generation must work before attempting to connect to LiveKit\n\n---\n\n#### 3.2: Review Client-Side Connection Logic\n\n**What:** Understand how the frontend connects to LiveKit rooms\n\n**Files to Review:**\n```bash\n# Main session component\ncat frontend/voice-ai-frontend/components/app/session-view.tsx\n\n# View controller\ncat frontend/voice-ai-frontend/components/app/view-controller.tsx\n\n# Connection utilities\ncat frontend/voice-ai-frontend/lib/connection.ts\n```\n\n**Key Flow:**\n1. User clicks \"Connect\" button\n2. Frontend generates room name (random or predefined)\n3. Frontend fetches token from `/api/token` endpoint\n4. Frontend connects to LiveKit room using `livekit-client`\n5. Agent is automatically dispatched to room\n6. User and agent establish WebRTC connection\n7. Audio tracks are exchanged\n\n**Important Variables:**\n- `NEXT_PUBLIC_LIVEKIT_URL` - LiveKit server URL (browser-accessible)\n- Room name generation logic\n- Participant name/identity\n- Agent dispatch configuration\n\n**Rationale:** Understanding client-side logic helps debug connection issues\n\n---\n\n#### 3.3: Configure Agent Dispatch\n\n**What:** Ensure frontend triggers automatic agent dispatch when users connect\n\n**File:** Review `frontend/voice-ai-frontend/app/api/connection-details/route.ts` (if exists) or equivalent\n\n**Verify Agent Name Configuration:**\n\n**Option A: Automatic Dispatch (Recommended):**\n```env\n# In .env.local\nAGENT_NAME=\n# Blank means \"dispatch any available agent\"\n```\n\n**Option B: Specific Agent:**\n```env\n# In .env.local\nAGENT_NAME=agent_abc123\n# Uses specific agent by ID or name\n```\n\n**Check Token Grant Configuration (Audio-Only):**\n```typescript\n// In app/api/token/route.ts or connection-details/route.ts\ntoken.addGrant({\n  room: roomName,\n  roomJoin: true,\n  canPublish: true,      // Allow publishing audio\n  canSubscribe: true,    // Allow receiving audio\n  canPublishSources: [   // AUDIO-ONLY: restrict to microphone\n    'microphone'\n    // NOTE: 'camera' and 'screen_share' are NOT included\n  ],\n});\n```\n\n**For agent-starter-react:**\nThe template typically handles agent dispatch automatically when a participant joins a room. Verify this by checking the token generation code and connection details endpoint.\n\n**Rationale:** Agent won't join room unless dispatch is configured correctly\n\n---\n\n#### 3.4: Test Token Expiration and Refresh\n\n**What:** Verify token expiration is set correctly and LiveKit handles refresh\n\n**Check Current TTL:**\n```typescript\n// In app/api/token/route.ts\nconst token = new AccessToken(\n  process.env.LIVEKIT_API_KEY,\n  process.env.LIVEKIT_API_SECRET,\n  {\n    identity: participantName,\n    ttl: '2h', // Current setting\n  }\n);\n```\n\n**Recommended TTL:**\n- Development: `2h` (2 hours)\n- Production: `2h` (LiveKit auto-refreshes for connected clients)\n- Pre-generated tokens: `1h` (if caching tokens)\n\n**Token Refresh Behavior:**\n- LiveKit client SDK automatically refreshes tokens before expiration\n- Refresh happens for connected clients only\n- Disconnected users must request new tokens\n\n**No changes needed if TTL is already `2h`.**\n\n**Rationale:** Prevents users from being disconnected due to token expiration\n\n---\n\n#### 3.5: Add Security Headers (Optional but Recommended)\n\n**What:** Add security headers to token API route\n\n**File:** `frontend/voice-ai-frontend/middleware.ts` (create if doesn't exist)\n\n**Content:**\n```typescript\nimport { NextResponse } from 'next/server';\nimport type { NextRequest } from 'next/server';\n\nexport function middleware(request: NextRequest) {\n  const response = NextResponse.next();\n\n  // Security headers\n  response.headers.set('X-Content-Type-Options', 'nosniff');\n  response.headers.set('X-Frame-Options', 'DENY');\n  response.headers.set('X-XSS-Protection', '1; mode=block');\n\n  return response;\n}\n\nexport const config = {\n  matcher: '/api/:path*',\n};\n```\n\n**Optional Rate Limiting:**\nConsider adding rate limiting to `/api/token` endpoint to prevent abuse.\n\n**Rationale:** Basic security hardening for production deployments\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Token endpoint returns valid JWT: `curl -X POST http://localhost:3000/api/token -H \"Content-Type: application/json\" -d '{\"roomName\":\"test\",\"participantName\":\"user\"}' | jq .token`\n- [ ] Token payload contains correct claims: Decode JWT and verify `video.roomJoin: true`\n- [ ] Environment variables loaded: `console.log(process.env.LIVEKIT_API_KEY)` in token route shows value (not undefined)\n- [ ] Token has correct expiration: Decoded JWT shows `exp` timestamp 2 hours in future\n\n#### Manual Verification:\n\n- [ ] Token endpoint accessible via browser: Visit http://localhost:3000/api/token (should return 405 Method Not Allowed for GET)\n- [ ] No errors in Next.js server logs when generating tokens\n- [ ] Token decodes successfully at https://jwt.io\n- [ ] Token issuer (`iss`) matches your LiveKit API key\n- [ ] Token subject (`sub`) matches requested participant name\n\n**Verify:** After completing automated verification, test token generation with curl and decode the JWT to inspect claims before proceeding to Phase 4.\n\n---\n\n## Phase 4: Connection Testing and Optimization\n\n### Overview\n\nTest the end-to-end connection flow from frontend to agent, verify audio works correctly, and optimize the connection speed.\n\n### Context\n\nBefore starting, ensure:\n- Phase 3 completed successfully\n- Agent running on LiveKit Cloud (`lk agent status` shows Running)\n- Frontend running at http://localhost:3000\n- Token generation working\n\nFiles to review:\n- `frontend/voice-ai-frontend/components/app/session-view.tsx` - Session management\n- `frontend/voice-ai-frontend/components/agents-ui/` - UI components\n\nTools needed:\n- Browser with microphone access\n- Terminal for monitoring agent logs\n\n### Dependencies\n\n**Depends on:** Phases 1-3 (agent deployed, frontend configured, authentication working)\n\n**Required by:** Phase 5 (customization), Phase 6 (production deployment)\n\n### Changes Required\n\n#### 4.1: Monitor Agent Logs\n\n**What:** Start monitoring agent logs before testing connection\n\n**Command:**\n```bash\n# Open a dedicated terminal window for agent logs\nlk agent logs --follow\n```\n\n**Keep this terminal open during all testing.**\n\n**What to Look For:**\n- Agent initialization messages\n- Room join events\n- STT transcriptions\n- LLM requests/responses\n- TTS generation\n- WebRTC connection events\n- Any error messages\n\n**Rationale:** Real-time logs are essential for debugging connection issues\n\n---\n\n#### 4.2: Test Basic Connection Flow\n\n**What:** Connect to the agent via frontend and verify basic functionality\n\n**Steps:**\n\n1. Open browser to http://localhost:3000\n2. Open browser DevTools Console (F12 → Console tab)\n3. Click \"Connect\" or \"Start Session\" button\n4. Grant microphone permissions when prompted\n5. Observe connection states in UI:\n   - \"Initializing...\"\n   - \"Listening\" (agent ready for input)\n   - \"Thinking\" (processing speech)\n   - \"Speaking\" (agent responding)\n\n**Expected Behavior:**\n- Connection establishes within 3-5 seconds\n- Agent state transitions to \"Listening\"\n- No errors in browser console\n- Agent logs show room join event\n\n**Troubleshooting:**\n- **Connection hangs:** Check token endpoint, verify LIVEKIT_URL is correct\n- **\"Failed to connect\":** Check agent status (`lk agent status`), verify agent is Running\n- **Microphone permission denied:** Grant permission in browser settings\n- **No audio:** Check browser audio output, verify speakers are enabled\n- **WebRTC errors:** Check firewall, ensure WebRTC ports not blocked\n\n**Rationale:** Validates basic connection before testing voice interaction\n\n---\n\n#### 4.3: Test Voice Interaction\n\n**What:** Verify end-to-end voice pipeline (STT → LLM → TTS)\n\n**Steps:**\n\n1. With frontend connected and agent in \"Listening\" state\n2. Speak clearly into your microphone: \"Hello, can you hear me?\"\n3. Observe agent state transition:\n   - \"Listening\" → \"Thinking\" → \"Speaking\"\n4. Listen for agent's voice response\n5. Check agent logs for:\n   - STT transcription of your speech\n   - LLM request and response\n   - TTS generation\n\n**Expected Outcome:**\n- Agent responds with natural voice within 2-4 seconds\n- Transcription appears in logs (if logging enabled)\n- No audio dropouts or distortion\n- Agent response is contextually appropriate\n\n**Additional Test Cases:**\n- **Interruption:** Speak while agent is speaking (should handle gracefully)\n- **Silence:** Wait 10 seconds without speaking (agent should remain connected)\n- **Background Noise:** Test with ambient noise (should filter with VAD)\n- **Multiple Turns:** Have a multi-turn conversation\n\n**Troubleshooting:**\n- **No transcription:** Check AssemblyAI API key in agent secrets\n- **No LLM response:** Check OpenAI API key, verify LLM model is available\n- **No TTS audio:** Check Cartesia API key, verify TTS voice model\n- **Garbled audio:** Check network connection, reduce network congestion\n- **High latency:** Check agent logs for slow API calls, consider region optimization\n\n**Rationale:** Validates the complete voice AI pipeline works end-to-end\n\n---\n\n#### 4.4: Verify Audio Visualization\n\n**What:** Test the audio visualizer component works correctly\n\n**Steps:**\n\n1. With frontend connected\n2. Speak into microphone\n3. Observe audio visualization:\n   - Bars should animate when you speak\n   - Bars should pulse when agent speaks\n   - Different colors/states for listening vs speaking\n\n**Expected Behavior:**\n- `BarVisualizer` component shows real-time audio levels\n- Smooth animations\n- Clear visual feedback of agent state\n- No lag between audio and visualization\n\n**Check Component:**\n```bash\n# Review visualizer component\ncat frontend/voice-ai-frontend/components/agents-ui/bar-visualizer.tsx\n```\n\n**Troubleshooting:**\n- **No visualization:** Check if audio track is being passed to component\n- **Choppy animation:** Check browser performance, reduce animation complexity\n- **Wrong colors:** Review CSS/Tailwind classes\n\n**Rationale:** Visual feedback improves user experience and debugging\n\n---\n\n#### 4.5: Test Disconnection and Reconnection\n\n**What:** Verify graceful disconnect and ability to reconnect\n\n**Steps:**\n\n**Test Disconnect:**\n1. With frontend connected\n2. Click \"Disconnect\" or \"End Session\" button\n3. Observe clean disconnect:\n   - Agent logs show participant left\n   - No error messages\n   - UI returns to welcome screen\n\n**Test Reconnect:**\n1. Click \"Connect\" again\n2. Verify new session starts successfully\n3. Test voice interaction again\n\n**Test Network Interruption (Optional):**\n1. While connected, disable network (Wi-Fi off)\n2. Observe reconnection behavior\n3. Re-enable network\n4. Verify auto-reconnect or error message\n\n**Expected Behavior:**\n- Clean disconnect without errors\n- Ability to reconnect immediately\n- Each session gets unique room/token\n- No lingering WebRTC connections\n\n**Rationale:** Ensures robust connection lifecycle management\n\n---\n\n#### 4.6: Optimize Connection Speed\n\n**What:** Reduce connection time from 3-5 seconds to <1 second using optimization techniques\n\n**Current Flow (Sequential):**\n```\n1. Click Connect (0ms)\n2. Fetch token from /api/token (500ms)\n3. Connect to LiveKit room (1000ms)\n4. Agent dispatched (1000ms)\n5. Agent connects and publishes (1500ms)\nTotal: ~4000ms (4 seconds)\n```\n\n**Optimization 1: Pre-generate Tokens**\n\nCreate a \"warm token\" approach for faster connection:\n\n**File:** Create `frontend/voice-ai-frontend/hooks/use-warm-token.ts`\n\n```typescript\n'use client';\n\nimport { useState, useEffect } from 'react';\n\nexport function useWarmToken() {\n  const [token, setToken] = useState<string | null>(null);\n\n  useEffect(() => {\n    // Pre-generate token on page load\n    async function generateToken() {\n      const response = await fetch('/api/token', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          roomName: `room-${Date.now()}`,\n          participantName: `user-${Math.random().toString(36).substring(7)}`,\n        }),\n      });\n      const data = await response.json();\n      setToken(data.token);\n    }\n\n    generateToken();\n  }, []);\n\n  return token;\n}\n```\n\n**Usage in Session Component:**\n```typescript\n// In session-view.tsx or similar\nconst warmToken = useWarmToken();\n\n// Use warmToken when connecting instead of fetching on-demand\n```\n\n**Optimization 2: Concurrent Dispatch**\n\nModify connection logic to dispatch agent and connect user simultaneously:\n\n```typescript\n// Parallel connection\nconst [roomConnection, agentDispatch] = await Promise.all([\n  connectToRoom(token),\n  dispatchAgent(roomName) // If manual dispatch required\n]);\n```\n\n**Expected Improvement:**\n- Pre-generated token: -500ms (eliminates token fetch delay)\n- Concurrent dispatch: -1000ms (parallel instead of sequential)\n- **New total:** ~2500ms → ~1500ms (1.5 seconds)\n\n**Trade-offs:**\n- Pre-generated tokens have expiration (ensure 2h TTL)\n- Unused tokens waste resources (minimal cost)\n- Complexity slightly increases\n\n**Rationale:** Faster connections improve user experience and perceived performance\n\n---\n\n#### 4.7: Test on Multiple Browsers\n\n**What:** Verify cross-browser compatibility\n\n**Browsers to Test:**\n- Chrome/Chromium\n- Firefox\n- Safari (macOS/iOS)\n- Edge\n\n**Test Matrix:**\n\n| Browser | Connection | Audio Input | Audio Output | Visualization |\n|---------|-----------|-------------|--------------|---------------|\n| Chrome  | ✓         | ✓           | ✓            | ✓             |\n| Firefox | ?         | ?           | ?            | ?             |\n| Safari  | ?         | ?           | ?            | ?             |\n| Edge    | ?         | ?           | ?            | ?             |\n\n**Common Issues:**\n- **Safari:** May require user interaction before audio playback\n- **Firefox:** Different WebRTC implementation, may have quirks\n- **Mobile Safari:** Requires specific audio context handling\n- **Edge:** Generally compatible with Chrome\n\n**Rationale:** Ensures wide browser support for production deployment\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Connection establishes successfully: Monitor for \"Room connected\" event in logs\n- [ ] Agent joins room: `lk agent logs` shows room join event\n- [ ] WebRTC connection: Browser DevTools Network tab shows WebRTC connections\n- [ ] No console errors: Browser DevTools Console shows no red errors\n- [ ] Audio tracks published: Check LiveKit Cloud dashboard for active tracks\n\n#### Manual Verification:\n\n- [ ] Voice input recognized: Speak and verify agent responds\n- [ ] Voice output works: Hear agent's TTS response clearly\n- [ ] Audio visualization animates correctly\n- [ ] Agent state transitions work (initializing → listening → thinking → speaking)\n- [ ] Interruption handling works (speak during agent response)\n- [ ] Disconnect and reconnect works cleanly\n- [ ] Connection time <3 seconds (before optimization) or <1.5s (after optimization)\n- [ ] Works in Chrome, Firefox, and Safari\n\n**Verify:** After completing automated verification, have a multi-turn conversation with the agent and test all edge cases before proceeding to Phase 5.\n\n---\n\n## Phase 5: Frontend Customization\n\n### Overview\n\nCustomize the frontend with your branding, colors, logo, and company information to make it production-ready.\n\n### Context\n\nBefore starting, ensure:\n- Phase 4 completed successfully\n- Voice interaction working end-to-end\n- Frontend running at http://localhost:3000\n\nFiles to customize:\n- `frontend/voice-ai-frontend/app-config.ts` - Main configuration\n- `frontend/voice-ai-frontend/public/` - Static assets (logo, favicon)\n- `frontend/voice-ai-frontend/app/layout.tsx` - Page metadata\n- `frontend/voice-ai-frontend/tailwind.config.ts` - Theme colors\n\n### Dependencies\n\n**Depends on:** Phase 4 (connection testing completed)\n\n**Required by:** Phase 6 (production deployment)\n\n### Changes Required\n\n#### 5.1: Update App Configuration\n\n**What:** Customize company name, page title, and feature flags\n\n**File:** `frontend/voice-ai-frontend/app-config.ts`\n\n**Edit:**\n```typescript\nexport const APP_CONFIG_DEFAULTS = {\n  // Branding\n  companyName: \"Your Company Name\", // Change this\n  pageTitle: \"AI Voice Assistant | Your Company\", // Change this\n\n  // Logo URLs\n  logoUrl: \"/logo.svg\", // Update after adding logo in 5.2\n  logoUrlDark: \"/logo-dark.svg\", // Optional: separate dark mode logo\n\n  // Accent color\n  accentColor: \"#4F46E5\", // Change to your brand color (hex)\n\n  // Feature toggles - AUDIO-ONLY CONFIGURATION\n  supportsChatInput: false, // Disable text chat (audio-only)\n  supportsVideoInput: false, // DISABLE camera video (audio-only)\n  supportsScreenShare: false, // DISABLE screen sharing (audio-only)\n  isPreConnectBufferEnabled: true, // Pre-load for faster connection\n\n  // Optional: Agent configuration\n  defaultAgentName: \"\", // Leave blank for auto-dispatch\n};\n```\n\n**Example Customization (Audio-Only):**\n```typescript\nexport const APP_CONFIG_DEFAULTS = {\n  companyName: \"Acme Voice AI\",\n  pageTitle: \"Voice AI Assistant | Acme Corp\",\n  logoUrl: \"/acme-logo.svg\",\n  accentColor: \"#FF6B35\", // Orange\n  supportsChatInput: false, // Audio-only: no text chat\n  supportsVideoInput: false, // Audio-only: no camera\n  supportsScreenShare: false, // Audio-only: no screen share\n  isPreConnectBufferEnabled: true,\n};\n```\n\n**Rationale:** Centralizes configuration for easy customization without code changes\n\n---\n\n#### 5.2: Add Custom Logo\n\n**What:** Replace default logo with your company logo\n\n**Steps:**\n\n1. Prepare logo files:\n   - **Format:** SVG (preferred) or PNG\n   - **Size:**\n     - SVG: Any size (scalable)\n     - PNG: 200x200px minimum, transparent background\n   - **Naming:**\n     - Light mode: `logo.svg` or `logo.png`\n     - Dark mode (optional): `logo-dark.svg` or `logo-dark.png`\n\n2. Copy to public directory:\n   ```bash\n   cp /path/to/your/logo.svg frontend/voice-ai-frontend/public/logo.svg\n   # Optional: dark mode logo\n   cp /path/to/your/logo-dark.svg frontend/voice-ai-frontend/public/logo-dark.svg\n   ```\n\n3. Update `app-config.ts`:\n   ```typescript\n   logoUrl: \"/logo.svg\",\n   logoUrlDark: \"/logo-dark.svg\", // If you have separate dark logo\n   ```\n\n4. Verify logo appears:\n   - Restart dev server: `pnpm dev`\n   - Visit http://localhost:3000\n   - Check logo displays correctly\n   - Toggle light/dark mode to test both logos\n\n**Fallback:**\nIf you don't have a logo ready, the template includes a default placeholder logo.\n\n**Rationale:** Custom logo reinforces brand identity\n\n---\n\n#### 5.3: Customize Theme Colors\n\n**What:** Update color scheme to match your brand\n\n**File:** `frontend/voice-ai-frontend/tailwind.config.ts`\n\n**Edit:**\n```typescript\nexport default {\n  theme: {\n    extend: {\n      colors: {\n        // Primary brand color\n        primary: {\n          50: '#f0f9ff',\n          100: '#e0f2fe',\n          // ... continue through 950\n          500: '#4F46E5', // Main brand color (change this)\n          600: '#4338ca',\n          // ...\n        },\n        // Accent color\n        accent: {\n          DEFAULT: '#FF6B35', // Change to your accent color\n          light: '#FF8A5B',\n          dark: '#E5501F',\n        },\n      },\n    },\n  },\n};\n```\n\n**Quick Method (Use Accent Color from app-config.ts):**\n\nThe template may automatically use `accentColor` from `app-config.ts`. If so, just update that value:\n\n```typescript\n// In app-config.ts\naccentColor: \"#FF6B35\", // Your brand color\n```\n\n**Generate Full Color Palette:**\nUse tools like https://uicolors.app/create to generate a full Tailwind color palette from your brand color.\n\n**Test Theme:**\n- Restart dev server\n- Visit http://localhost:3000\n- Check buttons, links, highlights use new colors\n- Toggle light/dark mode to verify both themes\n\n**Rationale:** Consistent color scheme creates professional, branded experience\n\n---\n\n#### 5.4: Update Page Metadata\n\n**What:** Set page title, description, and favicon for SEO and browser display\n\n**File:** `frontend/voice-ai-frontend/app/layout.tsx`\n\n**Edit:**\n```typescript\nexport const metadata: Metadata = {\n  title: \"AI Voice Assistant | Your Company\", // Change this\n  description: \"Connect with our AI voice assistant for instant help and support.\", // Change this\n  icons: {\n    icon: '/favicon.ico', // Update after adding favicon\n  },\n  openGraph: {\n    title: \"AI Voice Assistant | Your Company\",\n    description: \"Connect with our AI voice assistant for instant help and support.\",\n    images: ['/og-image.png'], // Optional: social share image\n  },\n};\n```\n\n**Add Custom Favicon:**\n\n1. Generate favicon files (use https://realfavicongenerator.net/):\n   - `favicon.ico` (16x16, 32x32, 48x48)\n   - `apple-touch-icon.png` (180x180)\n   - `favicon-16x16.png`\n   - `favicon-32x32.png`\n\n2. Copy to `public/`:\n   ```bash\n   cp /path/to/favicon.ico frontend/voice-ai-frontend/public/\n   cp /path/to/apple-touch-icon.png frontend/voice-ai-frontend/public/\n   ```\n\n3. Verify in browser:\n   - Clear browser cache\n   - Visit http://localhost:3000\n   - Check browser tab shows your favicon\n\n**Optional: Open Graph Image (Social Sharing):**\nCreate `og-image.png` (1200x630px) for social media previews.\n\n**Rationale:** Professional metadata improves SEO and user experience\n\n---\n\n#### 5.5: Customize Welcome Message\n\n**What:** Update the welcome screen text and instructions\n\n**File:** `frontend/voice-ai-frontend/components/app/welcome-view.tsx` or similar\n\n**Find and Edit:**\n```typescript\n<h1>Welcome to [Your Company] Voice AI</h1>\n<p>\n  Click the button below to start a voice conversation with our AI assistant.\n  We can help you with questions, information, and more.\n</p>\n```\n\n**Example Customization:**\n```typescript\n<h1>Welcome to Acme Voice Assistant</h1>\n<p>\n  Our AI assistant is ready to help you 24/7. Click \"Connect\" to start a\n  natural voice conversation. Just speak naturally - no keywords or commands needed.\n</p>\n<ul>\n  <li>Get instant answers to your questions</li>\n  <li>Learn about our products and services</li>\n  <li>Get personalized recommendations</li>\n</ul>\n```\n\n**Rationale:** Clear messaging helps users understand what to expect\n\n---\n\n#### 5.6: Configure Audio-Only Mode (REQUIRED)\n\n**What:** Disable video/screen share features for audio-only application\n\n**File:** `frontend/voice-ai-frontend/app-config.ts`\n\n**REQUIRED Configuration for Audio-Only App:**\n```typescript\nexport const APP_CONFIG_DEFAULTS = {\n  // ... other settings\n  supportsChatInput: false, // Audio-only: disable text chat\n  supportsVideoInput: false, // REQUIRED: disable camera\n  supportsScreenShare: false, // REQUIRED: disable screen sharing\n  isPreConnectBufferEnabled: true, // Keep for faster connection\n};\n```\n\n**Effect:**\n- Video camera icon hidden\n- Screen share button removed\n- UI simplified to voice-only interface\n- No video/screenshare permission requests to users\n- Browser only requests microphone permission\n\n**IMPORTANT:** This is a required configuration for this audio-only application. Do NOT enable video or screen sharing features.\n\n**Rationale:** This application is designed for audio-only interaction. No video capabilities should be exposed to users.\n\n---\n\n#### 5.7: Test Customizations\n\n**What:** Verify all customizations display correctly\n\n**Checklist:**\n- [ ] Company name displays on welcome screen\n- [ ] Custom logo appears (both light and dark modes)\n- [ ] Page title shows in browser tab\n- [ ] Custom favicon appears in browser tab\n- [ ] Brand colors visible on buttons and accents\n- [ ] Welcome message updated with custom text\n- [ ] Disabled features are hidden (if applicable)\n- [ ] No broken images or 404s\n- [ ] Responsive design maintained on mobile\n\n**Testing Steps:**\n1. Restart dev server: `pnpm dev`\n2. Clear browser cache (Cmd+Shift+R on Mac, Ctrl+Shift+R on Windows)\n3. Visit http://localhost:3000\n4. Toggle light/dark theme\n5. Resize browser to mobile size (375px width)\n6. Check all visual elements\n\n**Rationale:** Ensures professional, branded appearance before production deployment\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Build succeeds: `pnpm run build` completes without errors\n- [ ] No TypeScript errors: `pnpm run type-check` (if available)\n- [ ] Static assets exist: `ls public/logo.svg public/favicon.ico`\n- [ ] Config updated: `cat app-config.ts | grep companyName` shows your company\n\n#### Manual Verification:\n\n- [ ] Custom company name displays on welcome screen\n- [ ] Custom logo visible (light and dark modes)\n- [ ] Page title correct in browser tab\n- [ ] Favicon visible in browser tab\n- [ ] Brand colors applied throughout UI\n- [ ] Welcome message updated\n- [ ] Unused features hidden (if disabled)\n- [ ] Mobile responsive (test at 375px width)\n- [ ] No console errors or warnings\n- [ ] All images load correctly (no broken images)\n\n**Verify:** After completing automated verification, thoroughly test the UI on desktop and mobile, in light and dark modes, before proceeding to Phase 6.\n\n---\n\n## Phase 6: Production Deployment\n\n### Overview\n\nDeploy the customized frontend to Vercel (or another hosting provider) to make it publicly accessible via a URL that clients can visit.\n\n### Context\n\nBefore starting, ensure:\n- Phase 5 completed successfully\n- All customizations tested locally\n- Frontend builds successfully (`pnpm run build`)\n- Agent deployed and running on LiveKit Cloud\n\nFiles to review:\n- `frontend/voice-ai-frontend/.env.local` - Environment variables (will configure in Vercel)\n- `frontend/voice-ai-frontend/next.config.js` - Next.js configuration\n- `frontend/voice-ai-frontend/package.json` - Dependencies and scripts\n\nAccounts needed:\n- Vercel account (free tier sufficient): https://vercel.com\n- GitHub account (for connecting repo)\n\n### Dependencies\n\n**Depends on:** Phases 1-5 (agent deployed, frontend customized and tested)\n\n**Required by:** None (final phase)\n\n### Changes Required\n\n#### 6.1: Create Production Build\n\n**What:** Verify the production build works correctly before deploying\n\n**Commands:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\n\n# Create production build\npnpm run build\n\n# Test production build locally\npnpm start\n```\n\n**Expected Output:**\n```\n> next build\n\n✓ Compiled successfully\n✓ Linting and checking validity of types\n✓ Collecting page data\n✓ Generating static pages (X/X)\n✓ Finalizing page optimization\n\nRoute (app)                              Size     First Load JS\n┌ ○ /                                    XXX kB        XXX kB\n└ ○ /api/token                          XXX B          XXX kB\n```\n\n**Test Production Build:**\n1. Visit http://localhost:3000 (pnpm start)\n2. Connect to agent\n3. Verify voice interaction works\n4. Check for any errors in console\n\n**Troubleshooting:**\n- If build fails: Check TypeScript errors, fix before proceeding\n- If errors about environment variables: Ensure `.env.local` exists\n- If runtime errors: Check browser console for specific issues\n\n**Rationale:** Catches production-specific issues before deployment\n\n---\n\n#### 6.2: Push Frontend to GitHub (Optional but Recommended)\n\n**What:** Create a Git repository for the frontend to enable easy Vercel deployment\n\n**Option A: Separate Repository (Recommended):**\n\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\n\n# Initialize git repository\ngit init\n\n# Add .gitignore for Next.js\ncat > .gitignore << 'EOF'\n# Next.js\n.next/\nout/\nbuild/\ndist/\n\n# Dependencies\nnode_modules/\n\n# Environment variables\n.env\n.env.local\n.env.production.local\n.env.development.local\n.env.test.local\n\n# Logs\nnpm-debug.log*\nyarn-debug.log*\nyarn-error.log*\npnpm-debug.log*\n\n# OS\n.DS_Store\n*.swp\n*.swo\n\n# IDE\n.vscode/\n.idea/\n\n# Vercel\n.vercel\nEOF\n\n# Add files\ngit add .\ngit commit -m \"Initial commit: Voice AI frontend\"\n\n# Create GitHub repository (via GitHub UI or CLI)\ngh repo create voice-ai-frontend --public --source=. --remote=origin --push\n```\n\n**Option B: Same Repository as Agent:**\n\nIf you want frontend and agent in the same repo:\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\n\n# Remove frontend/ from .gitignore\nsed -i '' '/^frontend\\//d' .gitignore\n\n# Add and commit\ngit add frontend/\ngit commit -m \"Add voice AI frontend\"\ngit push\n```\n\n**Rationale:** Git repository enables continuous deployment and version control\n\n---\n\n#### 6.3: Sign Up for Vercel\n\n**What:** Create a Vercel account for hosting the frontend\n\n**Steps:**\n\n1. Visit https://vercel.com\n2. Click \"Sign Up\"\n3. Choose \"Continue with GitHub\" (recommended)\n4. Authorize Vercel to access your GitHub repositories\n\n**Pricing:**\n- **Free Tier:** Sufficient for testing and low traffic\n  - Unlimited deployments\n  - 100 GB bandwidth/month\n  - Serverless functions included\n- **Pro Tier:** $20/month (for production with higher traffic)\n\n**Rationale:** Vercel provides seamless Next.js hosting with automatic deployments\n\n---\n\n#### 6.4: Deploy Frontend to Vercel\n\n**What:** Deploy the frontend application to Vercel\n\n**Steps:**\n\n1. **From Vercel Dashboard:**\n   - Click \"Add New...\" → \"Project\"\n   - Select \"Import Git Repository\"\n   - Choose your frontend repository\n   - Configure project:\n     - **Framework Preset:** Next.js (auto-detected)\n     - **Root Directory:** `./` (or `frontend/voice-ai-frontend` if in monorepo)\n     - **Build Command:** `pnpm run build` (auto-detected)\n     - **Output Directory:** `.next` (auto-detected)\n     - **Install Command:** `pnpm install` (auto-detected)\n\n2. **Configure Environment Variables:**\n   Click \"Environment Variables\" and add:\n\n   ```\n   LIVEKIT_API_KEY=APIxxxxxxxxxxxx\n   LIVEKIT_API_SECRET=your-secret-here\n   LIVEKIT_URL=wss://your-project.livekit.cloud\n   NEXT_PUBLIC_LIVEKIT_URL=wss://your-project.livekit.cloud\n   AGENT_NAME=\n   ```\n\n   **Important:**\n   - Copy values from your local `.env.local`\n   - Apply to \"Production\", \"Preview\", and \"Development\" environments\n\n3. **Deploy:**\n   - Click \"Deploy\"\n   - Wait for build to complete (2-5 minutes)\n\n**Expected Outcome:**\n```\n✓ Build successful\n✓ Deployment successful\nYour project is now live at: https://your-app.vercel.app\n```\n\n**Rationale:** Makes frontend publicly accessible via HTTPS URL\n\n---\n\n#### 6.5: Test Production Deployment\n\n**What:** Verify the deployed frontend works correctly\n\n**Steps:**\n\n1. Visit your Vercel URL: `https://your-app.vercel.app`\n\n2. **Test Checklist:**\n   - [ ] Page loads without errors\n   - [ ] Custom branding displays correctly\n   - [ ] Click \"Connect\" button\n   - [ ] Grant microphone permissions\n   - [ ] Speak to agent\n   - [ ] Verify agent responds with voice\n   - [ ] Test on mobile device\n   - [ ] Test in different browsers\n\n3. **Monitor Logs:**\n   ```bash\n   # Monitor agent logs during production test\n   lk agent logs --follow\n   ```\n\n4. **Check Vercel Deployment Logs:**\n   - Go to Vercel dashboard → Your project → Deployments\n   - Click on latest deployment → \"Functions\" tab\n   - Check for any errors in `/api/token` function\n\n**Troubleshooting:**\n- **\"Failed to connect\":** Check environment variables in Vercel\n- **Token errors:** Verify `LIVEKIT_API_KEY` and `LIVEKIT_API_SECRET` are correct\n- **CORS errors:** Ensure `NEXT_PUBLIC_LIVEKIT_URL` is set correctly\n- **Agent not joining:** Check agent status, verify agent is Running\n\n**Rationale:** Ensures production environment works correctly\n\n---\n\n#### 6.6: Configure Custom Domain (Optional)\n\n**What:** Use a custom domain instead of `your-app.vercel.app`\n\n**Prerequisites:**\n- Own a domain name (e.g., `voiceai.yourcompany.com`)\n- Access to domain DNS settings\n\n**Steps:**\n\n1. **In Vercel Dashboard:**\n   - Go to your project → Settings → Domains\n   - Click \"Add Domain\"\n   - Enter your domain: `voiceai.yourcompany.com`\n\n2. **Configure DNS:**\n   Vercel will provide DNS configuration instructions:\n\n   **Option A: CNAME (Subdomain):**\n   ```\n   Type: CNAME\n   Name: voiceai\n   Value: cname.vercel-dns.com\n   ```\n\n   **Option B: A Record (Root Domain):**\n   ```\n   Type: A\n   Name: @\n   Value: 76.76.21.21\n   ```\n\n3. **Wait for DNS Propagation:**\n   - Usually takes 5-60 minutes\n   - Vercel will auto-configure SSL certificate (Let's Encrypt)\n\n4. **Verify:**\n   - Visit `https://voiceai.yourcompany.com`\n   - Should show your frontend with SSL (green lock icon)\n\n**Rationale:** Custom domain provides professional appearance and brand consistency\n\n---\n\n#### 6.7: Enable Automatic Deployments\n\n**What:** Configure automatic deployments when you push to GitHub\n\n**Vercel Auto-Deploys By Default:**\n- **Production:** Deploys on push to `main` branch\n- **Preview:** Deploys on push to any other branch or PR\n\n**Customize (Optional):**\n1. Go to Vercel dashboard → Your project → Settings → Git\n2. Configure:\n   - **Production Branch:** `main` (or `master`)\n   - **Ignored Build Step:** (leave blank to build on every commit)\n\n**Test Automatic Deployment:**\n```bash\ncd frontend/voice-ai-frontend\n\n# Make a small change\necho \"# Updated\" >> README.md\n\n# Commit and push\ngit add README.md\ngit commit -m \"Test automatic deployment\"\ngit push origin main\n```\n\n**Verify:**\n- Visit Vercel dashboard\n- Should see new deployment triggered automatically\n- Wait for build to complete\n- Visit production URL to see changes\n\n**Rationale:** Enables continuous deployment for easy updates\n\n---\n\n#### 6.8: Set Up Production Monitoring (Recommended)\n\n**What:** Monitor production errors and usage\n\n**Vercel Analytics (Built-in):**\n1. Go to Vercel dashboard → Your project → Analytics\n2. View:\n   - Page views\n   - Geographic distribution\n   - Performance metrics (Web Vitals)\n\n**Error Tracking (Optional):**\nConsider integrating Sentry or similar:\n```bash\npnpm add @sentry/nextjs\nnpx @sentry/wizard@latest -i nextjs\n```\n\n**LiveKit Cloud Monitoring:**\n- Visit LiveKit Cloud dashboard\n- Monitor:\n  - Active sessions\n  - Agent usage\n  - Costs (session minutes)\n\n**Rationale:** Production monitoring helps identify and resolve issues quickly\n\n---\n\n#### 6.9: Create Shareable Link\n\n**What:** Generate a clean, shareable URL for potential clients\n\n**Your Production URL:**\n```\nhttps://your-app.vercel.app\n```\n\n**Or with Custom Domain:**\n```\nhttps://voiceai.yourcompany.com\n```\n\n**Create Marketing Materials:**\n- Add link to your website\n- Share via email campaigns\n- Include in social media bios\n- Create QR code for physical materials\n\n**Example QR Code Generation:**\n```bash\n# Generate QR code (using qrencode)\nbrew install qrencode\nqrencode -o voiceai-qr.png \"https://voiceai.yourcompany.com\"\n```\n\n**Rationale:** Easy sharing enables potential clients to access your voice AI\n\n---\n\n#### 6.10: Document Production URLs and Credentials\n\n**What:** Save all production information for future reference\n\n**Create:** `frontend/voice-ai-frontend/PRODUCTION.md`\n\n**Content:**\n```markdown\n# Production Deployment Information\n\n## URLs\n- **Production Frontend:** https://your-app.vercel.app\n- **Custom Domain:** https://voiceai.yourcompany.com (if configured)\n- **LiveKit Cloud Dashboard:** https://cloud.livekit.io\n\n## Vercel\n- **Project:** voice-ai-frontend\n- **Account:** your-email@example.com\n- **Git Repository:** https://github.com/yourusername/voice-ai-frontend\n\n## LiveKit Cloud\n- **Project:** your-project-name\n- **Region:** us-west-2\n- **Agent ID:** agent_abc123\n\n## Deployment Commands\n```bash\n# Deploy agent updates\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\nlk agent deploy\n\n# Deploy frontend updates (automatic via Git)\ncd frontend/voice-ai-frontend\ngit add .\ngit commit -m \"Update frontend\"\ngit push origin main\n```\n\n## Monitoring\n- **Agent Logs:** `lk agent logs --follow`\n- **Vercel Logs:** https://vercel.com/your-project/deployments\n- **LiveKit Dashboard:** https://cloud.livekit.io/projects/your-project\n\n## Environment Variables (Vercel)\n- LIVEKIT_API_KEY=APIxxxxxxxxxxxx\n- LIVEKIT_API_SECRET=*** (not shown)\n- LIVEKIT_URL=wss://your-project.livekit.cloud\n- NEXT_PUBLIC_LIVEKIT_URL=wss://your-project.livekit.cloud\n\n## Costs\n- **LiveKit Cloud:** $0.01 per agent session minute\n- **Vercel:** Free tier (or $20/month Pro)\n\n## Support\n- **LiveKit:** https://livekit.io/discord\n- **Vercel:** https://vercel.com/support\n```\n\n**Rationale:** Documentation ensures you can manage production deployment long-term\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Production build succeeds: `pnpm run build` completes without errors\n- [ ] Vercel deployment successful: Deployment status shows \"Ready\"\n- [ ] HTTPS enabled: Visit production URL with green lock icon\n- [ ] Environment variables configured: Check Vercel dashboard\n- [ ] Custom domain configured (if applicable): DNS records set\n\n#### Manual Verification:\n\n- [ ] Visit production URL in browser\n- [ ] Page loads without errors\n- [ ] Custom branding displays correctly\n- [ ] Click \"Connect\" and grant microphone access\n- [ ] Speak to agent and verify voice response\n- [ ] Test on mobile device (iOS Safari, Android Chrome)\n- [ ] Test in incognito/private mode\n- [ ] Share URL with colleague and get confirmation it works\n- [ ] Agent logs show production sessions: `lk agent logs --follow`\n- [ ] No errors in Vercel function logs\n\n**Verify:** After completing automated verification, test the production URL on multiple devices and browsers, then share with a colleague to confirm public accessibility.\n\n---\n\n## Testing Strategy\n\n### Unit Tests\n\n**Not required for this plan.** The agent-starter-react template is a pre-built, production-ready template that doesn't require custom unit tests unless you add significant custom logic.\n\n**Optional:** Add tests if you customize components heavily:\n```bash\npnpm add -D @testing-library/react @testing-library/jest-dom jest\n```\n\n### Integration Tests\n\n**End-to-End Testing:**\n\nManually test the complete flow:\n1. User visits URL\n2. Clicks \"Connect\"\n3. Grants microphone access\n4. Speaks to agent\n5. Receives voice response\n6. Disconnects cleanly\n\n**Test Matrix:**\n\n| Scenario | Steps | Expected Outcome |\n|----------|-------|------------------|\n| First Connection | Visit URL → Click Connect → Speak | Agent responds with voice |\n| Interruption | Speak while agent is speaking | Agent handles gracefully |\n| Disconnect/Reconnect | End session → Start new session | New session works |\n| Multiple Turns | Have 3-5 turn conversation | All responses relevant |\n| Mobile Safari | Test on iPhone/iPad | Full functionality |\n| Network Interruption | Disable Wi-Fi during session | Reconnection or error message |\n\n### Manual Testing Steps\n\n**Pre-Deployment Checklist:**\n1. [ ] Agent deployed and running: `lk agent status`\n2. [ ] Local frontend works: `pnpm dev` at http://localhost:3000\n3. [ ] Voice interaction successful\n4. [ ] Audio visualization working\n5. [ ] Custom branding applied\n6. [ ] Production build succeeds: `pnpm run build`\n\n**Post-Deployment Checklist:**\n1. [ ] Production URL accessible\n2. [ ] HTTPS enabled (green lock)\n3. [ ] Voice interaction works on production\n4. [ ] Mobile responsive\n5. [ ] Cross-browser compatible\n6. [ ] Shareable link works for external users\n\n### Performance Considerations\n\n**Metrics to Monitor:**\n- **Connection Time:** Should be <3 seconds (or <1.5s with optimization)\n- **Response Latency:** STT → LLM → TTS should be 2-4 seconds\n- **Page Load Time:** Initial load <2 seconds (Lighthouse score >90)\n- **Audio Quality:** No dropouts or distortion\n\n**Optimization:**\n- Enable pre-connect buffering in `app-config.ts`\n- Use warm token approach (Phase 4.6)\n- Minimize bundle size (Next.js handles automatically)\n- Use CDN for static assets (Vercel provides automatically)\n\n## References\n\n### Original Ticket/Request\n- User request: \"I want potential clients to be able to interact with the livekit agent from this repo by clicking a link on a website.\"\n\n### Documentation\n- `docs/DEPLOYMENT.md` - Complete deployment guide for agent and frontend options\n- `README.md` - Project overview and setup instructions\n- `AGENTS.md` - Project guidelines and standards\n\n### LiveKit Resources\n- **Frontend Deployment Guide:** https://docs.livekit.io/agents/start/frontend/\n- **agent-starter-react Repository:** https://github.com/livekit-examples/agent-starter-react\n- **Token Authentication:** https://docs.livekit.io/home/get-started/authentication/\n- **Agents Playground:** https://agents-playground.livekit.io/\n- **LiveKit Cloud Dashboard:** https://cloud.livekit.io\n- **React Components Docs:** https://docs.livekit.io/reference/components/react/\n\n### NPM Packages\n- **livekit-client:** Client SDK for browser WebRTC\n- **@livekit/components-react:** React UI components\n- **livekit-server-sdk:** Server-side token generation\n\n### Vercel Resources\n- **Vercel Platform:** https://vercel.com\n- **Next.js Documentation:** https://nextjs.org/docs\n- **Deployment Docs:** https://vercel.com/docs\n\n### Related Plans\n- None (initial implementation)\n\n---\n\n**End of Implementation Plan**\n","structuredPatch":[{"oldStart":1685,"oldLines":7,"newStart":1685,"newLines":8,"lines":[" - [ ] Custom favicon appears in browser tab"," - [ ] Brand colors visible on buttons and accents"," - [ ] Welcome message updated with custom text","-- [ ] Disabled features are hidden (if applicable)","+- [ ] Video/screenshare features are hidden (REQUIRED for audio-only)","+- [ ] Only microphone permission requested (no camera/screenshare)"," - [ ] No broken images or 404s"," - [ ] Responsive design maintained on mobile"," "]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"6cdc3be7-2cc4-47d8-9cc0-43c882fd18a1"}
{"parentUuid":"97fff288-9b57-42f8-aee4-e625f3318b24","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","slug":"enumerated-shimmying-starlight","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01V5iPiQbHPRiuTTcZZSLMAY","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Let me also update the success criteria for Phase 5 to include verification of audio-only mode:","signature":"EocCCkYICxgCKkCfoNkGzZYUbHrZTxMsphNgF+c0Jk8KKNFKPnAzUMsDKq9dSy/C3nv5r0B1HSl6Vqwj4mLTQ18+3e/y8Tuv+G1PEgx/8KSHBw77+h3ybrQaDPLJSPlKrF0DbGpw3SIwHRpmKE1giXOApCgeirTvjduJRVYFvjtlYzvXr3gDiCqrqv5QqUoor9WPvrjgJWaVKm+hkbNN6sRXMqrzLPl5Kyxrjg2OiFsPjo1R5ByNnfY7lDylcdsRYkcaO52xI/mJY9N0tizVVS3muAb6jgwpzZdbO8BVlJM+32mU3gx7cxJXrleT45aX0Tnaql+noj2GomuzxggOqyZpTWRIIXLcIP0YAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":5,"cache_creation_input_tokens":480,"cache_read_input_tokens":68769,"cache_creation":{"ephemeral_5m_input_tokens":480,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXTtAPAA3LUJghnxbnGWv","type":"assistant","uuid":"63a731e1-2772-40ea-a837-422600aa40c9","timestamp":"2026-01-25T09:46:09.780Z"}
{"parentUuid":"63a731e1-2772-40ea-a837-422600aa40c9","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","slug":"enumerated-shimmying-starlight","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01V5iPiQbHPRiuTTcZZSLMAY","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01XAwPhtw5My8r6n9NHZP4zC","name":"Edit","input":{"replace_all":false,"file_path":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/plan/future-plans/2026-01-25-web-frontend-deployment.md","old_string":"#### Manual Verification:\n\n- [ ] Custom company name displays on welcome screen\n- [ ] Custom logo visible (light and dark modes)\n- [ ] Page title correct in browser tab\n- [ ] Favicon visible in browser tab\n- [ ] Brand colors applied throughout UI\n- [ ] Welcome message updated\n- [ ] Unused features hidden (if disabled)\n- [ ] Mobile responsive (test at 375px width)\n- [ ] No console errors or warnings\n- [ ] All images load correctly (no broken images)","new_string":"#### Manual Verification:\n\n- [ ] Custom company name displays on welcome screen\n- [ ] Custom logo visible (light and dark modes)\n- [ ] Page title correct in browser tab\n- [ ] Favicon visible in browser tab\n- [ ] Brand colors applied throughout UI\n- [ ] Welcome message updated\n- [ ] Video/screenshare features are hidden (REQUIRED - verify no camera/screenshare icons)\n- [ ] Browser only requests microphone permission (NOT camera)\n- [ ] Mobile responsive (test at 375px width)\n- [ ] No console errors or warnings\n- [ ] All images load correctly (no broken images)"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":5,"cache_creation_input_tokens":480,"cache_read_input_tokens":68769,"cache_creation":{"ephemeral_5m_input_tokens":480,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXTtAPAA3LUJghnxbnGWv","type":"assistant","uuid":"d5cc759d-6bba-4db3-9ac0-c9654ab2a8c6","timestamp":"2026-01-25T09:46:14.390Z"}
{"parentUuid":"d5cc759d-6bba-4db3-9ac0-c9654ab2a8c6","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","slug":"enumerated-shimmying-starlight","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01XAwPhtw5My8r6n9NHZP4zC","type":"tool_result","content":"The file /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/plan/future-plans/2026-01-25-web-frontend-deployment.md has been updated successfully."}]},"uuid":"f30983cb-844e-4036-8950-2d30928beb83","timestamp":"2026-01-25T09:46:14.447Z","toolUseResult":{"filePath":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/plan/future-plans/2026-01-25-web-frontend-deployment.md","oldString":"#### Manual Verification:\n\n- [ ] Custom company name displays on welcome screen\n- [ ] Custom logo visible (light and dark modes)\n- [ ] Page title correct in browser tab\n- [ ] Favicon visible in browser tab\n- [ ] Brand colors applied throughout UI\n- [ ] Welcome message updated\n- [ ] Unused features hidden (if disabled)\n- [ ] Mobile responsive (test at 375px width)\n- [ ] No console errors or warnings\n- [ ] All images load correctly (no broken images)","newString":"#### Manual Verification:\n\n- [ ] Custom company name displays on welcome screen\n- [ ] Custom logo visible (light and dark modes)\n- [ ] Page title correct in browser tab\n- [ ] Favicon visible in browser tab\n- [ ] Brand colors applied throughout UI\n- [ ] Welcome message updated\n- [ ] Video/screenshare features are hidden (REQUIRED - verify no camera/screenshare icons)\n- [ ] Browser only requests microphone permission (NOT camera)\n- [ ] Mobile responsive (test at 375px width)\n- [ ] No console errors or warnings\n- [ ] All images load correctly (no broken images)","originalFile":"# Web Frontend Deployment Implementation Plan\n\n> **Status:** DRAFT\n\n## Table of Contents\n\n- [Overview](#overview)\n- [Current State Analysis](#current-state-analysis)\n- [Desired End State](#desired-end-state)\n- [What We're NOT Doing](#what-were-not-doing)\n- [Implementation Approach](#implementation-approach)\n- [Dependencies](#dependencies)\n- [Phase 1: Agent Deployment to LiveKit Cloud](#phase-1-agent-deployment-to-livekit-cloud)\n- [Phase 2: Frontend Setup (agent-starter-react)](#phase-2-frontend-setup-agent-starter-react)\n- [Phase 3: Authentication and Token Generation](#phase-3-authentication-and-token-generation)\n- [Phase 4: Connection Testing and Optimization](#phase-4-connection-testing-and-optimization)\n- [Phase 5: Frontend Customization](#phase-5-frontend-customization)\n- [Phase 6: Production Deployment](#phase-6-production-deployment)\n- [Testing Strategy](#testing-strategy)\n- [References](#references)\n\n## Overview\n\nThis plan enables potential clients to interact with the LiveKit voice AI agent from this repository by clicking a link on a website. The implementation covers:\n\n1. Deploying the Python agent to LiveKit Cloud\n2. Setting up a Next.js/React frontend using the agent-starter-react template\n3. Implementing JWT token-based authentication\n4. Testing the connection flow\n5. Customizing the frontend with branding\n6. Deploying the frontend to production (Vercel)\n\nThe solution uses LiveKit's official starter templates and SDKs to create a production-ready web application with TypeScript/JavaScript.\n\n**IMPORTANT: This is an audio-only application. No video camera or screen sharing permissions should be requested from users. All configuration must disable video/screenshare features.**\n\n## Current State Analysis\n\n### What Exists Now\n\n**Agent Backend:**\n- Python voice AI agent in `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1`\n- Built with LiveKit Agents SDK\n- Uses OpenAI (LLM), AssemblyAI (STT), Cartesia (TTS)\n- Configured with `uv` package manager\n- Has `Dockerfile` for containerized deployment\n- Environment variables in `.env.local` (OpenAI, AssemblyAI, Cartesia API keys)\n\n**Missing:**\n- Agent not yet deployed to LiveKit Cloud\n- No web frontend for client interaction\n- No token generation server for authentication\n- No public-facing URL for clients to access\n\n### Key Discoveries\n\nFrom `docs/DEPLOYMENT.md`:\n- LiveKit Cloud deployment uses `lk` CLI\n- Agent deployment command: `lk agent create --secrets-file .env.local`\n- Multiple frontend options available (React, Flutter, Swift, Embed)\n- Connection requires JWT tokens generated server-side\n- agent-starter-react provides production-ready Next.js template\n- Token generation uses `livekit-server-sdk` npm package\n\n### Constraints\n\n1. **Security:** API secrets (LIVEKIT_API_SECRET) must never be exposed to frontend\n2. **Architecture:** Token generation must happen server-side (Next.js API routes)\n3. **Dependencies:** Agent must be deployed and running before frontend can connect\n4. **Cost:** LiveKit Cloud charges $0.01 per agent session minute\n\n## Desired End State\n\n### Success Criteria\n\n- [ ] Agent deployed and running on LiveKit Cloud\n- [ ] Next.js frontend application running locally\n- [ ] JWT token generation working via backend API route\n- [ ] Users can click a link and connect to voice AI agent\n- [ ] Audio conversation works end-to-end (STT → LLM → TTS)\n- [ ] Frontend deployed to production URL (Vercel)\n- [ ] Customized branding (logo, colors, company name)\n- [ ] Light/dark theme support\n- [ ] Audio visualization working\n- [ ] Mobile-responsive design\n\n### How to Verify\n\n**Agent Deployment:**\n```bash\nlk agent status\n# Expected: Status: Running, Replicas: X/X ready\n```\n\n**Frontend Connection:**\n1. Visit frontend URL (local: http://localhost:3000, prod: https://your-app.vercel.app)\n2. Click \"Connect\" or \"Start Session\"\n3. Grant microphone permissions when prompted\n4. Speak to the agent\n5. Verify agent responds with natural voice\n6. Check agent logs: `lk agent logs --follow`\n\n**End-to-End Test:**\n```bash\n# Terminal 1: Monitor agent logs\nlk agent logs --follow\n\n# Terminal 2: Run frontend\ncd /path/to/frontend\npnpm dev\n\n# Browser: Visit http://localhost:3000, connect, and speak\n```\n\n## What We're NOT Doing\n\n**Out of Scope:**\n- Multiple agent types or agent selection UI\n- User authentication/login system (anonymous users only)\n- Database integration or conversation history storage\n- Multi-language support (English only initially)\n- iOS/Android native apps (web only)\n- Custom voice customization UI\n- Payment integration or usage metering\n- Advanced analytics dashboard\n- Server-side rendering (SSR) for the voice interface\n- Custom WebRTC infrastructure (using LiveKit Cloud)\n\n**Future Considerations:**\n- User accounts and saved conversations\n- Analytics and usage tracking\n- Custom domain with branding\n- A/B testing different agent configurations\n- Rate limiting and abuse prevention\n\n## Implementation Approach\n\n### High-Level Strategy\n\n1. **Deploy Agent First:** Ensure the Python agent is running on LiveKit Cloud before building frontend\n2. **Use Official Template:** Start with agent-starter-react to avoid reinventing the wheel\n3. **Iterative Testing:** Test each phase independently before proceeding\n4. **Security-First:** Never expose API secrets; use environment variables and server-side token generation\n5. **Quick Validation:** Use LiveKit Agents Playground first to verify agent works before building frontend\n\n### Technology Stack\n\n**Backend (Agent):**\n- Python 3.11+\n- LiveKit Agents SDK\n- OpenAI GPT-4 (LLM)\n- AssemblyAI (STT)\n- Cartesia (TTS)\n- Deployed to: LiveKit Cloud\n\n**Frontend:**\n- Next.js 14+ (App Router)\n- React 18+\n- TypeScript\n- Tailwind CSS\n- Shadcn/ui components\n- `livekit-client` SDK\n- `@livekit/components-react`\n- Deployed to: Vercel\n\n**Authentication:**\n- JWT tokens (livekit-server-sdk)\n- Server-side generation (Next.js API routes)\n- 2-hour token expiration\n\n## Dependencies\n\n**Execution Order:**\n\n1. Phase 1: Agent Deployment (no dependencies)\n2. Phase 2: Frontend Setup (depends on Phase 1 for credentials)\n3. Phase 3: Authentication (depends on Phase 2)\n4. Phase 4: Connection Testing (depends on Phases 1-3)\n5. Phase 5: Frontend Customization (depends on Phase 4)\n6. Phase 6: Production Deployment (depends on Phase 5)\n\n**Dependency Graph:**\n\n```\nPhase 1 (Agent Deployment)\n  └─> Phase 2 (Frontend Setup)\n        └─> Phase 3 (Authentication)\n              └─> Phase 4 (Testing)\n                    └─> Phase 5 (Customization)\n                          └─> Phase 6 (Production)\n```\n\n**Parallelization:**\n- All phases are sequential due to dependencies\n- Within each phase, independent tasks can run in parallel\n\n---\n\n## Phase 1: Agent Deployment to LiveKit Cloud\n\n### Overview\n\nDeploy the Python voice AI agent to LiveKit Cloud to make it accessible via WebRTC. This creates a running agent that can be dispatched to rooms when users connect.\n\n### Context\n\nBefore starting, ensure you have:\n- LiveKit CLI installed: `brew install livekit/livekit/livekit-cli`\n- LiveKit Cloud account at https://cloud.livekit.io\n- Agent code in `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1`\n- API keys in `.env.local` (OpenAI, AssemblyAI, Cartesia)\n\nFiles to review:\n- `docs/DEPLOYMENT.md` - Complete deployment guide\n- `.env.local` - API keys and secrets\n- `Dockerfile` - Container build configuration\n- `src/app.py` - Agent entry point\n\n### Dependencies\n\n**Depends on:** None (first phase)\n\n**Required by:** Phase 2 (Frontend needs LiveKit credentials), Phase 4 (Testing needs deployed agent)\n\n### Changes Required\n\n#### 1.1: Authenticate with LiveKit Cloud\n\n**What:** Link your CLI to your LiveKit Cloud account\n\n**Command:**\n```bash\nlk cloud auth\n```\n\n**Expected Outcome:**\n- Browser opens for authentication\n- CLI displays: \"Successfully authenticated with LiveKit Cloud\"\n- Credentials saved in `~/.livekit/credentials`\n\n**Rationale:** Required for all subsequent `lk` CLI commands\n\n---\n\n#### 1.2: Create or Select LiveKit Project\n\n**What:** Create a new project or select an existing one for the agent deployment\n\n**Commands:**\n```bash\n# List existing projects\nlk project list\n\n# Option A: Use existing project\nlk project set-default \"your-project-name\"\n\n# Option B: Create new project via dashboard\n# Visit https://cloud.livekit.io and create a new project\n# Then set as default: lk project set-default \"new-project-name\"\n\n# Verify current project\nlk project current\n```\n\n**Expected Outcome:**\n```\nNAME                 PROJECT_ID\nyour-project-name   prj_abc123\n```\n\n**Rationale:** Agent deployments are scoped to projects; need a target project first\n\n---\n\n#### 1.3: Verify Secrets File\n\n**What:** Ensure `.env.local` contains all required API keys\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/.env.local`\n\n**Verify contents:**\n```bash\ncat .env.local\n```\n\n**Required secrets:**\n```env\nOPENAI_API_KEY=sk-...\nASSEMBLYAI_API_KEY=...\nCARTESIA_API_KEY=...\n```\n\n**Important Notes:**\n- Do NOT include `LIVEKIT_URL`, `LIVEKIT_API_KEY`, or `LIVEKIT_API_SECRET` in `.env.local`\n- LiveKit Cloud auto-injects these during deployment\n- Verify `.env.local` is in `.gitignore`\n\n**Rationale:** Agent needs these API keys to function; LiveKit Cloud encrypts and injects them as environment variables\n\n---\n\n#### 1.4: Download Model Files\n\n**What:** Download required models (Silero VAD, turn detector) before deployment\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\nuv run python src/app.py download-files\n```\n\n**Expected Outcome:**\n```\nDownloading Silero VAD model...\nDownloading multilingual turn detector model...\nDownload complete.\n```\n\n**Rationale:** Models are required at runtime; downloading during build ensures faster agent startup\n\n---\n\n#### 1.5: Deploy Agent to LiveKit Cloud\n\n**What:** Create and deploy the agent container to LiveKit Cloud\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\nlk agent create --secrets-file .env.local\n```\n\n**Expected Outcome:**\n```\nRegistering agent...\nAgent ID: agent_abc123\nBuilding container image...\nUploading code...\nBuild in progress (this may take 2-5 minutes)...\nBuild complete.\nDeploying agent...\nDeployment successful.\nStatus: Running\nReplicas: 2/2 ready\n```\n\n**What Happens:**\n1. CLI registers new agent with Cloud project\n2. Assigns unique agent ID (e.g., `agent_abc123`)\n3. Creates/updates `livekit.toml` configuration file\n4. Uploads source code to LiveKit build service\n5. Builds Docker container from `Dockerfile`\n6. Deploys container to Cloud project\n7. Encrypts and injects secrets as environment variables\n8. Starts 2 replica instances\n\n**Duration:** 2-5 minutes for initial build\n\n**Rationale:** Makes agent accessible via LiveKit's global WebRTC infrastructure\n\n---\n\n#### 1.6: Verify Agent Status\n\n**What:** Confirm agent is running and ready to accept sessions\n\n**Commands:**\n```bash\n# Check agent status\nlk agent status\n\n# View live logs\nlk agent logs --tail 50\n```\n\n**Expected Status Output:**\n```\nAgent ID:     agent_abc123\nStatus:       Running\nReplicas:     2/2 ready\nVersion:      v1\nLast Deploy:  2026-01-25 10:30:00 UTC\nRegion:       us-west-2\n```\n\n**Expected Log Output:**\n- No error messages\n- Successful initialization messages\n- \"Waiting for room assignment\" or similar\n\n**Troubleshooting:**\n- If status is `CrashLoop`: Check logs for Python exceptions\n- If status is `Build Failed`: Run `lk agent logs --build` to see build errors\n- If secrets missing: Run `lk agent secrets` to verify\n\n**Rationale:** Ensures agent is healthy before proceeding to frontend setup\n\n---\n\n#### 1.7: Quick Test with Agents Playground\n\n**What:** Test agent using LiveKit Agents Playground (no code required)\n\n**Steps:**\n1. Get project credentials:\n   ```bash\n   lk project current --json\n   ```\n\n2. Visit https://agents-playground.livekit.io/\n\n3. Enter credentials:\n   - **LiveKit URL:** `wss://your-project.livekit.cloud` (from JSON output)\n   - **API Key:** Your `LIVEKIT_API_KEY` (from JSON output)\n   - **API Secret:** Your `LIVEKIT_API_SECRET` (from JSON output)\n\n4. Click \"Connect\"\n\n5. Allow microphone access when prompted\n\n6. Speak to your agent\n\n7. Monitor agent logs in terminal:\n   ```bash\n   lk agent logs --follow\n   ```\n\n**Expected Outcome:**\n- Agent responds to your voice with natural TTS\n- Logs show STT transcriptions, LLM responses, TTS generation\n- No errors in logs\n\n**Rationale:** Validates agent works end-to-end before investing in frontend development\n\n---\n\n#### 1.8: Save LiveKit Credentials\n\n**What:** Export LiveKit project credentials for frontend configuration\n\n**Command:**\n```bash\nlk project current --json > livekit-credentials.json\n```\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/livekit-credentials.json`\n\n**Expected Contents:**\n```json\n{\n  \"name\": \"your-project-name\",\n  \"url\": \"wss://your-project.livekit.cloud\",\n  \"api_key\": \"APIxxxxxxxxxxxx\",\n  \"api_secret\": \"your-secret-here\"\n}\n```\n\n**Security Note:**\n- Add `livekit-credentials.json` to `.gitignore`\n- NEVER commit this file to version control\n- This file is for local reference only\n\n**Rationale:** Frontend needs these credentials to generate tokens and connect to LiveKit\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] CLI authenticated: `lk cloud auth` successful\n- [ ] Project selected: `lk project current` shows correct project\n- [ ] Agent deployed: `lk agent status` shows `Status: Running`\n- [ ] Replicas ready: `lk agent status` shows `X/X ready` (e.g., 2/2)\n- [ ] No crash loops: `lk agent logs --tail 50` shows no errors\n- [ ] Credentials saved: `livekit-credentials.json` exists and contains valid JSON\n\n#### Manual Verification:\n\n- [ ] Agents Playground connection successful\n- [ ] Agent responds to voice input with TTS output\n- [ ] Agent logs show successful STT → LLM → TTS pipeline\n- [ ] No API key errors in logs\n- [ ] Agent state transitions visible (initializing → listening → thinking → speaking)\n\n**Verify:** After completing automated verification, test agent with Agents Playground before proceeding to Phase 2.\n\n---\n\n## Phase 2: Frontend Setup (agent-starter-react)\n\n### Overview\n\nClone and configure the agent-starter-react template to create a Next.js web application that connects users to your deployed agent.\n\n### Context\n\nBefore starting, ensure:\n- Phase 1 completed successfully\n- Agent is running on LiveKit Cloud\n- `livekit-credentials.json` file exists with credentials\n\nPrerequisites:\n- Node.js 18+ installed\n- pnpm installed: `npm install -g pnpm`\n- `lk` CLI authenticated\n\nFiles to review:\n- `livekit-credentials.json` - LiveKit project credentials\n- N/A (frontend doesn't exist yet)\n\n### Dependencies\n\n**Depends on:** Phase 1 (needs LiveKit credentials)\n\n**Required by:** Phase 3 (authentication setup), Phase 4 (connection testing)\n\n### Changes Required\n\n#### 2.1: Create Frontend Project Directory\n\n**What:** Create a directory to house the frontend application\n\n**Commands:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\nmkdir -p frontend\ncd frontend\n```\n\n**Expected Outcome:**\n```\nDirectory created: /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/\n```\n\n**Rationale:** Separates frontend code from agent backend code\n\n---\n\n#### 2.2: Clone agent-starter-react Template\n\n**What:** Use LiveKit CLI to create a new project from the official template\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend\nlk app create --template agent-starter-react\n```\n\n**Interactive Prompts:**\n- **Project name:** (Press Enter for default or enter custom name like \"voice-ai-frontend\")\n- **Install dependencies?** Yes\n\n**Alternative (Manual Clone):**\n```bash\ngit clone https://github.com/livekit-examples/agent-starter-react.git voice-ai-frontend\ncd voice-ai-frontend\npnpm install\n```\n\n**Expected Outcome:**\n```\n✓ Created project: voice-ai-frontend\n✓ Installed dependencies\n✓ Ready to configure\n```\n\n**Directory Structure:**\n```\nfrontend/voice-ai-frontend/\n├── app/\n│   ├── api/token/route.ts     # Token generation endpoint\n│   ├── page.tsx               # Main page\n│   └── layout.tsx\n├── components/\n│   ├── agents-ui/             # Agents UI components\n│   ├── app/                   # Business logic\n│   └── ui/                    # Shadcn/ui primitives\n├── hooks/\n├── lib/\n├── public/\n├── package.json\n├── .env.example\n└── next.config.js\n```\n\n**Rationale:** Official template provides production-ready structure with all necessary LiveKit integrations\n\n---\n\n#### 2.3: Configure Environment Variables\n\n**What:** Set up LiveKit credentials for the frontend\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend/.env.local`\n\n**Commands:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\ncp .env.example .env.local\n```\n\n**Edit `.env.local`:**\n```env\n# LiveKit project credentials (from livekit-credentials.json)\nLIVEKIT_API_KEY=APIxxxxxxxxxxxx\nLIVEKIT_API_SECRET=your-secret-here\nLIVEKIT_URL=wss://your-project.livekit.cloud\n\n# Public URL (exposed to browser - same as LIVEKIT_URL)\nNEXT_PUBLIC_LIVEKIT_URL=wss://your-project.livekit.cloud\n\n# Agent configuration\nAGENT_NAME=\n# Leave AGENT_NAME blank for automatic agent dispatch\n# Or set to specific agent name if you have multiple agents\n```\n\n**How to Get Values:**\n```bash\n# Copy from livekit-credentials.json\ncat /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/livekit-credentials.json\n```\n\n**Security Notes:**\n- `LIVEKIT_API_SECRET` is server-side only (never exposed to browser)\n- `NEXT_PUBLIC_*` variables are exposed to browser\n- Only `NEXT_PUBLIC_LIVEKIT_URL` should be public\n- Never expose `LIVEKIT_API_KEY` or `LIVEKIT_API_SECRET` to browser\n\n**Rationale:** Frontend needs credentials to generate tokens and connect to LiveKit rooms\n\n---\n\n#### 2.4: Verify Dependencies Installation\n\n**What:** Ensure all npm packages are installed correctly\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\npnpm install\n```\n\n**Expected Outcome:**\n```\nPackages: +XXX\nProgress: resolved XXX, reused XXX, downloaded X, added XXX, done\n```\n\n**Key Dependencies (verify in `package.json`):**\n- `next` (v14+)\n- `react` (v18+)\n- `livekit-client`\n- `@livekit/components-react`\n- `livekit-server-sdk`\n- `tailwindcss`\n- `typescript`\n\n**Troubleshooting:**\n- If pnpm not installed: `npm install -g pnpm`\n- If peer dependency warnings: Generally safe to ignore\n- If install fails: Delete `node_modules` and `pnpm-lock.yaml`, retry\n\n**Rationale:** Ensures all required packages are available for development\n\n---\n\n#### 2.5: Run Development Server\n\n**What:** Start the Next.js development server to verify basic setup\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\npnpm dev\n```\n\n**Expected Outcome:**\n```\n> next dev\n\n  ▲ Next.js 14.x.x\n  - Local:        http://localhost:3000\n  - Environments: .env.local\n\n ✓ Ready in X.Xs\n```\n\n**Verification:**\n1. Open browser to http://localhost:3000\n2. Should see agent interface with \"Connect\" button\n3. No console errors in browser DevTools\n4. Page loads without 500 errors\n\n**Expected UI:**\n- Welcome/landing view\n- \"Connect\" or \"Start Session\" button\n- Logo and branding elements\n- Theme toggle (light/dark)\n\n**Troubleshooting:**\n- If port 3000 in use: `pnpm dev -- -p 3001`\n- If env vars missing: Check `.env.local` exists and has correct values\n- If build errors: Check `pnpm install` completed successfully\n\n**Rationale:** Validates Next.js setup before proceeding to authentication\n\n---\n\n#### 2.6: Inspect Token Generation API Route\n\n**What:** Review the built-in token generation endpoint to understand how authentication works\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend/app/api/token/route.ts`\n\n**Read the file:**\n```typescript\n// Expected structure (review actual implementation)\nimport { AccessToken } from 'livekit-server-sdk';\n\nexport async function POST(request: Request) {\n  const { roomName, participantName } = await request.json();\n\n  const token = new AccessToken(\n    process.env.LIVEKIT_API_KEY,\n    process.env.LIVEKIT_API_SECRET,\n    {\n      identity: participantName,\n      ttl: '2h', // Token valid for 2 hours\n    }\n  );\n\n  token.addGrant({\n    room: roomName,\n    roomJoin: true,\n    canPublish: true,\n    canSubscribe: true,\n  });\n\n  return Response.json({ token: await token.toJwt() });\n}\n```\n\n**Key Points:**\n- Uses `livekit-server-sdk` to generate JWT tokens\n- Reads `LIVEKIT_API_KEY` and `LIVEKIT_API_SECRET` from environment\n- Grants room join, publish, and subscribe permissions\n- Returns JWT token to frontend\n- Token expires after 2 hours (LiveKit auto-refreshes for connected clients)\n\n**Security Review:**\n- ✓ API key/secret are server-side only (not exposed to browser)\n- ✓ Token generation happens on server\n- ✓ Appropriate permissions granted\n- ⚠ Consider adding rate limiting for production\n\n**Rationale:** Understanding token flow is critical for debugging connection issues\n\n---\n\n#### 2.7: Add Frontend to .gitignore (Backend Repo)\n\n**What:** Prevent frontend from being committed to agent backend repo\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/.gitignore`\n\n**Add to `.gitignore`:**\n```bash\necho \"frontend/\" >> .gitignore\n```\n\n**Verify:**\n```bash\ngit status\n# frontend/ should not appear in untracked files\n```\n\n**Alternative Approach:**\nIf you want to commit the frontend to the same repo:\n- Create a separate `.gitignore` in `frontend/voice-ai-frontend/`\n- Add standard Next.js ignores (`.next/`, `node_modules/`, `.env.local`)\n\n**Rationale:** Keep frontend and backend as separate concerns, or manage carefully if in same repo\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Frontend directory created: `ls frontend/voice-ai-frontend`\n- [ ] Dependencies installed: `pnpm list --depth=0` shows key packages\n- [ ] Environment variables configured: `cat .env.local | grep LIVEKIT_API_KEY`\n- [ ] Development server starts: `pnpm dev` runs without errors\n- [ ] No TypeScript errors: `pnpm run build` completes successfully\n\n#### Manual Verification:\n\n- [ ] Visit http://localhost:3000 in browser\n- [ ] Page loads without 500 errors\n- [ ] UI displays welcome screen with \"Connect\" button\n- [ ] No console errors in browser DevTools\n- [ ] Theme toggle works (light/dark mode)\n- [ ] Responsive design works on mobile viewport\n\n**Verify:** After completing automated verification, open the app in a browser and verify UI loads correctly before proceeding to Phase 3.\n\n---\n\n## Phase 3: Authentication and Token Generation\n\n### Overview\n\nConfigure and test the JWT token generation flow to ensure frontend can authenticate users with LiveKit and connect them to agent sessions.\n\n### Context\n\nBefore starting, ensure:\n- Phase 2 completed successfully\n- Development server running at http://localhost:3000\n- Environment variables configured in `.env.local`\n\nFiles to review:\n- `frontend/voice-ai-frontend/app/api/token/route.ts` - Token generation endpoint\n- `frontend/voice-ai-frontend/.env.local` - Environment configuration\n- `frontend/voice-ai-frontend/components/app/` - Client-side connection logic\n\n### Dependencies\n\n**Depends on:** Phase 2 (frontend setup)\n\n**Required by:** Phase 4 (connection testing)\n\n### Changes Required\n\n#### 3.1: Test Token Generation Endpoint\n\n**What:** Verify the token API endpoint works correctly\n\n**Command:**\n```bash\n# Start dev server (if not running)\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\npnpm dev\n\n# In another terminal, test the endpoint\ncurl -X POST http://localhost:3000/api/token \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"roomName\": \"test-room\", \"participantName\": \"test-user\"}'\n```\n\n**Expected Response:**\n```json\n{\n  \"token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\"\n}\n```\n\n**Validate Token:**\n```bash\n# Decode the JWT to inspect claims (copy token from response)\necho \"eyJhbGciOiJ...\" | cut -d'.' -f2 | base64 -d | jq\n```\n\n**Expected Token Payload:**\n```json\n{\n  \"exp\": 1234567890,\n  \"iss\": \"APIxxxxxxxxxxxx\",\n  \"sub\": \"test-user\",\n  \"nbf\": 1234567890,\n  \"video\": {\n    \"room\": \"test-room\",\n    \"roomJoin\": true,\n    \"canPublish\": true,\n    \"canSubscribe\": true,\n    \"canPublishData\": true\n  }\n}\n```\n\n**Troubleshooting:**\n- If 500 error: Check environment variables in `.env.local`\n- If \"api_key undefined\": Verify `LIVEKIT_API_KEY` is set\n- If \"invalid signature\": Check `LIVEKIT_API_SECRET` is correct\n- If no response: Verify dev server is running on port 3000\n\n**Rationale:** Token generation must work before attempting to connect to LiveKit\n\n---\n\n#### 3.2: Review Client-Side Connection Logic\n\n**What:** Understand how the frontend connects to LiveKit rooms\n\n**Files to Review:**\n```bash\n# Main session component\ncat frontend/voice-ai-frontend/components/app/session-view.tsx\n\n# View controller\ncat frontend/voice-ai-frontend/components/app/view-controller.tsx\n\n# Connection utilities\ncat frontend/voice-ai-frontend/lib/connection.ts\n```\n\n**Key Flow:**\n1. User clicks \"Connect\" button\n2. Frontend generates room name (random or predefined)\n3. Frontend fetches token from `/api/token` endpoint\n4. Frontend connects to LiveKit room using `livekit-client`\n5. Agent is automatically dispatched to room\n6. User and agent establish WebRTC connection\n7. Audio tracks are exchanged\n\n**Important Variables:**\n- `NEXT_PUBLIC_LIVEKIT_URL` - LiveKit server URL (browser-accessible)\n- Room name generation logic\n- Participant name/identity\n- Agent dispatch configuration\n\n**Rationale:** Understanding client-side logic helps debug connection issues\n\n---\n\n#### 3.3: Configure Agent Dispatch\n\n**What:** Ensure frontend triggers automatic agent dispatch when users connect\n\n**File:** Review `frontend/voice-ai-frontend/app/api/connection-details/route.ts` (if exists) or equivalent\n\n**Verify Agent Name Configuration:**\n\n**Option A: Automatic Dispatch (Recommended):**\n```env\n# In .env.local\nAGENT_NAME=\n# Blank means \"dispatch any available agent\"\n```\n\n**Option B: Specific Agent:**\n```env\n# In .env.local\nAGENT_NAME=agent_abc123\n# Uses specific agent by ID or name\n```\n\n**Check Token Grant Configuration (Audio-Only):**\n```typescript\n// In app/api/token/route.ts or connection-details/route.ts\ntoken.addGrant({\n  room: roomName,\n  roomJoin: true,\n  canPublish: true,      // Allow publishing audio\n  canSubscribe: true,    // Allow receiving audio\n  canPublishSources: [   // AUDIO-ONLY: restrict to microphone\n    'microphone'\n    // NOTE: 'camera' and 'screen_share' are NOT included\n  ],\n});\n```\n\n**For agent-starter-react:**\nThe template typically handles agent dispatch automatically when a participant joins a room. Verify this by checking the token generation code and connection details endpoint.\n\n**Rationale:** Agent won't join room unless dispatch is configured correctly\n\n---\n\n#### 3.4: Test Token Expiration and Refresh\n\n**What:** Verify token expiration is set correctly and LiveKit handles refresh\n\n**Check Current TTL:**\n```typescript\n// In app/api/token/route.ts\nconst token = new AccessToken(\n  process.env.LIVEKIT_API_KEY,\n  process.env.LIVEKIT_API_SECRET,\n  {\n    identity: participantName,\n    ttl: '2h', // Current setting\n  }\n);\n```\n\n**Recommended TTL:**\n- Development: `2h` (2 hours)\n- Production: `2h` (LiveKit auto-refreshes for connected clients)\n- Pre-generated tokens: `1h` (if caching tokens)\n\n**Token Refresh Behavior:**\n- LiveKit client SDK automatically refreshes tokens before expiration\n- Refresh happens for connected clients only\n- Disconnected users must request new tokens\n\n**No changes needed if TTL is already `2h`.**\n\n**Rationale:** Prevents users from being disconnected due to token expiration\n\n---\n\n#### 3.5: Add Security Headers (Optional but Recommended)\n\n**What:** Add security headers to token API route\n\n**File:** `frontend/voice-ai-frontend/middleware.ts` (create if doesn't exist)\n\n**Content:**\n```typescript\nimport { NextResponse } from 'next/server';\nimport type { NextRequest } from 'next/server';\n\nexport function middleware(request: NextRequest) {\n  const response = NextResponse.next();\n\n  // Security headers\n  response.headers.set('X-Content-Type-Options', 'nosniff');\n  response.headers.set('X-Frame-Options', 'DENY');\n  response.headers.set('X-XSS-Protection', '1; mode=block');\n\n  return response;\n}\n\nexport const config = {\n  matcher: '/api/:path*',\n};\n```\n\n**Optional Rate Limiting:**\nConsider adding rate limiting to `/api/token` endpoint to prevent abuse.\n\n**Rationale:** Basic security hardening for production deployments\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Token endpoint returns valid JWT: `curl -X POST http://localhost:3000/api/token -H \"Content-Type: application/json\" -d '{\"roomName\":\"test\",\"participantName\":\"user\"}' | jq .token`\n- [ ] Token payload contains correct claims: Decode JWT and verify `video.roomJoin: true`\n- [ ] Environment variables loaded: `console.log(process.env.LIVEKIT_API_KEY)` in token route shows value (not undefined)\n- [ ] Token has correct expiration: Decoded JWT shows `exp` timestamp 2 hours in future\n\n#### Manual Verification:\n\n- [ ] Token endpoint accessible via browser: Visit http://localhost:3000/api/token (should return 405 Method Not Allowed for GET)\n- [ ] No errors in Next.js server logs when generating tokens\n- [ ] Token decodes successfully at https://jwt.io\n- [ ] Token issuer (`iss`) matches your LiveKit API key\n- [ ] Token subject (`sub`) matches requested participant name\n\n**Verify:** After completing automated verification, test token generation with curl and decode the JWT to inspect claims before proceeding to Phase 4.\n\n---\n\n## Phase 4: Connection Testing and Optimization\n\n### Overview\n\nTest the end-to-end connection flow from frontend to agent, verify audio works correctly, and optimize the connection speed.\n\n### Context\n\nBefore starting, ensure:\n- Phase 3 completed successfully\n- Agent running on LiveKit Cloud (`lk agent status` shows Running)\n- Frontend running at http://localhost:3000\n- Token generation working\n\nFiles to review:\n- `frontend/voice-ai-frontend/components/app/session-view.tsx` - Session management\n- `frontend/voice-ai-frontend/components/agents-ui/` - UI components\n\nTools needed:\n- Browser with microphone access\n- Terminal for monitoring agent logs\n\n### Dependencies\n\n**Depends on:** Phases 1-3 (agent deployed, frontend configured, authentication working)\n\n**Required by:** Phase 5 (customization), Phase 6 (production deployment)\n\n### Changes Required\n\n#### 4.1: Monitor Agent Logs\n\n**What:** Start monitoring agent logs before testing connection\n\n**Command:**\n```bash\n# Open a dedicated terminal window for agent logs\nlk agent logs --follow\n```\n\n**Keep this terminal open during all testing.**\n\n**What to Look For:**\n- Agent initialization messages\n- Room join events\n- STT transcriptions\n- LLM requests/responses\n- TTS generation\n- WebRTC connection events\n- Any error messages\n\n**Rationale:** Real-time logs are essential for debugging connection issues\n\n---\n\n#### 4.2: Test Basic Connection Flow\n\n**What:** Connect to the agent via frontend and verify basic functionality\n\n**Steps:**\n\n1. Open browser to http://localhost:3000\n2. Open browser DevTools Console (F12 → Console tab)\n3. Click \"Connect\" or \"Start Session\" button\n4. Grant microphone permissions when prompted\n5. Observe connection states in UI:\n   - \"Initializing...\"\n   - \"Listening\" (agent ready for input)\n   - \"Thinking\" (processing speech)\n   - \"Speaking\" (agent responding)\n\n**Expected Behavior:**\n- Connection establishes within 3-5 seconds\n- Agent state transitions to \"Listening\"\n- No errors in browser console\n- Agent logs show room join event\n\n**Troubleshooting:**\n- **Connection hangs:** Check token endpoint, verify LIVEKIT_URL is correct\n- **\"Failed to connect\":** Check agent status (`lk agent status`), verify agent is Running\n- **Microphone permission denied:** Grant permission in browser settings\n- **No audio:** Check browser audio output, verify speakers are enabled\n- **WebRTC errors:** Check firewall, ensure WebRTC ports not blocked\n\n**Rationale:** Validates basic connection before testing voice interaction\n\n---\n\n#### 4.3: Test Voice Interaction\n\n**What:** Verify end-to-end voice pipeline (STT → LLM → TTS)\n\n**Steps:**\n\n1. With frontend connected and agent in \"Listening\" state\n2. Speak clearly into your microphone: \"Hello, can you hear me?\"\n3. Observe agent state transition:\n   - \"Listening\" → \"Thinking\" → \"Speaking\"\n4. Listen for agent's voice response\n5. Check agent logs for:\n   - STT transcription of your speech\n   - LLM request and response\n   - TTS generation\n\n**Expected Outcome:**\n- Agent responds with natural voice within 2-4 seconds\n- Transcription appears in logs (if logging enabled)\n- No audio dropouts or distortion\n- Agent response is contextually appropriate\n\n**Additional Test Cases:**\n- **Interruption:** Speak while agent is speaking (should handle gracefully)\n- **Silence:** Wait 10 seconds without speaking (agent should remain connected)\n- **Background Noise:** Test with ambient noise (should filter with VAD)\n- **Multiple Turns:** Have a multi-turn conversation\n\n**Troubleshooting:**\n- **No transcription:** Check AssemblyAI API key in agent secrets\n- **No LLM response:** Check OpenAI API key, verify LLM model is available\n- **No TTS audio:** Check Cartesia API key, verify TTS voice model\n- **Garbled audio:** Check network connection, reduce network congestion\n- **High latency:** Check agent logs for slow API calls, consider region optimization\n\n**Rationale:** Validates the complete voice AI pipeline works end-to-end\n\n---\n\n#### 4.4: Verify Audio Visualization\n\n**What:** Test the audio visualizer component works correctly\n\n**Steps:**\n\n1. With frontend connected\n2. Speak into microphone\n3. Observe audio visualization:\n   - Bars should animate when you speak\n   - Bars should pulse when agent speaks\n   - Different colors/states for listening vs speaking\n\n**Expected Behavior:**\n- `BarVisualizer` component shows real-time audio levels\n- Smooth animations\n- Clear visual feedback of agent state\n- No lag between audio and visualization\n\n**Check Component:**\n```bash\n# Review visualizer component\ncat frontend/voice-ai-frontend/components/agents-ui/bar-visualizer.tsx\n```\n\n**Troubleshooting:**\n- **No visualization:** Check if audio track is being passed to component\n- **Choppy animation:** Check browser performance, reduce animation complexity\n- **Wrong colors:** Review CSS/Tailwind classes\n\n**Rationale:** Visual feedback improves user experience and debugging\n\n---\n\n#### 4.5: Test Disconnection and Reconnection\n\n**What:** Verify graceful disconnect and ability to reconnect\n\n**Steps:**\n\n**Test Disconnect:**\n1. With frontend connected\n2. Click \"Disconnect\" or \"End Session\" button\n3. Observe clean disconnect:\n   - Agent logs show participant left\n   - No error messages\n   - UI returns to welcome screen\n\n**Test Reconnect:**\n1. Click \"Connect\" again\n2. Verify new session starts successfully\n3. Test voice interaction again\n\n**Test Network Interruption (Optional):**\n1. While connected, disable network (Wi-Fi off)\n2. Observe reconnection behavior\n3. Re-enable network\n4. Verify auto-reconnect or error message\n\n**Expected Behavior:**\n- Clean disconnect without errors\n- Ability to reconnect immediately\n- Each session gets unique room/token\n- No lingering WebRTC connections\n\n**Rationale:** Ensures robust connection lifecycle management\n\n---\n\n#### 4.6: Optimize Connection Speed\n\n**What:** Reduce connection time from 3-5 seconds to <1 second using optimization techniques\n\n**Current Flow (Sequential):**\n```\n1. Click Connect (0ms)\n2. Fetch token from /api/token (500ms)\n3. Connect to LiveKit room (1000ms)\n4. Agent dispatched (1000ms)\n5. Agent connects and publishes (1500ms)\nTotal: ~4000ms (4 seconds)\n```\n\n**Optimization 1: Pre-generate Tokens**\n\nCreate a \"warm token\" approach for faster connection:\n\n**File:** Create `frontend/voice-ai-frontend/hooks/use-warm-token.ts`\n\n```typescript\n'use client';\n\nimport { useState, useEffect } from 'react';\n\nexport function useWarmToken() {\n  const [token, setToken] = useState<string | null>(null);\n\n  useEffect(() => {\n    // Pre-generate token on page load\n    async function generateToken() {\n      const response = await fetch('/api/token', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          roomName: `room-${Date.now()}`,\n          participantName: `user-${Math.random().toString(36).substring(7)}`,\n        }),\n      });\n      const data = await response.json();\n      setToken(data.token);\n    }\n\n    generateToken();\n  }, []);\n\n  return token;\n}\n```\n\n**Usage in Session Component:**\n```typescript\n// In session-view.tsx or similar\nconst warmToken = useWarmToken();\n\n// Use warmToken when connecting instead of fetching on-demand\n```\n\n**Optimization 2: Concurrent Dispatch**\n\nModify connection logic to dispatch agent and connect user simultaneously:\n\n```typescript\n// Parallel connection\nconst [roomConnection, agentDispatch] = await Promise.all([\n  connectToRoom(token),\n  dispatchAgent(roomName) // If manual dispatch required\n]);\n```\n\n**Expected Improvement:**\n- Pre-generated token: -500ms (eliminates token fetch delay)\n- Concurrent dispatch: -1000ms (parallel instead of sequential)\n- **New total:** ~2500ms → ~1500ms (1.5 seconds)\n\n**Trade-offs:**\n- Pre-generated tokens have expiration (ensure 2h TTL)\n- Unused tokens waste resources (minimal cost)\n- Complexity slightly increases\n\n**Rationale:** Faster connections improve user experience and perceived performance\n\n---\n\n#### 4.7: Test on Multiple Browsers\n\n**What:** Verify cross-browser compatibility\n\n**Browsers to Test:**\n- Chrome/Chromium\n- Firefox\n- Safari (macOS/iOS)\n- Edge\n\n**Test Matrix:**\n\n| Browser | Connection | Audio Input | Audio Output | Visualization |\n|---------|-----------|-------------|--------------|---------------|\n| Chrome  | ✓         | ✓           | ✓            | ✓             |\n| Firefox | ?         | ?           | ?            | ?             |\n| Safari  | ?         | ?           | ?            | ?             |\n| Edge    | ?         | ?           | ?            | ?             |\n\n**Common Issues:**\n- **Safari:** May require user interaction before audio playback\n- **Firefox:** Different WebRTC implementation, may have quirks\n- **Mobile Safari:** Requires specific audio context handling\n- **Edge:** Generally compatible with Chrome\n\n**Rationale:** Ensures wide browser support for production deployment\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Connection establishes successfully: Monitor for \"Room connected\" event in logs\n- [ ] Agent joins room: `lk agent logs` shows room join event\n- [ ] WebRTC connection: Browser DevTools Network tab shows WebRTC connections\n- [ ] No console errors: Browser DevTools Console shows no red errors\n- [ ] Audio tracks published: Check LiveKit Cloud dashboard for active tracks\n\n#### Manual Verification:\n\n- [ ] Voice input recognized: Speak and verify agent responds\n- [ ] Voice output works: Hear agent's TTS response clearly\n- [ ] Audio visualization animates correctly\n- [ ] Agent state transitions work (initializing → listening → thinking → speaking)\n- [ ] Interruption handling works (speak during agent response)\n- [ ] Disconnect and reconnect works cleanly\n- [ ] Connection time <3 seconds (before optimization) or <1.5s (after optimization)\n- [ ] Works in Chrome, Firefox, and Safari\n\n**Verify:** After completing automated verification, have a multi-turn conversation with the agent and test all edge cases before proceeding to Phase 5.\n\n---\n\n## Phase 5: Frontend Customization\n\n### Overview\n\nCustomize the frontend with your branding, colors, logo, and company information to make it production-ready.\n\n### Context\n\nBefore starting, ensure:\n- Phase 4 completed successfully\n- Voice interaction working end-to-end\n- Frontend running at http://localhost:3000\n\nFiles to customize:\n- `frontend/voice-ai-frontend/app-config.ts` - Main configuration\n- `frontend/voice-ai-frontend/public/` - Static assets (logo, favicon)\n- `frontend/voice-ai-frontend/app/layout.tsx` - Page metadata\n- `frontend/voice-ai-frontend/tailwind.config.ts` - Theme colors\n\n### Dependencies\n\n**Depends on:** Phase 4 (connection testing completed)\n\n**Required by:** Phase 6 (production deployment)\n\n### Changes Required\n\n#### 5.1: Update App Configuration\n\n**What:** Customize company name, page title, and feature flags\n\n**File:** `frontend/voice-ai-frontend/app-config.ts`\n\n**Edit:**\n```typescript\nexport const APP_CONFIG_DEFAULTS = {\n  // Branding\n  companyName: \"Your Company Name\", // Change this\n  pageTitle: \"AI Voice Assistant | Your Company\", // Change this\n\n  // Logo URLs\n  logoUrl: \"/logo.svg\", // Update after adding logo in 5.2\n  logoUrlDark: \"/logo-dark.svg\", // Optional: separate dark mode logo\n\n  // Accent color\n  accentColor: \"#4F46E5\", // Change to your brand color (hex)\n\n  // Feature toggles - AUDIO-ONLY CONFIGURATION\n  supportsChatInput: false, // Disable text chat (audio-only)\n  supportsVideoInput: false, // DISABLE camera video (audio-only)\n  supportsScreenShare: false, // DISABLE screen sharing (audio-only)\n  isPreConnectBufferEnabled: true, // Pre-load for faster connection\n\n  // Optional: Agent configuration\n  defaultAgentName: \"\", // Leave blank for auto-dispatch\n};\n```\n\n**Example Customization (Audio-Only):**\n```typescript\nexport const APP_CONFIG_DEFAULTS = {\n  companyName: \"Acme Voice AI\",\n  pageTitle: \"Voice AI Assistant | Acme Corp\",\n  logoUrl: \"/acme-logo.svg\",\n  accentColor: \"#FF6B35\", // Orange\n  supportsChatInput: false, // Audio-only: no text chat\n  supportsVideoInput: false, // Audio-only: no camera\n  supportsScreenShare: false, // Audio-only: no screen share\n  isPreConnectBufferEnabled: true,\n};\n```\n\n**Rationale:** Centralizes configuration for easy customization without code changes\n\n---\n\n#### 5.2: Add Custom Logo\n\n**What:** Replace default logo with your company logo\n\n**Steps:**\n\n1. Prepare logo files:\n   - **Format:** SVG (preferred) or PNG\n   - **Size:**\n     - SVG: Any size (scalable)\n     - PNG: 200x200px minimum, transparent background\n   - **Naming:**\n     - Light mode: `logo.svg` or `logo.png`\n     - Dark mode (optional): `logo-dark.svg` or `logo-dark.png`\n\n2. Copy to public directory:\n   ```bash\n   cp /path/to/your/logo.svg frontend/voice-ai-frontend/public/logo.svg\n   # Optional: dark mode logo\n   cp /path/to/your/logo-dark.svg frontend/voice-ai-frontend/public/logo-dark.svg\n   ```\n\n3. Update `app-config.ts`:\n   ```typescript\n   logoUrl: \"/logo.svg\",\n   logoUrlDark: \"/logo-dark.svg\", // If you have separate dark logo\n   ```\n\n4. Verify logo appears:\n   - Restart dev server: `pnpm dev`\n   - Visit http://localhost:3000\n   - Check logo displays correctly\n   - Toggle light/dark mode to test both logos\n\n**Fallback:**\nIf you don't have a logo ready, the template includes a default placeholder logo.\n\n**Rationale:** Custom logo reinforces brand identity\n\n---\n\n#### 5.3: Customize Theme Colors\n\n**What:** Update color scheme to match your brand\n\n**File:** `frontend/voice-ai-frontend/tailwind.config.ts`\n\n**Edit:**\n```typescript\nexport default {\n  theme: {\n    extend: {\n      colors: {\n        // Primary brand color\n        primary: {\n          50: '#f0f9ff',\n          100: '#e0f2fe',\n          // ... continue through 950\n          500: '#4F46E5', // Main brand color (change this)\n          600: '#4338ca',\n          // ...\n        },\n        // Accent color\n        accent: {\n          DEFAULT: '#FF6B35', // Change to your accent color\n          light: '#FF8A5B',\n          dark: '#E5501F',\n        },\n      },\n    },\n  },\n};\n```\n\n**Quick Method (Use Accent Color from app-config.ts):**\n\nThe template may automatically use `accentColor` from `app-config.ts`. If so, just update that value:\n\n```typescript\n// In app-config.ts\naccentColor: \"#FF6B35\", // Your brand color\n```\n\n**Generate Full Color Palette:**\nUse tools like https://uicolors.app/create to generate a full Tailwind color palette from your brand color.\n\n**Test Theme:**\n- Restart dev server\n- Visit http://localhost:3000\n- Check buttons, links, highlights use new colors\n- Toggle light/dark mode to verify both themes\n\n**Rationale:** Consistent color scheme creates professional, branded experience\n\n---\n\n#### 5.4: Update Page Metadata\n\n**What:** Set page title, description, and favicon for SEO and browser display\n\n**File:** `frontend/voice-ai-frontend/app/layout.tsx`\n\n**Edit:**\n```typescript\nexport const metadata: Metadata = {\n  title: \"AI Voice Assistant | Your Company\", // Change this\n  description: \"Connect with our AI voice assistant for instant help and support.\", // Change this\n  icons: {\n    icon: '/favicon.ico', // Update after adding favicon\n  },\n  openGraph: {\n    title: \"AI Voice Assistant | Your Company\",\n    description: \"Connect with our AI voice assistant for instant help and support.\",\n    images: ['/og-image.png'], // Optional: social share image\n  },\n};\n```\n\n**Add Custom Favicon:**\n\n1. Generate favicon files (use https://realfavicongenerator.net/):\n   - `favicon.ico` (16x16, 32x32, 48x48)\n   - `apple-touch-icon.png` (180x180)\n   - `favicon-16x16.png`\n   - `favicon-32x32.png`\n\n2. Copy to `public/`:\n   ```bash\n   cp /path/to/favicon.ico frontend/voice-ai-frontend/public/\n   cp /path/to/apple-touch-icon.png frontend/voice-ai-frontend/public/\n   ```\n\n3. Verify in browser:\n   - Clear browser cache\n   - Visit http://localhost:3000\n   - Check browser tab shows your favicon\n\n**Optional: Open Graph Image (Social Sharing):**\nCreate `og-image.png` (1200x630px) for social media previews.\n\n**Rationale:** Professional metadata improves SEO and user experience\n\n---\n\n#### 5.5: Customize Welcome Message\n\n**What:** Update the welcome screen text and instructions\n\n**File:** `frontend/voice-ai-frontend/components/app/welcome-view.tsx` or similar\n\n**Find and Edit:**\n```typescript\n<h1>Welcome to [Your Company] Voice AI</h1>\n<p>\n  Click the button below to start a voice conversation with our AI assistant.\n  We can help you with questions, information, and more.\n</p>\n```\n\n**Example Customization:**\n```typescript\n<h1>Welcome to Acme Voice Assistant</h1>\n<p>\n  Our AI assistant is ready to help you 24/7. Click \"Connect\" to start a\n  natural voice conversation. Just speak naturally - no keywords or commands needed.\n</p>\n<ul>\n  <li>Get instant answers to your questions</li>\n  <li>Learn about our products and services</li>\n  <li>Get personalized recommendations</li>\n</ul>\n```\n\n**Rationale:** Clear messaging helps users understand what to expect\n\n---\n\n#### 5.6: Configure Audio-Only Mode (REQUIRED)\n\n**What:** Disable video/screen share features for audio-only application\n\n**File:** `frontend/voice-ai-frontend/app-config.ts`\n\n**REQUIRED Configuration for Audio-Only App:**\n```typescript\nexport const APP_CONFIG_DEFAULTS = {\n  // ... other settings\n  supportsChatInput: false, // Audio-only: disable text chat\n  supportsVideoInput: false, // REQUIRED: disable camera\n  supportsScreenShare: false, // REQUIRED: disable screen sharing\n  isPreConnectBufferEnabled: true, // Keep for faster connection\n};\n```\n\n**Effect:**\n- Video camera icon hidden\n- Screen share button removed\n- UI simplified to voice-only interface\n- No video/screenshare permission requests to users\n- Browser only requests microphone permission\n\n**IMPORTANT:** This is a required configuration for this audio-only application. Do NOT enable video or screen sharing features.\n\n**Rationale:** This application is designed for audio-only interaction. No video capabilities should be exposed to users.\n\n---\n\n#### 5.7: Test Customizations\n\n**What:** Verify all customizations display correctly\n\n**Checklist:**\n- [ ] Company name displays on welcome screen\n- [ ] Custom logo appears (both light and dark modes)\n- [ ] Page title shows in browser tab\n- [ ] Custom favicon appears in browser tab\n- [ ] Brand colors visible on buttons and accents\n- [ ] Welcome message updated with custom text\n- [ ] Video/screenshare features are hidden (REQUIRED for audio-only)\n- [ ] Only microphone permission requested (no camera/screenshare)\n- [ ] No broken images or 404s\n- [ ] Responsive design maintained on mobile\n\n**Testing Steps:**\n1. Restart dev server: `pnpm dev`\n2. Clear browser cache (Cmd+Shift+R on Mac, Ctrl+Shift+R on Windows)\n3. Visit http://localhost:3000\n4. Toggle light/dark theme\n5. Resize browser to mobile size (375px width)\n6. Check all visual elements\n\n**Rationale:** Ensures professional, branded appearance before production deployment\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Build succeeds: `pnpm run build` completes without errors\n- [ ] No TypeScript errors: `pnpm run type-check` (if available)\n- [ ] Static assets exist: `ls public/logo.svg public/favicon.ico`\n- [ ] Config updated: `cat app-config.ts | grep companyName` shows your company\n\n#### Manual Verification:\n\n- [ ] Custom company name displays on welcome screen\n- [ ] Custom logo visible (light and dark modes)\n- [ ] Page title correct in browser tab\n- [ ] Favicon visible in browser tab\n- [ ] Brand colors applied throughout UI\n- [ ] Welcome message updated\n- [ ] Unused features hidden (if disabled)\n- [ ] Mobile responsive (test at 375px width)\n- [ ] No console errors or warnings\n- [ ] All images load correctly (no broken images)\n\n**Verify:** After completing automated verification, thoroughly test the UI on desktop and mobile, in light and dark modes, before proceeding to Phase 6.\n\n---\n\n## Phase 6: Production Deployment\n\n### Overview\n\nDeploy the customized frontend to Vercel (or another hosting provider) to make it publicly accessible via a URL that clients can visit.\n\n### Context\n\nBefore starting, ensure:\n- Phase 5 completed successfully\n- All customizations tested locally\n- Frontend builds successfully (`pnpm run build`)\n- Agent deployed and running on LiveKit Cloud\n\nFiles to review:\n- `frontend/voice-ai-frontend/.env.local` - Environment variables (will configure in Vercel)\n- `frontend/voice-ai-frontend/next.config.js` - Next.js configuration\n- `frontend/voice-ai-frontend/package.json` - Dependencies and scripts\n\nAccounts needed:\n- Vercel account (free tier sufficient): https://vercel.com\n- GitHub account (for connecting repo)\n\n### Dependencies\n\n**Depends on:** Phases 1-5 (agent deployed, frontend customized and tested)\n\n**Required by:** None (final phase)\n\n### Changes Required\n\n#### 6.1: Create Production Build\n\n**What:** Verify the production build works correctly before deploying\n\n**Commands:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\n\n# Create production build\npnpm run build\n\n# Test production build locally\npnpm start\n```\n\n**Expected Output:**\n```\n> next build\n\n✓ Compiled successfully\n✓ Linting and checking validity of types\n✓ Collecting page data\n✓ Generating static pages (X/X)\n✓ Finalizing page optimization\n\nRoute (app)                              Size     First Load JS\n┌ ○ /                                    XXX kB        XXX kB\n└ ○ /api/token                          XXX B          XXX kB\n```\n\n**Test Production Build:**\n1. Visit http://localhost:3000 (pnpm start)\n2. Connect to agent\n3. Verify voice interaction works\n4. Check for any errors in console\n\n**Troubleshooting:**\n- If build fails: Check TypeScript errors, fix before proceeding\n- If errors about environment variables: Ensure `.env.local` exists\n- If runtime errors: Check browser console for specific issues\n\n**Rationale:** Catches production-specific issues before deployment\n\n---\n\n#### 6.2: Push Frontend to GitHub (Optional but Recommended)\n\n**What:** Create a Git repository for the frontend to enable easy Vercel deployment\n\n**Option A: Separate Repository (Recommended):**\n\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\n\n# Initialize git repository\ngit init\n\n# Add .gitignore for Next.js\ncat > .gitignore << 'EOF'\n# Next.js\n.next/\nout/\nbuild/\ndist/\n\n# Dependencies\nnode_modules/\n\n# Environment variables\n.env\n.env.local\n.env.production.local\n.env.development.local\n.env.test.local\n\n# Logs\nnpm-debug.log*\nyarn-debug.log*\nyarn-error.log*\npnpm-debug.log*\n\n# OS\n.DS_Store\n*.swp\n*.swo\n\n# IDE\n.vscode/\n.idea/\n\n# Vercel\n.vercel\nEOF\n\n# Add files\ngit add .\ngit commit -m \"Initial commit: Voice AI frontend\"\n\n# Create GitHub repository (via GitHub UI or CLI)\ngh repo create voice-ai-frontend --public --source=. --remote=origin --push\n```\n\n**Option B: Same Repository as Agent:**\n\nIf you want frontend and agent in the same repo:\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\n\n# Remove frontend/ from .gitignore\nsed -i '' '/^frontend\\//d' .gitignore\n\n# Add and commit\ngit add frontend/\ngit commit -m \"Add voice AI frontend\"\ngit push\n```\n\n**Rationale:** Git repository enables continuous deployment and version control\n\n---\n\n#### 6.3: Sign Up for Vercel\n\n**What:** Create a Vercel account for hosting the frontend\n\n**Steps:**\n\n1. Visit https://vercel.com\n2. Click \"Sign Up\"\n3. Choose \"Continue with GitHub\" (recommended)\n4. Authorize Vercel to access your GitHub repositories\n\n**Pricing:**\n- **Free Tier:** Sufficient for testing and low traffic\n  - Unlimited deployments\n  - 100 GB bandwidth/month\n  - Serverless functions included\n- **Pro Tier:** $20/month (for production with higher traffic)\n\n**Rationale:** Vercel provides seamless Next.js hosting with automatic deployments\n\n---\n\n#### 6.4: Deploy Frontend to Vercel\n\n**What:** Deploy the frontend application to Vercel\n\n**Steps:**\n\n1. **From Vercel Dashboard:**\n   - Click \"Add New...\" → \"Project\"\n   - Select \"Import Git Repository\"\n   - Choose your frontend repository\n   - Configure project:\n     - **Framework Preset:** Next.js (auto-detected)\n     - **Root Directory:** `./` (or `frontend/voice-ai-frontend` if in monorepo)\n     - **Build Command:** `pnpm run build` (auto-detected)\n     - **Output Directory:** `.next` (auto-detected)\n     - **Install Command:** `pnpm install` (auto-detected)\n\n2. **Configure Environment Variables:**\n   Click \"Environment Variables\" and add:\n\n   ```\n   LIVEKIT_API_KEY=APIxxxxxxxxxxxx\n   LIVEKIT_API_SECRET=your-secret-here\n   LIVEKIT_URL=wss://your-project.livekit.cloud\n   NEXT_PUBLIC_LIVEKIT_URL=wss://your-project.livekit.cloud\n   AGENT_NAME=\n   ```\n\n   **Important:**\n   - Copy values from your local `.env.local`\n   - Apply to \"Production\", \"Preview\", and \"Development\" environments\n\n3. **Deploy:**\n   - Click \"Deploy\"\n   - Wait for build to complete (2-5 minutes)\n\n**Expected Outcome:**\n```\n✓ Build successful\n✓ Deployment successful\nYour project is now live at: https://your-app.vercel.app\n```\n\n**Rationale:** Makes frontend publicly accessible via HTTPS URL\n\n---\n\n#### 6.5: Test Production Deployment\n\n**What:** Verify the deployed frontend works correctly\n\n**Steps:**\n\n1. Visit your Vercel URL: `https://your-app.vercel.app`\n\n2. **Test Checklist:**\n   - [ ] Page loads without errors\n   - [ ] Custom branding displays correctly\n   - [ ] Click \"Connect\" button\n   - [ ] Grant microphone permissions\n   - [ ] Speak to agent\n   - [ ] Verify agent responds with voice\n   - [ ] Test on mobile device\n   - [ ] Test in different browsers\n\n3. **Monitor Logs:**\n   ```bash\n   # Monitor agent logs during production test\n   lk agent logs --follow\n   ```\n\n4. **Check Vercel Deployment Logs:**\n   - Go to Vercel dashboard → Your project → Deployments\n   - Click on latest deployment → \"Functions\" tab\n   - Check for any errors in `/api/token` function\n\n**Troubleshooting:**\n- **\"Failed to connect\":** Check environment variables in Vercel\n- **Token errors:** Verify `LIVEKIT_API_KEY` and `LIVEKIT_API_SECRET` are correct\n- **CORS errors:** Ensure `NEXT_PUBLIC_LIVEKIT_URL` is set correctly\n- **Agent not joining:** Check agent status, verify agent is Running\n\n**Rationale:** Ensures production environment works correctly\n\n---\n\n#### 6.6: Configure Custom Domain (Optional)\n\n**What:** Use a custom domain instead of `your-app.vercel.app`\n\n**Prerequisites:**\n- Own a domain name (e.g., `voiceai.yourcompany.com`)\n- Access to domain DNS settings\n\n**Steps:**\n\n1. **In Vercel Dashboard:**\n   - Go to your project → Settings → Domains\n   - Click \"Add Domain\"\n   - Enter your domain: `voiceai.yourcompany.com`\n\n2. **Configure DNS:**\n   Vercel will provide DNS configuration instructions:\n\n   **Option A: CNAME (Subdomain):**\n   ```\n   Type: CNAME\n   Name: voiceai\n   Value: cname.vercel-dns.com\n   ```\n\n   **Option B: A Record (Root Domain):**\n   ```\n   Type: A\n   Name: @\n   Value: 76.76.21.21\n   ```\n\n3. **Wait for DNS Propagation:**\n   - Usually takes 5-60 minutes\n   - Vercel will auto-configure SSL certificate (Let's Encrypt)\n\n4. **Verify:**\n   - Visit `https://voiceai.yourcompany.com`\n   - Should show your frontend with SSL (green lock icon)\n\n**Rationale:** Custom domain provides professional appearance and brand consistency\n\n---\n\n#### 6.7: Enable Automatic Deployments\n\n**What:** Configure automatic deployments when you push to GitHub\n\n**Vercel Auto-Deploys By Default:**\n- **Production:** Deploys on push to `main` branch\n- **Preview:** Deploys on push to any other branch or PR\n\n**Customize (Optional):**\n1. Go to Vercel dashboard → Your project → Settings → Git\n2. Configure:\n   - **Production Branch:** `main` (or `master`)\n   - **Ignored Build Step:** (leave blank to build on every commit)\n\n**Test Automatic Deployment:**\n```bash\ncd frontend/voice-ai-frontend\n\n# Make a small change\necho \"# Updated\" >> README.md\n\n# Commit and push\ngit add README.md\ngit commit -m \"Test automatic deployment\"\ngit push origin main\n```\n\n**Verify:**\n- Visit Vercel dashboard\n- Should see new deployment triggered automatically\n- Wait for build to complete\n- Visit production URL to see changes\n\n**Rationale:** Enables continuous deployment for easy updates\n\n---\n\n#### 6.8: Set Up Production Monitoring (Recommended)\n\n**What:** Monitor production errors and usage\n\n**Vercel Analytics (Built-in):**\n1. Go to Vercel dashboard → Your project → Analytics\n2. View:\n   - Page views\n   - Geographic distribution\n   - Performance metrics (Web Vitals)\n\n**Error Tracking (Optional):**\nConsider integrating Sentry or similar:\n```bash\npnpm add @sentry/nextjs\nnpx @sentry/wizard@latest -i nextjs\n```\n\n**LiveKit Cloud Monitoring:**\n- Visit LiveKit Cloud dashboard\n- Monitor:\n  - Active sessions\n  - Agent usage\n  - Costs (session minutes)\n\n**Rationale:** Production monitoring helps identify and resolve issues quickly\n\n---\n\n#### 6.9: Create Shareable Link\n\n**What:** Generate a clean, shareable URL for potential clients\n\n**Your Production URL:**\n```\nhttps://your-app.vercel.app\n```\n\n**Or with Custom Domain:**\n```\nhttps://voiceai.yourcompany.com\n```\n\n**Create Marketing Materials:**\n- Add link to your website\n- Share via email campaigns\n- Include in social media bios\n- Create QR code for physical materials\n\n**Example QR Code Generation:**\n```bash\n# Generate QR code (using qrencode)\nbrew install qrencode\nqrencode -o voiceai-qr.png \"https://voiceai.yourcompany.com\"\n```\n\n**Rationale:** Easy sharing enables potential clients to access your voice AI\n\n---\n\n#### 6.10: Document Production URLs and Credentials\n\n**What:** Save all production information for future reference\n\n**Create:** `frontend/voice-ai-frontend/PRODUCTION.md`\n\n**Content:**\n```markdown\n# Production Deployment Information\n\n## URLs\n- **Production Frontend:** https://your-app.vercel.app\n- **Custom Domain:** https://voiceai.yourcompany.com (if configured)\n- **LiveKit Cloud Dashboard:** https://cloud.livekit.io\n\n## Vercel\n- **Project:** voice-ai-frontend\n- **Account:** your-email@example.com\n- **Git Repository:** https://github.com/yourusername/voice-ai-frontend\n\n## LiveKit Cloud\n- **Project:** your-project-name\n- **Region:** us-west-2\n- **Agent ID:** agent_abc123\n\n## Deployment Commands\n```bash\n# Deploy agent updates\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\nlk agent deploy\n\n# Deploy frontend updates (automatic via Git)\ncd frontend/voice-ai-frontend\ngit add .\ngit commit -m \"Update frontend\"\ngit push origin main\n```\n\n## Monitoring\n- **Agent Logs:** `lk agent logs --follow`\n- **Vercel Logs:** https://vercel.com/your-project/deployments\n- **LiveKit Dashboard:** https://cloud.livekit.io/projects/your-project\n\n## Environment Variables (Vercel)\n- LIVEKIT_API_KEY=APIxxxxxxxxxxxx\n- LIVEKIT_API_SECRET=*** (not shown)\n- LIVEKIT_URL=wss://your-project.livekit.cloud\n- NEXT_PUBLIC_LIVEKIT_URL=wss://your-project.livekit.cloud\n\n## Costs\n- **LiveKit Cloud:** $0.01 per agent session minute\n- **Vercel:** Free tier (or $20/month Pro)\n\n## Support\n- **LiveKit:** https://livekit.io/discord\n- **Vercel:** https://vercel.com/support\n```\n\n**Rationale:** Documentation ensures you can manage production deployment long-term\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Production build succeeds: `pnpm run build` completes without errors\n- [ ] Vercel deployment successful: Deployment status shows \"Ready\"\n- [ ] HTTPS enabled: Visit production URL with green lock icon\n- [ ] Environment variables configured: Check Vercel dashboard\n- [ ] Custom domain configured (if applicable): DNS records set\n\n#### Manual Verification:\n\n- [ ] Visit production URL in browser\n- [ ] Page loads without errors\n- [ ] Custom branding displays correctly\n- [ ] Click \"Connect\" and grant microphone access\n- [ ] Speak to agent and verify voice response\n- [ ] Test on mobile device (iOS Safari, Android Chrome)\n- [ ] Test in incognito/private mode\n- [ ] Share URL with colleague and get confirmation it works\n- [ ] Agent logs show production sessions: `lk agent logs --follow`\n- [ ] No errors in Vercel function logs\n\n**Verify:** After completing automated verification, test the production URL on multiple devices and browsers, then share with a colleague to confirm public accessibility.\n\n---\n\n## Testing Strategy\n\n### Unit Tests\n\n**Not required for this plan.** The agent-starter-react template is a pre-built, production-ready template that doesn't require custom unit tests unless you add significant custom logic.\n\n**Optional:** Add tests if you customize components heavily:\n```bash\npnpm add -D @testing-library/react @testing-library/jest-dom jest\n```\n\n### Integration Tests\n\n**End-to-End Testing:**\n\nManually test the complete flow:\n1. User visits URL\n2. Clicks \"Connect\"\n3. Grants microphone access\n4. Speaks to agent\n5. Receives voice response\n6. Disconnects cleanly\n\n**Test Matrix:**\n\n| Scenario | Steps | Expected Outcome |\n|----------|-------|------------------|\n| First Connection | Visit URL → Click Connect → Speak | Agent responds with voice |\n| Interruption | Speak while agent is speaking | Agent handles gracefully |\n| Disconnect/Reconnect | End session → Start new session | New session works |\n| Multiple Turns | Have 3-5 turn conversation | All responses relevant |\n| Mobile Safari | Test on iPhone/iPad | Full functionality |\n| Network Interruption | Disable Wi-Fi during session | Reconnection or error message |\n\n### Manual Testing Steps\n\n**Pre-Deployment Checklist:**\n1. [ ] Agent deployed and running: `lk agent status`\n2. [ ] Local frontend works: `pnpm dev` at http://localhost:3000\n3. [ ] Voice interaction successful\n4. [ ] Audio visualization working\n5. [ ] Custom branding applied\n6. [ ] Production build succeeds: `pnpm run build`\n\n**Post-Deployment Checklist:**\n1. [ ] Production URL accessible\n2. [ ] HTTPS enabled (green lock)\n3. [ ] Voice interaction works on production\n4. [ ] Mobile responsive\n5. [ ] Cross-browser compatible\n6. [ ] Shareable link works for external users\n\n### Performance Considerations\n\n**Metrics to Monitor:**\n- **Connection Time:** Should be <3 seconds (or <1.5s with optimization)\n- **Response Latency:** STT → LLM → TTS should be 2-4 seconds\n- **Page Load Time:** Initial load <2 seconds (Lighthouse score >90)\n- **Audio Quality:** No dropouts or distortion\n\n**Optimization:**\n- Enable pre-connect buffering in `app-config.ts`\n- Use warm token approach (Phase 4.6)\n- Minimize bundle size (Next.js handles automatically)\n- Use CDN for static assets (Vercel provides automatically)\n\n## References\n\n### Original Ticket/Request\n- User request: \"I want potential clients to be able to interact with the livekit agent from this repo by clicking a link on a website.\"\n\n### Documentation\n- `docs/DEPLOYMENT.md` - Complete deployment guide for agent and frontend options\n- `README.md` - Project overview and setup instructions\n- `AGENTS.md` - Project guidelines and standards\n\n### LiveKit Resources\n- **Frontend Deployment Guide:** https://docs.livekit.io/agents/start/frontend/\n- **agent-starter-react Repository:** https://github.com/livekit-examples/agent-starter-react\n- **Token Authentication:** https://docs.livekit.io/home/get-started/authentication/\n- **Agents Playground:** https://agents-playground.livekit.io/\n- **LiveKit Cloud Dashboard:** https://cloud.livekit.io\n- **React Components Docs:** https://docs.livekit.io/reference/components/react/\n\n### NPM Packages\n- **livekit-client:** Client SDK for browser WebRTC\n- **@livekit/components-react:** React UI components\n- **livekit-server-sdk:** Server-side token generation\n\n### Vercel Resources\n- **Vercel Platform:** https://vercel.com\n- **Next.js Documentation:** https://nextjs.org/docs\n- **Deployment Docs:** https://vercel.com/docs\n\n### Related Plans\n- None (initial implementation)\n\n---\n\n**End of Implementation Plan**\n","structuredPatch":[{"oldStart":1719,"oldLines":7,"newStart":1719,"newLines":8,"lines":[" - [ ] Favicon visible in browser tab"," - [ ] Brand colors applied throughout UI"," - [ ] Welcome message updated","-- [ ] Unused features hidden (if disabled)","+- [ ] Video/screenshare features are hidden (REQUIRED - verify no camera/screenshare icons)","+- [ ] Browser only requests microphone permission (NOT camera)"," - [ ] Mobile responsive (test at 375px width)"," - [ ] No console errors or warnings"," - [ ] All images load correctly (no broken images)"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"d5cc759d-6bba-4db3-9ac0-c9654ab2a8c6"}
{"parentUuid":"f30983cb-844e-4036-8950-2d30928beb83","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","slug":"enumerated-shimmying-starlight","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01QzDnifhAhXCNYCBr55KtbR","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Let me also update the production deployment verification to include this check:","signature":"EvgBCkYICxgCKkAEl9dpQNyhK9ywkumXGxAdJBxwZDPDaCEn891pKxigPAMhTnegTDUzxgBXqw/utgkwNKpkwvZSl8dQVoyTuUauEgzdPbgFZJUi7z/l/owaDMJXlCB6O+vc4wFXnyIwfAXhrHzYGJrbEsKxHOk1IycoBwyTlqc+l6XnOrFi0OCPlE68lKxVJ9YRDsB8EDpFKmBFvNVK6T0rjm0N+tuSPDqm9YkUcxUjyk88CYO/g5/PKBZZohJmisEdsHoqnFqx6XZqfBjAkCoPLQa1ZTJe2vpe4CCMh3oE8HdHBPAZOLP4bKW6Mt+EwtBFjVMvhr5iV4QYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":4,"cache_creation_input_tokens":503,"cache_read_input_tokens":69249,"cache_creation":{"ephemeral_5m_input_tokens":503,"ephemeral_1h_input_tokens":0},"output_tokens":6,"service_tier":"standard"}},"requestId":"req_011CXTtAzTBan5bKLnMZsdKD","type":"assistant","uuid":"eab78d7d-3902-4d65-9d56-e1552313f09c","timestamp":"2026-01-25T09:46:17.765Z"}
{"parentUuid":"eab78d7d-3902-4d65-9d56-e1552313f09c","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","slug":"enumerated-shimmying-starlight","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01QzDnifhAhXCNYCBr55KtbR","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01D9Tog4PRFSFXHY1B4JJUrH","name":"Edit","input":{"replace_all":false,"file_path":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/plan/future-plans/2026-01-25-web-frontend-deployment.md","old_string":"2. **Test Checklist:**\n   - [ ] Page loads without errors\n   - [ ] Custom branding displays correctly\n   - [ ] Click \"Connect\" button\n   - [ ] Grant microphone permissions\n   - [ ] Speak to agent\n   - [ ] Verify agent responds with voice\n   - [ ] Test on mobile device\n   - [ ] Test in different browsers","new_string":"2. **Test Checklist:**\n   - [ ] Page loads without errors\n   - [ ] Custom branding displays correctly\n   - [ ] Click \"Connect\" button\n   - [ ] Verify ONLY microphone permission requested (no camera/screenshare)\n   - [ ] Grant microphone permission\n   - [ ] Speak to agent\n   - [ ] Verify agent responds with voice\n   - [ ] Confirm no video/screenshare UI elements visible\n   - [ ] Test on mobile device\n   - [ ] Test in different browsers"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":4,"cache_creation_input_tokens":503,"cache_read_input_tokens":69249,"cache_creation":{"ephemeral_5m_input_tokens":503,"ephemeral_1h_input_tokens":0},"output_tokens":6,"service_tier":"standard"}},"requestId":"req_011CXTtAzTBan5bKLnMZsdKD","type":"assistant","uuid":"52951924-821b-4cd6-a8d3-dc7ce5d949b8","timestamp":"2026-01-25T09:46:21.793Z"}
{"parentUuid":"52951924-821b-4cd6-a8d3-dc7ce5d949b8","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","slug":"enumerated-shimmying-starlight","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01D9Tog4PRFSFXHY1B4JJUrH","type":"tool_result","content":"The file /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/plan/future-plans/2026-01-25-web-frontend-deployment.md has been updated successfully."}]},"uuid":"1a4e906d-6a68-4bb9-8179-08ea2498f8fd","timestamp":"2026-01-25T09:46:21.848Z","toolUseResult":{"filePath":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/plan/future-plans/2026-01-25-web-frontend-deployment.md","oldString":"2. **Test Checklist:**\n   - [ ] Page loads without errors\n   - [ ] Custom branding displays correctly\n   - [ ] Click \"Connect\" button\n   - [ ] Grant microphone permissions\n   - [ ] Speak to agent\n   - [ ] Verify agent responds with voice\n   - [ ] Test on mobile device\n   - [ ] Test in different browsers","newString":"2. **Test Checklist:**\n   - [ ] Page loads without errors\n   - [ ] Custom branding displays correctly\n   - [ ] Click \"Connect\" button\n   - [ ] Verify ONLY microphone permission requested (no camera/screenshare)\n   - [ ] Grant microphone permission\n   - [ ] Speak to agent\n   - [ ] Verify agent responds with voice\n   - [ ] Confirm no video/screenshare UI elements visible\n   - [ ] Test on mobile device\n   - [ ] Test in different browsers","originalFile":"# Web Frontend Deployment Implementation Plan\n\n> **Status:** DRAFT\n\n## Table of Contents\n\n- [Overview](#overview)\n- [Current State Analysis](#current-state-analysis)\n- [Desired End State](#desired-end-state)\n- [What We're NOT Doing](#what-were-not-doing)\n- [Implementation Approach](#implementation-approach)\n- [Dependencies](#dependencies)\n- [Phase 1: Agent Deployment to LiveKit Cloud](#phase-1-agent-deployment-to-livekit-cloud)\n- [Phase 2: Frontend Setup (agent-starter-react)](#phase-2-frontend-setup-agent-starter-react)\n- [Phase 3: Authentication and Token Generation](#phase-3-authentication-and-token-generation)\n- [Phase 4: Connection Testing and Optimization](#phase-4-connection-testing-and-optimization)\n- [Phase 5: Frontend Customization](#phase-5-frontend-customization)\n- [Phase 6: Production Deployment](#phase-6-production-deployment)\n- [Testing Strategy](#testing-strategy)\n- [References](#references)\n\n## Overview\n\nThis plan enables potential clients to interact with the LiveKit voice AI agent from this repository by clicking a link on a website. The implementation covers:\n\n1. Deploying the Python agent to LiveKit Cloud\n2. Setting up a Next.js/React frontend using the agent-starter-react template\n3. Implementing JWT token-based authentication\n4. Testing the connection flow\n5. Customizing the frontend with branding\n6. Deploying the frontend to production (Vercel)\n\nThe solution uses LiveKit's official starter templates and SDKs to create a production-ready web application with TypeScript/JavaScript.\n\n**IMPORTANT: This is an audio-only application. No video camera or screen sharing permissions should be requested from users. All configuration must disable video/screenshare features.**\n\n## Current State Analysis\n\n### What Exists Now\n\n**Agent Backend:**\n- Python voice AI agent in `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1`\n- Built with LiveKit Agents SDK\n- Uses OpenAI (LLM), AssemblyAI (STT), Cartesia (TTS)\n- Configured with `uv` package manager\n- Has `Dockerfile` for containerized deployment\n- Environment variables in `.env.local` (OpenAI, AssemblyAI, Cartesia API keys)\n\n**Missing:**\n- Agent not yet deployed to LiveKit Cloud\n- No web frontend for client interaction\n- No token generation server for authentication\n- No public-facing URL for clients to access\n\n### Key Discoveries\n\nFrom `docs/DEPLOYMENT.md`:\n- LiveKit Cloud deployment uses `lk` CLI\n- Agent deployment command: `lk agent create --secrets-file .env.local`\n- Multiple frontend options available (React, Flutter, Swift, Embed)\n- Connection requires JWT tokens generated server-side\n- agent-starter-react provides production-ready Next.js template\n- Token generation uses `livekit-server-sdk` npm package\n\n### Constraints\n\n1. **Security:** API secrets (LIVEKIT_API_SECRET) must never be exposed to frontend\n2. **Architecture:** Token generation must happen server-side (Next.js API routes)\n3. **Dependencies:** Agent must be deployed and running before frontend can connect\n4. **Cost:** LiveKit Cloud charges $0.01 per agent session minute\n\n## Desired End State\n\n### Success Criteria\n\n- [ ] Agent deployed and running on LiveKit Cloud\n- [ ] Next.js frontend application running locally\n- [ ] JWT token generation working via backend API route\n- [ ] Users can click a link and connect to voice AI agent\n- [ ] Audio conversation works end-to-end (STT → LLM → TTS)\n- [ ] Frontend deployed to production URL (Vercel)\n- [ ] Customized branding (logo, colors, company name)\n- [ ] Light/dark theme support\n- [ ] Audio visualization working\n- [ ] Mobile-responsive design\n\n### How to Verify\n\n**Agent Deployment:**\n```bash\nlk agent status\n# Expected: Status: Running, Replicas: X/X ready\n```\n\n**Frontend Connection:**\n1. Visit frontend URL (local: http://localhost:3000, prod: https://your-app.vercel.app)\n2. Click \"Connect\" or \"Start Session\"\n3. Grant microphone permissions when prompted\n4. Speak to the agent\n5. Verify agent responds with natural voice\n6. Check agent logs: `lk agent logs --follow`\n\n**End-to-End Test:**\n```bash\n# Terminal 1: Monitor agent logs\nlk agent logs --follow\n\n# Terminal 2: Run frontend\ncd /path/to/frontend\npnpm dev\n\n# Browser: Visit http://localhost:3000, connect, and speak\n```\n\n## What We're NOT Doing\n\n**Out of Scope:**\n- Multiple agent types or agent selection UI\n- User authentication/login system (anonymous users only)\n- Database integration or conversation history storage\n- Multi-language support (English only initially)\n- iOS/Android native apps (web only)\n- Custom voice customization UI\n- Payment integration or usage metering\n- Advanced analytics dashboard\n- Server-side rendering (SSR) for the voice interface\n- Custom WebRTC infrastructure (using LiveKit Cloud)\n\n**Future Considerations:**\n- User accounts and saved conversations\n- Analytics and usage tracking\n- Custom domain with branding\n- A/B testing different agent configurations\n- Rate limiting and abuse prevention\n\n## Implementation Approach\n\n### High-Level Strategy\n\n1. **Deploy Agent First:** Ensure the Python agent is running on LiveKit Cloud before building frontend\n2. **Use Official Template:** Start with agent-starter-react to avoid reinventing the wheel\n3. **Iterative Testing:** Test each phase independently before proceeding\n4. **Security-First:** Never expose API secrets; use environment variables and server-side token generation\n5. **Quick Validation:** Use LiveKit Agents Playground first to verify agent works before building frontend\n\n### Technology Stack\n\n**Backend (Agent):**\n- Python 3.11+\n- LiveKit Agents SDK\n- OpenAI GPT-4 (LLM)\n- AssemblyAI (STT)\n- Cartesia (TTS)\n- Deployed to: LiveKit Cloud\n\n**Frontend:**\n- Next.js 14+ (App Router)\n- React 18+\n- TypeScript\n- Tailwind CSS\n- Shadcn/ui components\n- `livekit-client` SDK\n- `@livekit/components-react`\n- Deployed to: Vercel\n\n**Authentication:**\n- JWT tokens (livekit-server-sdk)\n- Server-side generation (Next.js API routes)\n- 2-hour token expiration\n\n## Dependencies\n\n**Execution Order:**\n\n1. Phase 1: Agent Deployment (no dependencies)\n2. Phase 2: Frontend Setup (depends on Phase 1 for credentials)\n3. Phase 3: Authentication (depends on Phase 2)\n4. Phase 4: Connection Testing (depends on Phases 1-3)\n5. Phase 5: Frontend Customization (depends on Phase 4)\n6. Phase 6: Production Deployment (depends on Phase 5)\n\n**Dependency Graph:**\n\n```\nPhase 1 (Agent Deployment)\n  └─> Phase 2 (Frontend Setup)\n        └─> Phase 3 (Authentication)\n              └─> Phase 4 (Testing)\n                    └─> Phase 5 (Customization)\n                          └─> Phase 6 (Production)\n```\n\n**Parallelization:**\n- All phases are sequential due to dependencies\n- Within each phase, independent tasks can run in parallel\n\n---\n\n## Phase 1: Agent Deployment to LiveKit Cloud\n\n### Overview\n\nDeploy the Python voice AI agent to LiveKit Cloud to make it accessible via WebRTC. This creates a running agent that can be dispatched to rooms when users connect.\n\n### Context\n\nBefore starting, ensure you have:\n- LiveKit CLI installed: `brew install livekit/livekit/livekit-cli`\n- LiveKit Cloud account at https://cloud.livekit.io\n- Agent code in `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1`\n- API keys in `.env.local` (OpenAI, AssemblyAI, Cartesia)\n\nFiles to review:\n- `docs/DEPLOYMENT.md` - Complete deployment guide\n- `.env.local` - API keys and secrets\n- `Dockerfile` - Container build configuration\n- `src/app.py` - Agent entry point\n\n### Dependencies\n\n**Depends on:** None (first phase)\n\n**Required by:** Phase 2 (Frontend needs LiveKit credentials), Phase 4 (Testing needs deployed agent)\n\n### Changes Required\n\n#### 1.1: Authenticate with LiveKit Cloud\n\n**What:** Link your CLI to your LiveKit Cloud account\n\n**Command:**\n```bash\nlk cloud auth\n```\n\n**Expected Outcome:**\n- Browser opens for authentication\n- CLI displays: \"Successfully authenticated with LiveKit Cloud\"\n- Credentials saved in `~/.livekit/credentials`\n\n**Rationale:** Required for all subsequent `lk` CLI commands\n\n---\n\n#### 1.2: Create or Select LiveKit Project\n\n**What:** Create a new project or select an existing one for the agent deployment\n\n**Commands:**\n```bash\n# List existing projects\nlk project list\n\n# Option A: Use existing project\nlk project set-default \"your-project-name\"\n\n# Option B: Create new project via dashboard\n# Visit https://cloud.livekit.io and create a new project\n# Then set as default: lk project set-default \"new-project-name\"\n\n# Verify current project\nlk project current\n```\n\n**Expected Outcome:**\n```\nNAME                 PROJECT_ID\nyour-project-name   prj_abc123\n```\n\n**Rationale:** Agent deployments are scoped to projects; need a target project first\n\n---\n\n#### 1.3: Verify Secrets File\n\n**What:** Ensure `.env.local` contains all required API keys\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/.env.local`\n\n**Verify contents:**\n```bash\ncat .env.local\n```\n\n**Required secrets:**\n```env\nOPENAI_API_KEY=sk-...\nASSEMBLYAI_API_KEY=...\nCARTESIA_API_KEY=...\n```\n\n**Important Notes:**\n- Do NOT include `LIVEKIT_URL`, `LIVEKIT_API_KEY`, or `LIVEKIT_API_SECRET` in `.env.local`\n- LiveKit Cloud auto-injects these during deployment\n- Verify `.env.local` is in `.gitignore`\n\n**Rationale:** Agent needs these API keys to function; LiveKit Cloud encrypts and injects them as environment variables\n\n---\n\n#### 1.4: Download Model Files\n\n**What:** Download required models (Silero VAD, turn detector) before deployment\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\nuv run python src/app.py download-files\n```\n\n**Expected Outcome:**\n```\nDownloading Silero VAD model...\nDownloading multilingual turn detector model...\nDownload complete.\n```\n\n**Rationale:** Models are required at runtime; downloading during build ensures faster agent startup\n\n---\n\n#### 1.5: Deploy Agent to LiveKit Cloud\n\n**What:** Create and deploy the agent container to LiveKit Cloud\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\nlk agent create --secrets-file .env.local\n```\n\n**Expected Outcome:**\n```\nRegistering agent...\nAgent ID: agent_abc123\nBuilding container image...\nUploading code...\nBuild in progress (this may take 2-5 minutes)...\nBuild complete.\nDeploying agent...\nDeployment successful.\nStatus: Running\nReplicas: 2/2 ready\n```\n\n**What Happens:**\n1. CLI registers new agent with Cloud project\n2. Assigns unique agent ID (e.g., `agent_abc123`)\n3. Creates/updates `livekit.toml` configuration file\n4. Uploads source code to LiveKit build service\n5. Builds Docker container from `Dockerfile`\n6. Deploys container to Cloud project\n7. Encrypts and injects secrets as environment variables\n8. Starts 2 replica instances\n\n**Duration:** 2-5 minutes for initial build\n\n**Rationale:** Makes agent accessible via LiveKit's global WebRTC infrastructure\n\n---\n\n#### 1.6: Verify Agent Status\n\n**What:** Confirm agent is running and ready to accept sessions\n\n**Commands:**\n```bash\n# Check agent status\nlk agent status\n\n# View live logs\nlk agent logs --tail 50\n```\n\n**Expected Status Output:**\n```\nAgent ID:     agent_abc123\nStatus:       Running\nReplicas:     2/2 ready\nVersion:      v1\nLast Deploy:  2026-01-25 10:30:00 UTC\nRegion:       us-west-2\n```\n\n**Expected Log Output:**\n- No error messages\n- Successful initialization messages\n- \"Waiting for room assignment\" or similar\n\n**Troubleshooting:**\n- If status is `CrashLoop`: Check logs for Python exceptions\n- If status is `Build Failed`: Run `lk agent logs --build` to see build errors\n- If secrets missing: Run `lk agent secrets` to verify\n\n**Rationale:** Ensures agent is healthy before proceeding to frontend setup\n\n---\n\n#### 1.7: Quick Test with Agents Playground\n\n**What:** Test agent using LiveKit Agents Playground (no code required)\n\n**Steps:**\n1. Get project credentials:\n   ```bash\n   lk project current --json\n   ```\n\n2. Visit https://agents-playground.livekit.io/\n\n3. Enter credentials:\n   - **LiveKit URL:** `wss://your-project.livekit.cloud` (from JSON output)\n   - **API Key:** Your `LIVEKIT_API_KEY` (from JSON output)\n   - **API Secret:** Your `LIVEKIT_API_SECRET` (from JSON output)\n\n4. Click \"Connect\"\n\n5. Allow microphone access when prompted\n\n6. Speak to your agent\n\n7. Monitor agent logs in terminal:\n   ```bash\n   lk agent logs --follow\n   ```\n\n**Expected Outcome:**\n- Agent responds to your voice with natural TTS\n- Logs show STT transcriptions, LLM responses, TTS generation\n- No errors in logs\n\n**Rationale:** Validates agent works end-to-end before investing in frontend development\n\n---\n\n#### 1.8: Save LiveKit Credentials\n\n**What:** Export LiveKit project credentials for frontend configuration\n\n**Command:**\n```bash\nlk project current --json > livekit-credentials.json\n```\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/livekit-credentials.json`\n\n**Expected Contents:**\n```json\n{\n  \"name\": \"your-project-name\",\n  \"url\": \"wss://your-project.livekit.cloud\",\n  \"api_key\": \"APIxxxxxxxxxxxx\",\n  \"api_secret\": \"your-secret-here\"\n}\n```\n\n**Security Note:**\n- Add `livekit-credentials.json` to `.gitignore`\n- NEVER commit this file to version control\n- This file is for local reference only\n\n**Rationale:** Frontend needs these credentials to generate tokens and connect to LiveKit\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] CLI authenticated: `lk cloud auth` successful\n- [ ] Project selected: `lk project current` shows correct project\n- [ ] Agent deployed: `lk agent status` shows `Status: Running`\n- [ ] Replicas ready: `lk agent status` shows `X/X ready` (e.g., 2/2)\n- [ ] No crash loops: `lk agent logs --tail 50` shows no errors\n- [ ] Credentials saved: `livekit-credentials.json` exists and contains valid JSON\n\n#### Manual Verification:\n\n- [ ] Agents Playground connection successful\n- [ ] Agent responds to voice input with TTS output\n- [ ] Agent logs show successful STT → LLM → TTS pipeline\n- [ ] No API key errors in logs\n- [ ] Agent state transitions visible (initializing → listening → thinking → speaking)\n\n**Verify:** After completing automated verification, test agent with Agents Playground before proceeding to Phase 2.\n\n---\n\n## Phase 2: Frontend Setup (agent-starter-react)\n\n### Overview\n\nClone and configure the agent-starter-react template to create a Next.js web application that connects users to your deployed agent.\n\n### Context\n\nBefore starting, ensure:\n- Phase 1 completed successfully\n- Agent is running on LiveKit Cloud\n- `livekit-credentials.json` file exists with credentials\n\nPrerequisites:\n- Node.js 18+ installed\n- pnpm installed: `npm install -g pnpm`\n- `lk` CLI authenticated\n\nFiles to review:\n- `livekit-credentials.json` - LiveKit project credentials\n- N/A (frontend doesn't exist yet)\n\n### Dependencies\n\n**Depends on:** Phase 1 (needs LiveKit credentials)\n\n**Required by:** Phase 3 (authentication setup), Phase 4 (connection testing)\n\n### Changes Required\n\n#### 2.1: Create Frontend Project Directory\n\n**What:** Create a directory to house the frontend application\n\n**Commands:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\nmkdir -p frontend\ncd frontend\n```\n\n**Expected Outcome:**\n```\nDirectory created: /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/\n```\n\n**Rationale:** Separates frontend code from agent backend code\n\n---\n\n#### 2.2: Clone agent-starter-react Template\n\n**What:** Use LiveKit CLI to create a new project from the official template\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend\nlk app create --template agent-starter-react\n```\n\n**Interactive Prompts:**\n- **Project name:** (Press Enter for default or enter custom name like \"voice-ai-frontend\")\n- **Install dependencies?** Yes\n\n**Alternative (Manual Clone):**\n```bash\ngit clone https://github.com/livekit-examples/agent-starter-react.git voice-ai-frontend\ncd voice-ai-frontend\npnpm install\n```\n\n**Expected Outcome:**\n```\n✓ Created project: voice-ai-frontend\n✓ Installed dependencies\n✓ Ready to configure\n```\n\n**Directory Structure:**\n```\nfrontend/voice-ai-frontend/\n├── app/\n│   ├── api/token/route.ts     # Token generation endpoint\n│   ├── page.tsx               # Main page\n│   └── layout.tsx\n├── components/\n│   ├── agents-ui/             # Agents UI components\n│   ├── app/                   # Business logic\n│   └── ui/                    # Shadcn/ui primitives\n├── hooks/\n├── lib/\n├── public/\n├── package.json\n├── .env.example\n└── next.config.js\n```\n\n**Rationale:** Official template provides production-ready structure with all necessary LiveKit integrations\n\n---\n\n#### 2.3: Configure Environment Variables\n\n**What:** Set up LiveKit credentials for the frontend\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend/.env.local`\n\n**Commands:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\ncp .env.example .env.local\n```\n\n**Edit `.env.local`:**\n```env\n# LiveKit project credentials (from livekit-credentials.json)\nLIVEKIT_API_KEY=APIxxxxxxxxxxxx\nLIVEKIT_API_SECRET=your-secret-here\nLIVEKIT_URL=wss://your-project.livekit.cloud\n\n# Public URL (exposed to browser - same as LIVEKIT_URL)\nNEXT_PUBLIC_LIVEKIT_URL=wss://your-project.livekit.cloud\n\n# Agent configuration\nAGENT_NAME=\n# Leave AGENT_NAME blank for automatic agent dispatch\n# Or set to specific agent name if you have multiple agents\n```\n\n**How to Get Values:**\n```bash\n# Copy from livekit-credentials.json\ncat /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/livekit-credentials.json\n```\n\n**Security Notes:**\n- `LIVEKIT_API_SECRET` is server-side only (never exposed to browser)\n- `NEXT_PUBLIC_*` variables are exposed to browser\n- Only `NEXT_PUBLIC_LIVEKIT_URL` should be public\n- Never expose `LIVEKIT_API_KEY` or `LIVEKIT_API_SECRET` to browser\n\n**Rationale:** Frontend needs credentials to generate tokens and connect to LiveKit rooms\n\n---\n\n#### 2.4: Verify Dependencies Installation\n\n**What:** Ensure all npm packages are installed correctly\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\npnpm install\n```\n\n**Expected Outcome:**\n```\nPackages: +XXX\nProgress: resolved XXX, reused XXX, downloaded X, added XXX, done\n```\n\n**Key Dependencies (verify in `package.json`):**\n- `next` (v14+)\n- `react` (v18+)\n- `livekit-client`\n- `@livekit/components-react`\n- `livekit-server-sdk`\n- `tailwindcss`\n- `typescript`\n\n**Troubleshooting:**\n- If pnpm not installed: `npm install -g pnpm`\n- If peer dependency warnings: Generally safe to ignore\n- If install fails: Delete `node_modules` and `pnpm-lock.yaml`, retry\n\n**Rationale:** Ensures all required packages are available for development\n\n---\n\n#### 2.5: Run Development Server\n\n**What:** Start the Next.js development server to verify basic setup\n\n**Command:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\npnpm dev\n```\n\n**Expected Outcome:**\n```\n> next dev\n\n  ▲ Next.js 14.x.x\n  - Local:        http://localhost:3000\n  - Environments: .env.local\n\n ✓ Ready in X.Xs\n```\n\n**Verification:**\n1. Open browser to http://localhost:3000\n2. Should see agent interface with \"Connect\" button\n3. No console errors in browser DevTools\n4. Page loads without 500 errors\n\n**Expected UI:**\n- Welcome/landing view\n- \"Connect\" or \"Start Session\" button\n- Logo and branding elements\n- Theme toggle (light/dark)\n\n**Troubleshooting:**\n- If port 3000 in use: `pnpm dev -- -p 3001`\n- If env vars missing: Check `.env.local` exists and has correct values\n- If build errors: Check `pnpm install` completed successfully\n\n**Rationale:** Validates Next.js setup before proceeding to authentication\n\n---\n\n#### 2.6: Inspect Token Generation API Route\n\n**What:** Review the built-in token generation endpoint to understand how authentication works\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend/app/api/token/route.ts`\n\n**Read the file:**\n```typescript\n// Expected structure (review actual implementation)\nimport { AccessToken } from 'livekit-server-sdk';\n\nexport async function POST(request: Request) {\n  const { roomName, participantName } = await request.json();\n\n  const token = new AccessToken(\n    process.env.LIVEKIT_API_KEY,\n    process.env.LIVEKIT_API_SECRET,\n    {\n      identity: participantName,\n      ttl: '2h', // Token valid for 2 hours\n    }\n  );\n\n  token.addGrant({\n    room: roomName,\n    roomJoin: true,\n    canPublish: true,\n    canSubscribe: true,\n  });\n\n  return Response.json({ token: await token.toJwt() });\n}\n```\n\n**Key Points:**\n- Uses `livekit-server-sdk` to generate JWT tokens\n- Reads `LIVEKIT_API_KEY` and `LIVEKIT_API_SECRET` from environment\n- Grants room join, publish, and subscribe permissions\n- Returns JWT token to frontend\n- Token expires after 2 hours (LiveKit auto-refreshes for connected clients)\n\n**Security Review:**\n- ✓ API key/secret are server-side only (not exposed to browser)\n- ✓ Token generation happens on server\n- ✓ Appropriate permissions granted\n- ⚠ Consider adding rate limiting for production\n\n**Rationale:** Understanding token flow is critical for debugging connection issues\n\n---\n\n#### 2.7: Add Frontend to .gitignore (Backend Repo)\n\n**What:** Prevent frontend from being committed to agent backend repo\n\n**File:** `/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/.gitignore`\n\n**Add to `.gitignore`:**\n```bash\necho \"frontend/\" >> .gitignore\n```\n\n**Verify:**\n```bash\ngit status\n# frontend/ should not appear in untracked files\n```\n\n**Alternative Approach:**\nIf you want to commit the frontend to the same repo:\n- Create a separate `.gitignore` in `frontend/voice-ai-frontend/`\n- Add standard Next.js ignores (`.next/`, `node_modules/`, `.env.local`)\n\n**Rationale:** Keep frontend and backend as separate concerns, or manage carefully if in same repo\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Frontend directory created: `ls frontend/voice-ai-frontend`\n- [ ] Dependencies installed: `pnpm list --depth=0` shows key packages\n- [ ] Environment variables configured: `cat .env.local | grep LIVEKIT_API_KEY`\n- [ ] Development server starts: `pnpm dev` runs without errors\n- [ ] No TypeScript errors: `pnpm run build` completes successfully\n\n#### Manual Verification:\n\n- [ ] Visit http://localhost:3000 in browser\n- [ ] Page loads without 500 errors\n- [ ] UI displays welcome screen with \"Connect\" button\n- [ ] No console errors in browser DevTools\n- [ ] Theme toggle works (light/dark mode)\n- [ ] Responsive design works on mobile viewport\n\n**Verify:** After completing automated verification, open the app in a browser and verify UI loads correctly before proceeding to Phase 3.\n\n---\n\n## Phase 3: Authentication and Token Generation\n\n### Overview\n\nConfigure and test the JWT token generation flow to ensure frontend can authenticate users with LiveKit and connect them to agent sessions.\n\n### Context\n\nBefore starting, ensure:\n- Phase 2 completed successfully\n- Development server running at http://localhost:3000\n- Environment variables configured in `.env.local`\n\nFiles to review:\n- `frontend/voice-ai-frontend/app/api/token/route.ts` - Token generation endpoint\n- `frontend/voice-ai-frontend/.env.local` - Environment configuration\n- `frontend/voice-ai-frontend/components/app/` - Client-side connection logic\n\n### Dependencies\n\n**Depends on:** Phase 2 (frontend setup)\n\n**Required by:** Phase 4 (connection testing)\n\n### Changes Required\n\n#### 3.1: Test Token Generation Endpoint\n\n**What:** Verify the token API endpoint works correctly\n\n**Command:**\n```bash\n# Start dev server (if not running)\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\npnpm dev\n\n# In another terminal, test the endpoint\ncurl -X POST http://localhost:3000/api/token \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"roomName\": \"test-room\", \"participantName\": \"test-user\"}'\n```\n\n**Expected Response:**\n```json\n{\n  \"token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\"\n}\n```\n\n**Validate Token:**\n```bash\n# Decode the JWT to inspect claims (copy token from response)\necho \"eyJhbGciOiJ...\" | cut -d'.' -f2 | base64 -d | jq\n```\n\n**Expected Token Payload:**\n```json\n{\n  \"exp\": 1234567890,\n  \"iss\": \"APIxxxxxxxxxxxx\",\n  \"sub\": \"test-user\",\n  \"nbf\": 1234567890,\n  \"video\": {\n    \"room\": \"test-room\",\n    \"roomJoin\": true,\n    \"canPublish\": true,\n    \"canSubscribe\": true,\n    \"canPublishData\": true\n  }\n}\n```\n\n**Troubleshooting:**\n- If 500 error: Check environment variables in `.env.local`\n- If \"api_key undefined\": Verify `LIVEKIT_API_KEY` is set\n- If \"invalid signature\": Check `LIVEKIT_API_SECRET` is correct\n- If no response: Verify dev server is running on port 3000\n\n**Rationale:** Token generation must work before attempting to connect to LiveKit\n\n---\n\n#### 3.2: Review Client-Side Connection Logic\n\n**What:** Understand how the frontend connects to LiveKit rooms\n\n**Files to Review:**\n```bash\n# Main session component\ncat frontend/voice-ai-frontend/components/app/session-view.tsx\n\n# View controller\ncat frontend/voice-ai-frontend/components/app/view-controller.tsx\n\n# Connection utilities\ncat frontend/voice-ai-frontend/lib/connection.ts\n```\n\n**Key Flow:**\n1. User clicks \"Connect\" button\n2. Frontend generates room name (random or predefined)\n3. Frontend fetches token from `/api/token` endpoint\n4. Frontend connects to LiveKit room using `livekit-client`\n5. Agent is automatically dispatched to room\n6. User and agent establish WebRTC connection\n7. Audio tracks are exchanged\n\n**Important Variables:**\n- `NEXT_PUBLIC_LIVEKIT_URL` - LiveKit server URL (browser-accessible)\n- Room name generation logic\n- Participant name/identity\n- Agent dispatch configuration\n\n**Rationale:** Understanding client-side logic helps debug connection issues\n\n---\n\n#### 3.3: Configure Agent Dispatch\n\n**What:** Ensure frontend triggers automatic agent dispatch when users connect\n\n**File:** Review `frontend/voice-ai-frontend/app/api/connection-details/route.ts` (if exists) or equivalent\n\n**Verify Agent Name Configuration:**\n\n**Option A: Automatic Dispatch (Recommended):**\n```env\n# In .env.local\nAGENT_NAME=\n# Blank means \"dispatch any available agent\"\n```\n\n**Option B: Specific Agent:**\n```env\n# In .env.local\nAGENT_NAME=agent_abc123\n# Uses specific agent by ID or name\n```\n\n**Check Token Grant Configuration (Audio-Only):**\n```typescript\n// In app/api/token/route.ts or connection-details/route.ts\ntoken.addGrant({\n  room: roomName,\n  roomJoin: true,\n  canPublish: true,      // Allow publishing audio\n  canSubscribe: true,    // Allow receiving audio\n  canPublishSources: [   // AUDIO-ONLY: restrict to microphone\n    'microphone'\n    // NOTE: 'camera' and 'screen_share' are NOT included\n  ],\n});\n```\n\n**For agent-starter-react:**\nThe template typically handles agent dispatch automatically when a participant joins a room. Verify this by checking the token generation code and connection details endpoint.\n\n**Rationale:** Agent won't join room unless dispatch is configured correctly\n\n---\n\n#### 3.4: Test Token Expiration and Refresh\n\n**What:** Verify token expiration is set correctly and LiveKit handles refresh\n\n**Check Current TTL:**\n```typescript\n// In app/api/token/route.ts\nconst token = new AccessToken(\n  process.env.LIVEKIT_API_KEY,\n  process.env.LIVEKIT_API_SECRET,\n  {\n    identity: participantName,\n    ttl: '2h', // Current setting\n  }\n);\n```\n\n**Recommended TTL:**\n- Development: `2h` (2 hours)\n- Production: `2h` (LiveKit auto-refreshes for connected clients)\n- Pre-generated tokens: `1h` (if caching tokens)\n\n**Token Refresh Behavior:**\n- LiveKit client SDK automatically refreshes tokens before expiration\n- Refresh happens for connected clients only\n- Disconnected users must request new tokens\n\n**No changes needed if TTL is already `2h`.**\n\n**Rationale:** Prevents users from being disconnected due to token expiration\n\n---\n\n#### 3.5: Add Security Headers (Optional but Recommended)\n\n**What:** Add security headers to token API route\n\n**File:** `frontend/voice-ai-frontend/middleware.ts` (create if doesn't exist)\n\n**Content:**\n```typescript\nimport { NextResponse } from 'next/server';\nimport type { NextRequest } from 'next/server';\n\nexport function middleware(request: NextRequest) {\n  const response = NextResponse.next();\n\n  // Security headers\n  response.headers.set('X-Content-Type-Options', 'nosniff');\n  response.headers.set('X-Frame-Options', 'DENY');\n  response.headers.set('X-XSS-Protection', '1; mode=block');\n\n  return response;\n}\n\nexport const config = {\n  matcher: '/api/:path*',\n};\n```\n\n**Optional Rate Limiting:**\nConsider adding rate limiting to `/api/token` endpoint to prevent abuse.\n\n**Rationale:** Basic security hardening for production deployments\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Token endpoint returns valid JWT: `curl -X POST http://localhost:3000/api/token -H \"Content-Type: application/json\" -d '{\"roomName\":\"test\",\"participantName\":\"user\"}' | jq .token`\n- [ ] Token payload contains correct claims: Decode JWT and verify `video.roomJoin: true`\n- [ ] Environment variables loaded: `console.log(process.env.LIVEKIT_API_KEY)` in token route shows value (not undefined)\n- [ ] Token has correct expiration: Decoded JWT shows `exp` timestamp 2 hours in future\n\n#### Manual Verification:\n\n- [ ] Token endpoint accessible via browser: Visit http://localhost:3000/api/token (should return 405 Method Not Allowed for GET)\n- [ ] No errors in Next.js server logs when generating tokens\n- [ ] Token decodes successfully at https://jwt.io\n- [ ] Token issuer (`iss`) matches your LiveKit API key\n- [ ] Token subject (`sub`) matches requested participant name\n\n**Verify:** After completing automated verification, test token generation with curl and decode the JWT to inspect claims before proceeding to Phase 4.\n\n---\n\n## Phase 4: Connection Testing and Optimization\n\n### Overview\n\nTest the end-to-end connection flow from frontend to agent, verify audio works correctly, and optimize the connection speed.\n\n### Context\n\nBefore starting, ensure:\n- Phase 3 completed successfully\n- Agent running on LiveKit Cloud (`lk agent status` shows Running)\n- Frontend running at http://localhost:3000\n- Token generation working\n\nFiles to review:\n- `frontend/voice-ai-frontend/components/app/session-view.tsx` - Session management\n- `frontend/voice-ai-frontend/components/agents-ui/` - UI components\n\nTools needed:\n- Browser with microphone access\n- Terminal for monitoring agent logs\n\n### Dependencies\n\n**Depends on:** Phases 1-3 (agent deployed, frontend configured, authentication working)\n\n**Required by:** Phase 5 (customization), Phase 6 (production deployment)\n\n### Changes Required\n\n#### 4.1: Monitor Agent Logs\n\n**What:** Start monitoring agent logs before testing connection\n\n**Command:**\n```bash\n# Open a dedicated terminal window for agent logs\nlk agent logs --follow\n```\n\n**Keep this terminal open during all testing.**\n\n**What to Look For:**\n- Agent initialization messages\n- Room join events\n- STT transcriptions\n- LLM requests/responses\n- TTS generation\n- WebRTC connection events\n- Any error messages\n\n**Rationale:** Real-time logs are essential for debugging connection issues\n\n---\n\n#### 4.2: Test Basic Connection Flow\n\n**What:** Connect to the agent via frontend and verify basic functionality\n\n**Steps:**\n\n1. Open browser to http://localhost:3000\n2. Open browser DevTools Console (F12 → Console tab)\n3. Click \"Connect\" or \"Start Session\" button\n4. Grant microphone permissions when prompted\n5. Observe connection states in UI:\n   - \"Initializing...\"\n   - \"Listening\" (agent ready for input)\n   - \"Thinking\" (processing speech)\n   - \"Speaking\" (agent responding)\n\n**Expected Behavior:**\n- Connection establishes within 3-5 seconds\n- Agent state transitions to \"Listening\"\n- No errors in browser console\n- Agent logs show room join event\n\n**Troubleshooting:**\n- **Connection hangs:** Check token endpoint, verify LIVEKIT_URL is correct\n- **\"Failed to connect\":** Check agent status (`lk agent status`), verify agent is Running\n- **Microphone permission denied:** Grant permission in browser settings\n- **No audio:** Check browser audio output, verify speakers are enabled\n- **WebRTC errors:** Check firewall, ensure WebRTC ports not blocked\n\n**Rationale:** Validates basic connection before testing voice interaction\n\n---\n\n#### 4.3: Test Voice Interaction\n\n**What:** Verify end-to-end voice pipeline (STT → LLM → TTS)\n\n**Steps:**\n\n1. With frontend connected and agent in \"Listening\" state\n2. Speak clearly into your microphone: \"Hello, can you hear me?\"\n3. Observe agent state transition:\n   - \"Listening\" → \"Thinking\" → \"Speaking\"\n4. Listen for agent's voice response\n5. Check agent logs for:\n   - STT transcription of your speech\n   - LLM request and response\n   - TTS generation\n\n**Expected Outcome:**\n- Agent responds with natural voice within 2-4 seconds\n- Transcription appears in logs (if logging enabled)\n- No audio dropouts or distortion\n- Agent response is contextually appropriate\n\n**Additional Test Cases:**\n- **Interruption:** Speak while agent is speaking (should handle gracefully)\n- **Silence:** Wait 10 seconds without speaking (agent should remain connected)\n- **Background Noise:** Test with ambient noise (should filter with VAD)\n- **Multiple Turns:** Have a multi-turn conversation\n\n**Troubleshooting:**\n- **No transcription:** Check AssemblyAI API key in agent secrets\n- **No LLM response:** Check OpenAI API key, verify LLM model is available\n- **No TTS audio:** Check Cartesia API key, verify TTS voice model\n- **Garbled audio:** Check network connection, reduce network congestion\n- **High latency:** Check agent logs for slow API calls, consider region optimization\n\n**Rationale:** Validates the complete voice AI pipeline works end-to-end\n\n---\n\n#### 4.4: Verify Audio Visualization\n\n**What:** Test the audio visualizer component works correctly\n\n**Steps:**\n\n1. With frontend connected\n2. Speak into microphone\n3. Observe audio visualization:\n   - Bars should animate when you speak\n   - Bars should pulse when agent speaks\n   - Different colors/states for listening vs speaking\n\n**Expected Behavior:**\n- `BarVisualizer` component shows real-time audio levels\n- Smooth animations\n- Clear visual feedback of agent state\n- No lag between audio and visualization\n\n**Check Component:**\n```bash\n# Review visualizer component\ncat frontend/voice-ai-frontend/components/agents-ui/bar-visualizer.tsx\n```\n\n**Troubleshooting:**\n- **No visualization:** Check if audio track is being passed to component\n- **Choppy animation:** Check browser performance, reduce animation complexity\n- **Wrong colors:** Review CSS/Tailwind classes\n\n**Rationale:** Visual feedback improves user experience and debugging\n\n---\n\n#### 4.5: Test Disconnection and Reconnection\n\n**What:** Verify graceful disconnect and ability to reconnect\n\n**Steps:**\n\n**Test Disconnect:**\n1. With frontend connected\n2. Click \"Disconnect\" or \"End Session\" button\n3. Observe clean disconnect:\n   - Agent logs show participant left\n   - No error messages\n   - UI returns to welcome screen\n\n**Test Reconnect:**\n1. Click \"Connect\" again\n2. Verify new session starts successfully\n3. Test voice interaction again\n\n**Test Network Interruption (Optional):**\n1. While connected, disable network (Wi-Fi off)\n2. Observe reconnection behavior\n3. Re-enable network\n4. Verify auto-reconnect or error message\n\n**Expected Behavior:**\n- Clean disconnect without errors\n- Ability to reconnect immediately\n- Each session gets unique room/token\n- No lingering WebRTC connections\n\n**Rationale:** Ensures robust connection lifecycle management\n\n---\n\n#### 4.6: Optimize Connection Speed\n\n**What:** Reduce connection time from 3-5 seconds to <1 second using optimization techniques\n\n**Current Flow (Sequential):**\n```\n1. Click Connect (0ms)\n2. Fetch token from /api/token (500ms)\n3. Connect to LiveKit room (1000ms)\n4. Agent dispatched (1000ms)\n5. Agent connects and publishes (1500ms)\nTotal: ~4000ms (4 seconds)\n```\n\n**Optimization 1: Pre-generate Tokens**\n\nCreate a \"warm token\" approach for faster connection:\n\n**File:** Create `frontend/voice-ai-frontend/hooks/use-warm-token.ts`\n\n```typescript\n'use client';\n\nimport { useState, useEffect } from 'react';\n\nexport function useWarmToken() {\n  const [token, setToken] = useState<string | null>(null);\n\n  useEffect(() => {\n    // Pre-generate token on page load\n    async function generateToken() {\n      const response = await fetch('/api/token', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          roomName: `room-${Date.now()}`,\n          participantName: `user-${Math.random().toString(36).substring(7)}`,\n        }),\n      });\n      const data = await response.json();\n      setToken(data.token);\n    }\n\n    generateToken();\n  }, []);\n\n  return token;\n}\n```\n\n**Usage in Session Component:**\n```typescript\n// In session-view.tsx or similar\nconst warmToken = useWarmToken();\n\n// Use warmToken when connecting instead of fetching on-demand\n```\n\n**Optimization 2: Concurrent Dispatch**\n\nModify connection logic to dispatch agent and connect user simultaneously:\n\n```typescript\n// Parallel connection\nconst [roomConnection, agentDispatch] = await Promise.all([\n  connectToRoom(token),\n  dispatchAgent(roomName) // If manual dispatch required\n]);\n```\n\n**Expected Improvement:**\n- Pre-generated token: -500ms (eliminates token fetch delay)\n- Concurrent dispatch: -1000ms (parallel instead of sequential)\n- **New total:** ~2500ms → ~1500ms (1.5 seconds)\n\n**Trade-offs:**\n- Pre-generated tokens have expiration (ensure 2h TTL)\n- Unused tokens waste resources (minimal cost)\n- Complexity slightly increases\n\n**Rationale:** Faster connections improve user experience and perceived performance\n\n---\n\n#### 4.7: Test on Multiple Browsers\n\n**What:** Verify cross-browser compatibility\n\n**Browsers to Test:**\n- Chrome/Chromium\n- Firefox\n- Safari (macOS/iOS)\n- Edge\n\n**Test Matrix:**\n\n| Browser | Connection | Audio Input | Audio Output | Visualization |\n|---------|-----------|-------------|--------------|---------------|\n| Chrome  | ✓         | ✓           | ✓            | ✓             |\n| Firefox | ?         | ?           | ?            | ?             |\n| Safari  | ?         | ?           | ?            | ?             |\n| Edge    | ?         | ?           | ?            | ?             |\n\n**Common Issues:**\n- **Safari:** May require user interaction before audio playback\n- **Firefox:** Different WebRTC implementation, may have quirks\n- **Mobile Safari:** Requires specific audio context handling\n- **Edge:** Generally compatible with Chrome\n\n**Rationale:** Ensures wide browser support for production deployment\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Connection establishes successfully: Monitor for \"Room connected\" event in logs\n- [ ] Agent joins room: `lk agent logs` shows room join event\n- [ ] WebRTC connection: Browser DevTools Network tab shows WebRTC connections\n- [ ] No console errors: Browser DevTools Console shows no red errors\n- [ ] Audio tracks published: Check LiveKit Cloud dashboard for active tracks\n\n#### Manual Verification:\n\n- [ ] Voice input recognized: Speak and verify agent responds\n- [ ] Voice output works: Hear agent's TTS response clearly\n- [ ] Audio visualization animates correctly\n- [ ] Agent state transitions work (initializing → listening → thinking → speaking)\n- [ ] Interruption handling works (speak during agent response)\n- [ ] Disconnect and reconnect works cleanly\n- [ ] Connection time <3 seconds (before optimization) or <1.5s (after optimization)\n- [ ] Works in Chrome, Firefox, and Safari\n\n**Verify:** After completing automated verification, have a multi-turn conversation with the agent and test all edge cases before proceeding to Phase 5.\n\n---\n\n## Phase 5: Frontend Customization\n\n### Overview\n\nCustomize the frontend with your branding, colors, logo, and company information to make it production-ready.\n\n### Context\n\nBefore starting, ensure:\n- Phase 4 completed successfully\n- Voice interaction working end-to-end\n- Frontend running at http://localhost:3000\n\nFiles to customize:\n- `frontend/voice-ai-frontend/app-config.ts` - Main configuration\n- `frontend/voice-ai-frontend/public/` - Static assets (logo, favicon)\n- `frontend/voice-ai-frontend/app/layout.tsx` - Page metadata\n- `frontend/voice-ai-frontend/tailwind.config.ts` - Theme colors\n\n### Dependencies\n\n**Depends on:** Phase 4 (connection testing completed)\n\n**Required by:** Phase 6 (production deployment)\n\n### Changes Required\n\n#### 5.1: Update App Configuration\n\n**What:** Customize company name, page title, and feature flags\n\n**File:** `frontend/voice-ai-frontend/app-config.ts`\n\n**Edit:**\n```typescript\nexport const APP_CONFIG_DEFAULTS = {\n  // Branding\n  companyName: \"Your Company Name\", // Change this\n  pageTitle: \"AI Voice Assistant | Your Company\", // Change this\n\n  // Logo URLs\n  logoUrl: \"/logo.svg\", // Update after adding logo in 5.2\n  logoUrlDark: \"/logo-dark.svg\", // Optional: separate dark mode logo\n\n  // Accent color\n  accentColor: \"#4F46E5\", // Change to your brand color (hex)\n\n  // Feature toggles - AUDIO-ONLY CONFIGURATION\n  supportsChatInput: false, // Disable text chat (audio-only)\n  supportsVideoInput: false, // DISABLE camera video (audio-only)\n  supportsScreenShare: false, // DISABLE screen sharing (audio-only)\n  isPreConnectBufferEnabled: true, // Pre-load for faster connection\n\n  // Optional: Agent configuration\n  defaultAgentName: \"\", // Leave blank for auto-dispatch\n};\n```\n\n**Example Customization (Audio-Only):**\n```typescript\nexport const APP_CONFIG_DEFAULTS = {\n  companyName: \"Acme Voice AI\",\n  pageTitle: \"Voice AI Assistant | Acme Corp\",\n  logoUrl: \"/acme-logo.svg\",\n  accentColor: \"#FF6B35\", // Orange\n  supportsChatInput: false, // Audio-only: no text chat\n  supportsVideoInput: false, // Audio-only: no camera\n  supportsScreenShare: false, // Audio-only: no screen share\n  isPreConnectBufferEnabled: true,\n};\n```\n\n**Rationale:** Centralizes configuration for easy customization without code changes\n\n---\n\n#### 5.2: Add Custom Logo\n\n**What:** Replace default logo with your company logo\n\n**Steps:**\n\n1. Prepare logo files:\n   - **Format:** SVG (preferred) or PNG\n   - **Size:**\n     - SVG: Any size (scalable)\n     - PNG: 200x200px minimum, transparent background\n   - **Naming:**\n     - Light mode: `logo.svg` or `logo.png`\n     - Dark mode (optional): `logo-dark.svg` or `logo-dark.png`\n\n2. Copy to public directory:\n   ```bash\n   cp /path/to/your/logo.svg frontend/voice-ai-frontend/public/logo.svg\n   # Optional: dark mode logo\n   cp /path/to/your/logo-dark.svg frontend/voice-ai-frontend/public/logo-dark.svg\n   ```\n\n3. Update `app-config.ts`:\n   ```typescript\n   logoUrl: \"/logo.svg\",\n   logoUrlDark: \"/logo-dark.svg\", // If you have separate dark logo\n   ```\n\n4. Verify logo appears:\n   - Restart dev server: `pnpm dev`\n   - Visit http://localhost:3000\n   - Check logo displays correctly\n   - Toggle light/dark mode to test both logos\n\n**Fallback:**\nIf you don't have a logo ready, the template includes a default placeholder logo.\n\n**Rationale:** Custom logo reinforces brand identity\n\n---\n\n#### 5.3: Customize Theme Colors\n\n**What:** Update color scheme to match your brand\n\n**File:** `frontend/voice-ai-frontend/tailwind.config.ts`\n\n**Edit:**\n```typescript\nexport default {\n  theme: {\n    extend: {\n      colors: {\n        // Primary brand color\n        primary: {\n          50: '#f0f9ff',\n          100: '#e0f2fe',\n          // ... continue through 950\n          500: '#4F46E5', // Main brand color (change this)\n          600: '#4338ca',\n          // ...\n        },\n        // Accent color\n        accent: {\n          DEFAULT: '#FF6B35', // Change to your accent color\n          light: '#FF8A5B',\n          dark: '#E5501F',\n        },\n      },\n    },\n  },\n};\n```\n\n**Quick Method (Use Accent Color from app-config.ts):**\n\nThe template may automatically use `accentColor` from `app-config.ts`. If so, just update that value:\n\n```typescript\n// In app-config.ts\naccentColor: \"#FF6B35\", // Your brand color\n```\n\n**Generate Full Color Palette:**\nUse tools like https://uicolors.app/create to generate a full Tailwind color palette from your brand color.\n\n**Test Theme:**\n- Restart dev server\n- Visit http://localhost:3000\n- Check buttons, links, highlights use new colors\n- Toggle light/dark mode to verify both themes\n\n**Rationale:** Consistent color scheme creates professional, branded experience\n\n---\n\n#### 5.4: Update Page Metadata\n\n**What:** Set page title, description, and favicon for SEO and browser display\n\n**File:** `frontend/voice-ai-frontend/app/layout.tsx`\n\n**Edit:**\n```typescript\nexport const metadata: Metadata = {\n  title: \"AI Voice Assistant | Your Company\", // Change this\n  description: \"Connect with our AI voice assistant for instant help and support.\", // Change this\n  icons: {\n    icon: '/favicon.ico', // Update after adding favicon\n  },\n  openGraph: {\n    title: \"AI Voice Assistant | Your Company\",\n    description: \"Connect with our AI voice assistant for instant help and support.\",\n    images: ['/og-image.png'], // Optional: social share image\n  },\n};\n```\n\n**Add Custom Favicon:**\n\n1. Generate favicon files (use https://realfavicongenerator.net/):\n   - `favicon.ico` (16x16, 32x32, 48x48)\n   - `apple-touch-icon.png` (180x180)\n   - `favicon-16x16.png`\n   - `favicon-32x32.png`\n\n2. Copy to `public/`:\n   ```bash\n   cp /path/to/favicon.ico frontend/voice-ai-frontend/public/\n   cp /path/to/apple-touch-icon.png frontend/voice-ai-frontend/public/\n   ```\n\n3. Verify in browser:\n   - Clear browser cache\n   - Visit http://localhost:3000\n   - Check browser tab shows your favicon\n\n**Optional: Open Graph Image (Social Sharing):**\nCreate `og-image.png` (1200x630px) for social media previews.\n\n**Rationale:** Professional metadata improves SEO and user experience\n\n---\n\n#### 5.5: Customize Welcome Message\n\n**What:** Update the welcome screen text and instructions\n\n**File:** `frontend/voice-ai-frontend/components/app/welcome-view.tsx` or similar\n\n**Find and Edit:**\n```typescript\n<h1>Welcome to [Your Company] Voice AI</h1>\n<p>\n  Click the button below to start a voice conversation with our AI assistant.\n  We can help you with questions, information, and more.\n</p>\n```\n\n**Example Customization:**\n```typescript\n<h1>Welcome to Acme Voice Assistant</h1>\n<p>\n  Our AI assistant is ready to help you 24/7. Click \"Connect\" to start a\n  natural voice conversation. Just speak naturally - no keywords or commands needed.\n</p>\n<ul>\n  <li>Get instant answers to your questions</li>\n  <li>Learn about our products and services</li>\n  <li>Get personalized recommendations</li>\n</ul>\n```\n\n**Rationale:** Clear messaging helps users understand what to expect\n\n---\n\n#### 5.6: Configure Audio-Only Mode (REQUIRED)\n\n**What:** Disable video/screen share features for audio-only application\n\n**File:** `frontend/voice-ai-frontend/app-config.ts`\n\n**REQUIRED Configuration for Audio-Only App:**\n```typescript\nexport const APP_CONFIG_DEFAULTS = {\n  // ... other settings\n  supportsChatInput: false, // Audio-only: disable text chat\n  supportsVideoInput: false, // REQUIRED: disable camera\n  supportsScreenShare: false, // REQUIRED: disable screen sharing\n  isPreConnectBufferEnabled: true, // Keep for faster connection\n};\n```\n\n**Effect:**\n- Video camera icon hidden\n- Screen share button removed\n- UI simplified to voice-only interface\n- No video/screenshare permission requests to users\n- Browser only requests microphone permission\n\n**IMPORTANT:** This is a required configuration for this audio-only application. Do NOT enable video or screen sharing features.\n\n**Rationale:** This application is designed for audio-only interaction. No video capabilities should be exposed to users.\n\n---\n\n#### 5.7: Test Customizations\n\n**What:** Verify all customizations display correctly\n\n**Checklist:**\n- [ ] Company name displays on welcome screen\n- [ ] Custom logo appears (both light and dark modes)\n- [ ] Page title shows in browser tab\n- [ ] Custom favicon appears in browser tab\n- [ ] Brand colors visible on buttons and accents\n- [ ] Welcome message updated with custom text\n- [ ] Video/screenshare features are hidden (REQUIRED for audio-only)\n- [ ] Only microphone permission requested (no camera/screenshare)\n- [ ] No broken images or 404s\n- [ ] Responsive design maintained on mobile\n\n**Testing Steps:**\n1. Restart dev server: `pnpm dev`\n2. Clear browser cache (Cmd+Shift+R on Mac, Ctrl+Shift+R on Windows)\n3. Visit http://localhost:3000\n4. Toggle light/dark theme\n5. Resize browser to mobile size (375px width)\n6. Check all visual elements\n\n**Rationale:** Ensures professional, branded appearance before production deployment\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Build succeeds: `pnpm run build` completes without errors\n- [ ] No TypeScript errors: `pnpm run type-check` (if available)\n- [ ] Static assets exist: `ls public/logo.svg public/favicon.ico`\n- [ ] Config updated: `cat app-config.ts | grep companyName` shows your company\n\n#### Manual Verification:\n\n- [ ] Custom company name displays on welcome screen\n- [ ] Custom logo visible (light and dark modes)\n- [ ] Page title correct in browser tab\n- [ ] Favicon visible in browser tab\n- [ ] Brand colors applied throughout UI\n- [ ] Welcome message updated\n- [ ] Video/screenshare features are hidden (REQUIRED - verify no camera/screenshare icons)\n- [ ] Browser only requests microphone permission (NOT camera)\n- [ ] Mobile responsive (test at 375px width)\n- [ ] No console errors or warnings\n- [ ] All images load correctly (no broken images)\n\n**Verify:** After completing automated verification, thoroughly test the UI on desktop and mobile, in light and dark modes, before proceeding to Phase 6.\n\n---\n\n## Phase 6: Production Deployment\n\n### Overview\n\nDeploy the customized frontend to Vercel (or another hosting provider) to make it publicly accessible via a URL that clients can visit.\n\n### Context\n\nBefore starting, ensure:\n- Phase 5 completed successfully\n- All customizations tested locally\n- Frontend builds successfully (`pnpm run build`)\n- Agent deployed and running on LiveKit Cloud\n\nFiles to review:\n- `frontend/voice-ai-frontend/.env.local` - Environment variables (will configure in Vercel)\n- `frontend/voice-ai-frontend/next.config.js` - Next.js configuration\n- `frontend/voice-ai-frontend/package.json` - Dependencies and scripts\n\nAccounts needed:\n- Vercel account (free tier sufficient): https://vercel.com\n- GitHub account (for connecting repo)\n\n### Dependencies\n\n**Depends on:** Phases 1-5 (agent deployed, frontend customized and tested)\n\n**Required by:** None (final phase)\n\n### Changes Required\n\n#### 6.1: Create Production Build\n\n**What:** Verify the production build works correctly before deploying\n\n**Commands:**\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\n\n# Create production build\npnpm run build\n\n# Test production build locally\npnpm start\n```\n\n**Expected Output:**\n```\n> next build\n\n✓ Compiled successfully\n✓ Linting and checking validity of types\n✓ Collecting page data\n✓ Generating static pages (X/X)\n✓ Finalizing page optimization\n\nRoute (app)                              Size     First Load JS\n┌ ○ /                                    XXX kB        XXX kB\n└ ○ /api/token                          XXX B          XXX kB\n```\n\n**Test Production Build:**\n1. Visit http://localhost:3000 (pnpm start)\n2. Connect to agent\n3. Verify voice interaction works\n4. Check for any errors in console\n\n**Troubleshooting:**\n- If build fails: Check TypeScript errors, fix before proceeding\n- If errors about environment variables: Ensure `.env.local` exists\n- If runtime errors: Check browser console for specific issues\n\n**Rationale:** Catches production-specific issues before deployment\n\n---\n\n#### 6.2: Push Frontend to GitHub (Optional but Recommended)\n\n**What:** Create a Git repository for the frontend to enable easy Vercel deployment\n\n**Option A: Separate Repository (Recommended):**\n\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/frontend/voice-ai-frontend\n\n# Initialize git repository\ngit init\n\n# Add .gitignore for Next.js\ncat > .gitignore << 'EOF'\n# Next.js\n.next/\nout/\nbuild/\ndist/\n\n# Dependencies\nnode_modules/\n\n# Environment variables\n.env\n.env.local\n.env.production.local\n.env.development.local\n.env.test.local\n\n# Logs\nnpm-debug.log*\nyarn-debug.log*\nyarn-error.log*\npnpm-debug.log*\n\n# OS\n.DS_Store\n*.swp\n*.swo\n\n# IDE\n.vscode/\n.idea/\n\n# Vercel\n.vercel\nEOF\n\n# Add files\ngit add .\ngit commit -m \"Initial commit: Voice AI frontend\"\n\n# Create GitHub repository (via GitHub UI or CLI)\ngh repo create voice-ai-frontend --public --source=. --remote=origin --push\n```\n\n**Option B: Same Repository as Agent:**\n\nIf you want frontend and agent in the same repo:\n```bash\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\n\n# Remove frontend/ from .gitignore\nsed -i '' '/^frontend\\//d' .gitignore\n\n# Add and commit\ngit add frontend/\ngit commit -m \"Add voice AI frontend\"\ngit push\n```\n\n**Rationale:** Git repository enables continuous deployment and version control\n\n---\n\n#### 6.3: Sign Up for Vercel\n\n**What:** Create a Vercel account for hosting the frontend\n\n**Steps:**\n\n1. Visit https://vercel.com\n2. Click \"Sign Up\"\n3. Choose \"Continue with GitHub\" (recommended)\n4. Authorize Vercel to access your GitHub repositories\n\n**Pricing:**\n- **Free Tier:** Sufficient for testing and low traffic\n  - Unlimited deployments\n  - 100 GB bandwidth/month\n  - Serverless functions included\n- **Pro Tier:** $20/month (for production with higher traffic)\n\n**Rationale:** Vercel provides seamless Next.js hosting with automatic deployments\n\n---\n\n#### 6.4: Deploy Frontend to Vercel\n\n**What:** Deploy the frontend application to Vercel\n\n**Steps:**\n\n1. **From Vercel Dashboard:**\n   - Click \"Add New...\" → \"Project\"\n   - Select \"Import Git Repository\"\n   - Choose your frontend repository\n   - Configure project:\n     - **Framework Preset:** Next.js (auto-detected)\n     - **Root Directory:** `./` (or `frontend/voice-ai-frontend` if in monorepo)\n     - **Build Command:** `pnpm run build` (auto-detected)\n     - **Output Directory:** `.next` (auto-detected)\n     - **Install Command:** `pnpm install` (auto-detected)\n\n2. **Configure Environment Variables:**\n   Click \"Environment Variables\" and add:\n\n   ```\n   LIVEKIT_API_KEY=APIxxxxxxxxxxxx\n   LIVEKIT_API_SECRET=your-secret-here\n   LIVEKIT_URL=wss://your-project.livekit.cloud\n   NEXT_PUBLIC_LIVEKIT_URL=wss://your-project.livekit.cloud\n   AGENT_NAME=\n   ```\n\n   **Important:**\n   - Copy values from your local `.env.local`\n   - Apply to \"Production\", \"Preview\", and \"Development\" environments\n\n3. **Deploy:**\n   - Click \"Deploy\"\n   - Wait for build to complete (2-5 minutes)\n\n**Expected Outcome:**\n```\n✓ Build successful\n✓ Deployment successful\nYour project is now live at: https://your-app.vercel.app\n```\n\n**Rationale:** Makes frontend publicly accessible via HTTPS URL\n\n---\n\n#### 6.5: Test Production Deployment\n\n**What:** Verify the deployed frontend works correctly\n\n**Steps:**\n\n1. Visit your Vercel URL: `https://your-app.vercel.app`\n\n2. **Test Checklist:**\n   - [ ] Page loads without errors\n   - [ ] Custom branding displays correctly\n   - [ ] Click \"Connect\" button\n   - [ ] Grant microphone permissions\n   - [ ] Speak to agent\n   - [ ] Verify agent responds with voice\n   - [ ] Test on mobile device\n   - [ ] Test in different browsers\n\n3. **Monitor Logs:**\n   ```bash\n   # Monitor agent logs during production test\n   lk agent logs --follow\n   ```\n\n4. **Check Vercel Deployment Logs:**\n   - Go to Vercel dashboard → Your project → Deployments\n   - Click on latest deployment → \"Functions\" tab\n   - Check for any errors in `/api/token` function\n\n**Troubleshooting:**\n- **\"Failed to connect\":** Check environment variables in Vercel\n- **Token errors:** Verify `LIVEKIT_API_KEY` and `LIVEKIT_API_SECRET` are correct\n- **CORS errors:** Ensure `NEXT_PUBLIC_LIVEKIT_URL` is set correctly\n- **Agent not joining:** Check agent status, verify agent is Running\n\n**Rationale:** Ensures production environment works correctly\n\n---\n\n#### 6.6: Configure Custom Domain (Optional)\n\n**What:** Use a custom domain instead of `your-app.vercel.app`\n\n**Prerequisites:**\n- Own a domain name (e.g., `voiceai.yourcompany.com`)\n- Access to domain DNS settings\n\n**Steps:**\n\n1. **In Vercel Dashboard:**\n   - Go to your project → Settings → Domains\n   - Click \"Add Domain\"\n   - Enter your domain: `voiceai.yourcompany.com`\n\n2. **Configure DNS:**\n   Vercel will provide DNS configuration instructions:\n\n   **Option A: CNAME (Subdomain):**\n   ```\n   Type: CNAME\n   Name: voiceai\n   Value: cname.vercel-dns.com\n   ```\n\n   **Option B: A Record (Root Domain):**\n   ```\n   Type: A\n   Name: @\n   Value: 76.76.21.21\n   ```\n\n3. **Wait for DNS Propagation:**\n   - Usually takes 5-60 minutes\n   - Vercel will auto-configure SSL certificate (Let's Encrypt)\n\n4. **Verify:**\n   - Visit `https://voiceai.yourcompany.com`\n   - Should show your frontend with SSL (green lock icon)\n\n**Rationale:** Custom domain provides professional appearance and brand consistency\n\n---\n\n#### 6.7: Enable Automatic Deployments\n\n**What:** Configure automatic deployments when you push to GitHub\n\n**Vercel Auto-Deploys By Default:**\n- **Production:** Deploys on push to `main` branch\n- **Preview:** Deploys on push to any other branch or PR\n\n**Customize (Optional):**\n1. Go to Vercel dashboard → Your project → Settings → Git\n2. Configure:\n   - **Production Branch:** `main` (or `master`)\n   - **Ignored Build Step:** (leave blank to build on every commit)\n\n**Test Automatic Deployment:**\n```bash\ncd frontend/voice-ai-frontend\n\n# Make a small change\necho \"# Updated\" >> README.md\n\n# Commit and push\ngit add README.md\ngit commit -m \"Test automatic deployment\"\ngit push origin main\n```\n\n**Verify:**\n- Visit Vercel dashboard\n- Should see new deployment triggered automatically\n- Wait for build to complete\n- Visit production URL to see changes\n\n**Rationale:** Enables continuous deployment for easy updates\n\n---\n\n#### 6.8: Set Up Production Monitoring (Recommended)\n\n**What:** Monitor production errors and usage\n\n**Vercel Analytics (Built-in):**\n1. Go to Vercel dashboard → Your project → Analytics\n2. View:\n   - Page views\n   - Geographic distribution\n   - Performance metrics (Web Vitals)\n\n**Error Tracking (Optional):**\nConsider integrating Sentry or similar:\n```bash\npnpm add @sentry/nextjs\nnpx @sentry/wizard@latest -i nextjs\n```\n\n**LiveKit Cloud Monitoring:**\n- Visit LiveKit Cloud dashboard\n- Monitor:\n  - Active sessions\n  - Agent usage\n  - Costs (session minutes)\n\n**Rationale:** Production monitoring helps identify and resolve issues quickly\n\n---\n\n#### 6.9: Create Shareable Link\n\n**What:** Generate a clean, shareable URL for potential clients\n\n**Your Production URL:**\n```\nhttps://your-app.vercel.app\n```\n\n**Or with Custom Domain:**\n```\nhttps://voiceai.yourcompany.com\n```\n\n**Create Marketing Materials:**\n- Add link to your website\n- Share via email campaigns\n- Include in social media bios\n- Create QR code for physical materials\n\n**Example QR Code Generation:**\n```bash\n# Generate QR code (using qrencode)\nbrew install qrencode\nqrencode -o voiceai-qr.png \"https://voiceai.yourcompany.com\"\n```\n\n**Rationale:** Easy sharing enables potential clients to access your voice AI\n\n---\n\n#### 6.10: Document Production URLs and Credentials\n\n**What:** Save all production information for future reference\n\n**Create:** `frontend/voice-ai-frontend/PRODUCTION.md`\n\n**Content:**\n```markdown\n# Production Deployment Information\n\n## URLs\n- **Production Frontend:** https://your-app.vercel.app\n- **Custom Domain:** https://voiceai.yourcompany.com (if configured)\n- **LiveKit Cloud Dashboard:** https://cloud.livekit.io\n\n## Vercel\n- **Project:** voice-ai-frontend\n- **Account:** your-email@example.com\n- **Git Repository:** https://github.com/yourusername/voice-ai-frontend\n\n## LiveKit Cloud\n- **Project:** your-project-name\n- **Region:** us-west-2\n- **Agent ID:** agent_abc123\n\n## Deployment Commands\n```bash\n# Deploy agent updates\ncd /Users/seanreed/PythonProjects/voice-ai/lk-agent-1\nlk agent deploy\n\n# Deploy frontend updates (automatic via Git)\ncd frontend/voice-ai-frontend\ngit add .\ngit commit -m \"Update frontend\"\ngit push origin main\n```\n\n## Monitoring\n- **Agent Logs:** `lk agent logs --follow`\n- **Vercel Logs:** https://vercel.com/your-project/deployments\n- **LiveKit Dashboard:** https://cloud.livekit.io/projects/your-project\n\n## Environment Variables (Vercel)\n- LIVEKIT_API_KEY=APIxxxxxxxxxxxx\n- LIVEKIT_API_SECRET=*** (not shown)\n- LIVEKIT_URL=wss://your-project.livekit.cloud\n- NEXT_PUBLIC_LIVEKIT_URL=wss://your-project.livekit.cloud\n\n## Costs\n- **LiveKit Cloud:** $0.01 per agent session minute\n- **Vercel:** Free tier (or $20/month Pro)\n\n## Support\n- **LiveKit:** https://livekit.io/discord\n- **Vercel:** https://vercel.com/support\n```\n\n**Rationale:** Documentation ensures you can manage production deployment long-term\n\n---\n\n### Success Criteria\n\n#### Automated Verification:\n\n- [ ] Production build succeeds: `pnpm run build` completes without errors\n- [ ] Vercel deployment successful: Deployment status shows \"Ready\"\n- [ ] HTTPS enabled: Visit production URL with green lock icon\n- [ ] Environment variables configured: Check Vercel dashboard\n- [ ] Custom domain configured (if applicable): DNS records set\n\n#### Manual Verification:\n\n- [ ] Visit production URL in browser\n- [ ] Page loads without errors\n- [ ] Custom branding displays correctly\n- [ ] Click \"Connect\" and grant microphone access\n- [ ] Speak to agent and verify voice response\n- [ ] Test on mobile device (iOS Safari, Android Chrome)\n- [ ] Test in incognito/private mode\n- [ ] Share URL with colleague and get confirmation it works\n- [ ] Agent logs show production sessions: `lk agent logs --follow`\n- [ ] No errors in Vercel function logs\n\n**Verify:** After completing automated verification, test the production URL on multiple devices and browsers, then share with a colleague to confirm public accessibility.\n\n---\n\n## Testing Strategy\n\n### Unit Tests\n\n**Not required for this plan.** The agent-starter-react template is a pre-built, production-ready template that doesn't require custom unit tests unless you add significant custom logic.\n\n**Optional:** Add tests if you customize components heavily:\n```bash\npnpm add -D @testing-library/react @testing-library/jest-dom jest\n```\n\n### Integration Tests\n\n**End-to-End Testing:**\n\nManually test the complete flow:\n1. User visits URL\n2. Clicks \"Connect\"\n3. Grants microphone access\n4. Speaks to agent\n5. Receives voice response\n6. Disconnects cleanly\n\n**Test Matrix:**\n\n| Scenario | Steps | Expected Outcome |\n|----------|-------|------------------|\n| First Connection | Visit URL → Click Connect → Speak | Agent responds with voice |\n| Interruption | Speak while agent is speaking | Agent handles gracefully |\n| Disconnect/Reconnect | End session → Start new session | New session works |\n| Multiple Turns | Have 3-5 turn conversation | All responses relevant |\n| Mobile Safari | Test on iPhone/iPad | Full functionality |\n| Network Interruption | Disable Wi-Fi during session | Reconnection or error message |\n\n### Manual Testing Steps\n\n**Pre-Deployment Checklist:**\n1. [ ] Agent deployed and running: `lk agent status`\n2. [ ] Local frontend works: `pnpm dev` at http://localhost:3000\n3. [ ] Voice interaction successful\n4. [ ] Audio visualization working\n5. [ ] Custom branding applied\n6. [ ] Production build succeeds: `pnpm run build`\n\n**Post-Deployment Checklist:**\n1. [ ] Production URL accessible\n2. [ ] HTTPS enabled (green lock)\n3. [ ] Voice interaction works on production\n4. [ ] Mobile responsive\n5. [ ] Cross-browser compatible\n6. [ ] Shareable link works for external users\n\n### Performance Considerations\n\n**Metrics to Monitor:**\n- **Connection Time:** Should be <3 seconds (or <1.5s with optimization)\n- **Response Latency:** STT → LLM → TTS should be 2-4 seconds\n- **Page Load Time:** Initial load <2 seconds (Lighthouse score >90)\n- **Audio Quality:** No dropouts or distortion\n\n**Optimization:**\n- Enable pre-connect buffering in `app-config.ts`\n- Use warm token approach (Phase 4.6)\n- Minimize bundle size (Next.js handles automatically)\n- Use CDN for static assets (Vercel provides automatically)\n\n## References\n\n### Original Ticket/Request\n- User request: \"I want potential clients to be able to interact with the livekit agent from this repo by clicking a link on a website.\"\n\n### Documentation\n- `docs/DEPLOYMENT.md` - Complete deployment guide for agent and frontend options\n- `README.md` - Project overview and setup instructions\n- `AGENTS.md` - Project guidelines and standards\n\n### LiveKit Resources\n- **Frontend Deployment Guide:** https://docs.livekit.io/agents/start/frontend/\n- **agent-starter-react Repository:** https://github.com/livekit-examples/agent-starter-react\n- **Token Authentication:** https://docs.livekit.io/home/get-started/authentication/\n- **Agents Playground:** https://agents-playground.livekit.io/\n- **LiveKit Cloud Dashboard:** https://cloud.livekit.io\n- **React Components Docs:** https://docs.livekit.io/reference/components/react/\n\n### NPM Packages\n- **livekit-client:** Client SDK for browser WebRTC\n- **@livekit/components-react:** React UI components\n- **livekit-server-sdk:** Server-side token generation\n\n### Vercel Resources\n- **Vercel Platform:** https://vercel.com\n- **Next.js Documentation:** https://nextjs.org/docs\n- **Deployment Docs:** https://vercel.com/docs\n\n### Related Plans\n- None (initial implementation)\n\n---\n\n**End of Implementation Plan**\n","structuredPatch":[{"oldStart":1962,"oldLines":9,"newStart":1962,"newLines":11,"lines":["    - [ ] Page loads without errors","    - [ ] Custom branding displays correctly","    - [ ] Click \"Connect\" button","-   - [ ] Grant microphone permissions","+   - [ ] Verify ONLY microphone permission requested (no camera/screenshare)","+   - [ ] Grant microphone permission","    - [ ] Speak to agent","    - [ ] Verify agent responds with voice","+   - [ ] Confirm no video/screenshare UI elements visible","    - [ ] Test on mobile device","    - [ ] Test in different browsers"," "]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"52951924-821b-4cd6-a8d3-dc7ce5d949b8"}
{"parentUuid":"1a4e906d-6a68-4bb9-8179-08ea2498f8fd","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","slug":"enumerated-shimmying-starlight","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01VTPKhejF9ams1aaj29H22o","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Perfect! Now let me add a note in the overview of the options summary file to emphasize this is audio-only at the top:","signature":"Ep8CCkYICxgCKkBGllZQ6pW73s0oqtuT0AdS6ZmY+XcVDrIkU0miaZ5ApP59IFWSo4umCRaXLaEnqU9IS0skoMo23f8fxm/XtP26EgzyUnr3sNkFZzd+5NQaDLabVgd4I7iA8wdyeSIwlk4CjnY4MrqM9mxxRBagjDjkhkXzbM1j/guR0po//24902n/p4w6io1zuLvKv+CAKoYBCZPcSOcGskKspUbcFPcSRe2blN+usJunp/VOReLbcriJJ+KXqmnZjwwLCFGKG2QmTEVYEUXU42PAEMHTw4pQA3OlusfvX868q0j1KXG+E52+CDY3Ge+pMEQW2y4ADE62NAw9LrXIAhnt3yWJX07C0EbyDpZqy83sFAdvfO3iGbaXLQtlVEYYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":449,"cache_read_input_tokens":69752,"cache_creation":{"ephemeral_5m_input_tokens":449,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXTtBY3yJZqLGWhcq9hKy","type":"assistant","uuid":"81c643c9-7761-4a7f-b079-37df073a20ad","timestamp":"2026-01-25T09:46:25.470Z"}
{"parentUuid":"81c643c9-7761-4a7f-b079-37df073a20ad","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","slug":"enumerated-shimmying-starlight","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01VTPKhejF9ams1aaj29H22o","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01LvpDqfRzvemDvBoSLcQeQy","name":"Edit","input":{"replace_all":false,"file_path":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/plan/future-plans/2026-01-25-web-frontend-options-summary.md","old_string":"## Executive Summary\n\nLiveKit provides multiple JavaScript/TypeScript solutions for building web frontends that connect users to voice AI agents. The recommended approach is **agent-starter-react**, a production-ready Next.js template that includes all necessary components:\n\n- JWT token generation (server-side for security)\n- WebRTC connection management via `livekit-client` SDK\n- Voice assistant UI components (`@livekit/components-react`)\n- Audio visualization and agent state tracking\n- Automatic agent dispatch when users connect\n\n**Timeline:** 6-8 hours for complete deployment (agent + frontend + customization)\n**Cost:** $0.01 per agent session minute (LiveKit Cloud) + Free (Vercel frontend hosting)","new_string":"## Executive Summary\n\nLiveKit provides multiple JavaScript/TypeScript solutions for building web frontends that connect users to voice AI agents. The recommended approach is **agent-starter-react**, a production-ready Next.js template that includes all necessary components:\n\n- JWT token generation (server-side for security)\n- WebRTC connection management via `livekit-client` SDK\n- Voice assistant UI components (`@livekit/components-react`)\n- Audio visualization and agent state tracking\n- Automatic agent dispatch when users connect\n\n**IMPORTANT: This deployment is for an AUDIO-ONLY application. All video camera and screen sharing features must be disabled. Only microphone permissions should be requested from users.**\n\n**Timeline:** 6-8 hours for complete deployment (agent + frontend + customization)\n**Cost:** $0.01 per agent session minute (LiveKit Cloud) + Free (Vercel frontend hosting)"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":449,"cache_read_input_tokens":69752,"cache_creation":{"ephemeral_5m_input_tokens":449,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CXTtBY3yJZqLGWhcq9hKy","type":"assistant","uuid":"31b4ba73-55c2-436d-8d08-935cb88231ff","timestamp":"2026-01-25T09:46:34.769Z"}
{"parentUuid":"31b4ba73-55c2-436d-8d08-935cb88231ff","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","slug":"enumerated-shimmying-starlight","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01LvpDqfRzvemDvBoSLcQeQy","type":"tool_result","content":"The file /Users/seanreed/PythonProjects/voice-ai/lk-agent-1/plan/future-plans/2026-01-25-web-frontend-options-summary.md has been updated successfully."}]},"uuid":"a2883b24-2f68-48d0-9447-0e3c4fc009ff","timestamp":"2026-01-25T09:46:34.841Z","toolUseResult":{"filePath":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1/plan/future-plans/2026-01-25-web-frontend-options-summary.md","oldString":"## Executive Summary\n\nLiveKit provides multiple JavaScript/TypeScript solutions for building web frontends that connect users to voice AI agents. The recommended approach is **agent-starter-react**, a production-ready Next.js template that includes all necessary components:\n\n- JWT token generation (server-side for security)\n- WebRTC connection management via `livekit-client` SDK\n- Voice assistant UI components (`@livekit/components-react`)\n- Audio visualization and agent state tracking\n- Automatic agent dispatch when users connect\n\n**Timeline:** 6-8 hours for complete deployment (agent + frontend + customization)\n**Cost:** $0.01 per agent session minute (LiveKit Cloud) + Free (Vercel frontend hosting)","newString":"## Executive Summary\n\nLiveKit provides multiple JavaScript/TypeScript solutions for building web frontends that connect users to voice AI agents. The recommended approach is **agent-starter-react**, a production-ready Next.js template that includes all necessary components:\n\n- JWT token generation (server-side for security)\n- WebRTC connection management via `livekit-client` SDK\n- Voice assistant UI components (`@livekit/components-react`)\n- Audio visualization and agent state tracking\n- Automatic agent dispatch when users connect\n\n**IMPORTANT: This deployment is for an AUDIO-ONLY application. All video camera and screen sharing features must be disabled. Only microphone permissions should be requested from users.**\n\n**Timeline:** 6-8 hours for complete deployment (agent + frontend + customization)\n**Cost:** $0.01 per agent session minute (LiveKit Cloud) + Free (Vercel frontend hosting)","originalFile":"# Web Frontend Options for LiveKit Voice AI Agent - Research Summary\n\n**Date:** 2026-01-25\n**Purpose:** Document TypeScript/JavaScript options for enabling web-based client interaction with deployed LiveKit agent\n\n---\n\n## Executive Summary\n\nLiveKit provides multiple JavaScript/TypeScript solutions for building web frontends that connect users to voice AI agents. The recommended approach is **agent-starter-react**, a production-ready Next.js template that includes all necessary components:\n\n- JWT token generation (server-side for security)\n- WebRTC connection management via `livekit-client` SDK\n- Voice assistant UI components (`@livekit/components-react`)\n- Audio visualization and agent state tracking\n- Automatic agent dispatch when users connect\n\n**Timeline:** 6-8 hours for complete deployment (agent + frontend + customization)\n**Cost:** $0.01 per agent session minute (LiveKit Cloud) + Free (Vercel frontend hosting)\n\n---\n\n## Option 1: agent-starter-react (Recommended)\n\n### Overview\nOfficial Next.js/React template from LiveKit with production-ready voice AI interface.\n\n### Repository\n**GitHub:** https://github.com/livekit-examples/agent-starter-react\n\n### Tech Stack\n- Next.js 14+ (App Router)\n- React 18+ with TypeScript\n- Tailwind CSS + Shadcn/ui components\n- `livekit-client` SDK (WebRTC)\n- `@livekit/components-react` (UI components)\n- `livekit-server-sdk` (token generation)\n\n### Key Features\n✓ Token generation API route (`/api/token`)\n✓ `useVoiceAssistant` React hook for agent state\n✓ Audio visualizer (`BarVisualizer`)\n✓ Audio-only interface (video and screen sharing disabled)\n✓ Light/dark theme with system preference\n✓ Customizable branding via `app-config.ts`\n✓ Mobile-responsive design\n✓ Production-ready architecture\n\n**IMPORTANT: This is an audio-only application. Video camera and screen sharing features should be disabled in configuration.**\n\n### Setup Process\n```bash\n# Install via LiveKit CLI\nlk app create --template agent-starter-react\ncd voice-ai-frontend\npnpm install\n\n# Configure environment\ncp .env.example .env.local\n# Add: LIVEKIT_API_KEY, LIVEKIT_API_SECRET, LIVEKIT_URL\n\n# Run development server\npnpm dev\n# Visit http://localhost:3000\n```\n\n### Customization\n**Easy to customize:**\n- Company name and branding (app-config.ts)\n- Logo and colors\n- Welcome message and instructions\n- Feature toggles (video, screen share, chat)\n- Theme colors (Tailwind CSS)\n\n### Deployment\n- **Recommended:** Vercel (free tier)\n- **Alternatives:** Netlify, AWS Amplify, Cloudflare Pages\n- **Build time:** ~2-5 minutes\n- **Automatic deployments:** Via Git integration\n\n### Best For\n- Production websites with custom branding\n- Full feature control\n- Professional, polished user experience\n- Organizations needing customization\n\n### Pros\n✓ Official template, actively maintained\n✓ Production-ready out of the box\n✓ Excellent documentation\n✓ Easy customization\n✓ Vercel deployment = free hosting\n✓ TypeScript for type safety\n✓ Modern UI with Shadcn/ui\n\n### Cons\n✗ Requires some React/Next.js knowledge for customization\n✗ Larger initial download (Next.js framework)\n✗ More complex than simple embed\n\n---\n\n## Option 2: agent-starter-embed (Embeddable Widget)\n\n### Overview\nEmbeddable widget for adding voice AI to existing websites without major changes.\n\n### Repository\n**GitHub:** https://github.com/livekit-examples/agent-starter-embed\n\n### Tech Stack\n- Next.js with TypeScript\n- Bundled JavaScript widget\n- Same core LiveKit SDKs as agent-starter-react\n\n### Key Features\n✓ Embeddable via `<script>` tag\n✓ Popup-style or inline widget\n✓ Minimal integration effort\n✓ Same features as agent-starter-react\n✓ Customizable appearance\n\n### Setup Process\n```bash\ngit clone https://github.com/livekit-examples/agent-starter-embed.git\ncd agent-starter-embed\npnpm install\npnpm build-embed-popup-script\npnpm dev\n```\n\n### Integration\n```html\n<!-- Add to any website -->\n<div id=\"livekit-agent\"></div>\n<script src=\"https://your-cdn.com/embed-popup.js\"></script>\n<script>\n  LiveKitAgent.init({\n    container: '#livekit-agent',\n    tokenUrl: 'https://your-backend.com/api/token',\n    theme: 'dark',\n    position: 'bottom-right'\n  });\n</script>\n```\n\n### Best For\n- Adding voice AI to existing websites\n- Minimal code changes required\n- Quick implementation\n- Embedded customer support agents\n\n### Pros\n✓ Easy integration (just add script tag)\n✓ No major site changes needed\n✓ Works with any website/CMS\n✓ Can be positioned anywhere (floating, inline)\n\n### Cons\n✗ Less customization than full React app\n✗ Still requires backend for token generation\n✗ Limited control over widget internals\n\n---\n\n## Option 3: Custom Build with LiveKit SDKs\n\n### Overview\nBuild from scratch using core LiveKit packages for maximum customization.\n\n### NPM Packages\n\n**Client SDK:**\n```bash\nnpm install livekit-client\n```\n- **Package:** `livekit-client` (v2.17.0+)\n- **Purpose:** WebRTC client for browser\n- **Docs:** https://docs.livekit.io/reference/client-sdk-js/\n\n**React Components:**\n```bash\nnpm install @livekit/components-react @livekit/components-styles\n```\n- **Package:** `@livekit/components-react`\n- **Purpose:** Pre-built React UI components\n- **Key Exports:** `useVoiceAssistant`, `BarVisualizer`, `VoiceAssistantControlBar`\n- **Docs:** https://docs.livekit.io/reference/components/react/\n\n**Server SDK (Backend):**\n```bash\nnpm install livekit-server-sdk\n```\n- **Package:** `livekit-server-sdk` (v2.15.0+)\n- **Purpose:** Token generation (server-side only)\n- **Docs:** https://docs.livekit.io/reference/server-sdk-js/\n\n### Minimal Example\n\n**Frontend (React):**\n```typescript\nimport { useVoiceAssistant, BarVisualizer } from '@livekit/components-react';\nimport '@livekit/components-styles';\n\nfunction VoiceAgent() {\n  const { state, audioTrack } = useVoiceAssistant();\n  // state: 'initializing' | 'listening' | 'thinking' | 'speaking'\n\n  return (\n    <div>\n      <p>Agent is {state}</p>\n      <BarVisualizer state={state} audioTrack={audioTrack} />\n      <button onClick={connect}>Connect</button>\n    </div>\n  );\n}\n```\n\n**Backend (Next.js API Route):**\n```typescript\nimport { AccessToken } from 'livekit-server-sdk';\n\nexport async function POST(req: Request) {\n  const { roomName, participantName } = await req.json();\n\n  const token = new AccessToken(\n    process.env.LIVEKIT_API_KEY,\n    process.env.LIVEKIT_API_SECRET,\n    { identity: participantName, ttl: '2h' }\n  );\n\n  token.addGrant({\n    room: roomName,\n    roomJoin: true,\n    canPublish: true,\n    canSubscribe: true,\n  });\n\n  return Response.json({ token: await token.toJwt() });\n}\n```\n\n### Best For\n- Integrating into existing React applications\n- Maximum customization control\n- Unique UI/UX requirements\n- Developers comfortable with WebRTC\n\n### Pros\n✓ Complete control over every aspect\n✓ Smaller bundle size (only what you need)\n✓ Deep integration with existing app\n✓ No template overhead\n\n### Cons\n✗ Requires understanding of LiveKit concepts\n✗ More time to build from scratch\n✗ Need to handle edge cases yourself\n✗ More maintenance burden\n\n---\n\n## Option 4: LiveKit Agents Playground (Quick Testing)\n\n### Overview\nZero-code web interface for instantly testing deployed agents.\n\n### Access\n**URL:** https://agents-playground.livekit.io/\n\n### Use Case\n- Quick testing of deployed agents\n- No frontend setup required\n- Demo to stakeholders\n- Debugging agent behavior\n\n### How to Use\n1. Visit https://agents-playground.livekit.io/\n2. Enter LiveKit credentials:\n   - LiveKit URL: `wss://your-project.livekit.cloud`\n   - API Key: Your `LIVEKIT_API_KEY`\n   - API Secret: Your `LIVEKIT_API_SECRET`\n3. Click \"Connect\"\n4. Speak to your agent\n\n### Best For\n- Testing before building frontend\n- Internal demos\n- Debugging agent issues\n- Validating deployment\n\n### Pros\n✓ Zero setup required\n✓ Instant testing\n✓ No code needed\n✓ Audio visualization included\n\n### Cons\n✗ Not for end users (exposes API secrets)\n✗ No customization\n✗ Not production-ready\n✗ Requires credentials each time\n\n---\n\n## Connection Flow Architecture\n\n### Standard Flow\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                      WEBSITE (FRONTEND)                     │\n│  ┌─────────────────┐         ┌─────────────────┐           │\n│  │   React/Next    │────────▶│  Token Server   │           │\n│  │   (Browser)     │  fetch  │  (Node.js API)  │           │\n│  └────────┬────────┘  token  └────────┬────────┘           │\n│           │                           │                     │\n│           │ WebRTC                    │ livekit-server-sdk  │\n│           │ (audio)                   │ (JWT generation)    │\n└───────────┼───────────────────────────┼─────────────────────┘\n            │                           │\n            ▼                           ▼\n┌─────────────────────────────────────────────────────────────┐\n│                    LIVEKIT CLOUD                            │\n│  ┌─────────────────┐         ┌─────────────────┐           │\n│  │  LiveKit Room   │◀────────│  Your Agent     │           │\n│  │  (WebRTC SFU)   │  audio  │  (Python)       │           │\n│  └─────────────────┘         └─────────────────┘           │\n│                                                             │\n│  Auto-dispatch agent when user joins room                  │\n└─────────────────────────────────────────────────────────────┘\n```\n\n### Connection Sequence\n\n1. **User clicks \"Connect\"** on website\n2. **Frontend requests token** from `/api/token` endpoint (500ms)\n3. **Backend generates JWT** using `livekit-server-sdk` (50ms)\n4. **Frontend connects to LiveKit room** with token (1000ms)\n5. **Agent automatically dispatched** to room (1000ms)\n6. **Agent connects** and publishes audio track (1500ms)\n7. **WebRTC media flow established** between user and agent\n\n**Total Time:** ~4 seconds (standard) → ~1.5 seconds (optimized)\n\n### Optimization Techniques\n\n**1. Pre-generate Tokens (Warm Token):**\n- Generate token on page load\n- Store for immediate use when \"Connect\" clicked\n- Saves ~500ms\n\n**2. Concurrent Dispatch:**\n- Connect user and dispatch agent in parallel\n- Saves ~1000ms\n\n**3. Pre-connect Buffer:**\n- Enable in `app-config.ts`\n- Reduces perceived latency\n\n---\n\n## Authentication Deep Dive\n\n### JWT Token Structure\n\n**Token Payload Example:**\n```json\n{\n  \"exp\": 1234567890,           // Expiration timestamp\n  \"iss\": \"APIxxxxxxxxxxxx\",    // API Key (issuer)\n  \"sub\": \"user-identity\",       // Participant identity\n  \"nbf\": 1234567890,           // Not before timestamp\n  \"video\": {\n    \"room\": \"room-name\",        // Room name\n    \"roomJoin\": true,           // Can join room\n    \"canPublish\": true,         // Can publish tracks\n    \"canSubscribe\": true,       // Can subscribe to tracks\n    \"canPublishData\": true      // Can send data messages\n  },\n  \"metadata\": \"\"                // Custom participant data\n}\n```\n\n### Token Generation Security\n\n**✓ CORRECT (Server-Side):**\n```typescript\n// Next.js API route (/api/token/route.ts)\nimport { AccessToken } from 'livekit-server-sdk';\n\nexport async function POST(req: Request) {\n  // Secret keys stay on server - NEVER exposed to browser\n  const token = new AccessToken(\n    process.env.LIVEKIT_API_KEY,\n    process.env.LIVEKIT_API_SECRET,\n    { identity: 'user' }\n  );\n\n  token.addGrant({ room: 'room', roomJoin: true });\n  return Response.json({ token: await token.toJwt() });\n}\n```\n\n**✗ WRONG (Client-Side):**\n```typescript\n// NEVER do this - exposes API secrets to browser!\nconst token = new AccessToken(\n  \"APIxxxxxxxxxxxx\",  // ⚠️ Exposed in browser\n  \"secret-key\",        // ⚠️ CRITICAL: Security breach!\n  { identity: 'user' }\n);\n```\n\n### Environment Variables\n\n**Server-Side Only (Never Exposed):**\n- `LIVEKIT_API_KEY` - Used for token signing\n- `LIVEKIT_API_SECRET` - Used for token signing\n\n**Public (Exposed to Browser):**\n- `NEXT_PUBLIC_LIVEKIT_URL` - WebRTC server URL\n\n**Configuration Example:**\n```env\n# .env.local (server-side)\nLIVEKIT_API_KEY=APIxxxxxxxxxxxx\nLIVEKIT_API_SECRET=your-secret-key-here\nLIVEKIT_URL=wss://your-project.livekit.cloud\n\n# Exposed to browser (NEXT_PUBLIC_ prefix)\nNEXT_PUBLIC_LIVEKIT_URL=wss://your-project.livekit.cloud\n```\n\n### Token Permissions\n\n**Recommended Grants (Audio-Only):**\n```typescript\ntoken.addGrant({\n  room: roomName,              // Specific room\n  roomJoin: true,              // Can join\n  canPublish: true,            // Can publish audio\n  canSubscribe: true,          // Can receive audio\n  canPublishData: true,        // Can send data messages\n  canPublishSources: [         // Audio-only: restrict to microphone only\n    'microphone'\n    // NOTE: 'camera' and 'screen_share' are NOT included\n    // This is an audio-only application\n  ],\n});\n```\n\n### Token Expiration\n\n- **Default TTL:** 2 hours\n- **Auto-Refresh:** LiveKit client automatically refreshes for connected users\n- **Disconnected Users:** Must request new token\n- **Production Recommendation:** 2h with auto-refresh\n\n---\n\n## Deployment Options\n\n### Frontend Hosting\n\n| Provider | Cost | Build Time | Auto Deploy | SSL | CDN |\n|----------|------|------------|-------------|-----|-----|\n| **Vercel** (Recommended) | Free tier | 2-5 min | ✓ Git | ✓ | ✓ |\n| Netlify | Free tier | 2-5 min | ✓ Git | ✓ | ✓ |\n| AWS Amplify | Free tier | 3-7 min | ✓ Git | ✓ | ✓ |\n| Cloudflare Pages | Free | 2-4 min | ✓ Git | ✓ | ✓ |\n\n**Recommendation:** Vercel for Next.js (seamless integration, best DX)\n\n### Agent Hosting\n\n**LiveKit Cloud (Recommended):**\n- **Cost:** $0.01 per agent session minute\n- **Deployment:** `lk agent create --secrets-file .env.local`\n- **Scaling:** Automatic (0 to N replicas)\n- **Regions:** Global (US, EU, APAC)\n\n**Alternative:** Self-hosted (requires own infrastructure)\n\n---\n\n## Cost Analysis\n\n### Estimated Monthly Costs\n\n**Scenario 1: Low Traffic (100 sessions/month, 5 min avg)**\n- Sessions: 100\n- Total minutes: 500\n- LiveKit Cloud: 500 × $0.01 = **$5/month**\n- Vercel: **Free tier**\n- **Total: ~$5/month**\n\n**Scenario 2: Medium Traffic (1,000 sessions/month, 10 min avg)**\n- Sessions: 1,000\n- Total minutes: 10,000\n- LiveKit Cloud: 10,000 × $0.01 = **$100/month**\n- Vercel: **Free tier** (or $20/month Pro)\n- **Total: ~$100-120/month**\n\n**Scenario 3: High Traffic (10,000 sessions/month, 8 min avg)**\n- Sessions: 10,000\n- Total minutes: 80,000\n- LiveKit Cloud: 80,000 × $0.01 = **$800/month**\n- Vercel: **$20/month Pro**\n- **Total: ~$820/month**\n\n**Additional Costs:**\n- OpenAI API (LLM): ~$0.03 per conversation\n- AssemblyAI (STT): ~$0.01 per minute\n- Cartesia (TTS): ~$0.05 per 1K characters\n\n---\n\n## Browser Compatibility\n\n### Supported Browsers\n\n| Browser | Desktop | Mobile | Notes |\n|---------|---------|--------|-------|\n| Chrome | ✓ v90+ | ✓ v90+ | Best support |\n| Firefox | ✓ v88+ | ✓ v88+ | Full support |\n| Safari | ✓ 14+ | ✓ 14+ | Requires user interaction for audio |\n| Edge | ✓ v90+ | ✓ v90+ | Chromium-based, same as Chrome |\n| Opera | ✓ v76+ | ✓ v64+ | Full support |\n\n### WebRTC Requirements\n\n**Required Browser Features:**\n- WebRTC support (RTCPeerConnection)\n- getUserMedia API (microphone access)\n- Web Audio API (audio processing)\n- WebSockets (signaling)\n\n**Not Supported:**\n- Internet Explorer (any version)\n- Legacy Edge (pre-Chromium)\n- Very old mobile browsers (<2020)\n\n---\n\n## Performance Benchmarks\n\n### Connection Time\n\n| Metric | Standard | Optimized |\n|--------|----------|-----------|\n| Token fetch | 500ms | 0ms (pre-generated) |\n| Room connect | 1000ms | 1000ms |\n| Agent dispatch | 1000ms | 500ms (concurrent) |\n| Media establish | 1500ms | 1000ms |\n| **Total** | **4000ms** | **1500ms** |\n\n### Audio Latency\n\n| Component | Latency |\n|-----------|---------|\n| User speech → STT | 500-800ms |\n| LLM processing | 1000-2000ms |\n| TTS generation | 300-500ms |\n| Audio playback | 100-200ms |\n| **Total (first response)** | **2-3.5 seconds** |\n| **Subsequent turns** | **1.5-2.5 seconds** (streaming) |\n\n### Page Load Performance\n\n**Lighthouse Scores (agent-starter-react):**\n- Performance: 90-95\n- Accessibility: 95-100\n- Best Practices: 90-95\n- SEO: 95-100\n\n**Bundle Sizes:**\n- Initial load: ~150-200 KB (gzipped)\n- Total JavaScript: ~400-500 KB\n- First Contentful Paint: <1.5s\n- Time to Interactive: <2.5s\n\n---\n\n## Mobile Considerations\n\n### iOS Safari Quirks\n\n**Audio Autoplay:**\n- Requires user interaction before audio playback\n- Solution: Play silent audio on first user click\n\n**Microphone Access:**\n- Must request permissions on user gesture\n- Browser prompts for microphone access\n\n**Web Audio Context:**\n- May be suspended on page load\n- Resume on user interaction\n\n### Android Chrome\n\n**Generally Better Support:**\n- Fewer audio restrictions\n- Better WebRTC implementation\n- More permissive autoplay policies\n\n**PWA Support:**\n- Can be installed as app\n- Better offline handling\n- Push notifications available\n\n### Responsive Design\n\n**agent-starter-react includes:**\n- Mobile-first responsive layout\n- Touch-optimized controls\n- Adaptive font sizes\n- Mobile-friendly visualizations\n\n---\n\n## Security Best Practices\n\n### Token Security\n\n✓ **DO:**\n- Generate tokens server-side only\n- Use environment variables for secrets\n- Set appropriate token expiration (2h)\n- Validate token claims on server\n- Use HTTPS in production\n\n✗ **DON'T:**\n- Expose API secrets to browser\n- Generate tokens client-side\n- Use long-lived tokens (>24h)\n- Store secrets in code or Git\n- Use HTTP (always HTTPS)\n\n### API Security\n\n**Rate Limiting:**\n```typescript\n// Add to token endpoint\nimport rateLimit from 'express-rate-limit';\n\nconst limiter = rateLimit({\n  windowMs: 15 * 60 * 1000, // 15 minutes\n  max: 100 // limit each IP to 100 requests per windowMs\n});\n\napp.use('/api/token', limiter);\n```\n\n**CORS Configuration:**\n```typescript\n// Only allow your domain\nconst allowedOrigins = ['https://yourdomain.com'];\n\nres.setHeader('Access-Control-Allow-Origin', allowedOrigins);\n```\n\n### Content Security Policy\n\n```typescript\n// Add CSP headers\nres.setHeader('Content-Security-Policy',\n  \"default-src 'self'; \" +\n  \"connect-src 'self' wss://your-project.livekit.cloud; \" +\n  \"media-src 'self';\"\n);\n```\n\n---\n\n## Troubleshooting Guide\n\n### Common Issues\n\n**\"Failed to connect to room\"**\n- **Cause:** Invalid token or LiveKit URL\n- **Fix:** Check environment variables, verify token generation\n\n**\"Microphone access denied\"**\n- **Cause:** User denied browser permission\n- **Fix:** Prompt user to grant permission in browser settings\n\n**\"No audio from agent\"**\n- **Cause:** Agent not joining room, TTS API issues\n- **Fix:** Check agent logs (`lk agent logs`), verify Cartesia API key\n\n**\"Token expired\"**\n- **Cause:** Token TTL exceeded, user inactive too long\n- **Fix:** Increase TTL or implement token refresh\n\n**\"WebRTC connection failed\"**\n- **Cause:** Firewall blocking WebRTC ports\n- **Fix:** Check firewall rules, ensure UDP ports open\n\n### Debug Tools\n\n**Browser DevTools:**\n- Console: Check for JavaScript errors\n- Network: Inspect WebSocket connections\n- Application: View local storage/cookies\n\n**LiveKit CLI:**\n```bash\n# Monitor agent logs\nlk agent logs --follow\n\n# Check agent status\nlk agent status\n\n# List active rooms\nlk room list\n\n# View room participants\nlk room participants <room-name>\n```\n\n**Vercel Logs:**\n- Dashboard → Deployments → Functions\n- Real-time function logs\n- Error tracking\n\n---\n\n## Next Steps\n\n### Immediate Actions\n\n1. **Review implementation plan:** See `2026-01-25-web-frontend-deployment.md`\n2. **Deploy agent:** Follow Phase 1 of plan\n3. **Set up frontend:** Follow Phases 2-3 of plan\n4. **Test connection:** Follow Phase 4 of plan\n5. **Customize:** Follow Phase 5 of plan\n6. **Deploy to production:** Follow Phase 6 of plan\n\n### Learning Resources\n\n**Documentation:**\n- LiveKit Docs: https://docs.livekit.io\n- agent-starter-react README: https://github.com/livekit-examples/agent-starter-react\n- Next.js Docs: https://nextjs.org/docs\n- React Hooks: https://react.dev/reference/react\n\n**Video Tutorials:**\n- LiveKit YouTube: https://www.youtube.com/@livekit\n- Next.js Learn: https://nextjs.org/learn\n\n**Community:**\n- LiveKit Discord: https://livekit.io/discord\n- GitHub Discussions: https://github.com/livekit/agents/discussions\n\n---\n\n## Appendix: Quick Reference\n\n### Essential Commands\n\n```bash\n# Agent deployment\nlk cloud auth\nlk agent create --secrets-file .env.local\nlk agent status\nlk agent logs --follow\n\n# Frontend setup\nlk app create --template agent-starter-react\npnpm install\npnpm dev\npnpm build\n\n# Production deployment (Vercel)\nvercel\nvercel --prod\n```\n\n### Environment Variables Checklist\n\n**Backend (Agent - `.env.local`):**\n```env\nOPENAI_API_KEY=sk-...\nASSEMBLYAI_API_KEY=...\nCARTESIA_API_KEY=...\n# Note: LIVEKIT_* vars auto-injected by LiveKit Cloud\n```\n\n**Frontend (Next.js - `.env.local`):**\n```env\nLIVEKIT_API_KEY=APIxxxxxxxxxxxx\nLIVEKIT_API_SECRET=your-secret-here\nLIVEKIT_URL=wss://your-project.livekit.cloud\nNEXT_PUBLIC_LIVEKIT_URL=wss://your-project.livekit.cloud\nAGENT_NAME=\n```\n\n### URL Reference\n\n- **Agent Playground:** https://agents-playground.livekit.io/\n- **LiveKit Cloud:** https://cloud.livekit.io\n- **Vercel Dashboard:** https://vercel.com/dashboard\n- **Your Production Frontend:** https://your-app.vercel.app\n\n---\n\n**Document Version:** 1.0\n**Last Updated:** 2026-01-25\n**Related Plan:** `2026-01-25-web-frontend-deployment.md`\n","structuredPatch":[{"oldStart":15,"oldLines":6,"newStart":15,"newLines":8,"lines":[" - Audio visualization and agent state tracking"," - Automatic agent dispatch when users connect"," ","+**IMPORTANT: This deployment is for an AUDIO-ONLY application. All video camera and screen sharing features must be disabled. Only microphone permissions should be requested from users.**","+"," **Timeline:** 6-8 hours for complete deployment (agent + frontend + customization)"," **Cost:** $0.01 per agent session minute (LiveKit Cloud) + Free (Vercel frontend hosting)"," "]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"31b4ba73-55c2-436d-8d08-935cb88231ff"}
{"parentUuid":"a2883b24-2f68-48d0-9447-0e3c4fc009ff","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","slug":"enumerated-shimmying-starlight","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01S32ELPnmKFx6KpWd7y9216","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Excellent! I've made comprehensive updates to both files. Let me create a summary of all the changes I made for the user.","signature":"EqICCkYICxgCKkDPzGkIjuMVhn6gDz62mBrESDL3QNFHafC+iBj/AKx0kPR6NvuTVtnM7/ONMTfNuFxkvBkgCcJN+wXBnrQl1SfPEgzViB9ZCWJDOYKiQ9gaDMpkj7RD/7lYUXmiwSIwqMNfCF5ePvr+leL/aRDEcsiLm1IPoc2HlXbx5Nj31e6Kt2CRHc8SeS4FF0wPKxUfKokBCgd6epoV8BGlW+nmvU71l+2DRkOQGqjNyBdXgNWNLVzatec2qLuvTc/NvO1Teus9Gfs7HJAyKjV3VQbUaDuVghKinXWmzvQy1pVv/Eg6w394aEnLgtihcr7yUDTH31CsQMomEtPQqCI9rz7hlQ//EYJdrfPjXhA9ZA7DR7v4FobnydJqTaYRPLIYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":2,"cache_creation_input_tokens":619,"cache_read_input_tokens":70201,"cache_creation":{"ephemeral_5m_input_tokens":619,"ephemeral_1h_input_tokens":0},"output_tokens":6,"service_tier":"standard"}},"requestId":"req_011CXTtCVe8unuFxNwN6SAPs","type":"assistant","uuid":"4016297e-db6f-43a0-9b56-ccbdc45720c6","timestamp":"2026-01-25T09:46:37.837Z"}
{"parentUuid":"4016297e-db6f-43a0-9b56-ccbdc45720c6","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","slug":"enumerated-shimmying-starlight","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01S32ELPnmKFx6KpWd7y9216","type":"message","role":"assistant","content":[{"type":"text","text":"I've updated both plan files to specify that this is an audio-only application and no video/screenshare permissions should be requested. Here's a summary of the changes:\n\n## Updated Files\n\n### 1. `2026-01-25-web-frontend-options-summary.md`\n\n**Changes:**\n- Added audio-only notice in Executive Summary emphasizing no video/screenshare\n- Updated agent-starter-react Key Features to specify \"Audio-only interface (video and screen sharing disabled)\"\n- Modified Token Permissions section to show audio-only configuration with only `'microphone'` in `canPublishSources`\n- Removed `'camera'` and `'screen_share'` from permission examples\n\n### 2. `2026-01-25-web-frontend-deployment.md`\n\n**Changes:**\n- Added audio-only notice in Overview section\n- Updated Phase 5.1 (App Configuration) to set:\n  - `supportsChatInput: false`\n  - `supportsVideoInput: false` (marked as REQUIRED)\n  - `supportsScreenShare: false` (marked as REQUIRED)\n- Renamed section 5.6 from \"Optional - Disable Features Not Needed\" to \"Configure Audio-Only Mode (REQUIRED)\"\n- Updated token grant configuration examples to include `canPublishSources: ['microphone']`\n- Added verification checklist items to confirm:\n  - Video/screenshare features are hidden\n  - Only microphone permission is requested\n  - No camera/screenshare UI elements visible\n- Updated production testing checklist to verify only microphone permissions requested\n\nAll changes emphasize that this is an **audio-only application** where users should only be asked for microphone access, never for camera or screen sharing permissions."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":2,"cache_creation_input_tokens":619,"cache_read_input_tokens":70201,"cache_creation":{"ephemeral_5m_input_tokens":619,"ephemeral_1h_input_tokens":0},"output_tokens":6,"service_tier":"standard"}},"requestId":"req_011CXTtCVe8unuFxNwN6SAPs","type":"assistant","uuid":"54a89659-ccaa-462a-b94d-c4c3cdb2efd8","timestamp":"2026-01-25T09:46:46.756Z"}
{"parentUuid":"54a89659-ccaa-462a-b94d-c4c3cdb2efd8","isSidechain":false,"userType":"external","cwd":"/Users/seanreed/PythonProjects/voice-ai/lk-agent-1","sessionId":"4f8d0b34-0277-4984-883d-917c4710b927","version":"2.1.19","gitBranch":"deploy-to-vercel-plan","slug":"enumerated-shimmying-starlight","type":"system","subtype":"turn_duration","durationMs":136255,"timestamp":"2026-01-25T09:46:46.809Z","uuid":"ae69a5d7-7ae6-4fde-a3d7-52c1ad0b62f8","isMeta":false}
