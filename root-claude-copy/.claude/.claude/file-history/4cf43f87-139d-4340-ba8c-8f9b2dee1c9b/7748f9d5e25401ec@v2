# McDonald's Drive-Thru Order Taker Agent - Implementation Plan

**Created**: 2026-01-21
**Status**: Planning Phase
**Goal**: Create a high-accuracy voice AI agent for taking McDonald's drive-thru orders

---

## Executive Summary

This plan outlines the implementation of a custom voice AI agent that acts as a McDonald's drive-thru order taker. The agent must accurately capture customer orders from the 212-item menu across 9 categories, maintain order state, and generate structured output files. The primary focus is on **maximizing accuracy** through multiple complementary strategies.

---

## 1. System Architecture

### 1.1 Core Components

```
Customer Voice Input
    ↓
[STT] → AssemblyAI Universal Streaming
    ↓
[Custom DriveThruLLM Wrapper]
    ├─ Menu Context Provider
    ├─ Order State Manager
    ├─ Validation Layer
    └─ Base LLM (OpenAI GPT-4.1 or similar)
    ↓
[TTS] → Inworld/Cartesia
    ↓
Agent Response
```

### 1.2 New Components to Build

1. **DriveThruLLM** (`src/drive_thru_llm.py`)
   - Custom LLM wrapper (similar to `KeywordInterceptLLM`)
   - Wraps a base LLM with order-taking capabilities
   - Manages conversation state and order tracking

2. **MenuProvider** (`src/menu_provider.py`)
   - Loads and manages menu data using existing Pydantic models
   - Provides relevant menu context to LLM
   - Implements fuzzy matching and search

3. **OrderStateManager** (`src/order_state_manager.py`)
   - Tracks items ordered during conversation
   - Appends to incremental log file after each turn
   - Generates final JSON output with timestamp

4. **MenuValidationTools** (`src/menu_validation.py`)
   - Validates LLM output against menu items
   - Fuzzy matching for spoken variations
   - Modifier validation

5. **DriveThruAgent** (`src/drive_thru_agent.py`)
   - Custom Agent subclass with drive-thru specific instructions
   - Configures the drive-thru persona

---

## 2. Accuracy-Boosting Strategies

### Priority 1: Core Strategies (Implement First)

#### Strategy 1: LLM Function Calling / Structured Output
**Approach**: Define tools/functions that the LLM can call to add items to the order.

**Implementation**:
- Create `add_item_to_order` function with parameters:
  - `category` (enum from menu categories)
  - `item_name` (string)
  - `modifiers` (list of strings)
  - `quantity` (int, default 1)
- LLM must use this function instead of free-form text
- Validates parameters against menu before accepting

**Pros**:
- Structured, parseable output
- Forces LLM to think in terms of menu structure
- Easy to validate

**Cons**:
- Requires LLM with good function calling support
- May feel less natural for complex orders

**Accuracy Impact**: HIGH (8/10) - Eliminates parsing errors

---

#### Strategy 2: Menu Context Injection
**Approach**: Dynamically inject relevant menu items into the LLM context based on customer utterance.

**Implementation**:
- When customer speaks, extract keywords (e.g., "burger", "breakfast", "coffee")
- Fetch relevant menu items from Menu model
- Include in system prompt: "Available items: [filtered list]"
- Reduces hallucination by showing exact menu item names

**Example**:
```
Customer: "I'd like a Big Mac"
→ Inject into context: "Beef & Pork items: Big Mac, McDouble, Quarter Pounder..."
```

**Pros**:
- Reduces hallucination
- Helps with exact item name matching
- Context-aware

**Cons**:
- Increases token usage
- May miss items if keyword matching fails

**Accuracy Impact**: HIGH (8/10) - Grounds LLM in actual menu

---

#### Strategy 3: Explicit Confirmation Loop
**Approach**: After each item is understood, explicitly confirm with customer.

**Implementation**:
- After LLM extracts an item, respond: "Got it, one Big Mac. Anything else?"
- Customer can correct if wrong
- Only write to order file after confirmation

**Example Flow**:
```
Customer: "Big Mac please"
Agent: "One Big Mac - is that correct?"
Customer: "Yes"
Agent: "Great! Anything else?"
[Write to order file]
```

**Pros**:
- Allows error correction
- Builds customer confidence
- Simple to implement

**Cons**:
- Slower ordering process
- May annoy customers with simple orders

**Accuracy Impact**: VERY HIGH (9/10) - Human-in-the-loop validation

---

#### Strategy 4: Fuzzy String Matching
**Approach**: Use fuzzy matching to handle pronunciation variations and STT errors.

**Implementation**:
- Use `rapidfuzz` or `fuzzywuzzy` library
- When LLM outputs an item name, fuzzy match against menu
- Accept if confidence > 85%
- Handle common variations:
  - "Big Mac" vs "big mac" vs "bigmac" vs "Big Mack"
  - "McNuggets" vs "chicken nuggets" vs "nuggets"

**Example**:
```python
from rapidfuzz import process, fuzz

def find_menu_item(utterance: str, menu_items: list[str]) -> tuple[str, float]:
    result = process.extractOne(utterance, menu_items, scorer=fuzz.ratio)
    return result[0], result[1]  # item, confidence_score
```

**Pros**:
- Handles STT errors
- Tolerates variations
- Fast and deterministic

**Cons**:
- Can match wrong items if names are similar
- Requires confidence threshold tuning

**Accuracy Impact**: MEDIUM-HIGH (7/10) - Catches STT errors

---

### Priority 2: Advanced Strategies (Implement Later for Optimization)

#### Strategy 5: Semantic Search with Embeddings
**Approach**: Use embeddings to find semantically similar menu items.

**Implementation**:
- Pre-compute embeddings for all menu items (OpenAI text-embedding-3-small)
- Store in vector DB or in-memory
- When customer speaks, embed their utterance
- Find nearest neighbors in embedding space
- Use as candidates for LLM to choose from

**Pros**:
- Handles synonyms ("cheeseburger" → "Quarter Pounder with Cheese")
- Semantic understanding
- Robust to paraphrasing

**Cons**:
- More complex implementation
- Requires embedding API calls
- May introduce latency

**Accuracy Impact**: HIGH (8/10) - Semantic understanding

---

#### Strategy 6: Two-Stage Parsing
**Approach**: Separate intent extraction from menu item selection.

**Implementation**:
1. **Stage 1**: Extract customer intent
   - "I want a burger with cheese"
   - Intent: {type: burger, modifiers: [cheese]}
2. **Stage 2**: Match intent to menu items
   - Search menu for burgers with cheese modifier
   - Return candidates: [Cheeseburger, Double Cheeseburger, Quarter Pounder with Cheese]
3. **Stage 3**: LLM selects best match or asks clarifying question

**Pros**:
- Cleaner separation of concerns
- Can optimize each stage separately
- Better debuggability

**Cons**:
- More complex
- Additional latency from multiple stages

**Accuracy Impact**: MEDIUM-HIGH (7/10) - Structured approach

---

#### Strategy 7: Chain-of-Thought Prompting
**Approach**: Ask LLM to explain its reasoning before outputting.

**Implementation**:
```
System: When a customer orders, think step-by-step:
1. What type of item are they requesting? (burger, drink, breakfast, etc.)
2. Which specific item from our menu matches best?
3. Did they mention any modifiers?
4. What quantity?
Then output the structured order.
```

**Pros**:
- Improves LLM reasoning
- More interpretable
- Can catch logic errors

**Cons**:
- Increases token usage
- May add latency
- Reasoning not always visible to customer

**Accuracy Impact**: MEDIUM (6/10) - Helps LLM think clearly

---

#### Strategy 8: Constrained Decoding
**Approach**: Use grammar-based constrained generation (if LLM supports it).

**Implementation**:
- Define grammar for valid responses
- LLM can only output strings that match the grammar
- Grammar includes exact menu item names

**Example Grammar**:
```
ORDER := <ITEM> | <ITEM> "and" <ORDER>
ITEM := <QUANTITY> <MENU_ITEM> <MODIFIERS>
MENU_ITEM := "Big Mac" | "Quarter Pounder" | ...
```

**Pros**:
- Guarantees valid output
- No hallucination possible
- Perfect accuracy for item names

**Cons**:
- Very few LLMs support this
- Complex to implement
- May be too rigid

**Accuracy Impact**: VERY HIGH (9/10) - If available

---

#### Strategy 9: Post-Processing Validation Layer
**Approach**: Validate every LLM output against menu before speaking to customer.

**Implementation**:
```python
class OrderValidator:
    def validate_order_item(self, item_name: str, modifiers: list[str]) -> ValidationResult:
        # Check item exists in menu
        # Check modifiers are valid for that item
        # Return corrected version or error
```

**Pros**:
- Last line of defense
- Can auto-correct minor errors
- Prevents invalid orders

**Cons**:
- Reactive, not proactive
- May reject valid variations

**Accuracy Impact**: MEDIUM-HIGH (7/10) - Safety net

---

#### Strategy 10: Context Window Optimization
**Approach**: Only include relevant portions of menu in context.

**Implementation**:
- Detect if customer is ordering breakfast, lunch, drinks, etc.
- Only inject that category's items into prompt
- Reduces noise and token count
- Improves focus

**Example**:
```
Customer: "I want breakfast"
→ Only include Breakfast category items in context
```

**Pros**:
- Reduces token usage
- Reduces hallucination
- Faster inference

**Cons**:
- May miss cross-category orders
- Requires intent detection

**Accuracy Impact**: MEDIUM (6/10) - Helps focus

---

### Recommended Strategy Combination

**Phase 1 (MVP)**:
1. Function Calling (Strategy 1) - Core structure
2. Menu Context Injection (Strategy 2) - Grounding
3. Fuzzy String Matching (Strategy 4) - STT error handling
4. Post-Processing Validation (Strategy 9) - Safety net

**Phase 2 (Optimization)**:
5. Explicit Confirmation Loop (Strategy 3) - User validation
6. Semantic Search (Strategy 5) - Better matching

**Phase 3 (Advanced)**:
7. Two-Stage Parsing (Strategy 6) - If needed
8. Chain-of-Thought (Strategy 7) - If needed

---

## 3. Order State Management

### 3.1 Order State Model

```python
@dataclass
class OrderItem:
    item_name: str
    category: str
    modifiers: list[str]
    quantity: int
    timestamp: datetime
    confirmed: bool = False

@dataclass
class OrderSession:
    session_id: str
    start_time: datetime
    items: list[OrderItem]
    status: Literal["in_progress", "completed", "cancelled"]
```

### 3.2 Incremental Logging

After each customer turn where an item is added:
- Append to `orders/{session_id}/incremental_log.jsonl`
- Each line is a JSON object with:
  - `timestamp`
  - `customer_utterance`
  - `item_parsed`
  - `agent_response`

### 3.3 Final Output

When customer says "done" or "that's all":
- Generate `orders/{session_id}/final_order.json`:

```json
{
  "session_id": "uuid-here",
  "timestamp": "2026-01-21T14:30:00Z",
  "items": [
    {
      "item_name": "Big Mac",
      "category": "Beef & Pork",
      "modifiers": [],
      "quantity": 1
    },
    {
      "item_name": "Medium Fries",
      "category": "Snacks & Sides",
      "modifiers": [],
      "quantity": 1
    }
  ],
  "total_items": 2,
  "order_summary": "1 Big Mac, 1 Medium Fries"
}
```

### 3.4 Menu Model Enhancements

To support order aggregation and better tracking, the `Item` class in `menus/mcdonalds/models.py` will be enhanced with the following features:

#### 3.4.1 New Fields

1. **quantity field** (`int`, default=1)
   - Tracks how many of this item are in the order
   - Default value is 1 for single items
   - Used for aggregating duplicate items

2. **item_id field** (`str`)
   - Unique identifier for each item instance
   - Auto-generated UUID to distinguish between item instances
   - Allows tracking individual items even with same name and modifiers

#### 3.4.2 Item Addition (`__add__` method)

Implements addition operator for combining items. Two items can be added if and only if:

**Conditions**:
- `item1.item_name == item2.item_name` (exact name match)
- `set(item1.modifiers) == set(item2.modifiers)` (same modifiers, order doesn't matter)

**Behavior**:
- If conditions are met: Create new item with `quantity = item1.quantity + item2.quantity`
- If conditions are not met: Raise `ValueError` with descriptive message

**Example Usage**:
```python
# Create two identical Big Macs
item1 = Item(
    category_name="Beef & Pork",
    item_name="Big Mac",
    available_as_base=True,
    quantity=1
)

item2 = Item(
    category_name="Beef & Pork",
    item_name="Big Mac",
    available_as_base=True,
    quantity=2
)

# Add them together
combined = item1 + item2  # quantity=3

# Items with different modifiers cannot be added
item3 = Item(
    category_name="Beef & Pork",
    item_name="Big Mac",
    available_as_base=True,
    quantity=1
)
item3.add_modifier("No Pickles")

# This will raise ValueError
combined = item1 + item3  # Error! Different modifiers
```

**Implementation Notes**:
- Modifier comparison uses set equality, so order doesn't matter
- The new combined item gets a new `item_id`
- Original items remain unchanged
- This enables order consolidation: "Two Big Macs" + "One Big Mac" = "Three Big Macs"

---

## 4. Agent Instructions & Persona

### 4.1 System Prompt

```
You are a friendly and efficient McDonald's drive-thru order taker. Your goal is to:

1. Greet the customer warmly
2. Listen carefully to their order
3. Use the add_item_to_order function to record each item
4. Confirm each item with the customer
5. When they're done, read back their complete order
6. Thank them and tell them the total

Guidelines:
- Be concise and natural in your responses
- If you're unsure about an item, ask for clarification
- Always confirm items before adding to the order
- Use the exact menu item names when confirming
- If a customer mentions an item not on the menu, politely inform them

Menu Structure:
- 9 categories: Breakfast, Beef & Pork, Chicken & Fish, Salads, Snacks & Sides, Desserts, Beverages, Coffee & Tea, Smoothies & Shakes
- 212 total items
- Some items have modifiers (e.g., "Quarter Pounder" with "Cheese")
```

### 4.2 Conversation Flow

```
Agent: "Welcome to McDonald's! What can I get for you today?"

Customer: "I'll have a Big Mac"

Agent: [Calls add_item_to_order(category="Beef & Pork", item_name="Big Mac", quantity=1)]
      "Got it, one Big Mac. Anything else?"

Customer: "And a medium fries"

Agent: [Calls add_item_to_order(category="Snacks & Sides", item_name="Medium Fries", quantity=1)]
      "One medium fries. Anything else?"

Customer: "No, that's all"

Agent: "Perfect! Your order is one Big Mac and one medium fries. Your total is [calculated].
       Please pull around to the first window."
       [Writes final order JSON]
```

---

## 5. Testing Strategy

### 5.1 Test Categories

1. **Single Item Orders**
   - Simple: "I want a Big Mac"
   - With quantity: "Two cheeseburgers"
   - With modifiers: "Quarter Pounder with cheese"

2. **Multi-Item Orders**
   - "Big Mac, large fries, and a Coke"
   - "Two Big Macs, one with no pickles"

3. **Complex Orders**
   - "I want a number 1 with a Coke" (if meal combos are supported)
   - Orders with substitutions
   - Orders with special requests

4. **Error Handling**
   - Invalid items: "I want a Whopper" (Burger King item)
   - Unclear requests: "I want a burger"
   - Corrections: "Actually, make that a McDouble"

5. **Accuracy Tests**
   - STT variations: "Big Mack" → "Big Mac"
   - Synonym handling: "chicken nuggets" → "Chicken McNuggets"
   - Modifier accuracy: Did modifiers get applied correctly?

### 5.2 Test Implementation

```python
@pytest.mark.asyncio
async def test_single_item_order_accuracy() -> None:
    """Test that a simple single-item order is captured accurately."""
    async with (
        _llm() as judge_llm,
        AgentSession(llm=drive_thru_llm) as session,
    ):
        await session.start(DriveThruAgent())

        # Customer orders a Big Mac
        result = await session.run(user_input="I'll have a Big Mac")

        # Verify the agent called the add_item_to_order function
        result.expect.next_event().is_function_call(
            function_name="add_item_to_order",
            arguments={
                "category": "Beef & Pork",
                "item_name": "Big Mac",
                "quantity": 1,
                "modifiers": []
            }
        )

        # Verify the agent confirmed the item
        await (
            result.expect.next_event()
            .is_message(role="assistant")
            .judge(
                judge_llm,
                intent="Confirms that one Big Mac was added to the order and asks if the customer wants anything else"
            )
        )

        # End the order
        result = await session.run(user_input="That's all")

        # Verify final order JSON was created correctly
        assert order_manager.get_final_order() == {
            "items": [
                {"item_name": "Big Mac", "category": "Beef & Pork", "modifiers": [], "quantity": 1}
            ]
        }
```

### 5.3 Accuracy Metrics

Track the following metrics:
- **Item Name Accuracy**: % of items correctly identified
- **Modifier Accuracy**: % of modifiers correctly applied
- **Quantity Accuracy**: % of quantities correctly captured
- **Order Completeness**: % of orders with all items captured
- **False Positives**: Items added that weren't ordered
- **False Negatives**: Items ordered but not added

Target: 95%+ accuracy on all metrics

---

## 6. Implementation Phases

### Phase 1: Core Infrastructure (2-3 days)
- [ ] Enhance `Item` class with `quantity` field
- [ ] Enhance `Item` class with `item_id` field
- [ ] Implement `__add__` method for `Item` class (item addition/aggregation)
- [ ] Write unit tests for `Item` enhancements (addition, field validation)
- [ ] Create `MenuProvider` class
- [ ] Create `OrderStateManager` class
- [ ] Create basic `DriveThruLLM` wrapper
- [ ] Implement function calling for `add_item_to_order`
- [ ] Set up order file output (incremental + final)
- [ ] Write basic unit tests for each component

### Phase 2: Accuracy Strategies - MVP (3-4 days)
- [ ] Implement Strategy 1: Function Calling
- [ ] Implement Strategy 2: Menu Context Injection
- [ ] Implement Strategy 4: Fuzzy String Matching
- [ ] Implement Strategy 9: Post-Processing Validation
- [ ] Write tests for each strategy
- [ ] Measure baseline accuracy

### Phase 3: Agent Integration (2 days)
- [ ] Create `DriveThruAgent` with proper instructions
- [ ] Integrate with `VoiceAgentApp`
- [ ] Add configuration options to `config.py`
- [ ] Test end-to-end in console mode
- [ ] Fix bugs and edge cases

### Phase 4: Testing & Refinement (2-3 days)
- [ ] Write comprehensive test suite (20+ tests)
- [ ] Test with real voice input (console mode)
- [ ] Measure accuracy metrics
- [ ] Identify failure modes
- [ ] Iterate on prompts and validation logic

### Phase 5: Advanced Strategies (Optional, 2-3 days)
- [ ] Implement Strategy 3: Explicit Confirmation Loop
- [ ] Implement Strategy 5: Semantic Search with Embeddings
- [ ] A/B test different strategy combinations
- [ ] Optimize for latency and cost

---

## 7. File Structure

```
src/
├── drive_thru_agent.py          # DriveThruAgent class
├── drive_thru_llm.py            # DriveThruLLM wrapper
├── menu_provider.py             # Menu loading and search
├── order_state_manager.py       # Order tracking and output
├── menu_validation.py           # Validation utilities
└── tools/
    └── order_tools.py           # LLM function definitions

tests/
├── test_drive_thru_agent.py     # End-to-end agent tests
├── test_menu_provider.py        # Menu search tests
├── test_order_state.py          # Order state management tests
└── test_accuracy.py             # Accuracy benchmarks

orders/
├── {session_id}/
│   ├── incremental_log.jsonl    # Per-turn logging
│   └── final_order.json         # Final order output

plan/
└── mcdonalds-drive-thru-agent-plan.md  # This document
```

---

## 8. Configuration

Add to `src/config.py`:

```python
class DriveThruConfig(BaseModel):
    """Configuration for drive-thru agent."""

    menu_file_path: str = Field(
        default="menus/mcdonalds/transformed-data/menu-structure-2026-01-21.json",
        description="Path to menu JSON file"
    )

    orders_output_dir: str = Field(
        default="orders",
        description="Directory to save order files"
    )

    fuzzy_match_threshold: int = Field(
        default=85,
        description="Minimum fuzzy match score (0-100)"
    )

    enable_confirmation_loop: bool = Field(
        default=True,
        description="Require confirmation before adding items"
    )

    enable_semantic_search: bool = Field(
        default=False,
        description="Use embeddings for semantic item search"
    )

    max_context_items: int = Field(
        default=50,
        description="Maximum number of menu items to inject into context"
    )
```

---

## 9. Risks & Mitigations

### Risk 1: STT Errors
**Impact**: Customer says "Big Mac" but STT hears "Big Mack" or "big man"
**Mitigation**:
- Fuzzy string matching (Strategy 4)
- Semantic search (Strategy 5)
- Confirmation loop (Strategy 3)

### Risk 2: LLM Hallucination
**Impact**: LLM adds items not on the menu
**Mitigation**:
- Function calling with strict validation
- Menu context injection (Strategy 2)
- Post-processing validation (Strategy 9)

### Risk 3: Modifier Errors
**Impact**: Customer wants "no pickles" but modifier not captured
**Mitigation**:
- Structured modifier field in function calling
- Validation against available modifiers per item
- Explicit confirmation

### Risk 4: Latency
**Impact**: Slow response times frustrate customers
**Mitigation**:
- Use faster LLM (GPT-4.1-nano or similar)
- Optimize context injection (Strategy 10)
- Precompute embeddings if using Strategy 5
- Enable preemptive generation

### Risk 5: Multi-Item Order Complexity
**Impact**: Customer orders 5 items in one utterance, agent misses some
**Mitigation**:
- Ask customer to order one item at a time
- Use two-stage parsing (Strategy 6) if needed
- Read back full order at end for correction

---

## 10. Success Criteria

The implementation will be considered successful when:

1. **Accuracy**: ≥95% item name accuracy on test suite
2. **Modifier Accuracy**: ≥90% modifier accuracy
3. **Completeness**: ≥95% of orders captured completely
4. **Latency**: <2 seconds per turn (STT → TTS)
5. **Robustness**: Handles invalid items gracefully (100% of test cases)
6. **Output**: Correctly generates incremental logs and final JSON for 100% of orders
7. **User Experience**: Judge-based tests confirm natural, friendly interaction

---

## 11. Future Enhancements

After initial implementation, consider:

1. **Meal Combos**: Support "Number 1" style ordering
2. **Upselling**: "Would you like to make that a meal?"
3. **Menu Recommendations**: Based on time of day, weather, etc.
4. **Price Calculation**: Calculate total cost
5. **Multi-Language Support**: Spanish, etc.
6. **Voice Biometrics**: Remember repeat customers
7. **Order History**: "Same as last time"
8. **Integration**: Connect to POS system for real orders

---

## 12. Key Design Decisions

### Why Function Calling?
Function calling provides structured output that's easy to validate and parse. It forces the LLM to think in terms of discrete actions rather than free-form text, reducing ambiguity.

### Why Multiple Strategies?
No single strategy achieves 100% accuracy. Layering multiple complementary strategies (function calling + fuzzy matching + validation) creates a robust system.

### Why Confirmation Loop?
Voice AI has inherent uncertainty (STT errors, LLM mistakes). Confirming each item catches errors before they compound.

### Why Incremental Logging?
Provides an audit trail and debugging information. If final order is wrong, we can trace back through the conversation.

### Why Focus on Accuracy Over Speed?
Wrong orders are worse than slow orders. Once accuracy is proven, we can optimize for latency.

---

## 13. Experimentation Framework

To determine which strategies work best, implement an experimentation framework:

```python
class AccuracyExperiment:
    """Framework for testing accuracy strategies."""

    def __init__(self, test_cases: list[OrderTestCase]):
        self.test_cases = test_cases

    async def run_experiment(self, strategy_config: dict) -> ExperimentResults:
        """Run all test cases with a given strategy configuration."""
        results = []
        for test_case in self.test_cases:
            result = await self.run_single_test(test_case, strategy_config)
            results.append(result)
        return ExperimentResults(results)

    def compare_strategies(self, strategy_a: dict, strategy_b: dict) -> Comparison:
        """A/B test two strategy configurations."""
        results_a = await self.run_experiment(strategy_a)
        results_b = await self.run_experiment(strategy_b)
        return Comparison(results_a, results_b)
```

Use this to answer questions like:
- Does semantic search improve accuracy over fuzzy matching?
- What's the optimal fuzzy match threshold?
- Does chain-of-thought reduce hallucination?
- What's the latency vs accuracy tradeoff?

---

## 14. Monitoring & Observability

In production, track:
- **Per-turn metrics**: Item extraction accuracy, latency
- **Per-order metrics**: Order completeness, correction rate
- **LLM metrics**: Token usage, cost per order
- **Error rates**: Invalid items, failed validations
- **User satisfaction**: Explicit feedback, order completion rate

Use LiveKit's built-in metrics framework + custom application metrics.

---

## Conclusion

This plan provides a comprehensive roadmap for building a high-accuracy McDonald's drive-thru order taker. The key insight is that **accuracy requires multiple layered strategies**, not a single silver bullet. By combining function calling, menu context injection, fuzzy matching, and validation, we can achieve 95%+ accuracy while maintaining a natural conversational experience.

The phased approach allows for iterative development: start with core infrastructure, implement MVP accuracy strategies, test thoroughly, then optimize with advanced strategies as needed.

**Next Steps**:
1. Review and approve this plan
2. Begin Phase 1 implementation
3. Set up testing infrastructure
4. Iterate based on real-world results
